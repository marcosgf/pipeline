<doc id="737" url="https://pt.wikipedia.org/wiki?curid=737" title="Pedro I de Portugal">
Pedro I de Portugal

Pedro I (Coimbra, – Estremoz, ), apelidado de "o Justo" e "o Cruel", foi o Rei de Portugal e Algarve de 1357 até sua morte. Era o único filho homem do rei Afonso IV e sua esposa Beatriz de Castela.
O Infante D. Pedro nasceu na cidade de Coimbra, a 8 de Abril de 1320, filho do então infante D. Afonso e sua esposa D. Beatriz de Castela. Pedro foi o quarto filho de um total de sete, três mulheres e quatro varões: D. Maria, D. Afonso, D. Dinis, ele próprio, D. Isabel, D. João, e D. Leonor. Destes, mais de metade cedo morre (D. Afonso nado-morto à nascença; D. Dinis, D. Isabel, e D. João na sua infância). Por este motivo, D. Pedro, não sendo primogénito, torna-se herdeiro do pai e vem a suceder-lhe no trono. Pedro I sucedeu a seu pai em 1357.
Dos seus primeiros anos de vida, pouco se sabe. Conhecem-se, todavia, através de fontes escritas, a sua ama, D. Leonor; o aio e mordomo-mor Lopo Fernandes Pacheco; o guarda, Domingos Anes; o reposteiro-mor, Gonçalo Lobato; e os reposteiros, Afonso Domingues e Afonso Esteves. É também sabido que, por volta dos seus quinze anos, em 1335, já tinha casa. Os cronistas fazem menção a um defeito de gaguez e ainda, no foro psíquico, "paixões exaltadas e violentas, cóleras explosivas, perversões várias"; é igualmente caracterizado como um amante da festa e da música, cantando e dançando por Lisboa ao som de "longas" com os populares.
D. Pedro é conhecido pela sua relação com Inês de Castro, a aia galega da sua mulher Constança Manuel, que influenciou fortemente a política interna de Portugal no reinado de D. Afonso IV. Inês acabou assassinada por ordens do rei em 7 de Janeiro de 1355, mas isto não trouxe Pedro de volta à influência paterna. Contrariamente, durante alguns meses, Pedro revoltou-se contra o pai; apoiado pela nobreza de Entre Douro e Minho e pelos irmãos de Inês. A paz veio por vontade declarada do povo e perdoaram-se mútuas ofensas. Aclamado rei em 1357, Pedro anunciou em Cantanhede, em junho de 1360, o casamento com Inês, realizado em segredo antes da sua morte, sendo sua intenção a ver lembrada como Rainha de Portugal. A promessa de perdão aos responsáveis pela morte de Inês foi esquecida
Este facto baseia-se apenas na palavra do rei, uma vez que não existem registos de tal união. Dois assassinos de Inês foram capturados e executados (Pêro Coelho e Álvaro Gonçalves) com uma brutalidade tal (a um foi arrancado o coração pelo peito, e a outro pelas costas), que lhe valeram os epítetos supramencionados.
Conta também a tradição que Pedro teria feito desenterrar o corpo da amada, coroando-o como Rainha de Portugal, e obrigando os nobres a procederem à cerimónia do beija-mão real ao cadáver, sob pena de morte. Em seguida ordenou a execução de dois túmulos (verdadeiras obras-primas da escultura gótica em Portugal), os quais foram colocados no transepto da igreja do Mosteiro de Alcobaça para que, no dia do Juízo Final, os eternos amantes, então ressuscitados, de imediato se vejam...
Como rei, Pedro revelou-se bom administrador, corajoso na defesa do país contra a influência papal (foi ele que promulgou o famoso Beneplácito Régio, que impedia a livre circulação de documentos eclesiásticos no país sem a sua autorização expressa), e foi justo na defesa das camadas menos favorecidas da população. Aplicava a justiça com brutalidade, de forma «democrática», punindo exemplarmente sem olhar a quem. Para não atrasar a aplicação das sentenças, puniu com pena de morte a prática da advocacia, isto levou a protestos nas cortes de 1361. Pouco fez para refrear o poder da nobreza, mas esta temia o rei. Gostava muito de estar próximo do povo nos festejos, daí ser adorado. Na política externa, Pedro ajudou seu sobrinho, o rei de Castela na guerra contra o meio-irmão.
A sua relação com o clero foi algo conflituosa, em relação à nobreza foi magnânimo. Deu o título de conde de Barcelos a João Afonso Telo com direito hereditário e deu terras aos filhos de Inês. A Ordem de Avis entregou-a a seu filho, João, futuro rei.
A forma como exerceu a justiça, parece-nos hoje cruel, mas era costume naqueles tempos difíceis. Diz-se que mandou servir um banquete enquanto assistia à execução de Pêro Coelho e Álvaro Gonçalves, típico dum neurótico. Gostava mais de ser algoz de que juiz, como atestam algumas sentenças que proferiu.
D. Pedro reinou durante dez anos, sendo tão popular ao ponto de dizer a população "que taes dez annos nunca houve em Portugal como estes que reinara el Rei Dom Pedro". O seu reinado foi o único no século XIV sem guerra e marcado com prosperidade financeira, daí ficar na memória como um bom reinado. Para Fernão Lopes foi o avô da dinastia de Avis.
Jaz no Mosteiro de Santa Maria de Alcobaça.
O estilo oficial de D. Pedro I enquanto rei era: "Pela Graça de Deus, Pedro I, Rei de Portugal e do Algarve"
Em 1329, Branca de Castela, a única filha de Pedro, infante de Castela e de Maria, infanta de Aragão foi prometida em casamento com D. Pedro, mas dada a sua debilidade e sua incapacidade o casamento não se chegou a realizar.
Seu primeiro casamento foi com Constança Manuel, filha de D. João Manuel de Castela, de quem teve a:
De seu segundo casamento com Inês de Castro (1320 - assassinada em 1355) nasceram:
De Teresa Lourenço: 
Embora havendo três filhos do seu segundo casamento e tendo vivido uma relação intensa com Inês de Castro, com quem também houve descendência, acerca do temperamento deste soberano, o cronista Fernão Lopes dedicou um capítulo que intitulou ""Como El-Rei mandou capar um seu escudeiro porque dormia com uma mulher casada", permitindo entrever que o gesto teria sido motivado por ciúmes do monarca por seu escudeiro, de nome Afonso Madeira. Madeira é descrito como um grande cavalgador, caçador, lutador e ágil acrobata, e regista: "Pelas suas qualidades, El-Rei amava-o muito e fazia-lhe generosas mercês." O escudeiro, entretanto, apaixonou-se por Catarina Tosse, esposa do Corregedor, descrita como "briosa, louçã e muito elegante, de graciosas prendas e boa sociedade". Para se aproximar dela, Madeira fez-se amigo do Corregedor, seduzindo-a e consumando a traição. O soberano, entretanto, tudo descobriu e não perdoou Madeira, castigando-o brutalmente. O cronista insiste no afeto do soberano, referindo enigmaticamente: "Como quer que o Rei muito amasse o escudeiro, mais do que se deve aqui dizer (...)", mas regista que D. Pedro mandou "cortar-lhe aqueles membros que os homens em maior apreço têm". O escudeiro recebeu assistência e sobreviveu, mas "engrossou nas pernas e no corpo e viveu alguns anos com o rosto engelhado e sem barba"". 
! colspan="3" style="background: #FBEC5D;" | Pedro I de PortugalCasa de Borgonha8 de abril de 1320 – 18 de janeiro de 1367

</doc>
<doc id="740" url="https://pt.wikipedia.org/wiki?curid=740" title="Disco rígido">
Disco rígido

Disco rígido ou disco duro, popularmente chamado também de "HD" (derivação de "HDD" do inglês "hard disk drive") ou "winchester" (termo em desuso), "memória de massa" ou ainda de "memória secundária" é a parte do computador onde são armazenados os dados.
O disco rígido é uma memória não-volátil, ou seja, as informações não são perdidas quando o computador é desligado, sendo considerado o principal meio de armazenamento de dados em massa. Por ser uma memória não-volátil, é um sistema necessário para se ter um meio de executar novamente programas e carregar arquivos contendo os dados inseridos anteriormente quando ligamos o computador. Nos sistemas operativos mais recentes, ele é também utilizado para expandir a memória RAM, através da gestão de memória virtual. Existem vários tipos de interfaces para discos rígidos diferentes: "IDE"/"ATA", "Serial ATA", "SCSI", "Fibre channel", "SAS".
O primeiro disco rígido foi construído pela IBM em 1956, e foi lançado em 16 de Setembro de 1957. Era formado por 50 discos magnéticos contendo 50 000 setores, sendo que cada um suportava 100 caracteres alfanuméricos, totalizando uma capacidade de 5 "megabytes", incrível para a época. Este primeiro disco rígido foi chamado de "305 RAMAC (Random Access Method of Accounting and Control)" e tinha dimensões de 152,4 centímetros de comprimento, 172,72 centimetros de largura e 73,66 centímetros de altura.
Em 1973 a "IBM" lançou o modelo 3340 "Winchester", com dois pratos de 30 "megabytes" e tempo de acesso de 30 milissegundos. Assim criou-se o termo 30/30 "Winchester" (uma referência à espingarda "Winchester" 30/30), termo muito usado antigamente para designar HDs de qualquer espécie. Ainda no início da década de 1980, os discos rígidos eram muito caros e modelos de 10 "megabytes" custavam quase 2 mil dólares americanos, enquanto em 2009 compramos modelos de 1.5 "terabyte" por pouco mais de 100 dólares. Ainda no começo dos anos 80, a mesma IBM fez uso de uma versão "pack" de discos de 80 "megabytes", usado nos sistemas "IBM Virtual Machine". Os discos rigidos foram criados originalmente para serem usados em computadores em geral.
Mas no século XXI as aplicações para esse tipo de disco foram expandidas e agora são usados em câmeras filmadoras, ou camcorders nos Estados Unidos; tocadores de música como iPod, MP3 player; PDAs; videogames, e até em celulares. Para exemplos em videogames temos o Xbox360 e o Playstation 3, lançados em 2005 e 2006 respectivamente, com esse diferencial, embora a Microsoft já tivesse lançado seu primeiro Xbox (em 2001) com disco rígido convencional embutido. Já para celular os primeiros a terem essa tecnologia foram os da Nokia e da Samsung. E também devemos lembrar que atualmente o disco rigido não é só interno, existem também os externos, que possibilitam o transporte de grandes quantidades de dados entre computadores sem a necessidade de rede.
Os discos magnéticos de um disco rígido são recobertos por uma camada magnética extremamente fina. Na verdade, quanto mais fina for a camada de gravação, maior será sua sensibilidade, e consequentemente maior será a densidade de gravação permitida por ela. Poderemos, então, armazenar mais dados num disco do mesmo tamanho, criando HDs de maior capacidade. Os primeiros discos rígidos, assim como os discos usados no início da década de 80, utilizavam a mesma tecnologia de mídia magnética utilizada em disquetes, chamada "coated media", que além de permitir uma baixa densidade de gravação, não é muito durável. Os discos atuais já utilizam mídia laminada ("plated media"), uma mídia mais densa, de qualidade muito superior, que permite a enorme capacidade de armazenamento dos discos modernos.
A cabeça de leitura e gravação de um disco rígido funciona como um eletroímã semelhante aos que estudamos nas aulas de ciências e física do colegial, sendo composta de uma bobina de fios que envolve um núcleo de ferro. A diferença é que, num disco rígido, este eletroímã é extremamente pequeno e preciso, a ponto de ser capaz de gravar trilhas (pistas em Portugal) medindo menos de um centésimo de milímetro de largura. Quando estão sendo gravados dados no disco, a cabeça utiliza seu campo magnético para organizar as moléculas de óxido de ferro da superfície de gravação, fazendo com que os pólos positivos das moléculas fiquem alinhados com o pólo negativo da cabeça e, conseqüentemente, com que os pólos negativos das moléculas fiquem alinhados com o pólo positivo da cabeça. Usamos, neste caso, a velha lei "os opostos se atraem". Como a cabeça de leitura e gravação do "HD" é um eletroímã, sua polaridade pode ser alternada constantemente. Com o disco girando continuamente, variando a polaridade da cabeça de gravação, variamos também a direção dos pólos positivos e negativos das moléculas da superfície magnética. De acordo com a direção dos pólos, temos um bit 1 ou 0 (sistema binário).
Para gravar as sequências de bits 1 e 0 que formam os dados, a polaridade da cabeça magnética é mudada alguns milhões de vezes por segundo, sempre seguindo ciclos bem determinados. Cada bit é formado no disco por uma sequência de várias moléculas. Quanto maior for a densidade do disco, menos moléculas serão usadas para armazenar cada bit, e teremos um sinal magnético mais fraco. Precisamos, então, de uma cabeça magnética mais precisa. Quando é preciso ler os dados gravados, a cabeça de leitura capta o campo magnético gerado pelas moléculas alinhadas. A variação entre os sinais magnéticos positivos e negativos gera uma pequena corrente elétrica que caminha através dos fios da bobina. Quando o sinal chega à placa lógica do HD, ele é interpretado como uma sequência de bits 1 e 0. Desse jeito, o processo de armazenamento de dados em discos magnéticos parece ser simples, e realmente era nos primeiros discos rígidos (como o 305 "RAMAC" da "IBM"), que eram construídos de maneira praticamente artesanal. Apesar de nos discos modernos terem sido incorporados vários aperfeiçoamentos, o processo básico continua sendo o mesmo. 
A formatação de um disco magnético é realizada para que o sistema operacional seja capaz de gravar e ler dados no disco, criando assim estruturas que permitam gravar os dados de maneira organizada e recuperá-los mais tarde.
Existem dois tipos de formatação, chamados de formatação física e formatação lógica. A formatação física é feita na fábrica ao final do processo de fabricação, que consiste em dividir o disco virgem em trilhas, setores, cilindros e isolar os "bad blocks" (danos no HD). Estas marcações funcionam como as faixas de uma estrada, permitindo à cabeça de leitura saber em que parte do disco está, e onde ela deve gravar dados. A formatação física é feita apenas uma vez, e não pode ser desfeita ou refeita através de software. Porém, para que este disco possa ser reconhecido e utilizado pelo sistema operacional, é necessária uma nova formatação, chamada de formatação lógica. Ao contrário da formatação física, a formatação lógica não altera a estrutura física do disco rígido, e pode ser desfeita e refeita quantas vezes for preciso, através do comando Format do DOS, por exemplo. O processo de formatação é quase automático; basta executar o programa formatador que é fornecido junto com o sistema operacional.
Os sistemas de arquivos mais conhecidos são os utilizados pelo "Microsoft Windows": "NTFS", "FAT32" e "FAT 16". O FAT32 é uma versão evoluída do FAT16 introduzida a partir do MS-DOS 4.0. A partir do Windows NT foi introduzido o NTFS, que trouxe novos recursos.
Quando o computador é ligado, o POST ("Power-on Self Test"), um pequeno programa gravado em um "chip" de memória ROM na placa-mãe, que tem a função de “dar a partida”, tentará inicializar o sistema operacional. Independentemente de qual sistema de arquivos se esteja usando, o primeiro setor do disco rígido será reservado para armazenar informações sobre a localização do sistema operacional, que permitem ao "BIOS" "achá-lo" e iniciar seu carregamento.
No setor de boot é registrado onde o sistema operacional está instalado, com qual sistema de arquivos o disco foi formatado e quais arquivos devem ser lidos para inicializar o computador. Um setor é a menor divisão física do disco, e possui na grande maioria das vezes 512 Bytes (nos CD-ROMs e derivados é de 2048 Bytes). Um "cluster", também chamado de agrupamento, é a menor parte reconhecida pelo sistema operacional, e pode ser formado por vários setores. Um arquivo com um número de "bytes" maior que o tamanho do "cluster", ao ser gravado no disco, é distribuído em vários clusters. Porém, um "cluster" não pode pertencer a mais de um arquivo. Um único setor de 512 Bytes pode parecer pouco, mas é suficiente para armazenar o registro de "boot" devido ao seu pequeno tamanho. O setor de "boot" também é conhecido como "trilha MBR", "trilha 0' etc. Como dito, no disco rígido existe um setor chamado Trilha 0, e nele está gravado o (MBR) ("Master Boot Record"), que significa "Registro de Inicialização Mestre", um estilo de formatação, onde são encontradas informações sobre como está dividido o disco (no sentido lógico)e sobre a ID de cada tabela de partição do disco, que dará o "boot". O MBR é lido pelo BIOS, que interpreta a informação e em seguida ocorre o chamado "bootstrap", "levantar-se pelo cadarço", lê as informações de como funciona o sistema de arquivos e efetua o carregamento do sistema operacional. O MBR e a ID da tabela de partição ocupam apenas um setor de uma trilha, o restante dos setores desta trilha não são ocupados, permanecendo vazios, servindo como área de proteção do MBR. É nesta mesma área que alguns vírus (Vírus de Boot) se alojam.
Com a constante demanda por espaço, mais as melhorias da tecnologia de fabricação, tem havido uma mudança para setores de tamanho maior, tipicamente para 4096 Bytes. Tal mudança é para que seja melhor utilizado o espaço do disco para mais informações úteis. Cada setor precisa(para que os dados sejam confiáveis) de um conjunto de bits adicionais para verificação contra erros(para que a própria controladora consiga detectar erros de leitura física), com o aumento de capacidade dos discos, diminui-se o número de átomos para representar um determinado bit, que o torna mais frágil, aumentando o risco de perca de dados. Para não haver problemas por causa dessa fragilidade, aumenta-se o número de bits para a verificação da integridade da informação no setor, o que acaba diminuindo o espaço utilizável para os dados do usuário. Com o aumento para 4096 Bytes, cai, consideravelmente, o número de bits usado para verificação de integridade em todo o disco, pois haverá menos setores no disco, e como o mesmo número de bits, por setor, consegue ser utilizado para uma verificação de uma porção maior de dados, decai o 'desperdício' por causa da verificação da integridade.
Disquetes, "Zip-disks" e CD-ROMs não possuem MBR; no entanto, possuem tabela de partição, no caso do CD-ROMs e seu descendentes (DVD-ROM, HDDVD-ROM, BD-ROM...) possuem tabela própria, podendo ser CDFS ("Compact Disc File System", norma ISO 9660) ou UDF ("Universal Disc Format", uma implementação do padrão ISO/IEC 13346) ou, para maior compatibilidade, os dois; já os cartões de memória "Flash" e "Pen-Drives" possuem tabela de partição e podem ter até mesmo MBR, dependendo de como formatados. O MBR situa-se no primeiro setor da primeira trilha do primeiro prato do HD (setor um, trilha zero, face zero, prato zero). O MBR é constituído pelo "bootstrap" e pela tabela de partição. O "bootstrap" é o responsável por analisar a tabela de partição em busca da partição ativa. Em seguida, ele carrega na memória o Setor de "Boot" da partição. Esta é a função do "bootstrap".
A tabela de partição contém informações sobre as partições existentes no disco. São informações como o tamanho da partição, em qual trilha/setor/cilindro ela começa e termina, qual o sistema de arquivos da partição, se é a partição ativa; ao todo, são dez campos. Quatro campos para cada partição possível (por isso, só se pode ter 4 partições primárias, e é por isso também que foi-se criada a partição estendida...), e dez campos para identificar cada partição existente. Quando acaba o POST, a instrução INT 19 do BIOS lê o MBR e o carrega na memória, e é executado o "bootstrap". O "bootstrap" vasculha a tabela de partição em busca da partição ativa, e em seguida carrega na memória o Setor de "Boot" dela. A função do Setor de "Boot" é a de carregar na memória os arquivos de inicialização do sistema operacional. O Setor de "Boot" fica situado no primeiro setor da partição ativa.
A capacidade de um disco rígido atualmente disponível no mercado para uso doméstico/comercial varia de 10 a 3000 GB, assim como aqueles disponíveis para empresas, de mais de 3 "TB". O HD evoluiu muito. O mais antigos possuíam 5 MB (aproximadamente 4 disquetes de 3 1/2 HD), sendo aumentada para 30 MB, em seguida para 500 MB (20 anos atrás), e 10 anos mais tarde, HDs de 1 a 3 GB. Em seguida lançou-se um HD de 10 GB e posteriormente um de 15 GB. Posteriormente, foi lançado no mercado um de 20 GB, até os atuais HDs dos mais variados tamanhos.
No entanto, as indústrias consideram 1 GB = formula_1 "bytes", pois no Sistema Internacional de Unidades(SI), que trabalha com potências de dez, o prefixo giga quer dizer formula_2 ou formula_3 (bilhões), enquanto os sistemas operacionais consideram 1 GB = formula_4 "bytes", já que os computadores trabalham com potências de dois e 1024 é a potência de dois mais próxima de mil. Isto causa uma certa disparidade entre o tamanho informado na compra do HD e o tamanho considerado pelo Sistema Operacional, conforme mostrado na tabela abaixo. Além disso, outro fator que pode deixar a capacidade do disco menor do que o anunciado é a formatação de baixo nível (formatação física) com que o disco sai de fábrica.
"Todos os valores acima são aproximações"
Toda a vez que um HD é formatado, uma pequena quantidade de espaço é marcada como utilizada, podendo ser(dependendo do suporte do sistema de arquivos) pelo log do Journaling, mapa de clusters livres, etc.
Disco rígido externo, conhecido popularmente como HD externo, é um dispositivo de armazenamento independente, que pode ser conectado a um computador através de USB, e-Sata, FireWire ou outros meios.
Capacidade de armazenamento de discos externos: 320GB, 500GB, 640GB, 750GB, 1TB, 2TB, 3TB, 4TB, 6TB, 8TB.

</doc>
<doc id="742" url="https://pt.wikipedia.org/wiki?curid=742" title="Economia">
Economia

Economia () é uma ciência que consiste na análise da produção, distribuição e consumo de bens e serviços. É também a ciência social que estuda a atividade económica, através da aplicação da teoria económica, tendo, na gestão, a sua aplicabilidade prática. O termo "economia" vem do grego οικονομία (de οἶκος, translit. "oikos", 'casa' + νόμος , translit. "nomos", 'costume ou lei', ou também 'gerir, administrar': daí "regras da casa" ou "administração doméstica".
Os modelos e técnicas atualmente usados em economia evoluíram da economia política do final do século XIX, derivado da vontade de usar métodos mais empíricos à semelhança das ciências naturais.
Pode representar, em sentido lato, a situação económica de um país ou região; isto é, a sua situação conjuntural (relativamente aos ciclos da economia) ou estrutural.
A economia é, geralmente, dividida em dois grandes ramos: a microeconomia, que estuda os comportamentos individuais, e a macroeconomia, que estuda o resultado agregado dos vários comportamentos individuais. Atualmente, a economia aplica o seu corpo de conhecimento para análise e gestão dos mais variados tipos de organizações humanas (entidades públicas, empresas privadas, cooperativas etc.) e domínios (internacional, finanças, desenvolvimento dos países, ambiente, mercado de trabalho, cultura, agricultura, etc.).
Outras formas de divisão da disciplina são: a distinção entre economia positiva ("o que é", que tenta explicar o comportamento ou fenômeno econômico observado) e economia normativa ("o que deveria ser", frequentemente relacionado com políticas públicas); a distinção entre economia ortodoxa, aquela que lida com o nexo "racionalidade-individualismo-equilíbrio", e a economia heterodoxa, que pode ser definida por um nexo "instituições-história-estrutura social".
Para Paul Krugman e Robin Wells,
Efetivamente, o foco de interesse da microeconomia é, antes de tudo, o estudo das escolhas dos agentes económicos, isto é, da forma como estes procedem dado um conjunto de diferentes opções, comparando os benefícios e inconvenientes para a prossecução dos seus objetivos ou para a satisfação dos seus interesses - o postulado utilitarista.
A microeconomia estuda as interações que ocorrem nos mercados em função da informação existente e da regulação estatal. Distinguem-se os mercado de bens e serviços dos mercados de fatores de produção, capital e trabalho, por terem diferentes agentes e formas de funcionamento.
A teoria compara os agregados da quantidade global demandada pelos compradores e da quantidade fornecida pelos vendedores, o que determina o preço.
Constrói modelos que descrevem como o mercado pode conseguir o equilíbrio entre o preço e a quantidade, ou como pode reagir a alterações do mercado ao longo do tempo, que é o que se denomina de mecanismo da oferta e da procura.
As estruturas de mercado, como a concorrência perfeita e o monopólio, são analisadas para tirar conclusões sobre o seu comportamento e a sua eficiência económica.
A análise de um mercado é feita a partir de hipóteses simplificadoras, como por exemplo a racionalidade dos agentes e equilíbrio parcial (parte-se do pressuposto de o mercado não é afetado pelo que se passa em outros mercados ).
Uma análise em equilíbrio geral é um estudo mais abrangente, que permite avaliar as consequências sobre os outros mercados, para compreender as interações e os mecanismos que podem levar a uma situação de equilíbrio.
A teoria microeconómica "standard" assume que os agentes económicos, as famílias ou as empresas, são "racionais", isto é, supõe-se terem habilidades cognitivas e informações suficientes para, por um lado, construir critérios de escolha entre diferentes opções possíveis, por outro, para maximizar a sua satisfação dadas as restrições a que estão sujeitos. Presume-se que são capazes de identificar as restrições sobre estas escolhas, tanto restrições "internas" (as suas capacidade tecnológica, no caso das empresas, por exemplo), como as "externas" (por exemplo, as resultantes da conjuntura económica).
É o paradigma do "homo economicus", que não implica "a priori" que os critérios de escolha dos indivíduos sejam puramente egoístas. Podem perfeitamente ser "racionalmente" altruístas.
Esta teoria deve sua existência à síntese feita pela economia matemática neoclássica das décadas de 1940 e 1950, entre os contributos da corrente marginalista do século XIX e da teoria do equilíbrio geral de Walras e Pareto.
John Hicks e Paul Samuelson são considerados os pais da microeconomia tradicional atual, que podemos dividir em quatro áreas:
Em microeconomia, produção é um processo que usa insumos para criar produtos, destinados ao comércio ou ao consumo. A produção é um fluxo, logo é mensurável através de um rácio por unidade de tempo. É comum distinguir entre a produção de bens de consumo (alimentos, cortes de cabelo, etc.) vs. bens de investimento (novos tratores, edifícios, estradas, etc.), bens públicos (defesa nacional, segurança pública, proteção civil, etc.) ou bens privados (computadores novos, bananas, etc.).
As entradas para o processo de produção incluem fatores de produção básicos como o trabalho, capital (bens duradouros usados na produção, como uma fábrica) e terra (incluindo recursos naturais). Outros fatores incluem bens intermédios usados na produção dos bens finais, como por exemplo o aço no fabrico de um carro novo.
O custo de oportunidade, relacionado com o custo económico, é o valor da melhor alternativa disponível quando se tem que fazer uma escolha entre duas opções mutuamente exclusivas.
É descrita como sendo a expressão da "relação básica entre escassez e escolha".
O custo de oportunidade é um fator que garante a utilização eficiente dos recursos escassos, pois o custo é ponderado face ao valor gerado, no momento de decidir aumentar ou reduzir uma atividade.
Os custos de oportunidade não se restringem a custos monetários. Podem também ser medidos em tempo (de lazer, por exemplo) ou qualquer outra coisa que corresponda a um benefício alternativo (utilidade, no vocabulário microeconómico)
A eficiência económica descreve o quanto um sistema utiliza bem os recursos disponíveis, dada a tecnologia disponível. A eficiência aumenta se conseguirmos obter um maior resultado sem aumentar os recursos usados, ou seja, se conseguirmos reduzir o "desperdício".
Dizemos que temos uma eficiência de Pareto quando estamos num ponto onde nenhuma alteração na forma como usamos os recursos disponíveis consegue melhorar o resultado para alguém sem piorar a situação de outro.
A fronteira de possibilidades de produção (FPP) é uma ferramenta analítica que representa a escassez, custo e eficiência. No caso mais simples, estudamos uma economia que produz apenas dois bens. A FPP é uma tabela ou gráfico (ver ilustração) que mostra as várias combinações de quantidades dos dois produtos que é possível ter, dado a tecnologia e os fatores de produção disponíveis.
Cada ponto na curva mostra uma produção potencial total máxima para a economia, que é a produção máxima possível para um bem, dada uma quantidade de produção para o outro bem. É um ponto de eficiência produtiva por maximizar a produção para um total dado de insumos. Um ponto "dentro" da curva é possível mas representa ineficiência produtiva (uso de insumos com desperdício), no sentido de que é possível aumentar a produção de um ou ambos os bens no sentido nordeste em direção a um ponto na curva.
O gráfico na ilustração exemplifica uma curva com todos os pontos economicamente eficientes. O ponto A no gráfico, por exemplo, indica-nos que a produção de F de comida e C de computadores é eficiente. O mesmo se passa com F de comida e C de computadores (ponto B). Os pontos abaixo dessa linha são ineficientes, pois é possível aumentar a produção de um dos bens sem ser forçado a reduzir a produção do outro.
A escassez é representada na figura pela impossibilidade de se poder produzir para além da FPP. São os pontos acima da linha, impossíveis de atingir com os recursos e tecnologia disponíveis.
É também representada pelo declive da curva, que representa o quanto da produção de um bem diminui quando a produção do outro aumenta, numa relação inversa.
Isso ocorre porque uma maior produção de um bem requer a transferência de insumos da produção do outro bem, forçando a sua diminuição.
É um exemplo de custo de oportunidade e significa que escolher mais de um bem implica ter menos do outro.
Estar na curva pode ainda não satisfazer completamente a eficiência alocativa (também apelidado de "eficiência de Pareto") se a curva não consistir numa combinação de produtos que os consumidores tenham preferência face a outros pontos ou combinações.
Numa economia de mercado, o ponto da curva onde a economia se posiciona pode ser explicado pela escolha que os agentes acham mais preferível.
Muito da economia aplicada em políticas públicas está preocupada em determinar como a eficiência de uma economia pode ser aumentada. 
Encarar a realidade da escassez para então perceber como podemos organizar a sociedade para ter o uso mais eficiente dos recursos tem sido descrito como sendo a "essência da economia", onde a disciplina "faz a sua contribuição ímpar". 
A especialização é considerada um aspecto chave para a eficiência económica, devido a diferentes agentes (indivíduos ou países) terem diferentes vantagens comparativas.
Mesmo que um país detenha vantagem absoluta em todos os setores, tem vantagem em se especializar nas áreas onde tenha as maiores vantagens comparativas, efetuando depois trocas comerciais com outros países. Consegue desta forma obter uma maior quantidade dos produtos onde não se especializou comparado com a opção de produzir tudo por si.
Um exemplo disso é a especialização dos países desenvolvidos em produtos de alta tecnologia, preferindo adquirir os bens de manufatura aos países em desenvolvimento, onde a mão-de-obra é barata e abundante.
A teoria defende que desta forma se consegue obter um maior total de produtos e utilidade, comparando com a situação em que cada país decide pela produção própria de todos os produtos.
A teoria da vantagem comparativa é responsável pela crença generalizada dos economistas nos benefícios do comércio livre.
O conceito aplica-se a indivíduos, fazendas, fábricas, fornecedores de serviços e a economias.
Em qualquer um destes sistemas produtivos podemos ter:
A Riqueza das Nações (1776), de Adam Smith faz uma discussão notável dos benefícios da divisão do trabalho. A forma como os indivíduos podem aplicar da melhor forma o seu trabalho, ou qualquer outro recurso, é um tema central do primeiro livro da obra.
Smith afirmava que um indivíduo deveria investir recursos, por exemplo, terra e trabalho, de forma a obter o maior retorno possível.
Desta forma, as várias aplicações de um mesmo recurso devem ter uma taxa de retorno igual (ajustada pelo risco relativo associado a cada atividade). Caso contrário, acabaria por ocorrer uma realocação de recursos melhorando o retorno.
O economista francês Turgot fez o mesmo raciocínio dez anos antes, em 1766.
Estas ideias, escreveu George Stigler, são a proposição central da teoria econômica.
De forma mais geral, a teoria diz que fatores do mercado, como os custos de produção e os preços dos insumos, determinam a alocação dos fatores de produção tendo em conta a "vantagem comparativa".
São escolhidos os insumos mais baratos, de forma a ter o mais baixo "custo de oportunidade" para cada tipo de produto.
Com este processo, a produção agregada aumenta como efeito colateral.
Esta especialização da produção cria oportunidades para "ganhos com o comércio" em que os detentores dos recursos beneficiam do comércio vendendo um tipo de produto contra outros bens de maior valor.
Uma medida dos ganhos de comércio é o aumento na produção (formalmente, a soma do acréscimo do excedente do consumidor e dos lucros do produtor) resultante da especialização na produção e do consequente comércio. 
A teoria de oferta e demanda explica os preços e as quantidades dos bens transacionados numa economia de mercado e as respetivas variações.
Na teoria microeconômica em particular, refere-se à determinação do preço e quantidade num mercado de concorrência perfeita, que tem um papel fundamental na construção de modelos para outras estruturas de mercado, como monopólio, oligopólio e competição monopolística) e para outras abordagens teóricas.
Para o mercado de um bem, a "demanda" mostra a quantidade que os possíveis compradores estariam dispostos a comprar para cada preço unitário do bem. A demanda é frequentemente representada usando uma tabela ou um gráfico relacionando o preço com a quantidade demandada (ver figura).
A teoria da demanda descreve os consumidores individuais como entidades "racionais" que escolhem a quantidade "melhor possível" de cada bem, em função dos rendimentos, preços, preferências, etc.
Uma expressão para isso é 'maximização da utilidade restringida' (sendo a renda a "restrição" da demanda).
Para esse contexto, "utilidade" refere-se às hipotéticas preferências relativas dos consumidores individuais.
A utilidade e a renda são então usadas para modelar os efeitos de mudanças de preço nas quantidades demandadas.
A lei da demanda diz que, regra geral, o preço e a quantidade demandada num determinado mercado estão inversamente relacionados.
Por outras palavras, quanto mais alto for o preço de um produto, menos pessoas estarão dispostas ou poderão comprá-lo ( tudo o resto inalterado).
Quando o preço de um bem sobe, o poder de compra geral diminui ("efeito renda") e os consumidores mudam para bens mais baratos ("efeito substituição").
Outros fatores também podem afetar a demanda. Por exemplo, um aumento na renda desloca a curva da demanda em direção oposta à origem, como é exemplificado na figura.
"Oferta" é a relação entre o preço de um bem e a quantidade que os fornecedores colocam à venda para cada preço desse bem. A oferta é normalmente representada através de um gráfico relacionando o preço com a quantidade ofertada. Assume-se que os produtores maximizam o lucro, o que significa que tentam produzir a quantidade que lhes irá dar o maior lucro possível. A oferta é tipicamente representada como uma relação diretamente proporcional entre preço e quantidade (tudo o resto inalterado).
Por outras palavras, quanto maior for o preço pelo qual uma mercadoria pode ser vendida, mais produtores estarão dispostos a fornecê-la. O preço alto incentiva a produção. Em oposição, para um preço abaixo do equilíbrio, há uma falta de bens ofertados em comparação com a quantidade demandada pelo mercado. Isso faz com que o preço desça. O modelo de oferta e demanda prevê que, para curvas de oferta e demanda dadas, o preço e quantidade irão se estabilizar no preço em que a quantidade ofertada é igual à quantidade demandada. Esse ponto é a intersecção das duas curvas no gráfico acima, o equilíbrio do mercado.
Para uma determinada quantidade de um bem, o ponto do preço na curva da demanda permite determinar o "valor", ou utilidade marginal para os consumidores para essa unidade de produto. Ele indica a quantia que um consumidor estaria disposto a pagar por aquela unidade específica do bem: o seu "custo marginal". O preço no ponto de equilíbrio é determinado pela conjugação da oferta e demanda. Por isso podemos dizer que, em mercados perfeitamente competitivos, a oferta e a demanda conseguem um equilíbrio entre o custo e o valor.
Do lado da oferta, alguns fatores de produção são relativamente fixos no curto prazo, o que pode afetar os custos em caso de alteração do nível de produção. Por exemplo, equipamentos ou maquinaria pesada, espaço de fábrica adequado, e pessoal qualificado. Um fator de produção variável pode ser alterado facilmente, para se adequar ao nível de produção escolhido. Exemplos incluem: o consumo de energia elétrica, a maioria das matérias primas, horas extraordinárias e trabalhadores temporários. No longo prazo, todos os fatores de produção podem ser ajustados pela gestão. Mas estas diferenças podem resultar numa diferente elasticidade (rapidez de resposta) da curva da oferta no curto prazo, que podem implicar diferenças face aos resultados de longo prazo previstos pelo modelo.
A oferta e demanda são usadas para explicar o comportamento dos mercados de concorrência perfeita, mas sua utilidade como modelo de referência é extensível a qualquer outro tipo de mercado. A oferta e demanda também pode ser generalizada para explicar a economia como um todo. Por exemplo a quantidade total produzida e o nível geral de preços (relacionado com a inflação) estudados pela macroeconomia.
A oferta e demanda também pode ser usada para modelar a distribuição de renda pelos fatores de produção, como o capital e trabalho, através de "mercados de fatores". Num mercado de trabalho competitivo, por exemplo, a quantidade de trabalho empregada e o preço do trabalho (o salário) são modelados pela demanda por trabalho (pelas firmas) e pela oferta de trabalho (pelos potenciais trabalhadores).
A economia do trabalho estuda as interações entre trabalhadores e empregadores através desses mercados, para explicar os níveis de salários e outros rendimentos do trabalho, o desenvolvimento de competências e capital humano, e o (des)emprego.
Na análise de oferta e demanda, o "preço" de um bem equilibra as quantidades produzidas e consumidas.
Preço e quantidade são habitualmente descritos como sendo as características mais diretamente observáveis de um bem produzido no mercado.
Oferta, demanda e equilíbrio de mercado são construções teóricas que relacionam preço e quantidade. Mas traçar os efeitos dos fatores que de acordo com a teoria alteram a oferta e a demanda - e através delas, o preço e a quantidade - é o exercício habitual da microeconomia e macroeconomia aplicadas. A teoria econômica pode especificar sob que circunstâncias os preços podem funcionar como um mecanismo de comunicação "eficiente" para regular a quantidade. Uma aplicação no mundo real pode ser tentar medir o quanto as variáveis que alteram a oferta e a demanda afetam o preço e a quantidade.
A teoria elementar da oferta e demanda prediz que o equilíbrio será alcançado, mas não a velocidade de ajuste que pode ser provocado por alterações na oferta e/ou demanda. Em muitas áreas, alguma forma de "inércia" do preço é postulada para explicar porque quantidades - e não preços - sofrem ajustes no curto prazo, devido a alterações tanto no lado da oferta quanto no da demanda. Isso inclui análises padrão de ciclos econômicos na macroeconomia. A análise frequentemente gira em torno de identificar as causas para essa inércia e suas implicações para que se alcance o equilíbrio de longo prazo previsto pela teoria. Exemplos em mercados específicos incluem níveis de salário nos mercados de trabalho e preços estabelecidos em mercados que se desviam da competição perfeita.
A teoria econômica do marginalismo aplica os conceitos de marginalidade na economia. O conceito de marginalidade dá relevância ao significado da variação da quantidade de um bem ou serviço, por oposição ao significado da quantidade como um todo. Mais especificamente, o conceito central ao marginalismo propriamente dito é a utilidade marginal, mas uma corrente seguidora de Alfred Marshall baseou-se mais fortemente no conceito de produtividade marginal física para a explicação do custo.
A corrente neoclássica que emergiu do marginalismo britânico trocou o conceito de utilidade pelo de taxa marginal de substituição no papel central da análise.
O marginalismo, tal como a teoria económica clássica, descreve os consumidores como agentes que almejam alcançar a posição mais desejada, sujeita a restrições como renda e riqueza. Descreve os produtores como agentes que buscam a maximização do lucro, sujeitos às suas próprias restrições (inclusive à demanda pelos bens produzidos, tecnologia e o preço dos insumos). Assim, para um consumidor, no ponto onde a utilidade marginal de um bem alcança zero, não há mais incremento no consumo desse bem. De forma análoga, um produtor compara a receita marginal contra o custo marginal de um bem, com a diferença sendo o "lucro marginal". No ponto onde o lucro marginal alcança zero, cessa o aumento na produção do bem. Para o movimento em direção ao equilíbrio e para mudanças no equilíbrio, o comportamento também muda "na margem" - geralmente mais-ou-menos de algo, ao invés de tudo-ou-nada.
Condições e considerações relacionadas se aplicam de forma mais geral a qualquer tipo de sistema econômico, baseados no mercado ou não, onde existe escassez. A escassez é definida pela quantidade de bens produzíveis ou comerciáveis, tanto necessários quanto desejados, maior do que capacidade de produção.
As condições são em forma de restrições à produção de fatores "finitos" disponíveis. Tais restrições dos recursos descrevem um conjunto de possibilidades de produção. Para consumidores ou outros agentes, as possibilidades de produção e a escassez implicam que, mesmo que os recursos sejam plenamente utilizados, existem "trade-offs", quer seja de rabanetes por cenouras, tempo livre por salário ou consumo presente por consumo futuro. A noção marginalista de custo de oportunidade é um instrumento para medir o tamanho do trade-off entre alternativas competidoras. Tais custos, refletidos nos preços, são usados para prever as reações á política pública, mudanças ou perturbações numa economia de mercado. Também são usadas para avaliar a eficiência econômica. De forma parecida, em uma "economia planejada", relações de "preço-sombra" devem ser satisfeitas para um uso eficiente dos recursos. Nesse caso também, o marginalismo pode ser usado como ferramenta, tanto para modelar unidades ou setores de produção quanto em relação aos objetivos do planejador central.
Agir pelo interesse individual conduz muitas vezes ao interesse geral, mas nem sempre é assim. Paul Krugman e Robin Wells notam que "a mão invisível não é sempre nossa aliada"..
Uma falha de mercado é um situação na qual o mercado não consegue a alocação óptima dos recursos económicos e dos bens e serviços. Isso pode acontecer, por exemplo, no caso de um monopólio (ou de um cartel), ou de uma situação em que coexistam desemprego e falta de mão-de-obra, ou ainda a existência de poluição.
A falha de mercado, no sentido de alocação económica, é um conceito diferente da anomalia de mercado, que tem um caráter mais financeiro, não da falta de eficiência do mercado. A anomalia de mercado diz respeito ao rendimento financeiro e a uma anomalia nos preços devida a fenómenos comportamentais. Estes dois fenómenos podem ser a causa ou a consequência um do outro, ou resultar de uma causa comum.
O conceito de falha tem também um aspecto político, e por isso algo controverso, na medida em que serve para justificar intervenções políticas para “corrigir”, ou até mesmo suprimir, o mercado. Apesar disso, a generalidade dos economistas utiliza o termo mais para se referir às situações em que o funcionamento real de um mercado se afasta significativamente do mercado perfeito, devido ao efeito de três causas principais:
O autores liberais, após o surgimento da teoria da escolha pública, acrescentam uma quarta causa, que na sua opinião tem consequências bem mais graves:
A partir dos dos anos 1970, o paradigma dominante na microeconomia sofre uma inflexão de modo a melhor integrar todas as anomalias e imperfeições do mercado. Para Pierre Cahuc "a nova microeconomia foi construída progressivamente, a partir de críticas dispersas, muitas inicialmente de forma isolada, ao modelo walrasiano". De uma forma mais geral, para a economista Anne Perrot, o edifício teórico da microeconomia tradicional deixava "desarmado o economista que procurasse uma representação positiva do funcionamento do mercado". Esta mudança aconteceu num momento em que a macroeconomia buscava os seus fundamentos microeconómicos, de forma que iria gerar alguma convergência entre os dois campos.
O quadro geral da nova microeconomia é preferencialmente reduzido à análise de um só mercado e o seu estudo científico baseia-se mais em constatações que se julga serem representativas do funcionamento da economia (que são apelidados de "factos estilizados").
A nova microeconomia enfatiza os problemas relativos aos estímulos, à informação e à teoria dos jogos.
Por "estímulo" entende-se toda a ação de um agente económico (incluindo o Estado) que levem a certos agentes económicos adotar este ou aquele comportamento. Esta noção tem todo o sentido se considerarmos que a informação disponível é inevitavelmente limitada por um agente económico desejoso de incentivar outros agentes a ter comportamentos do seu interesse.
A teoria dos jogos, por seu lado, é um ramo da matemática aplicada que estuda as interações estratégicas entre agentes. Segundo essa teoria, os agentes escolhem as estratégias que maximizam os seus benefícios, sendo dadas as estratégias que os outros agentes irão escolher. Propõem um modelo formal das situações em que os decisores interagem com outros agentes..
A teoria dos jogos generaliza a abordagem de maximização desenvolvida anteriormente para a análise de mercados. Foi desenvolvida a partir do livro de 1944 "Theory of Games and Economic Behavior", de John von Neumann e Oskar Morgenstern. É também empregue em numerosos domínios não económicos: estratégia nuclear, ética, ciência política e teoria evolucionista.
A extensão da abordagem microeconómica conduziu também ao desenvolvimento da "teoria dos contratos". Esta teoria conceptualiza as organizações, instituições, famílias e empresas como conjuntos de contratos (nós de contratos, na terminologia económica).
Uma empresa é, por exemplo, um nó composto por contratos de trabalho, ligando-a aos seus assalariados, por contratos ligando-a aos seus clientes e fornecedores, por contratos de produtos bancários e financeiros, por contratos legais ligando-a ao seu Estado ou região em matéria fiscal e de regulação.
os mercados são outro caso particular de nós de contratos, neste caso de contratos de comércio.
Os Estados, no sentido das organizações políticas que administram determinados espaços geográficos, são um outro exemplo de nó contratual, representando as Constituições contratos gerais ligando estas organizações ao povo que governam.
Um aspecto importante dos contratos é, regra geral, serem "incompletos", isto é, não conseguem especificar totalmente as obrigações das partes em todas as situações possíveis.
O desenvolvimento desta teoria gerou naturalmente um aprofundamento das teorias da negociação e renegociação. De facto, o seu propósito é não só explicar como e porquê os contratos são formados entre os agentes, mas também as razões pelas quais eles os põem, ou não, em causa com o decorrer do tempo.
A nova microeconomia pode ser usada pela economia industrial, economia do trabalho e pela economia pública, devido à sua capacidade para se aproximar das preocupações práticas de certos industriais.
A macroeconomia, também conhecida como "cross-section", examina a economia como um todo, "de cima para baixo", para explicar amplos agregados e suas interações. Tais agregados incluem as medições do produto nacional bruto, a taxa de desemprego, e inflação dos preços e subagregados como o consumo todas e os gastos com investimento e seus componentes. Ela também estuda os efeitos da política monetária e política fiscal. Desde pelo menos os anos 1960, a macroeconomia tem sido caracterizada pela integração cada vez maior com a modelagem de base micro de setores, inclusive a racionalidade dos agentes, o uso eficiente da informação no mercado, e a competição imperfeita. Isso tem abordado uma antiga preocupação sobre as inconsistências no desenvolvimentos da disciplina. A análise macroeconômica também considera fatores que afetem o nível de crescimento da renda nacional no longo-prazo. Tais fatores incluem a acumulação de capital, mudança tecnológica e crescimento da força de trabalho.
A "economia do desenvolvimento" estuda fatores que explicam o crescimento econômico – o aumento na produção per capita de um país ao longo de um extenso período de tempo. Os mesmos fatores são usados para explicar diferenças no "nível" de produção per capita "entre" países. Fatores muito estudados incluem a taxa de investimento, crescimento populacional, e mudança tecnológica. Que estão representados em formas empíricas e teóricas (como no modelo de crescimento neoclássico) e na contabilidade do crescimento. O campo distinto da "economia do desenvolvimento" examina aspectos econômicos do processo de desenvolvimento em países de baixa renda focando em mudanças estruturais, pobreza, e crescimento econômico. Abordagens em economia do desenvolvimento frequentemente incorporam fatores políticos e sociais.
"Sistemas econômicos" é o da economia que estuda os métodos e instituições pelas quais sociedades determinam a propriedade, direção e alocação dos recursos econômicos e as suas respectivas trajetórias de desenvolvimento econômico. Um "sistema econômico" de uma sociedade é a unidade de análise. Entre sistemas contemporâneos em diferentes partes do espectro organizacional são os sistemas socialistas e os sistemas capitalistas, nos quais ocorre a maior parte da produção, respectivamente em empresas estatais e privadas. Entre esses extremos estão as economias mistas. Um elemento comum é a interação de influências políticas e econômicas, amplamente descritas como economia política. "Sistemas econômicos comparados" é a área que estuda a performance e o comportamento relativos de diferentes economias ou sistemas.
A contabilidade nacional é um método para listar a atividade econômica agregada de uma nação. As contas nacionais são sistemas contábeis de partidas dobradas que fornecem informações detalhadas sobre a atividade econômica de um país. Essas incluem o produto nacional bruto (PNB), que fornece estimativas para o valor monetário da produção e da renda por ano ou por trimestre. O PNB permite que se acompanhe a performance de uma economia e seus componentes ao longo de ciclos econômicos ou períodos históricos. Dados de preços pedem permitir a distinção entre valores reais e nominais, isto é, corrigir totais monetários para refletir as variações nos preços ao longo do tempo. As contas nacionais também incluem aferições do estoque de capital, riqueza de uma nação, e fluxos internacionais de capital.
A economia tem inúmeros campos de estudo, abordando temáticas específicas. Os códigos de classificação JEL constituem um sistema de classificação dos assuntos em economia muito usado em publicações da área.
A economia política junta economia, legislação e ciência política para explicar como as instituições políticas e o sistema económico (capitalista, socialista ou misto) interagem. Estuda questões como impacto na política seguida pelos governos de factores como monopólios, comportamento para obtenção de rendimento e externalidades.
Para o prémio Nobel da economia Edmund Phelps "a economia política é o estudo das estrutras alternativas de rendimentos entre as quais a sociedade pode - e deve - escolher: como os mecanismos de um dado sistema, os impostos, subsídios, obrigações, deveres etc. atuam sobre os indivíduos e até que ponto funcionam bem ou mal?".
A economia pública ocupa-se do sector produtor de bens públicos e é frequentemente considerado um ramo da economia cujo objeto é o fornecimento de bens coletivos gratuitos cujos custos são financiados através de impostos.
De forma mais geral, integra também a produção de bens de mercado por empresas públicas. Estuda também as políticas que um Estado deve conduzir para promover o desenvolvimento económico e o bem-estar da população e os problemas de desigualdade social e redistribuição da riqueza.
Finanças públicas é o ramo da economia que lida com os gastos e receitas das entidades do setor público, geralmente o governo. Aborda questões como incidência fiscal (quem realmente paga um imposto), análise custo-benefício de programas do governo, efeitos na eficiência econômica e distribuição de renda de diferentes tipos de gastos e políticas fiscais. Essa última, um aspecto da teoria da escolha pública, modela o comportamento do setor público de forma análoga à microeconomia, envolvendo interações de eleitores, políticos e burocratas interessados em si mesmos.
A economia do bem-estar é um ramo normativo da economia que usa técnicas da microeconomia para determinar a eficiência de alocação e a distribuição de renda que lhe está associada. Visa medir o bem-estar social examinando as atividades econômicas dos indivíduos que compõem a sociedade.
A análise econômica do direito ("Economic Analysis of Law" ou "Law and Economics" em inglês) é a disciplina que procura explicar os fenómenos jurídicos através de métodos e conceitos da ciência económica. Usa de conceito econômicos para explicar os efeitos de normas legais a fim de determinar ou prever se serão economicamente eficientes.
São feitas críticas à intervenção pública. Para os economistas da teoria da escolha pública, os políticos e funcionários procuram o seu interesse individual e não o interesse geral. os primeiros procuram ser reeleitos, e os últimos procurar melhorar os seus rendimentos e poderes.
A busca de renda (do inglês "rent-seeking") retrata o comportamento de indivíduos e organizações que procuram obter rendimentos através de regulamentação que lhe seja favorável, ao invés de o conseguir através de uma atividade realmente criadora de riqueza. Por exemplo, estudos neste domínio evidenciam a existência de esforços para assegurar situações de monopólio.
A economia industrial, também conhecida nos Estados Unidos como organização industrial, estuda o comportamento estratégico das empresas, a estrutura dos mercados e suas interações. As estruturas comuns do mercado incluem competição perfeita, competição monopolística, várias formas de oligopólio e monopólio.
A economia gerencial aplica análise microeconômica para especificar decisões nas organizações. Ela se aproveita pesadamente de métodos quantitativos como pesquisa operacional e programação e também de métodos estatísticos como a regressão ausentes a certeza e informação perfeita. Um tema unificador é a tentativa de otimizar decisões de negócios, inclusive minimização de custo por unidade e maximização de lucro, dados os objetivos da firma e limitações impostas pela tecnologia e condições de mercado.
Segundo alguns autores, as necessidades do ser humano como indivíduo, tais como se alimentar, se abrigar e até mesmo respirar, exigem consumo de produtos conseguidos com uma atividade econômica, nesse caso chamada de "Economia Individual". Os extremos são os exemplos históricos ou literários clássicos como o de Santo Antão que viveu numa caverna do deserto da Arábia e que plantava trigo e fabricava pão para se sustentar; e de Robinson Crusoé que praticou várias atividades econômicas para se manter enquanto esteve isolado numa ilha oceânica. Outros autores, como Oscar Dias Corrêa, preferem não reconhecer tais atividades como econômicas ou pertencentes ao estudo da Economia .
Nas famílias primitivas autossuficientes já se identificavam as diversas fases da Economia: o produto de todos (da caça, pesca, plantação e colheita) era distribuído pelos chefes da família e consumido. O grupo necessitava de um planejamento rudimentar das atividades, que ficava a cargo do chefe familiar que o aplicava de forma autoritária e que, além de distribuir as atividades, podia também racionar o consumo .
O comércio internacional estuda os determinantes dos fluxos de bens e serviços através das fronteiras internacionais. Também estuda a quantidade e forma de distribuição dos ganhos com o comércio.
Aplicações em política incluem a capacidade de estimar os efeitos da alteração de taxas alfandegárias e quotas de comércio.
A primeira teoria de comércio internacional (teoria clássica de comércio internacional) foi formulada no início do século XIX por David Ricardo, também sendo conhecida por Teoria das Vantagens Comparativas ou Princípio das Vantagens Comparativas.
Finanças internacionais é uma área de estudo da macroeconomia que estuda os fluxos de capital através das fronteiras internacionais e os efeitos desses movimentos nas taxas de câmbio. O aumento do comércio de bens, serviços e capitais entre países é um dos maiores efeitos da globalização contemporânea.
A área de estudo da "economia do desenvolvimento" aborda os aspetos económicos do processo de desenvolvimento nos países em vias de desenvolvimento, focando na mudança estrutural, pobreza e crescimento económico. As abordagens à economia do desenvolvimento incorporam frequentemente fatores sociais e políticos.
"Sistemas económicos" é o ramo da economia que estuda os métodos e instituições através dos quais as sociedades determinam a propriedade, direção, e alocação dos recursos económicos. O "sistema económico" de uma sociedade é a unidade de análise.
Os extremos do espetro de sistema económicos são as economias planificadas e os sistemas capitalistas, onde a maioria da produção é efetuada, respetivamente, em organizações detidas pelo estado ou pela iniciativa privada.
Como meio termo temos as economias mistas. Um elemento comum a qualquer dos sistemas é a interação entre o poder económico e político, largamente descrito pela economia política.
A economia da agricultura é uma das mais antigas e mais bem estabelecidas áreas da economia. É o estudo das forças econômicas que afetam o setor agrícola e o impacto do setor agrícola no resto da economia. É uma área da economia que, graças à necessidade de se aplicar a teoria microeconômica a situações complexas do mundo real, tem contribuído com avanços importantes de aplicação mais geral; o papel do risco e da incerteza, o comportamento das famílias e as ligações entre direito de propriedade e incentivos. Mais recentemente áreas como o comércio internacional de "commodities" e meio ambiente tem recebido grande atenção.
A economia da informação examina como a informação (ou sua falta) afeta o processo decisório econômico. Um importante foco da disciplina é o conceito de assimetria de informação, onde um participante possui mais ou melhor informação que a outra. A existência da assimetria de informação abre espaço para o surgimento de problemas como risco moral e seleção adversa estudada na teoria dos contratos. A economia da informação tem relevância em muitas áreas como finanças, seguros, direito, e processo decisório em condições de risco e incerteza.
A economia do trabalho procura entender o funcionamento do mercado e a sua dinâmica relacionada ao trabalho. Os mercados de trabalho funcionam através das interações entre trabalhadores e empregadores. A economia do trabalho observa os ofertantes de força-de-trabalho (trabalhadores), seus demandantes (empregadores) e tenta entender os padrões resultantes de salários e outras rendas do trabalho, de emprego e desemprego. Usos práticos incluem a assistência na formulação de políticas de pleno emprego.
A economia enquanto uma disciplina contemporânea se fia em estilos rigorosos de argumentação. Os objetivos incluem a formulação de teorias que sejam mais simples, mais frutíferas e mais confiáveis do que outras teorias ou nenhuma teoria. A análise pode começar com um simples modelo que propõe uma hipótese de uma variável a ser explicada por outra variável. Com frequência uma hipótese em economia é somente qualitativa, não "quantitativa". Isto é, a hipótese implica a "direção" de uma mudança em uma variável, não o "tamanho" da mudança, para uma certa mudança de outra variável. Para clareza de exposição, a teoria pode proceder com a suposição de "ceteris paribus", isto é, mantendo constante outros termos explicatórios que não aquele em questão. Por exemplo, a teoria quantitativa da moeda prediz um aumento no valor nominal da produção a partir de um aumento da oferta de moeda, "ceteris paribus".
A teoria econômica é aberta às críticas de que ela confia em suposições irrealistas, não-verificáveis ou altamente simplificadas. Um exemplo é a suposição da maximização do lucro pelas firmas competitivas. Respostas de executivos a perguntas sobre os fatores que afetam as suas decisões podem mostrar nenhum cálculo desse tipo.
A ciência econômica como disciplina acadêmica frequentemente usa métodos geométricos, além de métodos literários. Outros métodos quantitativos e matemáticos também são frequentemente usados para análises rigorosas da economia ou de áreas dentro da economia. Tais métodos incluem os seguintes.
A economia matemática se refere a aplicações de métodos matemáticos para representar a teoria econômica ou analisar problemas surgidos na economia. Esses métodos incluem cálculo e álgebra matricial. Autores citam suas vantagens na formulação e derivação de relações centrais em um modelo econômico com clareza, generalidade, rigor, e simplicidade. Por exemplo, o livro de Paul Samuelson "Fundamentos da Análise Econômica" (1947) identifica uma estrutura matemática comum através de vários campos da disciplina.
A econometria aplica métodos matemáticos e estatísticos para analisar dados relacionados com modelos econômicos. Por exemplo, uma teoria pode levantar a hipótese de que pessoas com mais educação irão ter renda mais alta, na média, do que uma pessoa com menos educação, mantido o resto constante. Estimativas econométricas podem delimitar a magnitude e a significância estatística da relação. A econometria pode ser usada para tecer generalizações quantitativas. Essas incluem testar ou refinar uma teoria, descrever uma relação de variáveis no passado e prever variáveis futuras.
A teoria dos jogos é um ramo da matemática aplicada que estuda as interações estratégicas entre agentes. Nos jogos estratégicos, agentes escolhem estratégias que irão maximizar suas vantagens, dadas as estratégias que os outros agentes escolherem. Ela fornece uma abordagem formal para a modelação de situações sociais em que os decisores interagem com outros agentes.
A teoria dos jogos generaliza as abordagens ao problema da maximização desenvolvidas para analisar mercados como o modelo de oferta e demanda. O campo de estudo remonta ao clássico de 1944 "Theory of Games and Economic Behavior" de John von Neumann e Oskar Morgenstern. Tem encontrado aplicações significativas em muitas áreas fora da economia, incluindo a formulação de estratégia nuclear, ética, ciência política, e teoria evolucionária.
A profissionalização da economia, refletida no crescimento dos cursos de graduação, tem sido descrita como "a principal mudança na economia desde 1900".
A maioria das principais universidades e faculdades tem um curso, escola ou departamento que atribui títulos académicos na área.
O Prêmio Nobel de Economia é um prêmio anual concedido a economistas que tenham feito contribuições notáveis à disciplina.
No mundo profissional, os economistas encontram ocupação como consultores, principalmente nos setores bancário e financeiro. No setor público podem trabalhar em várias agências e departamentos como o tesouro nacional, o Banco Central, e , entre outros.
O pensamento econômico na Antiguidade remonta às civilizações mesopotâmicas, Grega, Romana, Indiana, Chinesa, Persa e àrabe. Dentro os autores mais notáveis estão Aristóteles, Chanakya, Qin Shi Huang, Tomás de Aquino e Ibn Khaldun. Joseph Schumpeter considerou inicialmente a escolástica tardia do período que vai do século XIV ao XVII como a "que chega mais perto do que qualquer outro grupo de ser os 'fundadores' da economia científica quanto às teoria monetária, de juros e do valor dentro de uma perspectiva das leis naturais. Depois de descobrir a obra "Muqaddimah" de Ibn Khaldun, no entanto, Schumpeter mais tarde considerou Ibn Khaldun o mais próximo antecedente da economia moderna, uma vez que muitas das suas teorias econômicas não eram conhecidas na Europa até épocas modernas.
Dois outros grupos, mais tarde chamados de ' mercantilistas e 'fisiocratas', influenciaram mais diretamente o desenvolvimento subsequente da disciplina. Ambos os grupos estavam associados com a ascensão do nacionalismo econômico e do capitalismo moderno na Europa. O mercantilismo era uma doutrina econômica que floresceu do século XVI ao XVIII através de uma prolífica literatura de panfleto quer de autoria de mercantes ou estadistas. Defendiam a ideia de que a riqueza de uma nação dependia da sua acumulação de ouro e prata. Nação que não tinham acesso à minas poderiam obter ouro e prata através do comércio internacional apenas se vendessem bens ao exterior e restringissem as importações que não fossem de ouro e prata. A doutrina advogava a importação de matérias-primas baratas para serem transformadas em produtos manufaturados destinados à exportação e também o intervencionismo estatal no sentido de impor tarifas protecionistas à importação de produtos manufaturados e a proibição de manufaturas nas colônias.
Os fisiocratas, um grupo de pensadores e escritores franceses do século XVIII, desenvolveram a ideia da economia como um fluxo circular. Adam Smith descreveu esse sistema com "todas as suas imperfeições" como "talvez a mais pura aproximação da verdade que já foi publicada" no assunto. Os fisiocratas acreditavam que somente a produção agrícola gerava um claro excedente sobre o custo, de forma que a agricultura constituía a base de toda riqueza. Assim, eles se opunham às políticas mercantilistas de promoção das manufaturas e do comércio em detrimento da agricultura, inclusive tarifas de importação. Advogavam a substituição do complexo e custoso sistema de arrecadação de tributos por um único imposto sobre a renda dos proprietários de terra. Variações sobre tal imposto fundiário foram retomadas por economistas posteriores (inclusive Henry George um século mais tarde) como uma fonte de receita que não distorcia tanto a economia. Como reação às copiosas regulamentações mercantilistas, os fisiocratas defendiam uma política de laissez-faire, que consistia numa intervenção estatal mínima na economia.
Apesar das discussões sobre produção e distribuição terem uma longa história, a ciência econômica no seu sentido moderno como uma disciplina separada é convencionalmente datada a partir da publicação de "A Riqueza das Nações" de Adam Smith em 1776. Nesse trabalho, ele descreve a disciplina nesses exatos termos:
Smith se referia à disciplina como 'economia política', mas esse termo foi gradualmente substituído por ciência econômica ("economics") depois de 1870.
A publicação da obra A Riqueza das Nações de Adam Smith em 1776, tem sido descrita como o "efetivo nascimento da economia como uma disciplina separada." O livro identificava o trabalho, a terra e o capital como os três fatores de produção e maiores contribuidores para a riqueza de uma nação. Para Smith, a economia ideal seria um sistema de mercado auto-regulador que automaticamente satisfaria as necessidades econômicas da população. Ele descreveu o mecanismo de mercado como uma "mão invisível" que leva todos os indivíduos, na busca de seus próprios interesses, a produzir o maior benefício para a sociedade como um todo. Smith incorporou algumas das ideias dos fisiocratas, inclusive o laissez-faire, nas suas próprias teorias econômicas, mas rejeitou a ideia de que somente a agricultura era produtiva.
Na sua famosa analogia da mão invisível, Smith argumentou em favor da noção, aparentemente paradoxal de que os mercados competitivos tendem a satisfazer às necessidades sociais mais amplas, apesar de ser guiado por interesses-próprios. A abordagem geral que Smith ajudou a formular foi chamada do economia política e mais tarde de economia clássica e incluiu nomes notáveis como Thomas Malthus, David Ricardo e John Stuart Mill, que escreveram de 1770 a 1870, aproximadamente.
Enquanto Adam Smith enfatizou a produção de renda, David Ricardo na sua distribuição entre proprietários de terras, trabalhadores e capitalistas. Ricardo enxergou um conflito inerente entre proprietários de terras e capitalistas. Ele propôs que o crescimento da população e do capital, ao pressionar um suprimento fixo de terras, eleva os aluguéis e deprime os salários e os lucros.
Thomas Robert Malthus usou a ideia dos retornos decrescentes para explicar as baixa condições de vida na Inglaterra. De acordo com ele, a população tendia a crescer geometricamente sobrecarregando a produção de alimentos, que cresceria aritmeticamente. A pressão que uma população crescente exerceria sobre um estoque fixo de terras significa produtividade decrescente do trabalho, uma vez que terras cada vez menos produtivas seriam incorporadas à atividade agrícola para suprir a demanda. 
O resultado seria salários cronicamente baixos, que impediriam que o padrão de vida da maioria da população se elevasse acima do nível de subsistência. Malthus também questionou a automaticidade da economia de mercado para produzir o pleno emprego. Ele culpou a tendência da economia de limitar o gasto por causa do excesso de poupança pelo desemprego, um tema que ficou esquecido por muitos anos até que John Maynard Keynes a reviveu nos anos 1930.
No final da tradição clássica, John Stuart Mill divergiu dos autores anteriores quanto a inevitabilidade da distribuição de renda pelos mecanismos de mercado. Mill apontou uma diferença dois papéis do mercado: alocação de recursos e distribuição de renda. O mercado pode ser eficiente na alocação de recursos mas não na distribuição de renda, ele escreveu, de forma que seria necessário que a sociedade intervenha.
A teoria do valor foi importante na teoria clássica. Smith escreveu que "o preço real de qualquer coisa… é o esforço e o trabalho de adquiri-la" o que é influenciado pela sua escassez. Smith dizia que os aluguéis e os salários também entravam na composição do preço de uma mercadoria. Outros economistas clássicos apresentaram variações das ideias de Smith, chamada 'Teoria do valor-trabalho'. Economistas clássicos se focaram na tendência do mercado de atingir o equilíbrio no longo prazo.
A economia marxista, mais tarde chamada marxiana, descende da economia clássica, em particular da obra de Karl Marx. O primeiro volume da obra de Marx, O Capital, foi publicada em alemão em 1867. Nela, Marx foca escreve sobre sua "teoria do valor-trabalho" e o que ele considera a exploração do trabalho pelo capital. Assim, a teoria do valor-trabalho, além de ser uma simples teoria dos preços, se transformou em um método para medir a utilização do trabalho num sistema capitalista, apesar de disfarçadas pela economia política "vulgar".
Um corpo teórico mais tarde chamado de 'economia neoclássica' ou 'economia marginalista' se formou entre 1870 e 1910. A expressão economics foi popularizada na língua inglesa por economistas neoclássicos como Alfred Marshall, como substituto para 'economia política'. A economia neoclássica sistematizou a oferta e demanda como determinantes conjuntos do preço e da quantidade transacionada em um equilíbrio de mercado, afetando tanto a alocação da produção quanto a distribuição de renda. Ela dispensou a teoria do valor-trabalho em favor da teoria do valor-utilidade marginal no lado da demanda e uma teoria mais geral de custos no lado da oferta.
Na microeconomia, a economia neoclássica diz que os incentivos e os custos tem um papel importante no processo de tomada de decisão. Um exemplo imediato disso é a teoria do consumidor da demanda individual, que isola como os preços (enquanto custos) e a renda afetam a quantidade demandada. Na macroeconomia é refletida numa antiga e duradoura síntese neoclássica com a macroeconomia keynesiana.
A economia neoclássica é a base do que hoje é chamada economia ortodoxa, tanto pelos críticos quanto pelos simpatizantes, mas com muitos refinamentos que ou complementam ou generalizam as análises anteriores , como a econometria, a teoria dos jogos, a análise das falhas de mercado e da competição imperfeita, assim como o modelo neoclássico do crescimento econômico para a análise das variáveis de longo-prazo que afetam a renda nacional.
A economia keynesiana deriva de John Maynard Keynes, em particular do seu livro "A Teoria Geral do Emprego, do Juro e da Moeda" (1936), que deu início à macroeconomia como um campo de estudo distinto. O livro foca nos determinantes da renda nacional no curto prazo, em que os preços são relativamente inflexíveis. Keynes tentou explicar com riqueza de detalhes teóricos por que o alto desemprego poderia não ser auto-corrigido devido a baixa "demanda efetiva" e por que mesmo a flexibilidade dos preços e a política monetária pode não ser suficiente para corrigir a situação. Expressão como "revolucionário" foram aplicadas ao livro devido ao seu impacto na análise econômica.
A economia keynesiana teve dois sucessores. A economia pós-keynesiana que busca resgatar as principais contribuições da Teoria Geral de Keynes, tendo economistas com pontos de vista plurais. É geralmente associada à Universidade de Cambridge e à obra de Joan Robinson. A nova economia keynesiana também está associada com desenvolvimentos à maneira keynesiana. No Brasil, grandes centros Keynesianos estão em Campinas, UNICAMP e no Rio de Janeiro, UFRJ.
Na verdade, a economia keynesiana não estabelece restrição alguma de preços e salários, o que Keynes disse foi o seguinte: em uma recessão, caso exista flexibilidade de preços e salários, o problema econômico será mais grave e ocorrerá de forma cumulativa. Por que? Na lógica individual da empresa (a microeconômica), com a crise faz sentido para a empresa reduzir salários e demitir funcionários. Contudo, aplicando a lógica para todo um setor ou para toda economia, a facilidade de reduzir salários e demitir acaba por deprimir ainda mais a economia, pois se de um lado o trabalhador é um custo para a empresa individual, de outro ele é consumidor de outras empresas. Caso ocorra o fato de muitos serem desempregados e a redução da renda for acentuada, a demanda agregada se reduzirá ainda mais. Desta forma o faturamento dos vários setores se reduzirá ainda mais, e o esforço de redução de custos inicial será solapado e o processo entra em nova espiral, agravando a crise, com mais queda de faturamento, mais redução de renda, mais desemprego.
Economia keynesiana significa estudar como a economia funciona na realidade, na qual os agentes modificam suas decisões frente a mudança de expectativas sobre o futuro (que não é passível de certeza matemática) Economia keynesiana enfatiza que o objetivo da produção é o lucro, mas que os agentes não maximizam previamente o lucro, dependem das decisões de todos os demais agentes sobre o que eles vão fazer com seu dinheiro, isto é, quanto as pessoas vão consumir de sua renda, quanto vão poupar, de que forma vão poupar, e além da poupança, como vão aplicar seu estoque de riqueza, qual taxa de retorno desejam, com qual liquidez e a que risco. Sendo isto válido para o público em geral, empresários, banqueiros e instituições financeiras .
Outras escolas reconhecidas ou linhas de pensamento relacionadas a um estilo próprio de fazer economia, disseminadas por um grupo bem conhecido de acadêmicos incluem a Escola Austríaca, Escola de Chicago, a Escola de Friburgo, a escola de Lausanne e a escola de Estocolmo.
Dentro da macroeconomia há, em ordem geral de aparecimento na literatura: economia clássica, economia keynesiana, a síntese neoclássica, economia pós-keynesiana, monetarismo, nova economia clássica e Economia pelo lado da oferta. Novos desenvolvimentos alternativos incluem economia ecológica, economia evolucionária, teoria da dependência, economia estruturalista, teoria dos juros da abstinência e teoria do sistema-mundo.
Discussões influentes nos primórdio da economia política estavam relacionadas com a "riqueza" amplamente definida, como na obra de David Hume e Adam Smith. Hume argumentava que ouro adicional sem incremento da produção só servia para aumentar os preços. Smith também descreveu a riqueza real não em termos de ouro e prata como anteriormente, mas como a "produção anual do trabalho e da terra da sociedade."
John Stuart Mill definiu a economia como "a ciência prática de produção e distribuição de riqueza"; esta foi a definição adotada pelo "Concise Oxford English Dictionary" apesar de não incluir o papel vital do consumo. Para Mill, a riqueza é definida como o estoque de coisas úteis.
Definições da disciplina em termos de riqueza enfatizam a produção e o consumo. Essa definição foi acusada pelos críticos por ser estreita demais, colocando a riqueza à frente do homem. Por exemplo, John Ruskin chamou a economia política de "a ciência de ficar rico" and a "bastard science."
Definições mais amplas se desenvolveram para incluir o estudo do homem, da atividade humana e do seu bem-estar. Alfred Marshall, no seu livro "Principles of Economics", escreveu, "A Economia Política ou Economia é um estudo da humanidade nos negócios da vida cotidiana; ela examina essa parte do indivíduo e da ação social que é mais fortemente ligada ao uso dos requisitos materiais para o bem-estar."
Uma das características de qualquer ciência é o uso do método científico, com a exigência de estabelecer hipóteses e fazer predições que possam ser testadas com dados empíricos, onde os resultados são passíveis de serem demonstrados e repetidos, através da reprodução das mesmas condições da experiência.
Em economia são conduzidos algumas experiências em áreas aplicadas, em particular nos sub-campos da economia experimental e comportamento do consumidor, focados na experimentação usando sujeitos humanos; e no sub-campo da econometria, focada em testar hipóteses quando os dados estatísticos não são gerados em experimentos controlados. No entanto, à semelhança das outras ciências sociais, pode ser difícil os economistas conduzirem certos experimentos formais devido a questões práticas e morais envolvendo sujeitos humanos.
O estatuto das ciências sociais como ciências empíricas, ou mesmo ciências, tem sido objeto de discussão desde o século XX. Alguns filósofos e cientistas, notavelmente Karl Popper, afirmam que nenhuma hipótese, proposição ou teoria empírica podem ser considerada científica se nenhuma observação puder ser feita que a possa contradizer, insistindo numa falseabilidade estrita (ver positivismo).
Os críticos alegam que a economia não pode atingir sempre a falseabilidade popperiana, mas os economistas apontam os muitos exemplos de experimentos controlados que fazem exatamente isso, apesar de conduzidos em laboratório.
Enquanto a economia tem produzido teorias que se correlacionam com os comportamentos observados na sociedade, a economia não gera leis naturais ou constantes universais devido à sua dependência de argumentos não-físicos. Isso tem levado alguns críticos a argumentar que a economia não é uma ciência.
Em geral, os economistas respondem que, enquanto esse aspecto apresenta sérias dificuldades, eles de fato testam as suas hipóteses usando métodos estatísticos como a econometria usando dados gerados no mundo real.
O campo da economia experimental tem feito esforços para testar pelo menos algumas das predições de teorias econômicas em ambientes simulados em laboratório – um esforço que rendeu a Vernon Smith e Daniel Kahneman o Prêmio Nobel em Economia em 2002.
Apesar de que a maneira convencional de conectar um modelo econômico com o mundo é através da análise econométrica, a professora e economista Deirdre McCloskey, através da crítica McCloskey, cita muitos exemplos em que professores de econometria usaram os mesmos dados para tanto provar e negar a aplicabilidade das conclusões de um modelo. Ela argumenta que muito dos esforços dispendidos por economistas em equações analíticas é essencialmente esforço desperdiçado (posição seguida por economistas brasileiros como Pérsio Arida).Os econometristas respondem que essa é uma objeção a qualquer ciência, não apenas à economia. Críticos de McCloskey replicam dizendo que, entre outras coisas, ela ignora exemplos em que a análise econômica é conclusiva e que as suas afirmações são ilógicas.
Alguns economistas, como ganhador do Prêmio Nobel Friedrich Hayek, são da opinião que a tendência para a economia imitar os métodos e procedimentos das ciências físicas leva a resultados não-científicos, por se tratar da aplicação mecânica e não-crítica de hábitos de pensamento vindos de áreas sem as especificidades das ciências sociais. A área econômica também é conhecida por ser excessivamente abstrata e se fechar para o mundo real.
A economia já foi apelidada de "ciência sombria" ("The dismal science" no original em inglês), de forma humorística e até mesmo depreciativa. A expressão é atribuída ao historiador vitoriano Thomas Carlyle, no século XIX. Afirma-se que Carlyle apelidou a economia de "ciência sombria" como resposta aos escritos do reverendo Thomas Robert Malthus do final do século XVIII, que sinistramente previa a fome como resultado do crescimento projetado da população exceder o taxa de aumento da oferta de alimentos. No entanto, a expressão foi efetivamente usada por Carlyle no contexto de um debate com John Stuart Mill sobre a escravidão, no qual Carlyle argumentava a favor e Mill contra.
Também existe controvérsia acerca da relação entre a economia e a política.
Alguns economistas, como John Stuart Mill ou Leon Walras, defenderam que a produção de riqueza não deveria estar ligada à sua distribuição. A primeira está no campo da "economia aplicada" enquanto a segunda pertence à "economia social" e é em grande parte uma questão de poder e política.
Certos modelos usados por economistas são criticados, até por outros economistas, pela sua dependência de pressupostos irrealistas, não-observáveis ou não-verificáveis. Uma resposta a essas críticas é que os pressupostos irrealistas resultam de abstrações que simplificam detalhes pouco importantes, e que tais abstrações são necessárias em um mundo real complexo. Isso significa que os pressupostos simplificadores, ao invés de afetar o valor epistêmico da economia, são essenciais para a formação do conhecimento em economia. Os economistas são também criticados por ignorar o papel da dívida das sociedades. A classe é considerada fechada em relação ao mundo real, e de se achar acima da mesma. A profissão é tida também como uma religião.
Um estudo chamou essa explicação de "defesa abstracionista" e concluiu que essa defesa não invalida a crítica aos pressupostos irrealistas.
No entanto não existe um consenso sobre esta questão, e diferentes campos da economia chegaram a conclusões suportadas em evidências empíricas com diferentes graus intensidade.
Os conceitos que costumam ser considerados como "axiomas" são simplificações da realidade mas que se espera serem consistentes com a observação empírica.
Alguns exemplos crenças ou axioma compartilhados por muitos economistas do "mainstream" são:
A questão dos pressupostos é delicada. Por um lado eles permitem que os problemas sejam "tratáveis". Por outro não podem ser demasiado simplificados sob pena de não conseguir retratar eficazmente o comportamento dos agentes económicos.
A economia é um campo de estudo com várias escolas e correntes de pensamento. Como resultado, há uma distribuição significativa de opiniões, abordagens e teorias. Algumas dessas chegam a conclusões opostas ou, devido à diferenças nos pressupostos, se contradizem.
Alguns economistas, como John Stuart Mill ou Leon Walras, defenderam a ideia de que a produção de riqueza não deveria ser limitada à sua distribuição. A produção estaria mais no campo da "economia aplicada" enquanto a distribuição na "economia social" e seria em grande medida uma questão política.
éia
A economia "per se", como ciência social, não se baseia em atos políticos de qualquer governo ou outra organização política, no entanto, muitos políticos ou indivíduos em posições de mando que podem influenciar as vidas de outras pessoas são conhecidas por usarem arbitrariamente uma infinidade de conceitos da teoria econômica e retórica como veículos para legitimar agendas e sistemas de valor, e não limitam suas observações aos assuntos relevantes para as suas responsabilidades. A íntima relação de teoria e prática econômica com a política é um foco de disputas que pode nublar ou distorcer as ideias originais mais despretenciosas da economia, e é frequentemente confundida com agendas sociais específicas e sistemas de valor.
Questões como a independência do banco central, políticas do banco central e retórica nos discursos de presidentes do banco central sobre as premissas das políticas macroeconômicas (monetária e fiscal) dos Estados, são focos de dissenso e criticismo.
Por exemplo, é possível associar a promoção da democracia por parte dos EUA pela força no século XXI, o trabalho de Karl Marx no século XIX ou o embate entre capitalismo e comunismo durante a guerra fria como questões de economia. Apesar da economia não fazer quaisquer juízos de valor, essa pode ser uma das razões pelas quais a economia pode ser vista como não baseada na observação empírica e no teste de hipóteses. Como uma ciência social, a economia tenta se focar nas consequências e eficiências observáveis de diferentes sistemas econômicos sem necessariamente fazer nenhum juízo de valor a respeito de tais sistemas - por exemplo, ao examinar a economia de sistemas autoritários, igualitários, ou mesmo um sistema de castas sem fazer quaisquer julgamentos a respeito da moralidade de qualquer um deles.
A relação entre ética e economia é complexa. Muitos economistas consideram escolhas normativas e juízos de valor - como o que seria preciso ou necessário, ou o que seria melhor para a sociedade - questões pessoais ou políticas fora do âmbito da economia. Uma vez que um governo ou economia estabelece um conjunto de objetivos, a economia pode fornecer "insight" sobre a melhor forma de se atingi-los.
Outros enxergam a influência das ideias econômicas, como aquelas que permeiam o capitalismo moderno, promovendo um determinado sistema de valores com os quais eles podem ou não concordar. (Veja, por exemplo, consumismo e Dia do Compre Nada.) De acordo com alguns pensadores, uma teoria econômica também é, ou implica, uma teoria de raciocínio moral.
A premissa do consumo responsável é que o consumidor deve levar em consideração preocupações éticas e ambientais, além das tradicionais considerações econômicas e financeiras, quando tomar decisões de compra.
Por outro lado, a alocação racional dos recursos limitados em prol do bem e segurança públicos também é uma área da economia. Alguns tem apontado que não estudar as melhores formas de alocar recursos para metas como saúde e segurança, o meio ambiente, justiça, ou assistência a desastres seria uma forma de ignorância voluntária que resultaria em menos bem-estar ou mesmo em mais sofrimento. Nesse sentido, não seria ético ignorar o lado econômico de tais questões.
Alguns poderiam dizer que estruturas de mercado e outras formas de distribuição de bens escassos, sugeridos pela economia, afetam não apenas seus "desejos e vontades" mas também "necessidades" e "hábitos". Muito da chamada "escolha" econômica é considerada involuntária, certamente dada por condicionamento social porque as pessoas passaram a esperar uma certa qualidade de vida. Isso leva a uma das mais debatidas áreas na política econômica hoje, a saber, o efeito e eficácia das políticas de bem-estar. Os libertários enxergam isso como uma falha com respeito ao raciocínio econômico - eles argumentam que a redistribuição de riqueza é moral e economicamente errada. Já os socialistas vêem aí uma falha da economia em respeitar a sociedade, argumentando que as disparidades de renda não deveriam ter sido permitidas para começar. Essa controvérsia levou à economia do trabalho no séc XIX e na economia do bem-estar no século XX antes de serem incluídas na teoria do desenvolvimento humano.
O antigo nome da economia, "economia política", ainda é frequentemente usado em vez de "economia", especialmente por algumas escolas como a marxista. O uso dessa expressão normalmente sinaliza um desacordo fundamental com a terminologia ou paradigma da economia de mercado. A economia política traz explicitamente considerações políticas e sociais em sua análise e é, portanto, amplamente normativa.
A economia marxista geralmente nega o "trade-off" de tempo por dinheiro. No ponto de vista marxista, é o trabalho que define o valor das mercadorias. As relações de troca dependem de que haja trabalho prévio para a determinação de preços. Os meios de produção são portanto a base compreender a alocação de recursos entre as classes, já que é nesta esfera que a riqueza é produzida. A escassez de qualquer recurso físico em particular é subsidiário à questão central das relações de poder atrelada ao monopólio dos meios de produção

</doc>
<doc id="743" url="https://pt.wikipedia.org/wiki?curid=743" title="Eric Steven Raymond">
Eric Steven Raymond

Eric Steven Raymond (4 de Dezembro de 1957 em Boston, Massachusetts), conhecido também como ESR, é um hacker e escritor americano. Depois da publicação em 1997 do seu livro "A Catedral e o Bazar", Raymond foi por alguns anos frequentemente citado como um porta-voz extra-oficial para o movimento open source. É quem mantém o "Jargon File", mais conhecido como "The Hacker's Dictionary" (O Dicionário dos Hackers).
Um ícone no movimento do Open Source e do software livre, é responsável pela famosa frase: ""Havendo olhos suficientes, todos os erros são óbvios". Que é o enunciado da Lei de Linus, em alusão ao criador do Linux, o finlandês Linus Torvalds.
Nascido em Boston, Massachusetts, em 1957, Raymond viveu na Venezuela quando criança, e em outros três continentes, antes de se fixar na Pensilvânia, em 1971. Seu envolvimento com a cultura hacker começou em 1976, e ele contribuiu pela primeira vez para um projeto de código aberto em 1982. Desde então, suas atividades de desenvolvimento de softwares de código aberto incluíram manter o cliente de e-mails fetchmail, contribuir de modos de edição para o editor Emacs, co-escrever porções da biblioteca GNU ncurses, e contribuir para as bibliotecas giflib/libungif, libpng e algumas das padrões do Python. Enquanto isso, ele escreveu alguns documentos HOWTO, incluindo vários do corpo do Projeto de Documentação do Linux.
Raymond cunhou o aforismo "Havendo olhos suficientes, todos os erros são óbvios"". Atribui os créditos da inspiração para esta citação a Linus Torvalds em seu livro A Catedral e o Bazar, de 1999.
Alguns dos projetos em quais ESR teve participação:

</doc>
<doc id="744" url="https://pt.wikipedia.org/wiki?curid=744" title="Engenharia">
Engenharia

Engenharia é aplicação do conhecimento científico, económico, social e prático, com o intuito de inventar, desenhar, construir, manter e melhorar estruturas, máquinas, aparelhos, sistemas, materiais e processos. É também profissão em que se adquire e se aplicam os conhecimentos matemáticos e técnicos na criação, aperfeiçoamento e implementação de utilidades que realizem uma função ou objetivo.
Nos processos de criação, aperfeiçoamento e complementação, a engenharia conjuga os vários conhecimentos especializados no sentido de viabilizar as utilidades, tendo em conta a sociedade, a técnica, a economia e o meio ambiente.
A "engenharia" é uma área bastante abrangente que engloba uma série de ramos mais especializados, cada qual com uma ênfase mais específica em determinados campos de aplicação e em determinados tipos de tecnologia.
O engenheiro é o profissional que exerce a prática de engenharia.
Em muitos países, o exercício da profissão de engenheiro obriga, para além da habilitação com um curso superior de engenharia, a uma licença ou certificação profissional atribuída pelo estado, por uma associação profissional, ordem ou instituição de engenheiros ou por um outro tipo de órgão de regulamentação profissional. Conforme o país, aos profissionais devidamente certificados ou licenciados está reservado o uso exclusivo do título profissional de "engenheiro" ou estão reservados outros títulos formais como "engenheiro profissional", "engenheiro encartado", "engenheiro incorporado", "engenheiro diplomado" ou "Engenheiro Europeu".
Normalmente, a lei restringe a prática de determinados atos de engenharia aos profissionais certificados e habilitados para tal, ainda que a prática dos restantes não esteja sujeita a essa restrição.
Para além da certificação como engenheiro propriamente dito, em alguns países existe a certificação como técnico de engenharia ou engenheiro técnico, associada aos profissionais com uma habilitação correspondente a um curso superior de 1º ciclo na área da engenharia.
O conceito de engenharia existe desde a antiguidade, a partir do momento em que o ser humano desenvolveu invenções fundamentais como a roda, a polia e a alavanca. Cada uma destas invenções é consistente com a moderna definição de engenharia, explorando princípios básicos da mecânica para desenvolver ferramentas e objetos utilitários.
O termo "engenharia" em si tem uma etimologia muito mais recente, derivando da palavra "engenheiro", que apareceu na língua portuguesa no início do século XVI e que se referia a alguém que construía ou operava um engenho. Naquela época, o termo "engenho" referia-se apenas a uma máquina de guerra como uma catapulta ou uma torre de assalto. A palavra "engenho", em si, tem uma origem ainda mais antiga, vindo do latim "ingenium" que significa "gênio" ou seja uma qualidade natural, especialmente mental, portanto uma invenção inteligente.
Mais tarde, à medida que o projeto de estruturas civis como pontes e edifícios amadureceu como uma especialidade técnica autónoma, entrou no léxico o termo "engenharia civil" como forma de distinção entre a atividade de construção daqueles projetos não militares e a mais antiga especialidade da engenharia militar. Hoje em dia, os significados originais dos termos "engenharia" e "engenharia civil" estão já largamente obsoletos, mas ainda são usados como tal em alguns países ou dentro do contexto de algumas forças armadas.
O Farol de Alexandria, as Pirâmides do Egipto, os Jardins Suspensos da Babilónia, a Acrópole de Atenas, o Parténon, os antigos aquedutos romanos, a Via Ápia, o Coliseu de Roma, Teotihuacán e as cidades e pirâmides dos antigos Maias, Incas e Astecas, a Grande Muralha da China, entre muitas outras obras, mantêm-se como um testamento do engenho e habilidade dos antigos engenheiros militares e civis.
O primeiro engenheiro civil conhecido pelo nome foi Imhotep. Como um dos funcionários do faraó Djoser, Imhotep provavelmente projetou e supervisionou a construção da Pirâmide de Djoser, uma pirâmide de degraus em Saqqara, por volta de 2630 a.C.-2611 a.C.. Este poderá também ter sido o responsável pelo primeiro uso da coluna na arquitetura.
Os antigos gregos desenvolveram máquinas tanto no domínio civil como no militar. A Máquina de Anticítera (o primeiro computador mecânico conhecido) e as invenções mecânicas de Arquimedes são exemplos da primitiva engenharia mecânica. Estas invenções requereram um conhecimento sofisticado de engrenagens diferenciais e planetárias, dois princípios-chave na teoria das máquinas que ajudou a projetar as embraiagens empregues na Revolução Industrial e que ainda são amplamente utilizadas na atualidade, em diversos campos como a robótica e a engenharia automóvel.
Os exércitos chineses, gregos e romanos empregaram máquinas e invenções complexas como a artilharia que foi desenvolvida pelos gregos por volta do século IV a.C.. Estes desenvolveram a trirreme, a balista e a catapulta. Na Idade Média, foi desenvolvido o trabuco.
Nos séculos XV e XVI, a engenharia naval emerge em Portugal. Os novos tipos de navios então desenvolvidos, como a caravela, a nau redonda e o galeão, irão ser fundamentais nos grandes descobrimentos marítimos.
William Gilbert é considerado o primeiro engenheiro eletrotécnico, devido à publicação da obra "De Magnete" em 1600, o qual foi o criador do termo "eletricidade".
A primeira máquina a vapor foi construída em 1698 por Thomas Savery, que assim é considerado o primeiro engenheiro mecânico moderno. O desenvolvimento deste aparelho deu origem à Revolução Industrial nas décadas seguintes, permitindo o início da produção em massa.
Com a ascensão da engenharia como profissão, durante o século XVIII, o termo tornou-se mais estritamente empregue para designar as atividades para cujos fins eram aplicadas a matemática e a ciência. Além disso, além das engenharias militar e civil, também foram incorporadas na engenharia o que antes eram conhecidas como "artes mecânicas".
A engenharia elétrica pode traçar as suas origens às experiências de Alexandre Volta em 1800, às experiências de Michael Faraday, Georg Ohm e outros, bem como à invenção do motor elétrico em 1872. O trabalho de James Maxwell e de Heinrich Hertz no final do século XIX deu origem à eletrónica.
As invenções de Thomas Savery e de James Watt deram origem à moderna engenharia mecânica. O desenvolvimento de máquinas especializadas e de ferramentas para a sua manutenção durante a Revolução Industrial levaram ao crescimento acentuado da engenharia mecânica.
A engenharia química tal como a engenharia mecânica, desenvolveu-se no século XIX, durante a Revolução Industrial. A produção à escala industrial precisava de novos materiais e de novos processos. Por volta de 1880, a necessidade da produção em larga escala de químicos era tanta que foi criada uma nova indústria, dedicada ao desenvolvimento e fabricação em massa de produtos químicos em novas fábricas. A função do engenheiro químico era a de projetar essas novas fábricas e processos.
A engenharia aeronáutica lida com o projeto de aeronaves. Nos tempos modernos, começou-se também a designá-la como "engenharia aeroespacial", dando ênfase à expansão daquele campo da engenharia que passou também lidar com o projeto de veículos espaciais. As suas origens podem ser traçadas até aos pioneiros da aviação da viragem do século XIX para o século XX. Os conhecimentos primitivos de engenharia aeronáutica eram largamente empíricos, com alguns conceitos e perícias a serem importados de outros ramos da engenharia. A partir dos experimentos muito bem sucedidos realizados por Alberto Santos Dumont no inicio do Século XX, como o primeiro voo com balão dirigível com motor a gasolina realizado em 1901, o primeiro no mundo a descolar a bordo de um avião impulsionado por um motor a gasolina em 23 de outubro de 1906, voando cerca de 60 metros a uma altura de dois a três metros com o "Oiseau de Proie"' (francês para "ave de rapina"), no Campo de Bagatelle, em Paris e apenas alguns anos depois dos bem sucedidos voos dos irmãos Wright, a década de 1920 viu um desenvolvimento intensivo da engenharia aeronáutica, através do desenvolvimento de aviões militares da época da Primeira Guerra Mundial. Entretanto, as pesquisas, para fornecer bases científicas fundamentais, continuaram através da combinação da física teórica com experiências.
Durante a Segunda Guerra Mundial, inicia-se o desenvolvimento da engenharia de computação. A expansão radical da informática depois do final da guerra tornou tanto os engenheiros de computação como os engenheiros informáticos em alguns dos maiores grupos de profissionais da engenharia.
Tradicionalmente, a engenharia lidava apenas com objetos concretos e palpáveis. Modernamente, porém, esse cenário mudou. A engenharia lida agora também com entidades não-palpáveis, tais como custos, obrigações fiscais, aplicações informáticas e sistemas.
Na engenharia, os conhecimentos científicos, técnicos e empíricos são aplicados para exploração dos recursos naturais e para a concepção, construção e operação de utilidades.
Os engenheiros aplicam as ciências físicas e matemáticas na busca por soluções adequadas para problemas ou no aperfeiçoamento de soluções já existentes. Mais do que nunca, aos engenheiros é agora exigido o conhecimento das ciências relevantes para os seus projetos, o que resulta que eles tenham que realizar uma constante aprendizagem de novas matérias ao longo de todas as suas carreiras.
Se existirem opções múltiplas, os engenheiros pesam as diferentes escolhas de projeto com base nos seus méritos e escolhem a solução que melhor corresponda aos requisitos. A tarefa única e crucial do engenheiro é identificar, compreender e interpretar os constrangimentos de um projeto, de modo a produzir o resultado esperado. Normalmente, não basta construir um produto tecnicamente bem sucedido, sendo também necessário que ele responda a outros requisitos adicionais.
Os constrangimentos podem incluir as limitações em termos físicos, criativos, técnicos ou de recursos disponíveis, a flexibilidade para permitir modificações e adições futuras, além de fatores como os custos, a segurança, a atratividade comercial, a funcionalidade e a suportabilidade. Através da compreensão dos constrangimentos, os engenheiros obtêm as especificações para os limites dentro dos quais um objeto ou sistema viável pode ser produzido e operado.
Tipicamente, os engenheiros irão tentar prever o quão bem os seus projetos se irão comportar em relação às suas especificações, antes de ser iniciada a produção em larga escala. Para isso, irão empregar, entre outros: protótipos, maquetes, simulações, testes destrutivos, testes não destrutivos e testes de esforços. Testar assegura que o produto irá comportar-se de acordo com o esperado.
Como profissionais, os engenheiros levam a sério a sua responsabilidade em produzir projetos que se comportem conforme o esperado e que não causem males não intencionados ao grande público. Tipicamente, os engenheiros incluem uma margem de segurança nos seus projetos para reduzir o risco de falha inesperada. contudo, quanto maior a sua margem de segurança, menos eficiente se poderá tornar o projeto.
A "engenharia" também se ocupa do estado dos produtos falhados. A sua aplicação é muito importante a seguir a desastres como o colapso de pontes ou a queda de aviões, onde uma análise cuidadosa é necessária para descobrir as causas das falhas ocorridas. Este estudo poderá ajudar o projetista a avaliar o seu projeto com base em condições reais ocorridas no passado com projetos semelhantes.
Tal como nas restantes atividades científicas e tecnológicas, os computadores e os programas informáticos desempenham um papel cada vez mais importante na engenharia. Existem inúmeras aplicações assistidas por computador específicas para a engenharia. Os computadores podem ser usados para gerarem modelos de processos físicos fundamentais, que podem ser resolvidos através de métodos numéricos.
Umas das ferramentas mais utilizadas pelos engenheiros são as aplicações de desenho assistido por computador (CAD), que lhes permitem criar desenhos e esquemas em 2D e modelos em 3D. As aplicações CAD, juntamente com as aplicações de maquete digital (DMU) e de engenharia assistida por computador (CAE), incluindo as de análise de elementos finitos e de elementos analíticos permitem criar modelos de projetos que podem ser analisados sem a necessidade da construção de protótipos dispendiosos em termos de custo e de tempo.
Estas aplicações permitem que os produtos e componentes sejam verificados para detecção de falhas, avaliados em termos de montagem e ajustamento e estudados em termos de ergonomia. Também permitem a análise das caraterísticas dinâmicas dos sistemas como as tensões mecânicas, temperaturas, emissões eletromagnéticas, correntes elétricas, tensão elétrica, vazão e cinemática. O acesso e a distribuição de toda esta informação é geralmente organizado através do uso de aplicações de gestão de dados do produto (PDM).
Existem também uma série de ferramentas para suporte de tarefas específicas de engenharia, como as aplicações de fabricação assistida por computador (CAM) que geram instruções para as máquinas de controlo numérico computorizado (CNC), as de gestão de processos de fabrico (MPM) para a engenharia de produção, as de desenho de eletrónica assistido por computador (ECAD ou EDA) para desenho de esquemas de circuitos elétricos e de circuitos impressos para a engenharia eletrónica, as de manutenção, reparação e operações para a gestão da manutenção e as de arquitetura, engenharia e construção (AEC) para a engenharia civil.
Recentemente, o uso do computador no auxílio ao desenvolvimento de utilidades passou a ser coletivamente conhecido como gestão do ciclo de vida do produto.
A "engenharia" é uma ciência bastante abrangente que é muitas vezes subdividida em diferentes ramos ou especialidades. Cada uma destas especialidades preocupa-se com um determinado tipo de tecnologia ou com um determinado campo de aplicação. Apesar de inicialmente um engenheiro se formar normalmente numa especialidade específica, ao longo da sua carreira na maioria dos casos, irá tornar-se polivalente, penetrando com o seu trabalho em diferentes áreas da engenharia. 
Historicamente, existiam a engenharia militar e a engenharia naval. A partir da engenharia militar começou por desenvolver-se o ramo da engenharia civil. Posteriormente, a engenharia civil (em sentido lato) subdividiu-se em diversas especialidades tradicionais:
Paralelamente, algumas das ciências agrárias aproximaram-se da engenharia e acabaram por nela se integrar, originando especialidades como:
Com o surgimento das engenharias relacionadas com a agricultura, surge a dicotomia entre estas e a engenharia industrial que agrupa as especialidades tradicionais da engenharia civil, mecânica, elétrica, química e de minas. A engenharia industrial irá contudo deixar de ser um agrupamento de especialidades e tornar-se ela própria numa especialidade da engenharia, vocacionada para o aperfeiçoamento de processos e da gestão industrial através da integração dos fatores tecnológicos, humanos e económicos.
Posteriormente, com o rápido avanço da tecnologia, foram-se desenvolvendo e ganhando proeminência diversos novos campos da engenharia, como o dos materiais, produção, aeronáutica, computação, informática, eletromecânica, mecatrónica, robótica, nanotecnologia, nuclear, molecular, ambiente, geológica, alimentar, biomédica e muitos outros. Alguns dos novos campos da engenharia resultam da subdivisão de especialidades tradicionais ou, pelo contrário, da combinação de diferentes especialidades.
O prestígio da engenharia fez com que áreas fora dela também a ela se quisessem associar. Surgiram assim campos exteriores ao que convencionalmente é considerado engenharia, mas também referidos como tal, sendo alguns exemplos a "engenharia jurídica", a "engenharia financeira", a "engenharia comercial" e a "engenharia social".
Quando uma nova área da engenharia emerge, normalmente é inicialmente definida como uma sub-especialidade ou como uma derivação de especialidades já existentes. Frequentemente, existe um período de transição entre o aparecimento do novo campo e o crescimento do mesmo até ter uma dimensão ou proeminência suficientes para poder ser classificado como nova especialidade da engenharia. Um indicador chave para essa emergência é o número de cursos criados nessa especialidade nas principais instituições de ensino superior.
Existe uma considerável sobreposição de matérias comuns a todas as especialidades da engenharia. Quase todas elas, por exemplo, fazem grande aplicação da matemática, da física e da química.
Existe uma sobreposição entre a prática da ciência e a da engenharia. Na engenharia aplica-se a ciência. Ambas as atividades baseiam-se na observação atenta dos materiais e dos fenómenos. Ambas usam a matemática e critérios de classificação para analisarem e comunicarem as observações.
Espera-se que os cientistas interpretem as suas observações e façam recomendações versadas para ações práticas baseadas nessas interpretações. Os cientistas podem também desempenhar tarefas totalmente de engenharia como a do desenho de aparelhos experimentais ou a da construção de protótipos. Reciprocamente, no processo de desenvolvimento de tecnologia, os engenheiros ocasionalmente apanham-se a explorar novos fenómenos, transformando-se assim, momentaneamente, em cientistas.
No entanto, a pesquisa em engenharia tem um carácter diferente da pesquisa científica. Em primeiro lugar, frequentemente lida com áreas em que a física e a química básicas são bem conhecidas, mas os problemas em si são demasiado complexos para serem resolvidos de uma forma exata. Exemplos, são o uso de aproximações numéricas nas equações de Navier-Stokes para a descrição do fluxo aerodinâmico sobre uma aeronave ou o uso da regra de Miner para cálculo dos danos provocados pela fadiga do material. Em segundo lugar, a pesquisa em engenharia emprega muitos métodos semiempíricos que são estranhos à pesquisa científica pura, sendo um exemplo o do método da variação de parâmetros.
Essencialmente, pode dizer-se que os cientistas tentam entender a natureza enquanto que os engenheiros tentam fazer coisas que não existem na natureza.
O estudo do corpo humano, em algumas das suas formas e propósitos, constitui uma importante ligação entre a medicina e alguns campos da engenharia. A medicina tem como objetivo sustentar, aumentar e até substituir funções do corpo humano, se necessário, através do uso da tecnologia.
A moderna medicina pode substituir várias funções do corpo através do uso de próteses e órgãos artificiais e pode alterar significativamente várias dessas funções através de dispositivos como implantes cerebrais e marca-passos. A biónica é um campo específico que se dedica ao estudo dos implantes sintéticos em sistemas naturais.
Reciprocamente, alguns campos da engenharia olham para o corpo humano como uma máquina biológica que merece ser estudada e dedicam-se a melhorar muitas das suas funções através da substituição da biologia pela tecnologia. Isto levou a campos como a inteligência artificial, as redes neurais, a lógica difusa e a robótica. Existem também interações substanciais entre a engenharia e a medicina.
Ambos os campos fornecem soluções para problemas do mundo real. Isto, frequentemente, requer avançar mesmo antes de um fenómeno ser completamente compreendido em termos científicos o que faz com que a experimentação e o conhecimento empírico sejam uma parte integral tanto da medicina como da engenharia.
A medicina ocupa-se do estudo do funcionamento do corpo humano o qual, como uma máquina biológica, tem muitas funções que podem ser modeladas através do uso de métodos da engenharia. O coração, por exemplo, funciona como uma bomba hidráulica, o esqueleto funciona como uma estrutura e o cérebro produz sinais elétricos. Estas semelhanças, bem como a crescente importância da aplicação dos princípios da engenharia à medicina levou ao desenvolvimento da engenharia biomédica, que usa conceitos de ambas.
Novos ramos emergentes da ciência, como a biologia de sistemas, vêm adaptando ferramentas analíticas tradicionalmente usadas na engenharia, como a modelação de sistemas e a análise computacional, para a descrição de sistemas biológicos.
A moderna engenharia deriva em parte do que, antigamente, eram consideradas as artes mecânicas. Ainda se mantêm muitas ligações entre as modernas artes e a engenharia, que são diretas em alguns campos como os da arquitetura, da arquitetura paisagista e do "design" industrial, ao ponto destas disciplinas serem parte integrantes dos currículos de alguns cursos superiores de engenharia.
De entre as figuras históricas famosas, Leonardo da Vinci é um bem conhecido artista e engenheiro do Renascimento, constituindo um exemplo da ligação entre as artes e a engenharia.
A ciência política, pegou no termo "engenharia" e empregou-o no âmbito do estudo de vários assuntos como a engenharia social e a engenharia política, que lidam com a formação das estrutura política e social usando uma metodologia da engenharia associada aos princípios da ciência política.
Até ao século XX, na maioria dos países, o ensino da engenharia era realizado em escolas superiores especializadas não universitárias, uma vez que tradicionalmente o ensino das universidades se concentrava em áreas como as humanidades, a medicina e o direito. Hoje em dia, no entanto, além de continuar a ser realizado em escolas especiais, o ensino da engenharia é já realizado na maioria das grandes universidades.
Na maioria dos países, os cursos que dão acesso à profissão de engenheiro têm uma duração mínima de quatro ou cinco anos. Nos países cujos sistemas de ensinos seguem os moldes do Processo de Bolonha, a formação de um engenheiro implica a realização do 2º ciclo do ensino superior, incluindo normalmente um total de cinco anos de estudos e a realização de uma dissertação, tese ou estágio final. Em alguns destes países, a conclusão do 1º ciclo de um curso superior de engenharia poderá dar acesso à profissão de engenheiro técnico ou de técnico de engenharia.
É difícil determinar quais eram as mais antigas escolas de engenharia, uma vez que o ensino de matérias que hoje fazem parte da engenharia vem já desde a antiguidade. No entanto, segundo os padrões modernos podem apontar-se as seguintes escolas precursoras deste ensino:
O ensino da engenharia no Brasil tem origem em 1699, altura em que o Rei D. Pedro II de Portugal ordena a criação aulas de fortificação em vários pontos do Ultramar Português. O objetivo era formar técnicos de engenharia militar nos territórios ultramarinos, de modo a que estes estivessem menos dependentes de engenheiros vindos do Reino. Em território brasileiro, seriam criadas destas aulas no Rio de Janeiro, em Salvador da Baía e no Recife.
No entanto, a mais antiga escola a ministrar cursos de engenharia segundo os moldes modernos foi a Real Academia de Artilharia, Fortificação e Desenho, fundada em 1792 no Rio de Janeiro pela rainha D. Maria I de Portugal, segundo o modelo da academia com o nome semelhante existente em Lisboa. A atual Escola Politécnica do Rio de Janeiro e o Instituto Militar de Engenharia consideram-se sucessores daquela academia, razão pela qual este último reivindica ser a mais antiga escola de engenharia das Américas.
Os profissionais de engenharia e de áreas correlatas são regulamentados pelo Conselho Federal de Engenharia e Agronomia e fiscalizados pelos conselhos regionais.
Há um crescente déficit de engenheiros no Brasil devido, em grande parte, ao alto índice de evasão dos estudantes da graduação na área. A Federação Nacional dos Engenheiros estima que seriam necessários ao menos 60 mil novos engenheiros formados por ano em um “cenário de expansão econômica”. Todavia, em 2011, esse número foi de apenas 42,8 mil segundo Instituto Nacional de Estudos e Pesquisas Educacionais Anísio Teixeira – Inep.
Em Portugal, o ensino do que é hoje a engenharia remonta à formação em artes mecânicas e em ciências físicas e matemáticas, realizadas desde a Idade Média. Destaca-se o ensino da construção naval, já com metodologias técnicas e científicas avançadas, que leva ao desenvolvimento de novos tipos de navios, permitindo as grandes explorações marítimas portuguesas.
O ensino da moderna engenharia começou a desenvolver-se na primeira metade do século XVII, com a necessidade de engenheiros militares em virtude da Guerra da Restauração. Para a formação dos mesmos, em 1647, o Rei D. João IV funda a Aula de Fortificação e Arquitetura Militar em Lisboa. Em 1699, o Rei D. Pedro II ordena a criação de aulas de fortificação em vários locais do Ultramar, como Angola e Brasil. Em 1707, a Aula de Fortificação e Arquitetura Militar é transformada na Academia Militar da Corte, sendo também criadas academias militares provinciais, a primeira das quais em Viana do Minho e, posteriormente, também em Elvas e Almeida. Em 1779, aquelas academias são extintas, ao mesmo tempo que é criada a Academia Real de Marinha, cujos estatutos prevêm a existência de uma escola de engenharia e fortificação, a qual seria frequentada pelos candidatos a engenheiros militares, depois da frequência do Curso Matemático dos Oficiais Engenheiros realizado na Academia de Marinha.
A referida escola de engenharia e fortificação só virá a ser criada pela Rainha D. Maria I, a 2 de janeiro de 1790, na forma da Academia Real de Fortificação, Artilharia e Desenho (ARFAD). Esta é considerada a primeira escola moderna de engenharia portuguesa e uma das primeiras do mundo. Na ARFAD era realizado um curso militar, que para os candidatos a oficiais engenheiros tinha a duração de quatro anos, incluindo as cadeiras de fortificação regular, de fortificação irregular, de arquitetura civil e de hidráulica, além de uma aula de desenho. A admissão no curso de oficiais engenheiros implicava a habilitação com os dois primeiros anos do curso matemático da Academia Real da Marinha ou, em alternativa, a habilitação com um curso preparatório na Faculdade de Matemática da Universidade de Coimbra.
Durante o século XIX, o ensino superior de engenharia irá desenvolver-se com a criação de diversas escolas militares e civis. Em 1837, são criadas a Escola Politécnica de Lisboa e a Escola do Exército - por remodelação, respetivamente da Academia Real da Marinha e da ARFAD - mantendo-se o sistema da primeira ministrar os preparatórios científicos dos cursos de engenharia a serem realizados na segunda. Além do curso de engenharia militar, a Escola do Exército passa também a ministrar o curso de engenharia civil. Em 1837, é também criada a Academia Politécnica do Porto, com os cursos completos de engenheiros civis nas especialidades de minas, de pontes e estradas e de construtores navais, além dos preparatórios para acesso à Escola do Exército. Em 1896, o Instituto Industrial e Comercial de Lisboa passa a ministrar um curso superior industrial, diplomando engenheiros industriais.
No século XX, o ensino da engenharia passa pela primeira vez a ser realizado na universidade, quando a Academia Politécnica do Porto é integrada na nova Universidade do Porto, criada em 1911, com os seus cursos de engenharia a estarem na génese da atual Faculdade de Engenharia daquela Universidade. Ao mesmo tempo, o Instituto Industrial e Comercial de Lisboa é desdobrado, com o seu ensino de engenharia a dar origem ao Instituto Superior Técnico. Entretanto, na sequência da reforma do ensino superior agrícola, o antigo curso de agronomia dá origem aos cursos de engenheiro agrónomo e de engenheiro silvicultor do Instituto Superior de Agronomia.
Também se desenvolve o ensino médio técnico industrial, cujos diplomados passam a ser considerados engenheiros auxiliares em 1918 e agentes técnicos de engenharia em 1926. Os institutos industriais são transformados em estabelecimentos de ensino superior em 1974, passando a ministrar cursos de bacharelato, cujos diplomados passam a ser engenheiros técnicos.
Atualmente, o ensino da engenharia é realizado em universidades e institutos politécnicos, tanto públicos como privados. São oferecidas várias centenas de cursos de engenharia de 1º e de 2º ciclo. No entanto, apenas uma pequena percentagem destes está acreditada, pela Ordem dos Engenheiros ou pela Ordem dos Engenheiros Técnicos, dando aos seus diplomados um acesso automático às profissões, respetivamente, de engenheiro e de engenheiro técnico.

</doc>
<doc id="745" url="https://pt.wikipedia.org/wiki?curid=745" title="Engenharia química">
Engenharia química

Engenharia química é o ramo da engenharia responsável por projetar, construir e operar plantas industriais. É também conhecida como engenharia universal por ser um ramo da engenharia que combina conhecimentos de química, biologia, física, computação e matemática para projetar, construir, e operar plantas químicas de matérias-primas em produtos finais através de processos químicos, biológicos ou físicos, chamados de Operações Unitárias.
Numa definição mais formal, dada pelo "American Institute of Chemical Engineers" (AIChe), “Engenharia Química é a área/profissão que dedica-se à concepção, desenvolvimento, dimensionamento, melhoramento e aplicação dos Processos e dos seus Produtos. Neste âmbito inclui-se a análise econômica, dimensionamento, construção, operação, controle e gestão das Unidades Industriais que concretizam esses Processos, assim como a investigação e formação nesses domínios”.
Embora a engenharia química tenha sido concebida inicialmente na Inglaterra, sofreu seu desenvolvimento principal nos Estados Unidos, impelida primeiramente pelo petróleo e indústrias químicas pesadas, e depois pela indústria petroquímica, com a produção de plásticos, borracha sintética e fibras sintéticas a partir do petróleo e do gás-natural. No início do século passado, a engenharia química adaptou para grande escala os processos físicos de separação tais como destilação, absorção e extração, que ja eram feitos em laboratorios , os quais foram combinados os princípios de transferência de massa, fluidodinâmica e transferência de calor com a finalidade de projetar equipamentos.
Os projetos de engenharia química são baseados em três leis fundamentais: conservação de massa, conservação de energia e conservação de quantidade de movimento. A Transferência de massa e a Transferência de calor entre os processos são determinados através da aplicação das leis fundamentais da Física. Na aplicação de tais leis os engenheiros químicos utilizam os princípios da Termodinâmica, cinética química e fenômenos de transporte. 
A tarefa complexa de dimensionamento e análise de equipamentos da engenharia química pode ser auxiliada pela simulação de processos. Os simuladores (ASCEND, Aspen Plus, CFX, Design II, Dymola, EMSO, Hysys, Petro-SIM, Pro II, SysCAD, DWSim, dentre outros) resolvem os balanços de massa e energia e são normalmente acompanhados de uma biblioteca de equipamentos que representam as mais diversas operações unitárias da engenharia química. Simulação é apenas mais uma ferramenta que o engenheiro químico pode lançar mão. Porém o domínio dos conceitos básicos são insubstituíveis.
O Engenheiro Químico deve ser um profissional apto a aperfeiçoar e elaborar novos métodos para fabricação de produtos químicos e outros produtos sujeitos a tratamento químico, projetar e controlar a construção, a montagem e o funcionamento de instalação e fábricas onde se realiza o preparo ou o tratamento químico, realizar investigações com o objetivo de verificar as diferentes etapas operacionais, as possibilidades de produção para fins comerciais e a maneira pela qual se podem reduzir os custos de produção e conseguir um melhor controle de qualidade, fiscalizar a montagem de instalações novas ou modificações de instalações já existentes, e inspecionar e coordenar atividades dos trabalhadores encarregados dos equipamentos e sistemas químicos.
Algumas das características de formação profissional são:

</doc>
<doc id="746" url="https://pt.wikipedia.org/wiki?curid=746" title="Período clássico (música)">
Período clássico (música)

Período clássico é o período da música erudita ocidental entre a segunda metade do século XVIII e o início do século XIX, caracterizada pela claridade, simetria e equilíbrio. Os compositores mais conhecidos do período são Franz Joseph Haydn (1732-1809), Wolfgang Amadeus Mozart (1756-1791) e Ludwig van Beethoven (1770-1827), embora este último, mostrava características do Romantismo desde sua Terceira Sinfonia.
Na cultura ocidental, a segunda metade do século XVIII coincidiu com a última parte do Período do Iluminismo. Este movimento, humanitário e secular por natureza, enfatizava a razão, a lógica e o conhecimento. Aqueles que se baseavam na religião, na superstição e no poder supremo para manterem as posições de poder, viram a sua autoridade questionada e eventualmente reduzida. A crença nos direitos humanos e na irmandade sobrepôs-se ao direito divino dos reis, até então considerado inegável. Ambas as revoluções americana e francesa foram combatidas durante esta metade do século. Considerando este período como um grande ponto de reviravolta, os filósofos e escritores promoveram a razão em detrimento do costume ou da tradição como o melhor guia da conduta humana. Uma mudança paralela ocorreu na música ocidental durante a segunda metade do século XVIII. Denominado normalmente "Período Clássico", este período musical era caracterizado pela objectividade (controlo, brilho e requinte), claridade, periodicidade (fraseologia regular) e equilíbrio.
Na história da música ocidental, o estilo que se desenvolveu durante os anos precedentes (1720/30 - 1770) é conhecido por "pré-clássico" ou menos pejorativo, o estilo de "meados do século". O gosto musical alterou-se profundamente como aconteceu com as artes visuais. Tal como estas últimas que revelaram uma preferência pelo equilíbrio e pela claridade da estrutura, também estas características tornaram-se pontos fulcrais para os compositores. No início, a composição musical passou de um estilo ornado do período Barroco para um estilo popular de extrema simplicidade. Os compositores deste período criaram obras que transpareciam claridade e acessibilidade acima de tudo; na verdade, reagiam contra o denso estilo polifónico do último período Barroco. Estas características encontram-se nas sinfonias de compositores como Giovanni Battista Sammartini (1700/01-1775) e Johann Stamitz (1717-1757). Estes traços de claridade e simplicidade, juntamente com uma elaboração sistemática de ideias, uma aproximação universal à expressão musical e uma preocupação com o equilíbrio entre estrutura e expressão, formam a base do estilo clássico.
Embora muitos compositores tenham vivido e composto durante o Período Clássico, as três maiores figuras são Franz Joseph Haydn (1732-1809), Wolfgang Amadeus Mozart (1756-1791) e Ludwig van Beethoven (1770-1827). Cada um contribuiu significativamente para a sinfonia, a sonata para piano, a música de câmara- o quarteto de cordas em particular - e para a música de igreja. Todos utilizaram a Forma-sonata, que constitui o cerne do Período Clássico. A estrutura da sonata clássica, dependendo primeiro e principalmente do movimento harmónico, foi a forma predominante numa vasta série de primeiros movimentos de sinfonias, sonatas e obras de câmara. Foi também utilizada de outras formas, assim como em movimentos lentos e conclusivos dos géneros mencionados, em movimentos de grande magnitude, aberturas e em algumas partes de óperas. Neste último campo, Haydn e Mozart escreveram obras que foram bem recebidas pela audiência de então; contudo, só Mozart foi incluído no actual repertório lírico.
Os historiadores teriam inserido facilmente Haydn e Mozart no Período Clássico. A vida de ambos encaixa-se nitidamente no período em questão; além disso, neles encontra-se uma exploração preliminar do estilo dos meados do século, que depois é convertido num estilo mais pessoal e totalmente desenvolvido, trazendo consigo os traços esperados de um compositor clássico. Beethoven é mais problemático porque a sua música abrange os períodos clássico e romântico. As suas primeiras obras (até cerca de 1802) inserem-se no estilo do período em questão. As últimas obras, cheias de drama, tensão, exploração harmónica e estrutural são melhor discutidas dentro do contexto do século XIX.
Esta é uma linha do tempo com os principais e mais influentes compositores Clássicos, separados por período e estética musical.
Nota: Algumas datas possuem apenas valor aproximado.

</doc>
<doc id="748" url="https://pt.wikipedia.org/wiki?curid=748" title="Esperanto">
Esperanto

O Esperanto é a língua artificial mais falada no mundo (Esperantujo, 120 países). Ao contrário da maioria das outras línguas planejadas, o esperanto já saiu dos níveis de projeto (publicação de instruções) e semilíngua (uso em algumas poucas esferas da vida social). 
Seu iniciador, o médico judeu Ludwik Lejzer Zamenhof, publicou a versão inicial do idioma em 1887 com a intenção de criar uma língua de mais fácil aprendizagem e que servisse como língua franca internacional para toda a população mundial (e não, como muitos supõem, para substituir todas as línguas existentes).
O esperanto é empregado em viagens, correspondência, intercâmbio cultural, convenções, literatura, ensino de línguas, televisão e transmissões de rádio. Alguns sistemas estatais de educação oferecem cursos opcionais de esperanto, e há evidências de que auxilia na aprendizagem dos demais idiomas.
Apesar da facilidade gramatical, o Esperanto enfrenta dificuldade de ser adotado como língua auxiliar universal porque as pessoas, em geral, preferem línguas naturais, adotadas pela sociedade de maneira espontânea e não programada, do que línguas planejadas.
"Esperanto" é formado pela junção do radical "sper" (do latim "sperare", "esperar"), da desinência "ant" (própria do particípio presente) e da desinência "o" (dos substantivos). Significa, portanto, "o que espera", "o que tem esperança".
Ludwik Lejzer Zamenhof vivia em Białystok (atualmente na Polônia, na época Império Russo). Em Białystok, moravam muitos povos e falavam-se muitas línguas, o que dificultava a compreensão, mesmo nas mais cotidianas situações, o que o motivou a criar uma língua auxiliar neutra, a fim de solucionar o problema.
Durante a adolescência, criou a primeira versão da "lingwe universala", uma espécie de esperanto arcaico. O seu pai, entretanto, fê-lo prometer deixar de trabalhar no seu idioma para se dedicar aos estudos. Zamenhof então foi para Moscou estudar medicina. Em uma de suas visitas à terra natal, descobriu que seu pai queimara todos os manuscritos do seu idioma.
Zamenhof pôs-se então a reescrever tudo, adicionando melhorias e fazendo a língua evoluir.
O primeiro livro sobre o esperanto foi lançado em 26 de julho de 1887, em russo, contendo as 16 regras gramaticais, a pronúncia, alguns exercícios e um pequeno vocabulário. Logo depois, mais edições do "Unua Libro" foram lançadas em alemão, polaco e francês. O número de falantes cresceu rapidamente nas primeiras décadas, primordialmente no Império Russo e na Europa Oriental, depois na Europa Ocidental, nas Américas, na China e no Japão. Muitos desses primeiros falantes vinham de outro idioma planificado: volapük. As primeiras revistas e obras originais em esperanto começaram a ser publicadas.
Em 1905, aconteceu o primeiro Congresso Universal de Esperanto, em Bolonha-sobre-o-Mar, na França, juntando quase mil pessoas, de diversos povos. Em 1906, foi fundado, no Brasil, o primeiro grupo esperantista: o Suda Stelaro, em Campinas.
Todo o movimento esperantista avançava a passos largos e seguros, mas, com o advento das duas guerras mundiais, o movimento teve um recuo: as tropas comandadas por Hitler perseguiam e matavam os esperantistas na Alemanha e nos países dominados por esta; as tropas de Stalin faziam o mesmo na Rússia; a família de Zamenhof foi dizimada; no Japão e na China, a perseguição ao esperanto também ganhou proporções assustadoras.
Após a segunda guerra mundial, o esperanto reergueu-se. Em 1954, a Organização das Nações Unidas para a Educação, a Ciência e a Cultura passou a reconhecer formalmente o valor do esperanto para a educação, a ciência e a cultura, e, em 1985, a mesma Organização das Nações Unidas para a Educação, a Ciência e a Cultura recomendou, aos países-membros, a difusão do esperanto.
Após 1995, com a popularização e disseminação da internet, o movimento esperantista ganhou uma nova força propulsora. Uma evidência do maior interesse contemporâneo pelo esperanto é o considerável número de artigos na : mais de , em dezembro de 2013, com índice de profundidade 18 — número maior que o de muitas línguas étnicas.
O esperanto é uma língua aglutinante, sem gêneros gramaticais para entidades assexuadas, sem conjugação de verbos variáveis por pessoa ou número e com três modos — indicativo, imperativo e subjuntivo, além das formas nominais do verbo e seis particípios; tem apenas dois casos morfológicos: o acusativo e o nominativo.
Como uma língua construída, o esperanto não é relacionado genealogicamente a nenhuma língua étnica; pode ser descrito como uma língua de léxico predominantemente românico e de morfologia aglutinante. A fonologia, a gramática, o vocabulário e a semântica são baseados em línguas indo-europeias ocidentais. Os fonemas são essencialmente eslavos, assim como muito da semântica, enquanto o vocabulário é derivado primordialmente de línguas românicas, com uma menor contribuição de línguas germânicas e algumas palavras de várias outras línguas (o dicionário etimológico de esperanto "Konciza Etimologia Vortaro", de André Cherpillod, faz referência a 110 línguas).
A pragmática e outros aspectos da língua não descritos especificamente nos documentos originais de Zamenhof foram influenciados pelas línguas nativas dos primeiros falantes, principalmente russo, polonês, alemão e francês. A relação entre grafemas e fonemas é biunívoca (uma letra para cada som e um som para cada letra) e a morfologia é extremamente regular e fácil de aprender.
Tipologicamente, a ordem sintática padrão do esperanto é sujeito-verbo-objeto e adjetivo-substantivo. Novas palavras podem ser formadas a partir de processos de construção com morfemas já existentes na língua, ou podem ser introduzidas como neologismos.
O esperanto tem cinco vogais e 23 consoantes, das quais duas são semivogais. Não há tons. A sílaba tônica é sempre a penúltima (paroxítona), a não ser que a palavra tenha apenas uma vogal ou que a vogal final tenha sido omitida (situação em que é tónica a última sílaba; neste caso, é graficamente substituída por um apóstrofo: "kastelo" = "kastel"’) - recurso estilístico para a poesia.
A gramática segue poucas regras simples, entre elas as chamadas 16 regras do esperanto, sendo porém necessário algum estudo para uma aprendizagem satisfatória.
As palavras são formadas pela junção regular de radicais (prefixos, sufixos e outros), de modo que "novas" palavras criadas "ad hoc" são compreendidas trivialmente através da sua análise morfológica (inconsciente, no caso de falantes fluentes).
As diferentes classes gramaticais são marcadas por desinências próprias: substantivos recebem a desinência "-o", adjetivos recebem a desinência "-a", advérbios derivados recebem a desinência "-e" e todos os verbos recebem uma de seis desinências de tempos e modos verbais.
A pluralidade é marcada nos substantivos e adjetivos concordantes pela desinência "j", e o caso acusativo é marcado pela desinência "n", cuja ausência indica o nominativo. Assim, "bela birdo" significa "bela ave", "belaj birdoj", "belas aves", e "belajn birdojn", como em "mi vidas belajn birdojn" ("eu vejo belas aves"), "belas aves" complementando diretamente uma ação (nesse caso, sendo vistas).
As seis inflexões são três tempos e três modos verbais. O tempo presente é marcado por "as", o futuro por "os", e o passado por "is"; o modo infinitivo é marcado por "i", o condicional por "us", e o volitivo (imperativo + conjuntivo) por "u". Assim: "mi vidas", "vejo"; "mi vidos", "verei"; "mi vidis", "vi"; "vidi", "ver"; "mi vidus", "eu veria"; "ni vidu", "vejamos". As desinências não variam de acordo com a pessoa.
Além dessas formas, o verbo pode se apresentar na forma de particípio. São os particípios do esperanto:
Terminados em -"a", os particípios são usados com o verbo esti (ser/estar) para a formação de tempos compostos. A desinência -"a" pode também designar um adjetivo do particípio. Trocando-se o -"a" por -"o", constrói-se um substantivo do particípio, e por -"e", um advérbio do particípio.
O vocabulário original do esperanto foi definido em "Lingvo internacia", publicado por Zamenhof em 1887. Trata-se de uma compilação de 900 radicais, passíveis de expansão para dezenas de milhares de palavras com prefixos, sufixos e composição. Em 1894, Zamenhof publicou o primeiro dicionário de esperanto, "Universala Vortaro", com uma maior quantidade de radicais. As próprias regras da língua permitem a introdução de novos radicais de acordo com a necessidade, recomendando apenas que isso seja feito a partir das formas mais internacionais.
Desde então, muitas palavras têm sido "emprestadas", basicamente mas não apenas de línguas da Europa ocidental. Nem todas as novas palavras propostas entram em uso generalizado, mas muitas o fazem, especialmente termos técnicos e científicos. Termos para uso cotidiano, por sua vez, geralmente são feitos a partir de outros radicais — por exemplo, "komputilo" (computador) a partir de "komputi" (computar) com o uso do sufixo "il" (para indicar ferramentas). Há frequentes debates entre esperantófonos sobre a justificabilidade da introdução de uma palavra em particular e sobre as possibilidades de alcançar o sentido pretendido através da construção de palavras com elementos já existentes.
O esperanto é escrito através de uma versão modificada do alfabeto latino, ao qual foram incluídas seis letras com sinais diacríticos: ĉ, ĝ, ĥ, ĵ, ŝ e ŭ. A língua não inclui as letras q, w, x e y, que podem porém ser encontradas em textos no seio de palavras não-assimiladas oriundas de outras línguas.
O alfabeto contém 28 letras:
a b c ĉ d e f g ĝ h ĥ i j ĵ k l m n o p r s ŝ t u ŭ v z
Todas as letras são pronunciadas como seus equivalentes minúsculos no Alfabeto Fonético Internacional, à exceção das seguintes:
A impossibilidade de se escrever as letras com sinais diacríticos em certos meios fez com que se adotassem convenções substitutivas. Zamenhof, ainda nos primeiros anos da língua, recomendou o uso de "h" após as letras "c", "g", "h", "j" e "s" para formar "ĉ", "ĝ", "ĥ", "ĵ" e "ŝ". Uma convenção semelhante, mas com o "x", usando-o também para o "ŭ" ("cx" = "ĉ", "ux" = "ŭ", etc.), foi criada originalmente para utilização em telegrafia, evitando situações de ambiguidade entre o "h" ortográfico e este "h" substituto de diacrítico; muito usado recentemente, principalmente em meio eletrônico, com a relativa popularização da internet.
Em setembro de 2006, a Seção de Pronúncia da Academia de esperanto propôs uma resolução sobre o uso de sistemas diferentes de escrita sob circunstâncias e necessidades especiais: a "substituição [das letras acentuadas por outros signos ou combinação de signos], quando for apenas um meio técnico que não objetive reformas da ortografia do esperanto, e quando ele não causar confusão alguma, não deve ser visto como contrária ao Fundamento". Assim, o uso do esperanto em código Morse, braile, taquigrafia e com a letra x em substituição aos sinais diacríticos é considerado correto por esta Academia, sob circunstâncias específicas.
Muitos esperantófonos tomaram a iniciativa de aprender esperanto pelo chamado "lingva problemo" (literalmente, problema linguístico). Uma das maiores faces desse problema é o chamado imperialismo cultural, que encerra, em si, o favorecimento a poucos grupos linguísticos, e a pouca praticidade da estrutura vigente de comunicação entre sujeitos sociais de línguas diferentes. Vários estudiosos têm se debruçado sobre esses aspectos. Izabel Cristina Oliveira Santiago levanta várias ocasiões históricas em que o custo de traduções alcança níveis questionáveis: "Nova Délhi, 1968. A Conferência da Organização das Nações Unidas sobre Comércio e Desenvolvimento custou mais de 2 milhões de dólares dos Estados Unidos, sendo que mais da metade disso foi gasto com o uso de apenas quatro línguas — tidas como predominantes. [...] só em 1976, por exemplo, em vez de serem investidos na alimentação das multidões de famintos, 700 mil dólares dos Estados Unidos foram gastos para traduzir, em seis línguas, os relatórios sobre a fome mundial." O psicólogo e ex-tradutor das Organização das Nações Unidas, Claude Piron (Bélgica, 1931 - 22 de janeiro de 2008), dedicou-se à temática, abordando-a sob um ponto de vista psicológico a partir de vastíssimo material bibliográfico e documental, tratando a insistência no atual modelo de comunicação internacional como uma neurose.
Esperantófonos são mais numerosos na Europa e Ásia Oriental do que nas Américas, África e Oceania, e mais numerosos em áreas urbanas do que em rurais. Na Europa, é mais comum nos países do norte e do leste; na Ásia, na China, na Coreia, no Japão e no Irã; nas Américas, no Brasil, na Argentina e no México; na África, no Togo e em Madagascar.
Uma estimativa do número de esperantófonos foi feita por Sidney S. Culbert, um professor de psicologia aposentado da Universidade de Washington e esperantista de longa data que rastreou e avaliou esperantófonos em áreas de amostragem em dezenas de países por mais de vinte anos. Culbert concluiu que entre um e dois milhões de pessoas falam esperanto no nível 3 da escala ILR (competência linguística para trabalho profissional). A estimativa de Culbert não foi feita apenas para o esperanto; incluía-se numa listagem de estimativas para todas as línguas com mais de um milhão de falantes, publicada anualmente no "The World Almanac and Book of Facts". Uma vez que Culbert nunca publicou os resultados detalhados para países e regiões particulares, é difícil verificar a precisão de seus resultados.
Como uma língua planejada, o esperanto realmente não possuía a princípio uma cultura, mas os quase 130 anos de história e divulgação da língua geraram o que poderíamos chamar assim. Algumas pessoas acusam-no quanto a ser um "idioma universal" por não apresentar cultura, literatura, falantes nativos e por outras razões. Em contrapartida, já há elementos de cultura própria do esperanto, há um acervo considerável de músicas e obras literárias originais na língua (inclusive alguns escritores, como William Auld, já foram indicados ao Nobel de Literatura por suas obras originais em esperanto), há pessoas que têm o esperanto como língua materna (na maioria dos casos, poliglotas) e a língua é usada em todos os continentes.
O esperanto não veio de uma cultura específica, mas formou uma. Esperantistas falam em esperanto e sobre esperanto, usando termos, gírias, sarcasmos e uma série de expressões próprias do meio esperantista, alguns aspectos comuns de todos os esperantistas podem definir tal cultura.
A literatura em esperanto, consistindo de obras traduzidas e escritas diretamente na língua é altamente universalista, pois são adicionadas à literatura esperantista as melhores obras de cada nação, juntamente com os aspectos particulares de cada uma, assim como as crenças e costumes típicos de cada povo. Nas obras escritas diretamente em esperanto, vemos a mesma universalidade presente em toda a cultura esperantista.
Devido à ideia inicial de fraternidade do esperanto, a tolerância e respeito aos costumes e crenças dos vários povos consiste em um dos componentes dessa cultura; o repúdio ao imperialismo cultural é comum entre os esperantistas, e o desejo de intercâmbio e contato com outros povos apresenta-se na absoluta maioria dos esperantistas, muitas vezes consistindo um dos motivos do aprendizado da língua. Isso é comprovado na leitura do Manifesto de Praga, documento que sintetiza os objetivos comuns a todos os falantes do esperanto.
Além do desenvolvimento da cultura em torno da língua, é interessante notar que a causa esperantista parece atingir um grupo especial de indivíduos, tendo eles em comum o desejo de democracia e igualdade entre as nações. A constante entrada desses indivíduos no meio esperantista, faz com que sua cultura se desenvolva e se torne mais universalista a cada dia. Um excelente exemplo das particularidades da cultura esperantista são as expressões idiomáticas surgidas ao longo da evolução da língua, frutos diretos da comunicação internacional entre esperantistas.
Um argumento comum dos esperantistas é que o esperanto é uma língua democrática, pois através dela uma cultura não é imposta aos novos falantes, como é o caso do inglês, então caberia perguntar se essa cultura nova, gerada ao longo da evolução esperantista pós guerras não seria imposta aos povos que a adotarem como língua auxiliar. Isso certamente pode acontecer, mas por ser altamente universalista, ela tenderia a não causar males às culturas locais, e sim absorver para si mais e mais dessas culturas locais, a cultura da língua esperantista, se adotada pelos povos, seria então uma cultura comum, gerada por todas as nações, e que poderia até mesmo servir para aproximar algumas populações. No Manifesto de Praga, a democracia cultural é tratada como algo extremamente forte no esperanto.
Os Congressos Universais de Esperanto, realizados anualmente desde 1905 (excluindo-se o período das grandes guerras), alimentam e aprimoram a cultura esperantista. Nesses congressos é visível a plena existência de uma cultura geral, independente da nacionalidade de cada participante. Os Discursos de Zamenhof mostram alguns indícios dessas características de forma clara.
Há alguns símbolos atribuídos pelo movimento esperantista a si mesmo ou à língua. Não há unanimidade no movimento esperantista a respeito da política do uso de símbolos, mas a maioria dos esperantistas reconhecem três símbolos: a estrela verde, a bandeira e o "Jubilea Símbolo". Argumenta-se contra a estrela e a bandeira que elas dão um ar nacionalista ao objeto representado, podendo também ser confundido com ideários de outra natureza (o Islão e o movimento dito comunista, por exemplo).
O mais simples e antigo dos símbolos é a estrela verde de cinco pontas, usada, por exemplo, como broche ou adesivo para automóvel. Segundo a tradição, as cinco pontas representam os cinco continentes (segundo cálculo tradicional) e o verde simboliza a esperança. Zamenhof, entretanto, em 1911, já não tinha mais certeza de sua origem; a cor lhe fora proposta pelo irlandês A. Richard Henry Geoghegan, que depois lhe esclareceu que se tratava da cor nacional da Irlanda. Já em 1893, Louis de Beaufront propunha o uso do verde e da estrela em tudo que se relacionasse ao movimento. A consolidação da estrela como símbolo do esperanto data dos últimos anos do século XIX; da estrela na cor verde, provavelmente apenas em 1904.
A bandeira é uma espécie de extensão da estrela verde, retomando a mesma cor e significados, com a adição do branco, para representar paz e neutralidade. Era originalmente a bandeira do clube de esperanto de Bolonha-sobre-o-Mar (França). Foi adotada generalizadamente nessa cidade por ocasião do primeiro Congresso Universal de Esperanto, em 1905.
O "jubilea simbolo" ("símbolo do jubileu") é um símbolo alternativo proposto para o esperanto, contendo a ideia interna da língua: juntar todos. As suas duas metades laterais representam a letra latina E (Esperanto) e a letra cirílica Э (Эсперанто), simbolizando a união do ocidente e do oriente. A ideia de usar as duas letras ocorreu por causa da Guerra Fria, quando as duas grandes potências estatais a se enfrentar tinham como línguas maternas o inglês (com alfabeto latino) e o russo (com alfabeto cirílico).
A sua elaboração foi promovida através de um concurso em 1983, por ocasião do centenário da língua (1987). A ideia original é do brasileiro Hilmar Ilton S. Ferreira. O símbolo é usado com cores diferentes, com ou sem contornos, de acordo com a opção do usuário.
Existem diversos movimentos sociais e culturais que apoiam o esperanto de alguma forma.
Entre eles, podemos destacar o anarquismo. Paul Bertelot, anarquista francês, em 1905, criou a revista Revuo Esperanto, que é, até hoje, o órgão oficial de divulgação da Associação Universal de Esperanto. Bertelot viajou pela Europa divulgando o esperanto entre os trabalhadores, ajudou a organizar o primeiro congresso de esperanto e fundou clubes esperantistas na América do Sul, morrendo prematuramente no Brasil em 1910. A seção libertária da Sennacieca Asocio Tutmonda ("Associação Mundial Anacional"), criada na década de 1920, até hoje é atuante. No Brasil, desde 2005, funciona o grupo de propaganda e ação esperantista-anarquista Fenikso Nigra.
O Centro de Mídia Independente (CMI) é uma rede internacional formada por produtores de informação de ordem política e social que se autodeclaram independentes de quaisquer interesses empresariais ou governamentais. O site brasileiro do CMI possui versão em esperanto.
Bona Espero é uma escola e internato localizada no município de Alto Paraíso de Goiás, região norte do estado de Goiás, a 412 quilômetros de Goiânia (capital do estado) e a 280 quilômetros de Brasília (capital federal), que abriga crianças carentes da região onde a utilização e o ensino do esperanto é comum no dia a dia. A instituição vem sendo visitada por muitos esperantistas ao longo de seus mais de 50 anos de existência. Foi fundada por um grupo nordestino de esperantistas; hoje, é administrada pelo casal Gratapagglia, por Ursula (alemã) e Giuseppe (italiano), além de outros três diretores.
Alguns grupos religiosos ao redor do mundo apoiam, de alguma forma, o esperanto.
Em 1910, foi fundada a União Internacional Católica Esperantista, cujo órgão, a revista Espero Katolika, é o periódico em esperanto mais antigo ainda em atividade.
Papas católicos romanos (incluindo pelo menos o Papa João Paulo II e Bento XVI) usaram o esperanto ocasionalmente no "urbi et orbi" multilíngue.
A "Kristana Esperantista Ligo Internacia" (Liga Internacional Cristã Esperantista) foi formada logo cedo na história do esperanto e é de orientação predominantemente protestante, mas também são filiados a ela católicos romanos e ortodoxos.
Há alguns apologistas e professores cristãos que usam o esperanto como um meio de comunicação. O pastor nigeriano Bayo Afolaranmi tem um grupo no Yahoo! chamado "Spirita nutraĵo" (alimento espiritual), que hospeda mensagens semanais desde 2003.
Em 1908, o espírita Camilo Chaigneau escreveu um artigo intitulado "O Espiritismo e o Esperanto" na revista de Gabriel Delanne (depois reproduzido no periódico "La Vie d'Outre-Tombe", de Charleroi, e na revista brasileira Reformador em 1909), recomendando o uso de Esperanto em uma "revista central" para todos os espíritas no mundo.
O esperanto, então, foi divulgado ativamente no Brasil por espíritas. Este fenómeno originou-se através de Ismael Gomes Braga e Francisco Valdomiro Lorenz, sendo o último um emigrante de origem checa que foi pioneiro de ambos os movimentos neste país.
Assim, a Federação Espírita Brasileira publica livros didáticos de esperanto, traduções das obras básicas do espiritismo e encoraja os espíritas a se tornarem esperantistas.
Por causa disso, no Brasil, muitos não-esperantistas mal-informados têm a impressão de que o esperanto é "língua de espírita"; a contradizê-lo é de notar a discrepância entre o número relativamente elevado de espíritas entre os esperantófonos brasileiros (entre um quarto e um terço) e a insignificância do recíproco (número de espíritas brasileiros que falam esperanto, cerca de 1%). Este fenómeno não se verifica noutros países.
A Fé Bahá'í encoraja o uso de uma língua auxiliar, e, sem endossar nenhuma língua específica, vê no esperanto um grande potencial para esse papel. Considera-se, entretanto, que qualquer língua ao ser adotada poderá ser modificada e adaptada através de um consenso com representação de todos os países.
Lidja Zamenhof, filha do fundador do esperanto, tornou-se Bahá'i.
Vários volumes de escritos da Fé Bahá'i já foram traduzidos para esperanto.
Zamenhof promoveu uma doutrina filosófica e religiosa chamada homaranismo, mas temeu que se confundissem as ideias da doutrina com o ideal pró-esperanto. Por esse e outros motivos, não se empenhou tanto em sua divulgação. Todavia, a maior parte dos adeptos do homaranismo hoje são esperantistas, tendo conhecido a doutrina através do esperanto.
Ayatollah Khomeini do Irã fez um chamado oficial aos islâmicos ao aprendizado do esperanto e elogiou o uso dessa língua como um meio para melhor compreensão entre povos de diferentes religiões. Após sugerir que o esperanto substituísse o inglês como uma língua franca internacional, a língua foi introduzida nos seminários de Qom. Uma tradução do Corão em esperanto foi publicada pelo estado pouco tempo depois Khomeini e o governo iraniano passaram a fazer oposição ao esperanto em 1981 após notar que seguidores da Fé Bahá'i estavam interessados no esperanto.
A religião oomoto encoraja o uso do esperanto entre seus seguidores, e inclui Zamenhof entre seus espíritos divinos.
A Congregação Cristã no Brasil recebeu uma versão em Esperanto, intitulada de "Kristana Kongregacio en Brazilo".
A primeira tradução da Bíblia para esperanto foi uma tradução do Tanakh (Velho Testamento), feita por Zamenhof. A tradução foi revisada e comparada com traduções para outras línguas por um grupo de clérigos britânicos, antes de sua publicação na "British and Foreign Bible Society" em 1910. Em 1926, ela foi publicada junto com uma tradução do Novo Testamento, numa edição geralmente chamada de "Londona Biblio". Nos anos 1960, "Internacia Asocio de Bibliistoj kaj Orientalistoj" tentou organizar uma nova e ecumênica versão da Bíblia em esperanto. Desde então, o pastor luterano Gerrit Berveling traduziu os Livros Deuterocanônicos, além de novas traduções dos Evangelhos, algumas das epístolas do Novo Testamento e alguns livros do Tanakh; estes foram publicados em várias brochuras separadas, ou em série na revista "Dia Regno", mas os deuterocanônicos apareceram numa edição recente da "Londona Biblio".
O esperanto é, frequentemente, usado para se ter acesso a uma cultura internacional, dispondo ele de um vasto leque de obras literárias, tanto traduzidas como originais. Há mais de 25 000 livros em esperanto, entre originais e traduções, além de mais de uma centena de revistas editadas regularmente. Muitos esperantófonos usam a língua para viajar livremente pelo mundo usando o Pasporta Servo, rede internacional de hospedagem solidária. Outros têm correspondentes em vários países diferentes através de serviços como o Esperanto Koresponda Servo.
Com o desenvolvimento da internet e sua maior popularização, as iniciativas de imprensa em esperanto têm se tornado mais fáceis, e pouco a pouco ela se desenvolve.
Atualmente, vários Estados subvencionam transmissões regulares em esperanto de suas estações de rádio oficiais, como República Popular da China, Polónia (diariamente), Cuba, Itália e Vaticano. Em menor escala, várias estações de rádio mantêm programas em ou sobre esperanto, como a Rádio Rio de Janeiro, que tem um departamento dedicado exclusivamente ao esperanto.
Anualmente, de 1 200 a 3 000 esperantistas encontram-se anualmente no Congresso Universal de Esperanto.
A língua mostra-se útil essencialmente para a troca de informações entre indivíduos de etnias diferentes que, doutra maneira, só seria realizada através de elementos mediadores (uma língua estranha a pelo menos um deles, um intérprete, organizações privadas, Estados etc.).
Comparado a uma língua étnica, o esperanto apresentou algumas utilidades particulares:
Num estudo, um grupo de estudantes do ensino secundário estudou esperanto durante seis meses e, depois, francês durante ano e meio, obtendo um melhor conhecimento de francês do que o grupo-controle, que estudou só o francês durante dois anos.
É provável que outras línguas planificadas também apresentem esse efeito no mesmo grau que o esperanto, mas devido ao maior número de falantes e melhor disponibilidade de material didático, a língua esperantista parece ser a mais recomendável para obter o efeito propedêutico.

</doc>
<doc id="750" url="https://pt.wikipedia.org/wiki?curid=750" title="Ajuda:Erros comuns">
Ajuda:Erros comuns

Os recém-chegados são muito bem-vindos à Wikipédia. Esperamos que se sintam bem por aqui e esperamos que de forma construtiva para o projeto. A Wikipédia possui um ambiente democrático e igualitário, no sentido em que as opiniões não valem mais só porque são defendidas por quem está aqui há mais tempo. No entanto, isso não significa que não existam regras na Wikipédia. 
Essas regras existem por boas razões e foram estabelecidas com o tempo e com a experiência. Não são regras obrigatórias, mas condensam alguma sabedoria obtida com a experiência e devem ser levadas em consideração pelos recém-chegados.
Existem alguns erros que os recém-chegados costumam cometer. A lista que se segue existe para que esses erros sejam evitados.
Esta lista está limitada aos erros "mais comuns e importantes" na Wikipédia. Para ver outras "regras" ou sugestões, consulte as .
Como qualquer texto da Wikipédia pode ser por qualquer pessoa, sendo inevitável que isso aconteça (exceto nas ), cada artigo da Wikipédia acaba por ter vários autores. Estes autores ficam guardados na base de dados automaticamente, desde que o usuário esteja . A lista de autores de cada artigo pode ser consultada no separador "" de cada artigo. Por esses motivos, não assine as suas contribuições no próprio artigo.
O uso exclusivo de letras maiúsculas num artigo prejudica sua leitura além de significar "gritaria" no internetês, o que pode ser considerado má educação.
Por exemplo, não se deve usar letras maiúsculas nos l e p de "língua portuguesa". Isso facilita a leitura e a escrita de ligações para o artigo. A ligação deve ter esta aparência: língua portuguesa. Deixar com "Iniciais Maiúsculas Tudo o que For Ligação Deixa Tudo com Aparência Muito Estranha".
Algo comum para os novos editores é inserir informações no artigo por ter visto, lido ou ouvido na mídia. Ao editar, procure sempre , referenciando de forma correta o seu texto. Procure ler as regras para uma boa edição, que estão descritas no .
A Wikipédia é uma enciclopédia escrita em português vernacular e culto, portanto cuidado com os vícios de linguagem e não utilize o "internetês" (vícios da Internet), tais como "aki" (aqui), "vc" (você), "k" ou "q" (que) e "lol" (risos). Evite também utilizar gírias ou expressões idiomáticas que possam dificultar a compreensão a usuários que não utilizem a sua variante do português.
Você provavelmente vai cometer erros — acontece com todo mundo, de diferentes formas. Mas nós estamos sempre corrigindo os erros de outros colegas. E tudo termina bem. Por isso, ! No entanto, tente sempre aprimorar suas edições, minimizando o trabalho alheio de correção.
Um engano comum dos leitores recentes da Wikipédia é achar que existe um único autor ou responsável por cada artigo. Isso faz as pessoas sentirem-se limitadas ao alterar artigos, fazendo sugestões e críticas nas , quando podiam estar alterando os artigos. O fato é que nenhum artigo tem um autor oficial, mesmo quando apenas uma pessoa trabalhou nele. Na teoria, qualquer pessoa pode escrever em qualquer artigo e se você vir algum problema num artigo e puder corrigi-lo, por favor, "faça-o na hora". Não é preciso ir antes à página de discussão, a menos que considere necessário explicar o que você alterou (geralmente não é preciso) ou que você queira esclarecer algo antes de alterar. Como foi dito acima, !
Nas é muito fácil as pessoas envolverem-se emocionalmente nos debates dos vários tópicos. A não ser que isso resulte num artigo "melhorado" (algo pouco habitual), por favor não entre em debates inúteis. Há muitos outros "sites" na Internet onde se pode envolver em debates e tentar persuadir os outros dos seus pontos de vista controversos. Isso não é mesmo nada apropriado na Wikipédia, pois estamos a tentar concentrar-nos na criação de uma enciclopédia. Por favor veja .
Alguns novos utilizadores veem logo que há aqui uma comunidade especial, esforçando-se para trabalhar em conjunto à volta de um consenso amigável. Outros cometem o erro de entrarem nas disputas da Wikipédia como se estas fossem "flame wars" da Usenet. A Wikipédia não é isso. Claro que há discussões acesas, mesmo entre os membros mais antigos. No entanto, parece ser certo que a maioria de nós não está cá para isso e ficamos envergonhados quando isso acontece. Estamos aqui para escrever uma enciclopédia. Torna-se necessário obedecer a . "Veja também ."
Perceba que a Wikipédia é um trabalho em curso, onde muitas pessoas inteligentes e bem educadas estão a trabalhar nela e preocupam-se com ela. E pensaram muito nela. Algumas pessoas, recém chegadas, falham na compreensão de como e por que é que a Wikipédia funciona e começam a pedir mais controle, ou então julgam o projeto baseando-se em artigos novos, incompletos e inadequados. De uma forma geral, se quer sentir-se confortável aqui, tolere alguma (temporária) imperfeição. Tenha em conta que estamos todos a trabalhar nisto, e está ficando cada vez melhor. Veja Wikipédia e as para mais informações gerais sobre o projeto. Veja as .
Nunca edite comentários alheios em páginas de discussão, mesmo que encontre erros ortográficos ou de digitação. Se achar importante que tais erros sejam corrigidos, procure contatar o usuário, exortando-o a que corrija seus erros. Não é autorizada a edição de comentários alheios. A reincidência em tais atos será interpretada como .
Na eventualidade de haver textos com conteúdo ofensivo ou , contrariando as boas , tente convencer o autor através de sua a remover o conteúdo. Caso não seja atendido e esteja convicto da violação das normas, exponha o caso em .
Pense duas vezes antes de alterar uma . Somente altere o que for imprescindível, tal qual a correção de um atalho. Considere a possibilidade de sugerir a ele(a) a alteração em mente, enviando uma mensagem para a página de discussão dele(a).
Para facilitar a compreensão das discussões, sugere-se que todo o novo comentário seja inserido sempre no final da discussão ou no final da respetiva secção e assinado com quatro tiles: ~~~~.

</doc>
<doc id="751" url="https://pt.wikipedia.org/wiki?curid=751" title="Enciclopédia">
Enciclopédia

Enciclopédia (do Gregoantigo εγκυκλοπαιδεία, transl. "enkyklopaideía", ἐγκυκλο "circular" + παιδεία "educação") é uma coletânea de textos bastante numerosos, cujo objetivo principal é descrever o melhor possível o estado atual do conhecimento humano. Pode-se definir como uma obra que trata de todas as ciências e artes do conhecimento do homem atual. Pode ser tanto um livro de referência para praticamente qualquer assunto do domínio humano como também uma obra na internet.
As enciclopédias podem ser divididas em dois grupos: "genéricas", que coletam conhecimentos de todo o conhecimento humano (como, por exemplo, a Encyclopaedia Britannica), ou especializadas, com tópicos relacionados a um assunto específico (como, por exemplo, uma enciclopédia de medicina ou de matemática).
O termo "enciclopédia" começou a ser utilizado em meados do século XVI, embora trabalhos de formato similar já existissem em épocas anteriores.
A palavra "enciclopédia" provém do Grego Clássico ἐγκύκλιος παιδεία" (transliterado: "enkyklios paideia"), literalmente "educação circular", isto é, "conhecimento geral". Embora a noção de um compêndio de conhecimento remonte a milhares de anos, o termo foi utilizado pela primeira vez no título de um livro publicado em 1541 por Joachimus Fortius Ringelbergius, "Lucubrationes vel potius absolutissima kyklopaideia" (Basileia, 1541). A palavra "enciclopédia" foi utilizada primeiramente como um substantivo, no título do livro do enciclopedista croata Skalić, "Encyclopaedia seu orbis disciplinarum tam sacrarum quam prophanarum epistemon" (Enciclopédia, ou conhecimento do mundo das disciplinas, Basel, 1559). Um dos mais antigos usos em francês foi realizado por François Rabelais em sua obra "Pantagruel", em 1532.
Várias enciclopédias têm nomes que incluem o sufixo "-pedia", como por exemplo a Banglapedia, uma enciclopédia sobre as questões relevantes para Bengala, ou a própria Wikipédia, uma enciclopédia redigida com o sistema wiki.
A enciclopédia como conhecemos hoje foi desenvolvida a partir do dicionário no século XVIII. Um dicionário concentra-se principalmente em palavras e as suas definições e, normalmente, dá uma informação limitada, a análise do uso linguístico ou o contexto para cada termo definido. Essa definição linguística pode deixar de informar ao leitor o significado, a importância ou as limitações de um prazo, ou as relações do termo com um vasto campo de conhecimento.
Para fazer face a essas necessidades, um artigo de enciclopédia aborda, além da palavra, o próprio conceito e também o tema ou disciplina, tratando-os com profundidade, a fim de transmitir o conhecimento acumulado sobre esse tema. Uma enciclopédia muitas vezes também inclui mapas e ilustrações, bem como bibliografias e estatísticas. Historicamente, tanto a enciclopédia como o dicionário foram pesquisados e escritos com o fim de contribuir para a educação e informação, muitas vezes com a contribuição de peritos, ou especialistas.
Algumas obras intituladas "dicionário" são, de facto, similares a uma enciclopédia, especialmente as ligadas a área determinada (como os "Dictionary of the Middle Ages", "Dictionary of American Naval Fighting Ships" e "Black's Law Dictionary"). O "Dicionário Macquarie", reconhecido como o dicionário oficial da Austrália, tornou-se um dicionário enciclopédico após a sua primeira edição, em reconhecimento do uso de nomes próprios em comum, e as palavras derivadas de tais nomes próprios, típicos de uma básica obra enciclopédica.
Grande parte dos escritos que procuravam englobar o conhecimento humano na Antiguidade eram de estilo "específico", ou especializado (geralmente relacionados à natureza ou à filosofia). Alguns dos grandes filósofos da Antiguidade já haviam tentado escrever sobre todos os campos de conhecimento estudados. 
Na China antiga, no século 3 AEC, foi escrito a enciclopédia chinesa mais antiga conhecida, o Erya. O autor do livro é desconhecido. Embora seja tradicionalmente atribuída ao Duque de Zhou , Confúcio , ou os seus discípulos.
Aristóteles escreveu um conjunto de obras sobre os seres vivos, que foram preservadas: "De anima", "Parva naturalia", "Historia animalium", "De partibus animalium", "De motu animalium", "De incessu animalium" e "De generatione animalium". Muitas delas tratam de assuntos bastante teóricos, discutindo os motivos dos fenômenos da vida; outras são mais descritivas, compreendendo um vasto volume de fatos. Em "Historia animalium", o filósofo grego apresentou uma descrição muito detalhada de aproximadamente 550 espécies, incluindo vertebrados e invertebrados. Também tratou de descrever as aparências externa e interna, os costumes dos animais, redigiu uma comparação detalhada entre as espécies e tentou descrever suas principais características e diferenças.
Quatro séculos após a obra de Aristóteles ser publicada, Plínio, o Velho coligiu, em sua obra "Naturalis historiae", todas as informações que pôde encontrar sobre plantas, animais, minerais e diversos outros tópicos, repartidos em 37 partes. A primeira obra apresenta um índice e uma bibliografia por completo. Os livros II a VI tratam, respectivamente, sobre a astronomia e a geografia; os livros VII a XI, tratam sobre a zoologia; os XII a XIX, sobre a botânica e a agricultura; os XX a XXVII, sobre apenas a botânica médica; os livros XXVIII a XXXII descrevem diferentes remédios e antídotos retirados de diferentes animais e do próprio homem; e os livros XXXIII a XXXVII tratam unicamente sobre mineralogia e metais. Essa obra, em conjunto, é considerada uma grande enciclopédia sobre a natureza.
No século X, em Constantinopla, apareceu uma obra coletiva greco-bizantina de grande interesse para o conhecimento da Antiguidade Grega. Trata-se de uma compilação de obras e personagens classificadas de forma inovadora por ordem alfabética que se apresenta, portanto, como a primeira enciclopédia: a Suda. Apesar de várias imprecisões e erros, a Suda contém informações inestimáveis, uma vez que seus autores tiveram acesso a obras agora perdidas. Esse cobiçado livro, nos dias atuais, é conhecido como a primeira enciclopédia de que se tem notícia, pela amplidão de conhecimento atingido (porém, não se extinguem possibilidades de terem existidas outras obras, talvez mais completas, de não tanto sucesso).
Santo Isidoro de Sevilha, um dos maiores estudiosos do início da Idade Média, é amplamente reconhecido como sendo o autor da primeira enciclopédia de que se tem conhecimento dos tempos medievais, o "Etymologiae" (publicado em torno do ano de 630), no qual ele compilou a mais ampla possível aprendizagem disponível na sua época, criando uma enorme leva de conhecimento de 448 capítulos em 20 volumes; é muito valioso não só pela sua importância, mas também por causa das citações e fragmentos de textos de outros autores que teriam sido perdidos, nos tempos atuais não se tem mais vestígios e que não tinha sido feito pelo Santo Isidoro.
"De Rerum proprietatibus" (1240) de Bartholomeus Anglicus foi a mais lida e citada enciclopédia na Baixa Idade Média, enquanto "Speculum Majus" (1260) de Vicente de Beauvais foi a mais ambiciosa enciclopédia do período tardo-medieval, com mais de 3 milhões de palavras.
As primeiras compilações de conhecimento muçulmanas de que se tem notícia na Idade Média incluía muitas obras já completas, e um desenvolvimento respeitosamente vasto do que, agora, chamamos método científico, método histórico, e citação. Por volta do ano 960, os Irmãos da Pureza de Baçorá se empenharam na confecção de sua obra "Enciclopédia dos Irmãos da Pureza". Obras notáveis incluem: enciclopédia de ciências de Abu Bakr al-Razi, a prolífica produção de Al-Kindi de 270 livros, e a enciclopédia médica de Ibn Sina, que foram, por séculos, padrões de referência para trabalhos. Também notáveis são obras de história universal (ou sociologia), como "História de Profetas e Reis" de Asharites, al-Tabri, al-Masudi, Tabari, Ibn Rustah, al-Athir, e Ibn Khaldun, cuja "Muqadimmah" contém alertas quanto a confiança em registos escritos que permanecem totalmente aplicáveis hoje. Esses estudiosos tiveram uma incalculável influência sobre os métodos de investigação e edição, em parte devido à prática islâmica isnad que destacou a fidelidade do registo escrito, verificando fontes, e céticos inquéritos.
Hoje em dia, é creditada a criação da primeira enciclopédia moderna a "Encyclopédie", de 28 volumes, 71 818 artigos, e 2 885 ilustrações, editada por Jean le Rond d’Alembert e Denis Diderot em 1772, tendo como colaboradores Rousseau, Voltaire, Montesquieu e outros ensaístas ilustres. Porém, antes destes respeitáveis iluministas terem atingido um grau de amplitude muito superior, John Harris havia escrito anteriormente, em 1704, a "Lexicon technicum", e a ele é creditado o estabelecer do formato moderno de uma enciclopédia, tal como a conhecemos hoje.
No século seguinte, George Wilhem Hegel publicou a sua "Enciclopédia das Ciências Filosóficas", em que se cristaliza a ideia de enciclopédia como apresentação sistemática de uma ciência ou de um conjunto de ciências.
O formato hierárquico e sua natureza em permanente evolução tornam obras enciclopédicas alvos perfeitos para publicação em formato digital e praticamente todas as grandes enciclopédias tiveram uma versão em CD-ROM no final do século XX. A versão em CD-ROM conta com a vantagem de ser portátil e de produção extremamente econômica. Além disso, uma enciclopédia em formato digital pode ter conteúdos como animações e áudio, impossíveis de serem inseridos numa tradicional publicação escrita. A inclusão de hyperlinks ligando artigos relacionados também é uma enorme vantagem do formato digital.
Por fim, o advento da internet possibilitou a criação das enciclopédias livres, sendo atualmente as mais conhecidas: a Everything2, a Encarta, a h2g2 e a Wikipédia. Nestas, pela primeira vez na história da humanidade, qualquer pessoa pode fazer contribuições e corrigir e/ou ampliar as entradas já existentes, o que resulta num banco de dados universal que é continuamente aperfeiçoado. Este tipo de enciclopédia permite ainda que o significado de um determinado verbete seja consultado em vários idiomas, expandindo os resultados da pesquisa.

</doc>
<doc id="752" url="https://pt.wikipedia.org/wiki?curid=752" title="Encyclopædia Britannica">
Encyclopædia Britannica

A Encyclopædia Britannica é uma enciclopédia generalista de língua inglesa publicada pela Encyclopædia Britannica, Inc., uma editora privada. Os verbetes na "Britannica" têm como público alvo diretamente os leitores adultos cultos; a enciclopédia é escrita por 19 editores em tempo integral e conta com a colaboração de mais de quatro mil peritos. É amplamente considerada como a mais acadêmica das enciclopédias.
A "Britannica" inicialmente foi publicada entre 1768 e 1771, em Edimburgo, Reino Unido, e depressa aumentou em popularidade e tamanho, com a sua terceira edição, em 1801, alcançando os vinte volumes. O aumento de tamanho implicou a contratação de colaboradores, e as suas 9.ª (1875–1889) e 11.ª edições (1911) são consideradas como marcos no que toca a enciclopédias acadêmicas e de estilo literário. Começando com a 11.ª edição, a "Britannica" foi gradualmente diminuindo e simplificando os seus artigos a fim de os tornar mais acessíveis, e alargar a sua expansão ao mercado nos Estados Unidos. Em 1933, a "Britannica" tornou-se a primeira enciclopédia a adotar a política "em contínua revisão", que resulta em que a enciclopédia seja continuamente reimpressa e cada verbete seja atualizado regularmente.
A edição atual (a 15.ª) tem uma única estrutura dividida em três partes: a "Micropædia", de 12 volumes, contém verbetes menores (geralmente tendo menos de 750 palavras), a "Macropædia", de 17 volumes, com longos artigos (tendo de duas a 310 páginas cada) e a "Propædia", num só volume, que pretende fornecer um esboço do conhecimento humano, de modo hierárquico. A "Micropædia" é destinada a pesquisa rápida e a servir como guia para a "Macropædia"; os leitores são aconselhados a estudar o esboço da "Propædia" a fim de entender o contexto do assunto e para encontrar outros artigos, mais detalhados. O tamanho da "Britannica" tem-se mantido muito constante ao longo dos últimos 70 anos, com cerca de 40 milhões de palavras e meio milhão de tópicos. Embora a sua publicação tenha sede nos Estados Unidos desde 1901, a "Britannica" manteve a ortografia inglesa tradicional.
Ao longo da História, a "Britannica" tem tido dificuldade em permanecer rentável — um problema enfrentado por muitas enciclopédias. Alguns verbetes, em determinadas edições anteriores da "Britannica", foram acusados de imprecisão, viés ou falta de qualificação dos colaboradores. A precisão de partes da edição mais recente (de 2005) tem sido igualmente questionada, embora tais críticas tenham sido contestadas pela gestão da "Britannica". Apesar disso, a "Britannica" mantém a sua reputação como fonte de pesquisa confiável. Em 3 de março de 2012, foi anunciado que a "Encyclopædia Britannica", agora com sede em Chicago, não iria publicar mais versões impressas em papel focando-se apenas na sua versão "online".
A propriedade da "Britannica" mudou muitas vezes ao longo do tempo, tendo passado por vários donos como: a editora escocesa A & C Black, Horace Everett Hooper, Sears Roebuck e William Benton. O presente dono da Encyclopædia Britannica, Inc. é Jacqui Safra, de nacionalidade suíça, milionário e ator. Os recentes avanços das tecnologias da informação e o aumento das enciclopédias eletrônicas tais como a "Encarta" e a Wikipédia reduziram a procura de enciclopédias impressas. A fim de permanecer competitiva, a "Encyclopædia Britannica, Inc." tem enfatizado a boa reputação da "Britannica", reduzindo seu preço e os custos de produção e desenvolvido versões eletrônicas em CD-ROM, DVD e World Wide Web. Desde os primeiros anos da década de 1930, a editora promoveu também trabalhos de referência spin-off.
A "Britannica" foi impressa em 15 edições oficiais, com suplementos multi-volumes da 3.ª a 5.ª edições (ver a Tabela abaixo). Estritamente falando, a décima edição foi apenas um suplemento da 9.ª, assim como as edições 12.ª e 13.ª foram suplementos da 13.ª edição. A 15.ª edição sofreu uma mudança drástica, em termos de organização, em 1985, mas a atualização, versão corrente, continuou conhecida como 15.ª edição.
Ao longo de sua história, a "Britannica" foi desenvolvida com dois objetivos: ser um excelente livro de referências e providenciar material educacional para quem tenha desejo de estudar. Em 1974, a 15.ª edição adotou um terceiro alvo: sistematizar todo o conhecimento humano.
A história da "Britannica" pode ser dividida em cinco fases principais em que se destacam mudanças maiores, tanto na gestão quanto na reorganização do seu conteúdo. Na primeira fase (edições 1 a 6, 1768–1826), a "Britannica" foi gerida por seus fundadores originais, Colin Macfarquhar e Andrew Bell, e por seus amigos e conhecidos, tais como Thomas Bonar, George Gleig e Archibald Constable. A "Britannica" foi primeiramente publicada entre 1768 e 1771 em Edimburgo como "Encyclopædia Britannica, ou, Um dicionário de arte e ciência, compilado sob um novo plano". Foi concebida como uma reacção conservadora à provocativa "Encyclopédie" francesa de Denis Diderot (publicada entre 1751 e 1766), que por sua vez havia sido inspirada pela anterior "Chambers Cyclopaedia". A "Britannica" foi, primeiramente, uma empresa escocesa e tinha como símbolo o cardo, o emblema nacional da Escócia. A criação da enciclopédia é um dos mais famosos e perseverantes legados do Iluminismo Escocês. Nesta fase, a "Britannica" deixou de ser um conjunto de três volumes (1.ª edição) compilados por um jovem editor — William Smellie — para se tornar uma obra de vinte volumes escrita por numerosas autoridades. Embora várias outras enciclopédias tenham competido com a "Britannica", como a "Rees's Cyclopaedia" e a "Encyclopaedia Metropolitana", de Samuel Taylor Coleridge, estes rivais ou faliram ou ficaram inacabados por desentendimentos entre os editores. No fim desta fase, a "Britannica" tinha constituído uma rede de ilustradores, primeiramente entre os conhecidos de seus editores, sendo os mais relevantes Constable e Gleig.
Durante a segunda fase (edições 7 a 9, 1827–1901), a "Britannica" foi gerida pela editora de Edimburgo, A & C Black. Embora alguns colaboradores fossem recrutados novamente através de relacionamentos, sendo Macvey Napier o mais relevante, outros foram atraídos pela reputação sempre crescente da "Britannica". Os colaboradores muitas vezes vinham de outros países e incluíam algumas das autoridades mais respeitadas nas suas áreas. Na sétima edição foi incluído, pela primeira vez, um índice geral de todos os artigos, prática que se manteve até 1974. O primeiro editor-chefe nascido em Inglaterra foi Thomas Spencer Baynes, que supervisionou a produção da famosa 9.ª edição; nomeada "Edição Acadêmica", a 9.ª edição é muitas vezes considerada como sendo a "Britannica" mais direcionada ao uso acadêmico alguma vez produzida. No entanto, no fim do século XIX, a 9.ª edição estava desatualizada e a "Britannica" enfrentava sérias dificuldades financeiras.
Na terceira fase (10.ª a 14.ª edições, 1901–1973), a "Britannica" foi gerida por negociantes estadunidenses, que introduziram técnicas de venda agressivas, tais como o marketing direto e venda porta a porta, a fim de aumentar os lucros. Os donos norte-americanos simplificaram, gradualmente, os verbetes da "Britannica", fazendo-a menos acadêmica, mas mais inteligível para o mercado das massas. A décima edição foi rapidamente produzida, como suplemento da 9.ª, mas a 11.ª edição ainda é prezada pela sua excelência; o seu dono, Horace Everett Hooper, esforçou-se na busca da sua perfeição. Quando Hooper entrou em dificuldades financeiras, a "Britannica" passou a ser gerida por Sears Roebuck durante cerca de 18 anos (1920–1923, 1928–1943). Em 1932, a vice-presidente de Sears, Elkan Harrison Powell, assumiu a presidência da "Britannica"; em 1936, começou a política de revisão contínua (ainda praticada), que faz com que cada verbete seja verificado e possivelmente revisado pelo menos duas vezes em cada década. Esta foi uma grande mudança pois, com a prática anterior, os artigos não eram alterados a não ser aquando de uma nova edição, com cerca de 25 anos de intervalo, com alguns artigos sendo transportados de edições anteriores sem alteração. Powell, agressivamente, desenvolveu novos produtos educacionais, que se baseavam na reputação da "Britannica". Em 1943, a posse passou de Sears Roebuck para William Benton, diretor da "Britannica" até sua morte, em 1973. Benton fundou ainda a Fundação Benton, que geriu a "Britannica" até 1996. Em 1968, perto do fim desta fase, a "Britannica" celebrou o seu bicentenário.
Na quarta fase (15.ª edição, 1974–1994), a "Britannica" introduziu a sua 15.ª edição, que foi reorganizada em três partes: a "Micropædia", a "Macropædia" e a "Propædia". Sob influência de Mortimer J. Adler (membro do quadro de editores da "Encyclopædia Britannica" desde o seu ingresso na companhia, em 1949, e seu presidente desde 1974; diretor dos planos para realização da 15.ª edição da "Britannica", desde 1965), a "Britannica" procurou não só ser uma boa obra de referência e uma ferramenta educacional, mas também sistematizar todo o conhecimento humano. A ausência de um índice separado e o agrupamento de artigos em duas enciclopédias paralelas (a "Micro-" e a "Macropædia") provocaram uma "tempestade de críticas" sobre a 15.ª edição, inicialmente. Em resposta, a 15.ª edição foi totalmente reorganizada e indexada para novo lançamento em 1985. A segunda versão da 15.ª edição continua a ser revisada e publicada; a versão mais recente foi impressa em 2007. O título oficial da 15.ª edição é "Nova Encyclopædia Britannica", e está ainda a ser promovida como "Britannica 3".
Na quinta fase (1994–presente), foram desenvolvidas versões digitais da "Britannica", lançadas em disco óptico e internet. Em 1996, a "Britannica" foi comprada à Fundação Benton por Jacqui Safra, bastante abaixo do seu valor, devido às dificuldades financeiras por que a editora passava. A editora Encyclopædia Britannica, Inc. dividiu-se em 1999. Uma parte manteve o nome da companhia e desenvolveu a versão impressa; a outra parte, Britannica.com Inc., desenvolveu as versões digitais. Desde 2001, estas duas companhias partilharam um único CEO, Ilan Yeshua, que continuou a estratégia de expansão da "Encyclopædia Britannica, Inc." de Elkan Harrison Powell em lançar novos produtos sob a marca "Britannica".
A "Britannica" foi dedicada aos monarcas britânicos de 1788 a 1901 e, após sua venda a uma sociedade estadunidense, ao monarca britânico e ao presidente dos EUA. Assim, a 11.ª edição foi "dedicada, com permissão, a Sua Majestade Jorge V, Rei da Grã-Bretanha e Irlanda e dos Domínios Britânicos de além-mar, Imperador da Índia, e a William Howard Taft, Presidente dos Estados Unidos da América." A ordem destas duas dedicatórias mudou com os poderes relativos dos EUA e da Grã-Bretanha, e com as vendas relativas da "Britannica" nesses países; a versão de 1954 da 14.ª edição é "dedicada, com permissão aos Chefes de Estado das Duas Nações Anglófonas, Dwight D. Eisenhower, Presidente dos Estados Unidos da América, e a sua Majestade, Isabel II." De acordo com esta tradição, a versão de 2007 da corrente 15.ª edição é "dedicada, com permissão, ao ex Presidente dos Estados Unidos da América, George W. Bush, e a sua Majestade, Elizabeth II."
Desde a 3.ª edição, a "Britannica" usufruiu de uma reputação excelente, tanto popular como crítica. Várias edições, desde a 3.ª a 9.ª foram pirateadas para venda nos EUA, começando com a Dobson's Encyclopædia. No lançamento da 14.ª edição a revista "Time" batizou a "Britannica" como "O Patriarca das Bibliotecas". Em um anúncio relacionado, o naturalista William Beebe foi citado como dizendo que a "Britannica" estava "além de comparação porque não há nenhum concorrente."
Referências à "Britannica" podem ser encontradas em meio da literatura inglesa, notadamente na obra de Arthur Conan Doyle, em seu personagem mais conhecido, Sherlock Holmes, na história "The Red-Headed League". Este conto foi realçado pelo Lord Mayor of London, Gilbert Inglefield, durante o bicentenário da "Britannica"
A obra goza de reputação popular como o sumário de todo o conhecimento humano. A fim de aprimorar seus conhecimentos, muitos se dedicaram à leitura de toda a enciclopédia, levando de 3 a 22 anos para consegui-lo. Quando Fat'h Ali Shah Qajar se tornou o Xá da Pérsia, em 1797, foi-lhe ofertado um conjunto completo da 3.ª edição da "Britannica", que ele leu na íntegra; depois deste feito, ele estendeu o seu título real, incluindo "O Mais Formidável Senhor e Mestre da "Encyclopædia Britannica"”. O escritor George Bernard Shaw afirma ter lido inteira a 9.ª edição — excepto os artigos científicos — e Richard Evelyn Byrd levou a "Britannica" como material de leitura para a sua estadia de cinco meses no Polo Sul, em 1934. Mais recentemente, A.J. Jacobs, um editor da revista Esquire, leu a versão inteira de 2002 da 15.ª edição, descrevendo as suas experiências num livro, em 2004, intitulado "The Know-It-All: One Man's Humble Quest to Become the Smartest Person in the World" (“O Sabe-tudo: Um homem humilde indaga como se tornar a pessoa mais inteligente do mundo”, em livre tradução). Apenas duas pessoas se conhece como tendo lido duas edições diferentes: o autor C. S. Forester e Amos Urban Shirk, um negociante estadunidense, que leu a 11.ª e a 14.ª edições, dedicando, para isso, cerca de três a quatro horas e meia por noite para ler a 11.ª. Vários editores-chefes da "Britannica" provavelmente leram as suas edições na íntegra, tais como William Smellie (1.ª edição), William Robertson Smith (9.ª edição), e Walter Yust (14.ª edição).
A "Britannica" tem recebido diversas premiações ao longo de sua existência. A versão on-line ganhou, em 2005, o Prêmio Codie para "Melhor Serviço Online de Informação ao Cliente"; os prêmios Codie são concedidos anualmente pela "Software and Information Industry Association" a fim de reconhecer os melhores produtos entre as categorias de software. Em 2006, a "Britannica" foi de novo finalista. Similarmente, a versão CD/DVD-ROM da "Britannica" recebeu, em 2004, o Prêmio de Distinção, pela "Association of Educational Publishers", e prêmio Codie, em 2001 e 2002.
Como enciclopédia generalista, a "Britannica" procura descrever a mais ampla gama de assuntos possível. Os temas são escolhidos, em parte, por referência no "Esboço do Conhecimento" da "Propædia". Grande parte da "Britannica" é dedicada à geografia (26% da "Macropædia"), biografia (14%), biologia e medicina (11%), literatura (7%), física e astronomia (6%), religião (5%), arte (4%), filosofia ocidental (4%), e direito (3%). Um estudo complementar da "Micropædia" descobriu que 25% dos verbetes eram do ramo da geografia, 18% de ciências exatas, 17% das ciências humanas, 17% eram biografias, e 25% sobre todos os outros ramos das humanidades. Em 1992, um revisor escreveu que "o alcance, a profundidade, a exatidão da análise [da "Britannica"] são insuperáveis por qualquer outra enciclopédia generalista."
A "Britannica" não trata os tópicos equivalentes com igual riqueza de detalhes; por exemplo, o verbete Budismo e a maioria das outras religiões são cobertas por um único verbete da "Macropædia", enquanto que 14 verbetes são dedicados ao Cristianismo, representando cerca de metade de todos os verbetes sobre religião. No entanto, tem recebidos louvores por ser considerada a menos "enviesada" de todas as enciclopédias generalistas, comercializadas para leitores ocidentais e prezada pelas suas biografias de mulheres importantes de todas as eras.
A "Britannica" também tem recebido fortes críticas, especialmente quando as suas edições se tornam desatualizadas. É dispendioso produzir uma nova edição, completa, da "Britannica," e os seus editores, em geral, atrasam as novas edições, tanto quanto sensatamente possível (por norma, cerca de 25 anos). Por exemplo, apesar da política de revisão contínua, a 14.ª edição ficou significativamente desatualizada após 35 anos (1929–1964). Quando o físico norte-americano Harvey Einbinder detalhou os seus erros no seu livro de 1964, "The Myth of the Britannica", o feito resultou em que a enciclopédia produziu a 15.ª edição, que requereu dez anos de trabalho. Continua sendo difícil manter a "Britannica" atualizada; um crítico escreveu, recentemente, que "não é difícil encontrar verbetes desatualizados ou a precisar de revisão", constatando que os artigos maiores, da "Macropædia", correm mais riscos de estarem desatualizados do que os mais curtos, da "Micropædia". A informação na "Micropædia" por vezes é inconsistente com a matéria correspondente no verbete da "Macropædia", principalmente porque uma delas está desatualizada. As bibliografias dos artigos da "Macropædia" obtiveram mais críticas por estarem mais desatualizadas do que pelos artigos em si.
Historicamente, dentre os autores da "Britannica"' foram incluídas autoridades eminentes, tais como Albert Einstein, Marie Curie e Leon Trotsky. No entanto, alguns dos seus colaboradores têm sido criticados pela sua falta de conhecimento técnico específico:
Várias autoridades, desde Virginia Woolf até professores académicos, têm criticado a "Britannica" por esta conter opiniões burguesas e antiquadas sobre as artes, a literatura e as ciências sociais. Por exemplo, a 11.ª edição foi acusada de negligenciar a obra de Sigmund Freud. Um professor contemporâneo da Universidade Cornell, Edward B. Titchener, escreveu, "a "Britannica" não reproduz a atmosfera filosófica dos seus dias e sua geração… Apesar da aura de autoridade, e apesar da fiscalização do pessoal, a grande maioria dos artigos secundários, em geral psicologia;… não estão adequados aos parâmetros da cultura do leitor."
Pelos padrões modernos, as edições passadas da "Britannica" contiveram artigos cobertos de racismo e sexismo. A 11.ª edição caracteriza a Ku Klux Klan como que protegendo a raça branca e restaurando a ordem aos Estados Sulistas depois da guerra civil, citando a necessidade de "controlar os negros" para "prevenir qualquer combinação de raças" e "a frequente ocorrência do crime de violação de mulheres brancas, por homens negros." Similarmente, o verbete sobre "Civilização" argumenta sobre eugenia, afirmando que é irracional "propagar pessoas com baixo grau de inteligência, aumentando as fileiras dos pobres, deficientes e criminosos, que hoje em dia constituem obstáculo a ameaçar o progresso racial." A 11.ª edição não biografou Marie Curie, apesar de ela ter recebido o Nobel de Física de 1903 e o Nobel de Química de 1911, embora seja brevemente mencionada na biografia do marido Pierre Curie. A "Britannica" empregava uma vasta equipa feminina, que escreveu centenas de verbetes, pelos quais não obtiveram qualquer crédito.
Em 1912, o matemático L. C. Karpinski criticou a 11.ª edição da "Britannica" pelas suas muitas imprecisões em artigos de história da matemática, nenhum dos quais havia sido escrito por especialistas da área. Em 1917, o crítico de arte Willard Huntington Wright publicou o livro, "Misinforming a Nation", que trouxe a público as imprecisões na língua inglesa da 11.ª edição, particularmente nos verbetes sobre humanidades. Muito das críticas de Wright foram também endereçadas a edições posteriores da "Britannica". No entanto, o seu livro foi acusado de polêmico por alguns órgãos da imprensa de seu tempo; por exemplo, o "New York Times" descreveu-o como "livro maldoso e frívolo", enquanto o "The New Republic" opinava que "é uma infelicidade para o propósito do Sr. Wright, o facto de ter procedido de modo anticientífico e ter justificado tão pouco a sua crítica" Outro crítico, o escritor inglês e antigo padre Joseph McCabe, afirmou em seu livro "Lies And Fallacies of The Encyclopedia Britannica" (1947), que a "Britannica" era susceptível à pressão editorial da Igreja Católica Romana.
A "Britannica" sempre admitiu que os erros eram inevitáveis numa enciclopédia. Falando da 3.ª edição (1788-97), seu editor-chefe George Gleig escreveu que “a perfeição parece ser incompatível com a natureza do trabalho de construir-se algo como este planejado, e que alberga tamanha variedade de assuntos”. Mais recentemente (março de 2006), a Britannica trouxe uma mensagem onde lia-se que “nós nunca insinuamos que a "Britannica" é livre de erros, nunca fizemos tal afirmação”.
O sentimento é expressado pelo editor original da obra, William Smellie:
Desde 1985, a enciclopédia está dividida em quatro partes: a "Micropædia," a "Macropædia," a "Propædia," e os dois volumes do índice. Seus verbetes estão contidos na "Micro-" e "Macropædia" com doze e 17 volumes, respectivamente, cada um deles contendo aproximadamente mil páginas. A versão de 2007 traz 699 artigos na "Macropædia", que variam em tamanho de duas até 310 páginas, contendo referências e nome dos autores; em contrapartida, a "Micropædia" possui cerca de 65 mil verbetes, a grande maioria dos quais (em volta de 97%) contendo menos que 750 palavras, nenhuma referência e nenhum colaborador assinando. Estes artigos foram planejados para oferecer uma informação rápida, e para auxiliar a localização rápida do conteúdo disponível na "Macropædia" que, por sua vez, possui artigos elaborados por autoridades e bem-escritos dentro de cada especialização, contendo dados reunidos sobre o tema que não se encontram noutra parte. O mais longo artigo, com 310 páginas é sobre os Estados Unidos da América, e é resultado da fusão dos artigos de todos os 50 estados. As informações podem ser encontradas seguindo-se as referências cruzadas entre "Micro" e "Macropædia" - embora elas sejam escassas, sendo calculada uma média de uma referência cruzada por página. Conseqüentemente, recomenda-se aos leitores que façam a busca no índice alfabético inicialmente, ou à "Propædia", que organizam o conteúdo geral através de tópicos.
O lema da "Propædia" é "Esboço do Conhecimento" ("Outline of Knowledge"), indicando que pretende realizar uma organização lógica para todo o conhecimento humano. Efetivamente, esse esboço é usado pelos editores da enciclopédia para decidir quais artigos devem ser incluídos nas duas outras subdivisões. Também tem a pretensão de servir de guia ao consulente, sugerindo-lhe os artigos que deverá ler para ter um conhecimento mais aprofundado sobre o tópico. As bibliotecas, entretanto, constataram que este volume é raramente utilizado, e os revisores sugeriram que fosse abolido da enciclopédia. A "Propædia" também possui transparências coloridas da anatomia humana, e vários apêndices contendo a listagem dos membros administrativos, conselheiros e colaboradores de todas as três subdivisões da obra.
Vistas juntas, "Micropædia" e "Macropædia" contêm cerca de 40 milhões de palavras e 24 mil imagens. Os dois volumes de índice têm 2.350 páginas, listando 225.274 tópicos junto com 474.675 sub-entradas sob esses tópicos. A ortografia britânica é preferida sobre a norte-americana, em geral; como exemplo, a palavra "colour" é usada ao invés de "color", "centre" no lugar de "center" e "encyclopaedia" em vez de "encyclopedia". Entretanto, algumas exceções ocorrem, como uso de "defense" ao invés do britânico "defence". A solução alternativa encontrada é o uso de referências cruzadas como em "Color: "see" Colour."
Desde 1936 os artigos são revisados em períodos regulares, considerando que a cada ano ao menos 10% deles sejam revisados. De acordo com um dos sítios da "Britannica", 46% dos artigos são revisados a cada três anos; entretanto, em outro sítio, é informado que apenas 35% dos verbetes sofrem revisão neste período.
A ordenação alfabética dos artigos na "Micro-" e "Macropædia" segue a regras rígidas.
Diacríticos e letras não usadas no inglês são ignorados, enquanto entradas numéricas como ""1812, War of" são ordenadas como se os números fossem escritos na forma cardinal ("Eighteen-twelve, War of"). Verbetes com nomes iguais recebem a seguinte ordem: primeiro as pessoas, depois os lugares e por último as coisas. Governantes com nomes idênticos são seqüenciados primeiro pelo país, e em seguida pela cronologia; Assim, Carlos III da França ("Charles III of France") precede a Carlos I do Reino Unido ("Charles I of England"), por ser listado na "Britannica" como rei da Grã-Bretanha e Irlanda ("Great Britain and Ireland") - ou seja, são listados como se seus nomes fossem escritos assim: "Charles, France, 3" e "Charles, Great Britain and Ireland, 1". De forma similar, os lugares de nomes iguais são organizados alfabeticamente pelos países, e depois pela condição das subdivisões políticas.
Existem diversas edições abreviadas da enciclopédia "Britannica". A "Concise", por exemplo, reúne num só volume 28 mil verbetes curtos que condensam os 32 volumes da edição integral. A "Compton's by Britannica", que incorpora o formato da Enciclopédia Compton, e dirigida a crianças e adolescentes entre 10-17 anos, consiste em 26 volumes e 11 mil páginas.
Outros produtos incluem o "My First Britannica", voltado para crianças entre 6 a 12 anos, e a "Britannica Discovery Library", escrita para crianças com idades de 3 a 6 anos.
Desde 1938 a Encyclopædia Britannica, Inc. edita anualmente o "Book of the Year" ("Livro do Ano"), reunindo os eventos ocorridos no último ano, e que estão disponíveis on-line a partir da edição de 1994 (com os eventos de 1993, portanto).
A companhia ainda edita material especializado de referência, trabalhos como "Shakespeare: The Essential Guide to the Life and Works of the Bard"" ("Shakespeare: O Guia Essecial da Vida e da Obra do Bardo") (Wiley, 2006).
O "Britannica Ultimate Reference Suite 2006 DVD" contém mais de cem mil artigos. Inclui 73.645 artigos da "Britannica" impressa, com restante de material da "Britannica Student Encyclopædia", da "Britannica Elementary Encyclopædia" e do "Britannica Book of the Year" (1993–2004), e ainda alguns artigos "clássicos" das primeiras versões da enciclopédia. O pacote inclui uma gama de conteúdos adicionais, como mapas, vídeos, clipes sonoros, animações e ligações à web. Também oferece ferramentas de estudo e entradas de dicionário e léxico da Merriam-Webster.
A "Encyclopædia Britannica On-line" é um site com mais de 120 mil artigos atualizados regularmente. Possui referências diárias, atualizações e ligação para notícias do "The New York Times" e da "BBC". A assinatura do conteúdo pode ser anual, mensal ou semanal. Planos especiais de assinatura são oferecidos a escolas, faculdades e bibliotecas; estes subscritores institucionais são uma parte importante dos negócios da "Britannica". Alguns artigos têm acesso livre, mas são exibidas apenas algumas linhas de texto. Iniciado no começo de 2007, a "Britannica" vem disponibilizando ligações para artigos com acesso livre, em sítios externos. Tais ligações externas melhoram com frequência o ranking dos artigos nos resultados dos buscadores.
Em 20 de fevereiro de 2007 a "Encyclopædia Britannica, Inc." anunciou que irá trabalhar com a companhia de buscas em telefonia móvel AskMeNow a fim de lançar uma enciclopédia móvel. Os usuários poderão enviar uma pergunta por mensagem de texto, e a AskMeNow procurará num dos 28 mil verbetes da "Britannica" uma resposta concisa para a questão. Tópicos diários, que serão enviados diretamente aos celulares dos usuários, também fazem parte do plano.
A versão impressa de 2007 da "Britannica" ostenta 4.411 colaboradores, com figuras proeminentes, entre eles o Nobel de Economia Milton Friedman, o astrônomo Carl Sagan e o cirurgião Michael DeBakey. Um quarto dos colaboradores já faleceu, alguns há tempo tão distante como em 1947 (caso de Alfred North Whitehead), enquanto outro quarto é aposentado ou emérito. A maioria (98%, aproximadamente), contribui para um único artigo; entretanto, 64 contribuíram em três artigos, 23 ajudaram em quatro, dez contribuíram em cinco e oito contribuíram em mais de cinco verbetes. Uma exceção prolífica foi o Drª. Christine Sutton, da Universidade de Oxford, que contribuiu em 24 artigos sobre física de partículas.
Dale Hoiberg, um sinólogo, é presentemente o vice-presidente sênior e editor-chefe da Britannica. Seus predecessores como editores-chefes foram Hugh Chisholm (1902–1924), James Louis Garvin (1926–1932), Franklin Henry Hooper (1902–1938), Walter Yust (1938–1960), Harry Ashmore (1960–1963), Warren E. Preece (1964–1968, 1969–1975), Sir William Haley (1968–1969), Philip W. Goetz (1979–1991), e Robert McHenry (1992–1997). Anita Wolff e Theodore Pappas são editora assistente e editor executivo, respectivamente. Editores executivos anteriores incluem John V. Dodge (1950–1964) e Philip W. Goetz.
A "Britannica" mantém um departamento editorial com cinco editores seniores, e nove editores associados, supervisado por Dale Hoiberg e outros quatro. O departamento editorial auxilia na autoria dos artigos da "Micropædia" e nalgumas seções da "Macropædia".
A "Britannica" possui um quadro de conselheiro editoriais, que correntemente inclui 14 acadêmicos distintos:
A "Propædia" e seu "Outline of Knowledge" são feitos por dúzias de conselheiros editoriais sob a direção de Mortimer J. Adler. Metade destes conselheiros já é falecida, incluindo antigos chefes dos editores dessa seção: René Dubos (m. 1982), Loren Eiseley (m. 1977), Harold D. Lasswell (m. 1978), Mark Van Doren (m. 1972), Peter Ritchie Calder (m. 1982) e Mortimer J. Adler (m. 2001). A "Propædia" lista ainda quatro mil colaboradores que foram consultados, mas que não assinaram os artigos da "Micropædia".
Em janeiro de 1996, a "Britannica" pertencente à Benton Foundation (Fundação Benton), foi comprada pelo milionário suíço das finanças Jacqui Safra, e que atualmente é o presidente do quadro administrativo. Em 1997, Don Yannias, sócio de longa data e conselheiro de negócios de Safra, tornou-se o executivo-chefe da Encyclopædia Britannica, Inc.. Uma nova companhia, a Britannica.com Inc., foi iniciada em Spin-off em 1999, para desenvolver uma versão digital da "Britannica", tendo Yannias a chefia desse empreendimento, enquanto o cargo equivalente da Encyclopædia Britannica, Inc. permaneceu acéfalo por dois anos. A gestão de Yannias deu prejuízos, grandes demissões e perdas financeiras. Em 2001, ele foi finalmente substituído por Ilan Yeshua, que reuniu a direção das duas companhias. Yannias retornou mais tarde como administrador financeiro, mas não mais integrou o Conselho de Administração da "Britannica".
Em 2003, o então consultor administrativo Jorge Aguilar-Cauz foi nomeado presidente da Encyclopædia Britannica, Inc. Cauz é executivo sênior e reporta-se diretamente ao Conselho Administrativo da empresa. Apesar de seu estilo dominador e acadêmico, realizou alianças agressivas com outras empresas e estendeu a marca Britannica como um marco e como produto de referência educativa, continuando uma estratégia iniciada ainda em meados dos anos 30 por seu predecessor Elkan Harrison Powell.
Sob a propriedade de Safra a companhia sofreu dificuldades financeiras, o que foram enfrentadas com a redução dos preços de seus produtos e implementação de drásticos cortes de gastos. De acordo com um relatório de 2003 do "New York Post", a administração da "Britannica" demitiu os empregados do plano 401(k) e encorajou o uso de imagens sem direito autoral. Estas mudanças, porém, tiveram impactos negativos, como por exemplo a demora de seis meses no pagamento dos colaboradores independentes, e seu pessoal passou vários anos sem melhoria de salários
A Encyclopædia Britannica, Inc. possui atualmente as marcas registradas das palavras "Britannica", "Encyclopædia Britannica", "Macropædia", "Micropædia", e "Propædia", como também do seu logotipo em formato de cardo. Vem exercendo seus direitos de copyright desde 2005
Por ser uma obra genérica, a "Britannica" não compete com enciclopédias especializadas, como por exemplo uma "Encyclopaedia of Mathematics" ou um "Dictionary of the Middle Ages" ("dicionário da Idade Média"), obras que podem dedicar muito mais espaço aos temas específicos de que tratam. Em seus primeiros anos, o principal concorrente, em língua inglesa, era a enciclopédia geral de Ephraim Chambers e, logo após, "Rees's Cyclopaedia" e a "Encyclopaedia Metropolitana", de Coleridge. No século XX, os mais diretos competidores foram "Collier's Encyclopedia," a "Encyclopedia Americana," e o "World Book Encyclopedia". Cada uma dessas publicações tinha qualidades para tornar-se excelente, com escrita excepcionalmente clara ou ilustrações soberbas. Não obstante, era consideração geral que a "Britannica" possuía maior autoridade do que qualquer outra enciclopédia em língua inglesa, especialmente em razão de sua extensa abrangência e por possuir em seus quadros autores eminentes. Entretanto, a versão impressa da Britannica é mais cara do que a de seus competidores.
Desde o começo dos anos 90 que a "Britannica" enfrenta o desafio de novas fontes de informação digitais. A internet, facilitada com o desenvolvimento dos sistemas de busca, cresceu como uma fonte comum de informação para muitas pessoas, provendo acesso fácil e rápido a fontes originais seguras e opiniões de expertos, graças em parte a iniciativas como o Google Books, o MIT e seu "MIT OpenCourseWare", e ainda a "PubMed Central" - uma biblioteca livre da National Library of Medicine. Em geral, a internet tende a prover cobertura mais atual do que a mídia impressa, devido à facilidade de atualização. Em campos com rápidas mudanças tal como ciência, tecnologia, política, cultura e história moderna, a "Britannica" luta para manter-se atualizada, um problema que foi sistematicamente analisado, inicialmente por seu ex-editor Walter Yust. Embora a enciclopédia esteja disponível atualmente em multimídia e ainda na internet, sua primazia é desafiada por outras enciclopédias on-line, como a "Encarta" e a "Wikipédia".
A "Encyclopædia Britannica" foi comparada com outras enciclopédias impressas, tanto qualitativa como quantitativamente. O comparativo mais famoso foi feito em nos anos 90 por Kenneth Kister, que traçou um paralelo desta com a "Collier's Encyclopedia" e a "Encyclopedia Americana". Para a análise "quantitativa", dez artigos foram escolhidos ao acaso: circuncisão, Charles Drew, Galileu, Philip Glass, cardiopatia ("doenças cardíacas"), QI, urso panda, assédio sexual, Santo Sudário e Uzbequistão - e notas (A-D, F) foram atribuídas em quatro categorias: amplitude, precisão, clareza e atualização. Em todas as quatro categorias avaliadas, e para as três enciclopédias, as médias atribuídas ficaram entre B- e B+, principalmente porque nenhuma delas apresentava, em 1994, nenhum verbete sobre assédio sexual. Na categoria precisão, a "Britannica" recebeu um "D" e oito "A"s. A "Encyclopedia Americana" teve oito "A"s, e a "Collier's" recebeu um "D" e sete "A"s; Assim a "Americana" ficou com 95%, enquanto as duas outras tiveram 92% no quesito "precisão". A edição de 1994 da "Britannica" falhou por publicar uma história polêmica sobre Charles Drew, que havia sido desmentida há muito tempo. No quesito cronologia, a "Britannica" recebeu aprovação de 86%, a "Americana" 90% e a "Collier's" 85%. Depois de uma análise comparativa mais completa entre as três enciclopédias, Kister recomendou a "Collier's Encyclopedia" como a superior entre as três, considerando principalmente a escrita excelente, apresentação equilibrada e facilidade na consulta.
O mais notável competidor da "Britannica" em matéria de enciclopédias digitais em CD/DVD-ROM é a Encarta, uma moderna enciclopédia de multimédia que incorpora três enciclopédias impressas: "Funk and Wagnalls", "Collier's" e "New Merit Scholar". A "Encarta" é a mais vendida enciclopédia multimédia, tomando por base a venda a varejo no mercado norte-americano entre janeiro de 2000 a fevereiro de 2006
Ambas ocupam a mesma faixa de preços, sendo que em 2007 o último CD ou DVD da "Encyclopædia Britannica" valia 50 dólares estadunidenses e o DVD da "Microsoft Encarta Premium 2007" valia 45 dólares estadunidenses. A "Britannica" possui cem mil artigos, além do Dicionário "Merriam-Webster" (somente na edição norte-americana), e oferece edições mais simplificadas para as escolas primárias e secundárias. A "Encarta" possui 66 mil verbetes, uma interface amigável personalizada, mapas interativos, matemática, gramática e ferramentas para trabalhos escolares, dicionários de língua inglesa em versões dos EUA e do Reino Unido, e uma edição para jovens. Assim como a "Encarta", a "Britannica" foi criticada por ter edição parcial, dirigida ao público estadunidense; verbetes referentes ao Reino Unido são bem menos atualizados, os mapas dos EUA são mais detalhados que dos demais países e falta um dicionário do Reino Unido.
As duas enciclopédias estão disponíveis on-line por assinatura, embora mantenham parte do conteúdo para livre acesso.
Alternativas on-line para a "Britannica" incluem a Wikipédia, uma iniciativa livre e pioneira na Web, com conteúdo livre. A "Wiki" recebe um tráfego 450 vezes maior que a versão on-line da "Britannica", segundo estatísticas independentes de visita em páginas feitas pela Alexa, nos primeiros três meses de 2007. Julgando pelos mais recentes dados de número de artigos ou palavras, a versão anglófona da "Wikipédia" é 20 vezes maior que a "Britannica".
Uma diferença fundamental entre as duas enciclopédias reside na autoria dos verbetes. Os 699 artigos da Macropædia em geral são produzidos por colaboradores identificados, e os 65 mil da Micropædia são fruto do corpo editorial e identifica apenas os consultores. Assim, um verbete da "Britannica" ou identifica seu autor ou um grupo de possíveis autores (o corpo editorial). Com exceção destes últimos, a maioria dos colaboradores da "Britannica" é de peritos em suas áreas, inclusive com laureados pelo prêmio Nobel. Em contrapartida, os artigos da "Wikipédia" são escritos por uma comunidade de editores de níveis variados de conhecimento: a maioria dos editores não atribui nenhuma especialização em particular; dentre aqueles que o fazem, muitos são anônimos e não possuem alguma credencial verificável.
Outra diferença é a velocidade de mudanças nos verbetes: a "Britannica" é publicada em modo impresso em intervalos de poucos anos, ao passo em que os artigos da "Wiki" mudam com frequência. Esta vem recebendo críticas em vários aspectos, e argumenta-se que não se pode esperar que venha competir com a "Britannica" em termos de precisão.
Em 14 de dezembro de 2005, o jornal científico "Nature" informou que existiam 162 erros na "Wikipédia" contra 123 na "Britannica", dentro de 42 verbetes sobre ciências gerais, fortuitamente selecionados. Em sua réplica, detalhada em 20 páginas, a Encyclopædia Britannica, Inc. caracterizou o estudo da "Nature" como falho e enganado, e exigiu uma "imediata" retratação. Observou que dois dos artigos eram estudos feitos pelo "livro do ano" da edição, e não eram enciclopédicos; outros dois pertenciam à "Compton's Encyclopedia" (chamadas pelo sítio oficial da companhia de "Britannica Student Encyclopedia" - "enciclopédia estudantil"). A refutação menciona que alguns dos artigos apreciados pelos revisores eram combinados de vários verbetes, e que os outros artigos eram apenas excertos e foram penalizados por omissões factuais. A companhia também observou que vários fatos classificados pela "Nature" como erros eram variações menores de ortografia, e vários dos demais alegados erros eram questão de interpretação. A "Nature" defendeu sua publicação e não se retratou, declarando ainda que, como estava a comparar a "Wikipédia" com a versão na rede da "Britannica", utilizou-se do material que esta última disponibilizava em seu sítio da Web.
A Barsa, fundada no Brasil em 1949, hoje pertence ao grupo espanhol Planeta. Embora seu conteúdo seja oriundo da original da matriz, a marca acabou adquirindo uma identidade própria, a ponto de tornar-se a mais importante enciclopédia lusófona. Foi editada no país sob os auspícios da Encyclopaedia Britannica do Brasil Publicações Ltda. Na década de 1970, sob a direção do Imortal da ABL, Antônio Houaiss, lançou a Enciclopédia Mirador Internacional
Alguns produtos tiveram existência curta devido à evolução tecnológica, como foi o caso da "Videopédia". Dentre os principais produtos da Barsa estão:
Composta em três mídias distintas, a enciclopédia possui atualizações semanais pela Internet, através de seu sítio. Possui um “Conselho Acadêmico” do qual fazem parte catorze universidades.
Possui mais de 122 mil verbetes, dos quais 500 são desenvolvidos para concentrar as informações temáticas, ilustrada em mais de dez mil fotografias, 900 desenhos, 500 mapas e 300 tabelas
A Barsa Society possui diversos lançamentos em várias mídias. São produtos como livros de Direito, Enciclopédia Multimédia do corpo humano (em 6 cd-roms) , tradutores etc.
A Barsa está presente em vários países de língua castelhana, como Argentina, Chile, Espanha, México e Venezuela e também em Portugal.
Sítio oficial
Verbetes históricos
Edições anteriores (em domínio público nos EUA)
Eventos recentes
Histórico da empresa

</doc>
<doc id="753" url="https://pt.wikipedia.org/wiki?curid=753" title="Lista de escultores">
Lista de escultores

Esta é uma lista de escultores.

</doc>
<doc id="754" url="https://pt.wikipedia.org/wiki?curid=754" title="Expressão regular">
Expressão regular

Em ciência da computação, uma expressão regular (ou o estrangeirismo regex, abreviação do inglês "regular expression") provê uma forma concisa e flexível de identificar cadeias de caracteres de interesse, como caracteres particulares, palavras ou padrões de caracteres. Expressões regulares são escritas numa linguagem formal que pode ser interpretada por um processador de expressão regular, um programa que serve um gerador de analisador sintático ou examina o texto e identifica as partes que casam com a especificação dada.
O termo deriva do trabalho do matemático norte-americano Stephen Cole Kleene, que desenvolveu as expressões regulares como uma notação ao que ele chamava de álgebra de conjuntos regulares. Seu trabalho serviu de base para os primeiros algoritmos computacionais de busca, e depois para algumas das mais antigas ferramentas de tratamento de texto da plataforma Unix.
O uso atual de expressões regulares inclui procura e substituição de texto em editores de texto e linguagens de programação, validação de formatos de texto (validação de protocolos ou formatos digitais), realce de sintaxe e filtragem de informação.
Uma expressão regular (ou, um padrão) descreve um conjunto de cadeias de caracteres, de forma concisa, sem precisar listar todos os elementos do conjunto. Por exemplo, um conjunto contendo as cadeias ""Handel", "Händel" e "Haendel" pode ser descrito pelo padrão codice_1. A maioria dos formalismos provê pelo menos três operações para construir expressões regulares.
A primeira delas é a alternância, em que uma barra vertical (codice_2) separa alternativas. Por exemplo, codice_3 pode casar "psicadélico" ou "psicodélico". A segunda operação é o agrupamento, em que parênteses (codice_4, codice_5) são usados para definir o escopo e a precedência de operadores, entre outros usos. Por exemplo, codice_3 e codice_7 são equivalentes e ambas descrevem "psicadélico" e "psicodélico". Por fim, a terceira operação é a quantificação (ou repetição). Um quantificador após um "token" (como um caractere) ou um agrupamento especifica a quantidade de vezes que o elemento precedente pode ocorrer. Os quantificadores mais comuns são codice_8, codice_9 e codice_10. O ponto de interrogação indica que há zero ou uma ocorrência do elemento precedente. Por exemplo, codice_11 casa tanto "acção" quanto "ação". Já o asterisco indica que há zero ou mais ocorrências do elemento precedente. Por exemplo, codice_12 casa "ac", "abc", "abbc", "abbbc", e assim por diante. Por fim, o sinal de adição indica que há uma ou mais ocorrências do elemento precedente. Por exemplo, codice_13 casa "abc", "abbc", "abbbc", e assim por diante, mas não "ac"".
Essas construções podem ser combinadas arbitrariamente para formar expressões complexas, assim como expressões aritméticas com números e operações de adição, subtração, multiplicação e divisão. De forma geral, há diversas expressões regulares para descrever um mesmo conjunto de cadeias de caracteres. A sintaxe exata da expressão regular e os operadores disponíveis variam entre as implementações.
A origem das expressões regulares estão na teoria dos autômatos e na teoria das linguagens formais, e ambas fazem parte da teoria da computação. Esses campos estudam modelos de computação (autômatas) e formas de descrição e classificação de linguagens formais. Na década de 1950, o matemático Stephen Cole Kleene descreveu tais modelos usando sua notação matemática chamada de "conjuntos regulares", formando a álgebra de Kleene. A linguagem SNOBOL foi uma implementação pioneira de casamento de padrões, mas não era idêntica às expressões regulares. Ken Thompson construiu a notação de Kleene no editor de texto QED como uma forma de casamento de padrões em arquivos de texto. Posteriormente, ele adicionou essa funcionalidade no editor de texto Unix ed, que resultou no uso de expressões regulares na popular ferramenta de busca grep. Desde então, diversas variações da adaptação original de Thompson foram usadas em Unix e derivados, incluindo expr, AWK, Emacs, vi e lex.
As expressões regulares de Perl e Tcl foram derivadas da biblioteca escrita por Henry Spencer, e no Perl a funcionalidade foi expandida posteriormente. Philip Hazel desenvolveu a PCRE (Perl Compatible Regular Expressions), uma biblioteca usada por diversas ferramentas modernas como PHP e o servidor Apache. Parte do desenvolvimento do Perl 6 foi melhorar a integração das expressões regulares de Perl, e aumentar seu escopo e funcionalidade para permitir a definição de gramáticas de expressão de analisadores sintáticos. O resultado foi uma mini-linguagem, as regras do Perl 6, usada para definir a gramática do Perl 6 assim como fornecer uma ferramenta para programadores da linguagem. Tais regras mantiveram as funcionalidades de expressões regulares do Perl 5.x, mas também permitiram uma definição BNF de um analisador sintático descendente recursivo.
O uso de expressões regulares em normas de informação estruturada para a modelagem de documentos e bancos de dados começou na década de 1960, e expandiu na década de 1980 quando normas como a ISO SGML foram consolidadas.
Expressões regulares podem ser expressas através da teoria de linguagens formais. Elas consistem de constantes e operadores que denotam conjuntos de cadeias de caracteres e operações sobre esses conjuntos, respectivamente. Dado um alfabeto finito Σ, as seguintes constantes são definidas:
As seguintes operações são definidas:
As constantes e os operadores acima formam a álgebra de Kleene.
Para evitar parênteses, é assumido que o fecho de Kleene possui a maior prioridade, depois a concatenação e por fim a alternância. Se não houver ambiguidades, os parênteses podem ser omitidos. Por exemplo, codice_14 pode ser escrito como codice_15, e codice_16 pode ser escrito como codice_17.
A definição formal de expressões regulares é concisa e evita a utilização dos quantificadores redundantes codice_8 e codice_10, que podem ser expressados respectivamente por codice_23 e codice_24. Por vezes o operador de complemento ~ é adicionado; ~"R" denota o conjunto das cadeias de caracteres de Σ* que não estão em "R". Esse operador é redundante, e pode ser expressado usando outros operadores, apesar da computação para tal representação ser complexa.
Expressões regulares podem expressar linguagens regulares, a classe de linguagens aceita por um autômato finito. Entretanto, há uma diferença significativa na compactação. Algumas classes de linguagens regulares podem ser descritas somente por autômatos que crescem exponencialmente em tamanho, enquanto o tamanho das expressões regulares requeridas só pode crescer linearmente. Expressões regulares correspondem ao Tipo-3 das gramáticas da Hierarquia de Chomsky. Por outro lado, existe um mapeamento simples de expressões regulares para máquinas de estado finito não-determinísticas que não leva ao crescimento desgovernado do tamanho. Por essa razão, essas máquinas não determinísticas são geralmente usadas como representação alternativa das expressões regulares.
É possível escrever um algoritmo que, para duas expressões regulares dadas, decide se as linguagens descritas são essencialmente iguais. Reduz-se cada expressão na máquina de estado finito mínima, e determina-se se ambas as máquinas mínimas são isomórficas (equivalentes).
Vale notar que diversas implementações de expressões regulares implementam funcionalidades que não podem ser expressadas na álgebra de Kleene; ver abaixo mais sobre o assunto.
De 1986, a norma IEEE POSIX 1003.2 (POSIX.2) padroniza expressões regulares, e fornece duas especificações, a saber: o conjunto básico (BRE) e o conjunto estendido (ERE).
A sintaxe tradicional de expressões regulares em Unix seguiu convenções comuns, mas diferiu entre as implementações. A norma IEEE POSIX BRE ("Basic Regular Expressions", do inglês, expressões regulares básicas) foi desenvolvida primordialmente por compatibilidade com a sintaxe tradicional, mas fornecia uma norma comum que desde então foi adotada por diversas ferramentas.
Na sintaxe de BRE, a maioria dos caracteres são tratados como literais — eles casam somente com eles próprios (por exemplo, codice_25 casa "a"). As exceções são chamadas metacaracteres ou metassequências, definidos abaixo:
Uma característica da BRE é que os metacaracteres geralmente exigem barras invertidas para serem tratador como tal. Por exemplo, em BRE, codice_26 é composto somente por literais, e casará somente "a{1,2}"". Para casar entre uma a duas ocorrências de "a", deve-se usar a expressão regular codice_27. A motivação desse sistema é a compatibilidade com sistemas antigos, já que na época da padronização já havia código Unix legado que usava chaves como literais.
O significado dos metacaracteres serem escapados com a barra invertida é revertido na sintaxe POSIX ERE ("Extended Regular Expression", do inglês, expressões regulares estendidas). Isso significa que não são usadas barras invertidas para identificar metacaracteres. Pelo contrário, elas servem justamente para transformar metacaracteres em literais. Retomando o exemplo da seção anterior, em ERE, codice_26 casa uma a duas ocorrências de "a", enquanto codice_27 casa o literal "a{1,2}".
Os seguintes metacaracteres foram adicionados:
Ferramentas que adotaram a sintaxe incluem MySQL e PHP, esta, que suporta também as derivações de Perl no modelo do PCRE.
Já que diversos grupos de caracteres dependem duma configuração de locale específica, a POSIX define algumas classes (ou categorias) de caracteres para fornecer um método padrão de acesso a alguns grupos específicos de caracteres bastante utilizados, como mostrado na seguinte tabela:
Notar que as doze classes definidas acima também estão definidas na biblioteca padrão do C, na seção de funções de testes de caracteres do cabeçalho codice_30.
Tais classes só podem ser usadas dentro de expressões de listas de caracteres. Diferentes locales podem fornecer classes adicionais. Uma extensão não POSIX difundida é codice_31 (atalho do Perl codice_32), geralmente definida como codice_33 ou traço baixo (codice_34) e codice_35, contendo somente caracteres ASCII (codice_36).
Pode-se negar uma classe de caracteres precedendo um acento circunflexo ao nome da classe. Por exemplo, para negar codice_37 usa-se codice_38.
A norma POSIX define ainda dois metacaracteres especiais que servem para casar os limites de palavras nas cadeias de caracteres. Nesse contexto da POSIX, uma palavra é formada por caracteres codice_33 ou traço baixo (codice_34). Assim como as âncoras, esses metacaracteres não casam pedaços do texto, elas servem apenas como uma referência. Eles são:
Perl possui uma sintaxe mais consistente e rica que as normas POSIX BRE e ERE. Um exemplo é que codice_41 sempre escapa um caractere não alfanumérico. Devido ao poder de expressão, outras ferramentas adotaram a sintaxe do Perl, como por exemplo Java, JavaScript, PCRE, Python, Ruby e .NET. Algumas linguagens e ferramentas como PHP suportam diversos tipos de expressões regulares.
Um exemplo de funcionalidade possível em Perl mas não em POSIX é a quantificação preguiçosa. Os quantificadores padrões das expressões regulares são "gananciosos", isto é, casam o quanto puderem, voltando atrás somente se necessário para casar o resto da expressão regular. Por exemplo, um novato no assunto tentando encontrar a primeira instância de um item entre os símbolos < e > no texto ""Outra explosão ocorreu em <26 de janeiro> de <2004>" provavelmente usaria o padrão codice_42, ou similar. Entretanto, esse padrão retornará "<26 de janeiro> de <2004>" ao invés de "<26 de janeiro>", como esperado, pois o quantificador codice_9 é ganancioso — ele consumirá a quantidade máxima de caracteres, e "26 de janeiro> de <2004" possui mais caracteres que "26 de janeiro".
Apesar desse problema ser evitável de diferentes formas (por exemplo, especificando o que não casar: codice_44), a maioria das ferramentas permitem que um quantificador seja preguiçoso, ou não ganancioso, ao suceder o quantificador com um ponto de interrogação. No exemplo anterior, a alternativa seria codice_45. Seguem os quantificadores não gulosos:
O PERL define algumas sequências de escape que servem como atalhos para certos metacaracteres:
Além dos quantificadores preguiçosos e das novas sequências de escape, o Perl também adicionou uma forma nova de casamento de padrões que estendem a POSIX. São um conjunto de metacaracteres que seguem o padrão codice_46, listados abaixo:
Diversas funcionalidades encontradas em bibliotecas atuais de expressões regulares provem um poder de expressão que excede as linguagens regulares. Por exemplo, a habilidade de agrupar subexpressões com parênteses e chamar novamente o valor casado na mesma expressão significa que o padrão pode casar cadeias de palavras repetidas como "papa" ou "WikiWiki"", os chamados quadrados na teoria de linguagens formais. O padrão para essas cadeias é codice_47. Entretanto, a linguagem de quadrados não é regular, nem livre de contexto. Casamento de padrões com um número indeterminado de referências anteriores, como suportado em ferramentas atuais, é NP-difícil.
Entretanto, as ferramentas que fornecem tais construções ainda usam o termo expressões regulares para os padrões, o que leva a uma nomenclatura que difere da teoria das linguagens formais. Por essa razão, algumas pessoas usam o termo "regex" ou simplesmente "padrão" para descrever esse conceito mais abrangente.
Existem pelo menos dois algoritmos fundamentalmente diferentes entre si que decidem se e como uma expressão regular casa uma cadeia de caracteres.
O mais antigo e mais rápido faz uso dum princípio da teoria de linguagens formais que permite a todas as máquinas de estado finito não determinísticas serem transformadas em máquinas de estado finito determinísticas. Geralmente chamado de DFA, o algoritmo realiza ou simula tal transformação e então executa a máquina determinística resultante na cadeia de caracteres, um símbolo de cada vez. Esse último processo tem complexidade linear relativa ao tamanho da cadeia de caracteres. Mais precisamente, uma cadeia de caracteres de tamanho "n" pode ser testada numa expressão regular de tamanho "m" no tempo "O"("formula_1") ou "O"("formula_2"), dependendo dos detalhes de implementação. Esse algoritmo é rápido, mas pode ser usado somente para casamentos e não para a rechamada de grupos de captura, quantificação preguiçosa e diversas outras funcionalidades encontradas nas bibliotecas modernas de expressões regulares. Também é possível executar a máquina não determinística diretamente, construindo cada estado da máquina determinística quando necessário e então descartando-o no próximo passo. Isso evita a quantidade exponencial de memória necessária para a construção completa da máquina determinística, ainda que garantindo a busca em tempo linear.
O outro algoritmo é casar o padrão com a cadeia de caracteres através de "backtracking". Geralmente chamado de NFA, Seu tempo de execução pode ser exponencial, o que pode acontecer em implementações simples no casamento de expressões como codice_48, que forçam o algoritmo a considerar um número exponencial de subcasos. Implementações modernas geralmente identificam tais casos, e aceleram e abortam a execução. Apesar dessas implementações com "backtracking" garantirem tempo exponencial no pior caso, elas fornecem mais flexibilidade e poder de expressão.
Originalmente, as expressões regulares eram usadas com caracteres ASCII, mas várias implementações atuais suportam Unicode. Na maioria dos casos não há diferença entre conjuntos de caracteres, mas algumas questões são relevantes ao suportar Unicode.
Uma delas é a codificação suportada, já que algumas implementações esperam UTF-8, enquanto outras podem esperar UTF-16 ou UTF-32. Outra questão é estender as funcionalidades disponíveis para ASCII no Unicode. Por exemplo, em implementações ASCII, conjuntos de caracteres na forma codice_49 são válidos para quaisquer "x" e "y" no intervalo [0x00,0x7F] desde que o código de "x" seja menor que o código de "y". A escolha natural seria permitir o mesmo em Unicode no intervalo de códigos [0,0x10FFFF], o que não é possível pois algumas implementações não permitem que conjuntos de caracteres ultrapassem os blocos de código disponíveis.
Do ponto de vista dos detalhes técnicos do Unicode, também surgem questões. Como a normalização, pois, em Unicode, mais de um código pode representar o mesmo caractere. Por exemplo, o caractere "é" pode ser representado por U+0065 (letra latina "e" minúsculo) combinado com U+0301 (diacrítico "acento agudo"), mas também pode ser representado como U+00E9 (letra latina "e" com diacrítico "acento agudo"). Também há os códigos de controle Unicode, as marcas de ordem de byte e as marcas de direção de texto, que devem ser tratados separadamente.
Expressões regulares são usadas por diversos editores de texto, utilitários e linguagens de programação para procurar e manipular texto baseado em padrões. Por exemplo, Perl e Tcl possuem suporte a expressões regulares nativamente. Diversos utilitários de distribuições Unix incluem o editor de texto ed, que popularizou o conceito de expressão regular, e o filtro grep.
Outro uso é a validação de formatos de texto (validação de protocolos ou formatos digitais). Por exemplo, ao receber a entrada dum campo de formulário duma aplicação que supõe receber um endereço de "email", pode-se usar uma expressão regular para garantir que o que foi recebido de fato é um endereço de "email".
Mais um uso é a implementação interna dum sistema de realce de sintaxe, como encontrado em ambientes de desenvolvimento integrado. Expressões regulares podem ser usadas para encontrar palavras reservadas, literais e outros tokens específicos, e para alterar a formatação do texto de acordo com o casamento feito.
Um uso difundido de expressões regulares é a filtragem de informação em bancos de dados de texto. Por exemplo, num arquivo de texto contendo cadastros de pessoas e suas datas de aniversário como a seguir:
Pode-se filtrar pessoas que nasceram num determinado ano, mês ou dia. Por exemplo, o uso do padrão codice_50 identifica o nome das pessoas que nasceram em outubro. Para o cadastro acima seriam retornados dois grupos de captura, codice_51 contendo ""João Alberto" e codice_52 contendo "Carlos Silva". Explorando o exemplo anterior e o uso de validação de formatos digitais, é possível usar expressões regulares para validar as datas presentes no arquivo de texto de aniversários acima. O padrão codice_53 é usado para validar uma data entre 1900-01-01 e 2099-12-31. Atentar que a separação entre ano, mês e dia pode se dar através de hífen, espaço em branco, barra ou ponto. Mas deve-se usar o mesmo símbolo de separação entre ano e mês e entre mês e dia, o que é possível através da rechamada do grupo de captura anterior (o trecho codice_52 do padrão). Atentar também que o padrão é incompleto na medida em que não diferencia a quantidade de dias em cada mês, o que resulta no casamento duma cadeia de caracteres "2000-02-31"", incorreta de acordo com o calendário gregoriano.

</doc>
<doc id="756" url="https://pt.wikipedia.org/wiki?curid=756" title="Entretenimento">
Entretenimento

"O artigo Eventos redireciona para esta página. Para ver outros conceitos homônimos, veja Evento."
Entretenimento ou entretimento é qualquer ação, evento ou atividade com o fim de entreter e suscitar o interesse de uma audiência. É a presença de uma audiência que torna qualquer atividade privada de recreação ou lazer em entretenimento. A audiência pode ter um papel passivo, como quando se assiste a uma peça teatral, ópera, programa de televisão ou filme; ou um papel ativo, como no caso dos jogos. O entretenimento pode ser público ou privado e envolver uma atuação formal e pré-determinada, como no caso do teatro ou dos concertos, ou uma atuação espontânea, como no caso dos jogos. Muitas das formas de entretenimento são transversais ao longo da História e das culturas e evoluem em função das alterações culturais e tecnológicas. Os filmes e os jogos eletrônicos, por exemplo, embora façam uso de novos suportes e "media", continuam a narrar histórias e a fazer uso da música. Os festivais dedicados à música, cinema ou dança permitem o entretenimento de uma audiência ao longo de vários dias consecutivos.
Algumas das atividades que outrora foram consideradas entretenimento, como as execuções públicas, foram sendo sucessivamente removidas da esfera pública. Outras atividades que ao longo da História foram competências essenciais de determinadas profissões, como o manejo de espadas ou o tiro com arco, são hoje desportos de competição, tornando-se ao mesmo tempo formas de entretenimento à medida que se tornam apelativos para uma audiência cada vez maior. O que um grupo ou indivíduo interpreta como entretenimento pode ser encarado como trabalho por outros.
O entretenimento proporciona divertimento, satisfação pessoal e boa disposição. Em determinadas circunstâncias e contextos, o entretenimento tem adjacente um propósito sério, como no caso de celebrações, festividades religiosas ou sátiras. Como tal, existe a possibilidade de que o que aparenta ser entretenimento possa também ser uma forma de desenvolvimento cultural e intelectual. O apelo do entretenimento, a par com a sua capacidade de usar diferentes "media" e do seu potencial para adaptações criativas, tem assegurado a continuidade e longevidade de muitas formas, temas, imagens e estruturas sociais.
O entretenimento é diferente de atividades como a educação ou o "marketing", embora essas atividades tenham aprendido a recorrer ao apelo do entretenimento como ferramenta auxiliar. A importância e o impacto do entretenimento é reconhecida no meio acadêmico e a sua crescente sofisticação tem influenciado a prática em campos tão diversos como a museologia.
A psicologia determina que a função do entretenimento é a obtenção de gratificação pessoal ou coletiva. Normalmente, não se espera mais nenhum resultado ou benefício quantificável. O entretenimento tem mecanismos opostos à educação, a qual é concebida com a função de desenvolver as capacidades de compreensão ou de ajudar as pessoas na aprendizagem, e do "marketing", cuja função é aliciar as pessoas a comprar produtos. No entanto, a fronteira tem-se tornado ténue à medida que a educação procura incorporar elementos recreativos e o entretenimento e o "marketing" procuram incorporar elementos educativos. Estas simbioses são conhecidas pelos neologismos de "edutainment" ou "infotainment". No entanto, muitas situações em que se combina entretenimento com educação são tentativas sérias de conjugar as melhores valências de cada um.
O entretenimento pode ir para além da simples gratificação e ser um veículo de transmissão de elementos culturais na audiência. Muitas das grandes questões filosóficas e existenciais podem proporcionar uma infinidade de narrativas, apresentadas na forma de histórias, argumentos de cinema ou teatro, poesia, literatura, dança, banda desenhada ou jogos. Entre as obras dramáticas que articulam questões filosóficas contam-se exemplos tão diversos como o influente Hamlet de Shakespeare, que explora temas como a traição, vingança, incesto, corrupção e moralidade, ou The Matrix, que explora a natureza do conhecimento. Os romances proporcionam igualmente um vasto leque de exploração de questões filosóficas ao mesmo tempo que entretêm os leitores. Um dos exemplos de uma obra criativa que apresenta questões filosóficas de forma entretida é "The Hitchhiker's Guide to the Galaxy"; inicialmente um programa de humor radiofónico, a história tornou-se tão popular que foi adaptada para a literatura, cinema, televisão, teatro, banda desenhada, "audiobook", jogos eletrónicos, e traduzida para várias línguas. Os temas apresentados vão desde o sentido da vida à ética do entretenimento, inteligência artificial, Deus ou métodos filosóficos.
A narração de histórias desempenha um papel importante na maior parte das formas de entretenimento desde a pré-história, e cujo método simples ainda hoje é um comportamento cultural frequente.
A mesma peça dramática pode ser apresentada num teatro ao ar livre, num "music hall", numa sala de cinema ou através de um dispositivo eletrónico pessoal, como um "tablet". A alteração do contexto histórico, cultural, tecnológico e económico influencia a escolha ou a preferência por determinados recintos de entretenimento, embora as características principais de cada um deles pouco se tenha alterado ao longo dos séculos. Desde a antiguidade que existem estruturas arquitetónicas dedicadas em exclusivo às formas de entretenimento, como teatros, auditórios e estádios. Um dos recintos mais notáveis é o Coliseu de Roma, onde eram apresentados ao público espetáculos, competições, corridas e desportos.
Algumas formas de entretenimento tornaram-se controversas, tendo algumas sido proibidas. A caça de animais selvagens é ainda hoje vista por alguns como entretenimento, embora outras formas de entretenimento com recurso a animais se tenham tornado extremamente controversas. A caça desportiva, enquanto forma de entretenimento público e espetáculo, foi introduzida no Império Romano a partir de Cartago.
Algumas das formas de entretenimento, sobretudo música e peças dramáticas, deram origem a inúmeras variantes de forma a responder a um vasto leque de preferências pessoais e expressões culturais. Muitas das formas de entretenimento estão incorporadas ou são apoiadas por outras formas. Por exemplo, muitas das peças dramáticas recorrem à música para realçar a sua expressividade. Outras formas incorporam jogos ou desporto de forma a serem mais atrativas. É relativamente comum que a origem de algumas formas de entretenimento tenham tido origem em atividades tidas como sérias ou necessárias (como a corrida ou o salto), que evoluem para competição e, consequentemente, para entretenimento. Os combates de gladiadores, populares durante a época Romana, são um bom exemplo de uma atividade que combina desporto, castigos corporais e entretenimento. Exemplos de entretenimento violento como este têm servido como argumento para a posição de que o entretenimento contemporâneo é menos violento do que no passado, apesar do recurso à violência como forma de entretenimento nos "media" modernos. Muito do equipamento para atividades outrora necessárias, como a pesca, foi alvo de inovações tecnológicas em função da sua função recreativa.
Embora a maior parte das formas de entretenimento tenha sido constante ao longo da História, algumas formas bastante populares em épocas passadas já não são vistas como aceitáveis. Por exemplo, durante vários séculos a participação popular no julgamento e castigo de criminosos e proscritos, ou outras cerimónias de humilhação pública eram vistas como entretenimento. Mesmo a execução de penas capitais como o enforcamento e a decapitação, exibidas em público como medida de dissuacção, eram vistas em parte como entretenimento, chegando-se mesmo a optar por execuções com processos demorados, como o apedrejamento, de forma a prolongar o espetáculo público. Os castigos públicos enquanto entretenimento só cessaram no século XIX, fruto da crescente contestação na classe média.
O entretenimento infantil centra-se em jogos e brincadeiras, e é fundamental na aprendizagem, desenvolvimento e formação de personalidade da criança. Os adultos ensinam e transmitem várias formas de entretenimento e muitas das atividades apelativas às crianças, como os fantoches, palhaços, pantominas ou banda desenhada são também apreciadas por adultos.
A maior parte das formas de entretenimento pode ser adaptada para se ajustar ao interesse e capacidade das crianças. Durante o século XX, tornou-se evidente que o desenvolvimento psicológico das crianças se processa em estágios e que as suas capacidades são diferentes das dos adultos. Começam a surgir histórias e atividades desenvolvidas especificamente para uma audiência infantil, na forma de livros, filmes ou jogos. São implementados sistemas de classificação etária de forma a orientar melhor o público.
Na atualidade, tal como acontece para os adultos, estão disponíveis várias formas de entretenimento para crianças através da internet, o que constitui uma alteração significativa em relação a épocas anteriores. A quantidade de tempo dispendida pelas crianças em entretenimento proporcionado pela televisão ou computadores, a par do assinalável colapso da relação da criança com o meio envolvente, tem sido alvo de diversas críticas pelo efeito negativo que acarreta a nível da imaginação, cognição e bem-estar psicológico.<ref name=http://www.guardian.co.uk/commentisfree/2012/nov/19/children-lose-contact-with-nature></ref>
A música é um componente fundamental em muitas formas de entretenimento e em vários artes performativas. É usada para realçar determinados aspetos de uma narrativa, é indispensável na dança (1) e na ópera, e é muito frequentemente incorporada em filmes e peças de teatro.
A música é em si própria uma forma autónoma de entretenimento popular e universal. (2, 4, 5, 6, 7, 8, 9) De acordo com o ritmo, instrumentos, estilo e forma de atuação, a música pode ser dividida em vários géneros, como a música clássica, o jazz, "folk" (3, 5, 8) ou o rock (6, 9). Até ao século XX, as atuações musicais estavam ao alcance de apenas uma minoria capaz de pagar a atuação dos intérpretes. A introdução do registo em suportes pré-gravados, para venda ou difusão radiofónica, fez com que a música passasse a ser um bem de consumo, disponível de forma barata a milhões de pessoas.
Todas as atuações musicais constituem uma forma de entretenimento, independentemente de serem ou não amplificadas (4, 6, 7, 9, 10) ou de serem interpretadas a solo (4, 6), em coro (2), orquestra (5, 8) ou conjunto (3). As atuações ao vivo são realizadas em recintos próprios, com tamanho variável, interiores ou exteriores e desde gratuitos a caros. Os diferentes tipos de audiência têm diferentes expectativas em relação aos intérpretes e ao seu próprio papel durante a atuação. Por exemplo, determinadas audiências preferem a audição em silêncio e são entretidas puramente pela excelência da música ou da interpretação (5, 8), enquanto que outro tipo de audiência recebe o entretenimento através do ambiente e participação coletiva (7, 9). Grande parte dos ouvintes é entretida pela audição em privado de música pré-gravada (10).
Os instrumentos usados em entretenimento musical podem ser constituídos apenas pela voz (2, 6), serem apenas instrumentais (1, 3), ou serem alguma conjugação de ambos (4, 5, 7, 8). A audiência pode ser individual (10), móvel (3), pequena (1, 2) ou grande (6, 7, 8, 9). O canto é normalmente acompanhado por instrumentos, embora algumas formas usem apenas a voz.
Algumas formas de entretenimento (excluem-se atividades comerciais):
Alguns lugares também são considerados entretenimento, como os seguintes:

</doc>
<doc id="758" url="https://pt.wikipedia.org/wiki?curid=758" title="Engenharia eletrônica">
Engenharia eletrônica

A é uma área de Engenharia que lida com grandezas elétricas de pequena amplitude e de elevadas frequências, os chamados sinais elétricos ou eletrônicos. A engenharia eletrônica cuida da energia elétrica sob os micro-aspectos de controle, automação e telecomunicação.
O estudo da engenharia eletrônica fornece meios para o desenvolvimento de componentes, dispositivos, sistemas e equipamentos como: transistores, circuitos integrados e placas de circuito impresso. Nos Estados Unidos, assim como no Brasil, os cursos de engenharia eletrônica são tradicionalmente dados como conteúdo da engenharia elétrica, tal como definido pelo MEC e CREA no Brasil.
A engenharia eletrônica a partir do desenvolvimento tecnológico nas indústrias do telégrafo, no final do século 19; e do rádio e telefone no início do século 20. A maior parte do desenvolvimento dessa disciplina ocorreu durante o período da segunda guerra mundial, com o advento do radar, do sonar, dos sistemas de comunicação e de outros sistemas com fins de aplicação bélica. Durante os anos que precederam a segunda guerra o assunto era conhecido como "engenharia de rádio" e apenas no final dos anos 50 o termo engenharia eletrônica começou a surgir.
Em 1948 surgiu o transistor e em 1960 o circuito integrado (CI) viria a revolucionar a indústria eletrônica. 
Historicamente considerada mera subdivisão da engenharia elétrica, especialmente durante a "era da válvula", ganhou autonomia plena com o advento da "era do semicondutor", rapidamente sucedida pela era da miniaturização em larga escala.
A engenharia eletrônica, constitui-se atualmente de várias subdivisões e ramos, cada vez mais numerosos. Algumas das especialidades e áreas de estudos incluem:
Rukillson Stifley DK

</doc>
<doc id="759" url="https://pt.wikipedia.org/wiki?curid=759" title="Ecologia">
Ecologia

A Ecologia é a ciência que estuda o meio ambiente e os seres vivos que vivem nele,ou seja, é o estudo científico da distribuição e abundância dos seres vivos e das interações que determinam a sua distribuição. As interações podem ser entre seres vivos e/ou com o meio ambiente. A palavra tem origem no grego ""oikos", que significa casa, e "logos"", estudo. 
Como matéria pode ser dividida em Autoecologia (é um dos dois grandes ramos em que Schot dividiu a ecologia), Demoecologia e Sinecologia. Entretanto, diversos ramos têm surgido utilizando diversas áreas do conhecimento: Biologia da Conservação, Ecologia da Restauração, Ecologia Numérica, Ecologia Quantitativa, Ecologia Teórica, Macroecologia, Ecofisiologia, Agroecologia, Ecologia da Paisagem. Ainda pode-se dividir a Ecologia em Ecologia Vegetal e Animal e ainda em Ecologia Terrestre e Aquática.
O meio ambiente afeta os seres vivos não só pelo espaço necessário à sua sobrevivência e reprodução, mas também às suas funções vitais, incluindo o seu comportamento, através do metabolismo. Por essa razão, o meio ambiente e a sua qualidade determinam o número de indivíduos e de espécies que podem viver no mesmo habitat. Por outro lado, os seres vivos também alteram permanentemente o meio ambiente em que vivem. O exemplo mais dramático de alteração do meio ambiente por organismos é a construção dos recifes de coral por minúsculos invertebrados, os pólipos coralinos. As relações entre os seres vivos do ecossistema também influencia na distribuição e abundância deles próprios. Como exemplo, incluem-se a competição pelo espaço, pelo alimento ou por parceiros para a reprodução, a predação de organismos por outros, a simbiose entre diferentes espécies que cooperam para a sua mútua sobrevivência, o comensalismo, o parasitismo e outras.
A maior compreensão dos conceitos ecológicos e da verificação das alterações de vários ecossistemas pelo homem levou ao conceito da Ecologia Humana que estuda as relações entre o homem e a biosfera, principalmente do ponto de vista da manutenção da sua saúde, não só física, mas também social. Com o passar do tempo surgiram também os conceitos de conservação que se impuseram na atuação dos governos, quer através das ações de regulamentação do uso do ambiente natural e das suas espécies, quer através de várias organizações ambientalistas que promovem a disseminação do conhecimento sobre estas interações entre o homem e a biosfera. Há muitas aplicações práticas da ecologia, como a biologia da conservação, gestão de zonas úmidas, gestão de recursos naturais (agricultura, silvicultura e pesca), planejamento da cidade e aplicações na economia.
A Ecologia tem uma complexa origem, em grande parte devido a sua natureza multidisciplinar.
Os antigos filósofos da Grécia, incluindo Hipócrates e Aristóteles, foram os primeiros a registrar observações sobre história natural. No entanto, os filósofos da Grécia Antiga consideravam a vida como um elemento estático, não existindo a noção de adaptação. Tópicos mais familiares do contexto moderno, incluindo cadeias alimentares, regulação populacional e produtividade, não foram desenvolvidos antes de 1700. Os primeiros trabalhos foram do microscopista Antoni van Leeuwenhoek (1632–1723) e do botânico Richard Bradley(1688-1732). O biogeógrafo Alexander von Humboldt (1769–1859) foi outro pioneiro do pensamento ecológico, um dos primeiros a reconhecer gradientes ecológicos e fazer alusão às relações entre espécies e área.
No início do século XX, a ecologia foi uma forma analítica de história natural. Seguindo a tradição de Aristóteles, a natureza descritiva da história natural examina a interação dos organismos com o seu meio ambiente e suas comunidades. Historiadores naturais, incluindo James Hutton e Jean-Baptiste de Lamarck, contribuíram com obras significativas que lançaram as bases das modernas ciências ecológicas. O termo "ecologia" é de origem mais recente e foi escrito pelo biólogo alemão Ernst Haeckel no seu livro "Generelle Morphologie der Organismen" (1866). Haeckel foi um zoólogo, artista, escritor e professor de anatomia comparada.
As opiniões divergem sobre quem foi o fundador da teoria ecológica moderna. Alguns marcam a definição de Haeckel como o início, outros atribuem a Eugenius Warming com a escrita de "Oecology of Plants: An Introduction to the Study of Plant Communities" (1895). A ecologia pode também ter começado com Carl Linnaeus, principal pesquisador da economia da natureza no início do século XVIII. Ele fundou um ramo de estudo ecológico que chamou de economia da natureza. Os trabalhos de Linnaeus influenciaram Darwin no "The Origin of Species" onde adota a frase de Linnaues "economia ou política da natureza". Linnaeus foi o primeiro a enquadrar "o equilíbrio da natureza", como uma hipótese testável. Haeckel, que admirava o trabalho de Darwin, definiu ecologia com base na economia da natureza, o que levou alguns a questionar se a ecologia é sinônimo dos conceitos de Linnaues para a economia da natureza.
A síntese moderna da ecologia é uma ciência jovem, que substancial atenção formal no final do século XIX e tornando se ainda mais popular durante os movimento ambientais da década de 1960, embora muitas observações, interpretações e descobertas relacionadas a ecologia estendem-se desde o início dos estudos da história natural. Por exemplo, o conceito de balanço ou regulação da natureza pode ser rastreado até Herodotos (morto em 425 ac.), que descreveu mutualismo no Rio Nilo, quando crocodilos abrem a boca permitindo escolopacídeos remover sanguessugas.
Contribuições mais ampla para o desenvolvimento histórico das ciências ecológicas, Aristóteles é considerado um dos primeiros naturalistas que teve um papel influente no desenvolvimento filosófico das ciências ecológicas. Um dos alunos de Aristóteles, Teofrasto, fez observações ecológicas sobre plantas e postulava uma postura filosófica sobre as relações autônomas entre as plantas e seu ambiente, que está mais na linha com o pensamento ecológico moderno. Tanto Aristóteles e Teofrasto fizeram observações detalhadas sobre as migrações de plantas e animais, biogeografia, fisiologia e seus hábitos no que poderia ser considerado um análogo do nicho ecológico moderno. Hipócrates, outro filósofo grego, também é creditado com referência a temas ecológicos em seus primeiros desenvolvimentos.
De Aristóteles a Darwin o mundo natural foi predominantemente considerado estático e sem mudanças desde criação original. Antes do livro "The Origin of Species" teve pouca valorização ou entendimento das dinâmicas relações entre os organismos e suas adaptações e modificações relacionadas ao meio ambiente. Enquanto Charles Darwin é o mais conhecido por seus trabalhos em evolução, ele é também um dos fundadores de ecologia de solo. Em "The Origin of Species" Darwin faz nota a o primeiro experimento ecológico publicado em 1816. Na ciência que antecederam a Darwin a noção de evolução das espécies foi ganhando apoio popular. Este paradigma científico mudou a maneira que os pesquisadores se aproximaram das ciências ecológicas.
Alguns sugerem que o primeiro texto ecológico ("Natural History of Selborne") foi publicado em 1789, por Gilbert White (1720–1793). O primeiro livro ecológico da América foi publicado em 1905 por Frederic Edward Clements. No livro, Clements passa a ideia que as comunidades de plantas são como superorganismos. Essa publicação lança o debate entre o holismo ecológico e individualismo que durou até a década de 1970. O conceito de Clements para superorganismo propõem quem os ecossistemas progridem por um regulado e determinado estágio de desenvolvimento, análogo ao estágios de desenvolvimento de um organismo, cujas partes função para manter a integridade do todo. O paradigma de Clements foi desafiado por Henry Gleason. De acordo com Gleason, comunidades ecológicas se desenvolvem a partir da associação única de organismos individuais. Essa mudança de percepção colocado o foco para as histórias de vida de organismos individuais e como isso se relaciona com o desenvolvimento de comunidades.
A teoria de superorganismo de Clements não foi completamente rejeitada, mas alguns sugerem que ela foi uma aplicação além do limite do holismo. Holismo continua a ser uma parte crítica da fundamentação teórica contemporânea em estudos ecológicos. Holismo foi primeiro introduzido em 1926 por uma polarizada figura histórica, um general da África do Sul chamado Jan Christian Smuts. Smuts foi inspirado pela teoria de superorganismo de Clement's e desenvolveu e publicou o conceito de holismo, que contrasta com a visão política do seu pai sobre o Apartheid . Quase ao mesmo tempo, Charles Elton pioneiro no conceito de cadeias alimentares no livro "Animal Ecology". Elton definiu relações ecológicas usando conceitos de cadeias alimentares, ciclos de alimentos, o tamanho de alimentos, e descreveu as relações numéricas entre os diferentes grupos funcionais e suas relativas abundâncias. 'ciclos alimentares' foram substituídos por 'teias tróficas `em posteriores textos ecológicos um texto posterior ecológica.
Ecologia desenvolveu-se em muitas nações, incluindo na Rússia com Vladimir Vernadsky que fundou o conceito de biosfera na década de 1920 ou Japão com Kinji Imanishi e seu conceito de harmonia na natureza e segregação de habitat na década de 1950. O reconhecimento científico ou a importância das contribuições para a ecologia de outras culturas é dificultada por barreiras linguísticas e de tradução.
Como ecologia lida sempre com ecossistemas em mudança, por isso, tempo e espaço devem ser levados em conta quando são descritos fenômenos ecológicos. No que diz respeito ao tempo, pode levar milhares de anos para um processo ecológico amadurecer. O tempo de vida de uma árvore, por exemplo, pode passar através de diferentes estágios sucessionais até atingir a maturidade de uma floresta. O processo ecológico ainda é estendido mais ao longo do tempo até a arvore cair e decompor.
Ecossistemas são também classificados em diferentes escalas espaciais. A área de um ecossistema pode variar muito, de muito pequeno a muito vasto.
Por exemplo, várias gerações de um pulgão e seus predadores podem existir sobre uma única folha, e dentro de cada um destes pulgões podem existir diversas comunidades de bactérias. A escalada do estudo deve ser muito ampla para estudar árvores de uma floresta, onde vivem pulgões e bactérias. Para entender o crescimento das arvores, por exemplo, o tipo de solo, umidade, inclinação do terreno, abertura do dossel e outras variáveis locais devem ser examinadas. Para entender a ecologia de uma floresta, complexos fatores locais, como clima também devem ser levados em conta.
Estudos ecológicos de longo prazo promovem importantes registros para entender melhor os ecossistemas no espaço e no tempo. O International Long Term Ecological Network gerencia e faz intercambio de informação entre locais de pesquisas. O mais longo experimentos existente é o Park Grass Experiment que início em 1856. Outro exemplo inclui o Hubbard Brook Experimental Forest em operação desde 1960. Em ecologia também é complicado o fato de que os padrões de pequena escala não necessariamente explicam os fenômenos de grande escala. Estes fenômenos operam em diferentes escalas no ambiente, que vão desde a escala molecular a escala planetaria, e requerem diferentes conjuntos de explicação.
Para estruturar o estudo da ecologia em um quadro de entendimento o mundo biológico é conceitualmente organizado em uma estrutura hierárquica, variando de uma escala de genes, para células, tecidos, órgãos, organismos, espécies, até o nível de biosfera. Ecossistemas são primeiramente pesquisados em seus principais níveis de organização, incluindo (1)organismos, (2) populações e (3) comunidades. Ecólogos estudam ecossistemas por amostragem de um certo número de indivíduos que representam uma população. Os ecossistemas consistem nas comunidades que entre elas e com o meio ambiente. E em ecologia, comunidades são criadas por interação de populações de diferentes espécies de uma área.
Biodiversidade é simplesmente a forma resumida para a diversidade biológica. Biodiversidade descreve todas as variantes da vida de genes a ecossistemas, e é uma área complexa que abrange todos os níveis biológicos de organização. Há muitos índices, maneiras para medir e representar a biodiversidade. Biodiversidade inclui diversidade de espécies, diversidade de ecossistemas, diversidade genética e os complexos processos que operam em e entre esses diversos níveis. Biodiversidade executa um importante papel na saúde ecológica, quanto na saúde dos humanos. Prevenindo ou priorizando a extinção das espécies é uma maneira de preservar a biodiversidade, nas populações, a diversidade genética entre elas e os processos ecológicos, como migração, que estão sendo ameaçados em escala global e desaparecendo rapidamente. Prioridades de conservação e técnicas de gestão requerem diferentes abordagens e considerações para abordar toda gama ecológica da biodiversidade. População e migração de espécies, por exemplo, são os mais sensíveis indicadores de serviços ecológicos que sustentam e contribuem para o capital natural e para o "bem estar" do ecossistema. O entendimento da biodiversidade tem uma aplicação pratica para o planejamento da conservação dos ecossistemas, para tomar decisões ecologicamente responsáveis nas gestão de empresas de consultoria, governos e empresas.
O nicho ecológico é um conceito central na ecologia de organismos. São muitos as definições do nicho ecológico desde 1917 , mas George Evelyn Hutchinson fez um avanço conceitual em 1957 e introduziu a definição mais amplamente aceita: "O nicho é o grupo de condições bioticas e abióticas nas quais uma espécie é capaz de persistir e manter estável o tamanho da população." O nicho ecológico é dividido em nicho fundamental e nicho efetivo. O nicho fundamental é o grupo de condições ambientais sobre qual uma espécie é apta a persistir. O nicho efetivo é o grupo de condições ambientais ótimas sobre a qual uma espécie é apta a persistir. Organismos tem traços fundamentais que são excepcionalmentes adaptados ao nicho ecológico. Um traço é uma propriedade mensurável do organismo que fortemente influencia sua performance. Padrões biogeográficos e escalas de distribuição são explicados e previstos através do conhecimento e compreensão das exigências do nicho da espécie. Por exemplo, a adaptação natural de cada espécie no seu nicho ecológico significa que ela é apta para excluir competitivamente outras espécies similarmente adaptada que tem uma escala geográfica de sobreposição. Isso é chamado de princípio de exclusão competitiva Importante do conceito do nicho é o habitat. O habitat é o ambiente sobre a qual uma espécies sabemos que ocorre e o tipo de comunidade que é formada como resultado. Por exemplo, habitat pode se referia a um ambiente aquático ou terrestre que pode ser categorizado como ecossistemas de montanha ou Alpes.
Organismos são sujeitos a pressões ambientais, mas eles também podem modificar seus habitats. O feedback positivo entre organismos e seu ambiente pode modificar as condições em uma escala local ou global (Ver Hipótese Gaia) e muitas vezes até mesmo após a morte do organismo, como por exemplo deposição de esqueletos de sílica ou calcário por organismos marinhos. Este processo de engenharia de ecossistemas também pode ser chamado de construção de nicho. Engenheiro de ecossistemas são definidos como:”...organismos que diretamente ou indiretamente modulam a disponibilidade de recursos para outras espécies, causando mudanças nos estados físicos nos matérias bióticos ou abióticos. Assim eles modificam, mantem e criam habitats."
O conceito de engenharia ecológica foi estimulado por uma nova apreciação do grau de influencia que os organismos tem no ecossistemas e no processo evolutivo. O conceito de construção de nicho destaca um prévio subvalorizado mecanismo de feedback na seleção natural transmitindo forças no nicho abiótico. Um exemplo de seleção natural através de engenharia de ecossistemas ocorre em nichos de insetos sociais, incluindo formigas, abelhas, vespas e cupins. Lá é uma emergência de homeostase na estrutura do nicho que regula, mantém e defende a fisiologia no interior da colônia. Montes de cupins, por exemplo, mantém uma temperatura interna constante através de chaminés de ar condicionado. A estrutura dos nichos é sujeita as forças da seleção natural. Além disso, o nicho pode sobreviver a sucessivas gerações, o que significa que os organismos herdam o material genético e um nicho, que foi construído antes do seu tempo.
A população é a unidade de analise da ecologia de populações. Uma população consiste nos indivíduos de uma mesma espécie que vivem, interagem e migram através do mesmo nicho e habitat . Uma primárias lei da ecologia de populações é a Teoria Populacional Malthusiana. Este modelo prevê que: "...uma população pode crescer (ou declinar) exponencialmente enquanto o ambiente experimentado por todos os indivíduos da população se mantém constante..." 
Esta premissa Malthusiana fornece a base para a formulação de teorias preditivas e testes que se seguem. Modelagens simples de populações usualmente começam com quatro variáveis incluído nascimento, morte, imigração e emigração. Modelos matemáticos são usados para calcular a mudança demográfica na população usando modelos nulos. Um modelo nulo é usado como uma hipótese nula para os testes estatísticos. A hipótese nula parte da pressuposto que processos aleatórios criam os padrões observados. Alternativamente o padrão observado difere significantemente do modelo aleatório e exige mais explicação. Modelos podem ser matematicamente complexos quando “...varias hipóteses competitivas são simultaneamente confrontadas com os dados." Um exemplo de um modelo introdutório de população descreve uma população fechada, como em uma ilha, onde a imigração e emigração não ocorre. Nestes modelos de ilha as taxas per capita de variação são descritos como:
formula_1,
onde "N" é o número total de indivíduos na população, "B" é o número de nascimentos, "D" é o número de mortos, "b" e "d" são as taxas per capita de nascimento e morte respectivamente, e "r" é a taxa per capita de mudança populacional. Esta formula pode ser lida como a taxa de mudança na população ("dN/dT") é igual aos nascimentos menos as mortes (B - D).
Usando estas técnicas de modelagem, os modelo de crescimento populacional de Malthus`s foi mais tarde transformado em um modelo conhecido como a equação logística:
formula_2,
onde "N" é o número de indivíduos medidos como densidade de biomassa, "a" é a taxa per capita máxima de mudança, e "K" é a capacidade de suporte da população. A formula pode ser lida assim, a taxa de mudança na população ("dN/dT") é igual ao crescimento ("aN") que é limitado pela capacidade de suporte "(1-N/K)". A disciplina de ecologia de populações baseia-se estes modelos introdutórios para entender os processos demográficos em populações real e conduz testes de hipóteses estatísticos. O campo da ecologia populacional, muitas vezes utiliza os dados sobre história de vida e álgebra matricial para desenvolver matrizes de projeção em fecundidade e sobrevivência. Esta informação é usada para o gerenciamento de estoques da vida selvagem e fixação de quotas de colheita.
As populações são também estudadas através do conceito de metapopulações.
O conceito de metapopulação foi introduzido em 1969 :"como uma população de populações que vai se extinguindo e recolonizando localmente." Ecologia de metapopulações é uma abordagem estatística que é frequentemente usada na biologia da conservação. A pesquisa com metapopulações simplifica a paisagem em manchas com diferentes níveis de qualidade. Como o modelo de seleçãor/K, o modelo de metapopulações pode ser usado para explicar a evolução da história de vida, como a estabilidade ecológica da metamorfose dos amfibios, que deslocam nos estágios de vida de manchas aquáticas para manchas terrestres. Na terminologia de metapopulação existem emigrantes (indivíduos que deixam um fragmento), imigrantes (indivíduos que se movem nos fragmentos) e os sítio (site) são classificados ou como fontes ou sumidouros. Um sítio (site) é um termo genérico que se refere a lugares onde as amostras das populações, tais como lagoas ou definidas áreas de amostragem em uma floresta. Sítios fontes são locais produtivos que geram uma oferta sazonal de organismos jovens que migram para outros fragmentos. Sítios sumidouros são locais improdutivos que só recebem os migrantes e estes vão se extinguir a menos que resgatados por um sítios fonte adjacentes ou as condições ambientais tornam-se mais favoráveis. Modelos de metapopulação examinar a dinâmica dos fragmentos ao longo do tempo para responder perguntas sobre ecologia espacial e demográfica. A ecologia de metapopulações é um processo dinâmico de extinção e colonização. Pequenos fragmentos de menor qualidade são mantidos ou resgatados por um fluxo sazonal de novos imigrantes. Uma estrutura de metapopulação dinâmica evolui de ano para ano, onde alguns fragmentos são sumidouros em anos secos e se tornam fontes de quando as condições são mais favoráveis. Ecologistas utilizam uma mistura de modelos de computador e estudos de campo para explicar a estrutura das metapopulações.
Ecologia de comunidades é uma subdisciplina da ecologia que estuda a distribuição, abundância, demografia e interações entre populações coexistentes. Um exemplo do um estudo na ecologia de comunidades medida da produção primária em uma área alagada em relação as taxas de decomposição em consumo. Isto requer o entendimento da conexão da comunidade entre plantas (produtores primários) e os decompositores (fungos e bactérias). ou a analise da dinâmica predador presa afetando a biomassa de anfíbios . Teias alimentares e níveis tróficos são dois modelos conceituais bastante utilizados para explicar a ligações entre espécies.
Teias alimentares são um tipo de mapa conceitual que ilustra os caminhos ecológicos reais, usualmente começando com a energia solar sendo usado pelas plantas durante a fotossíntese. As plantas crescem acumulando carboidratos que são consumidos pelos herbívoros. Passo a passo as linhas ou relações são elaboradas até uma teia de vida ser ilustrada.
Existem diferentes dimensões ecológicas que podem ser mapeados para criar teias alimentares mais complicadas, incluindo: composição de espécies (Tipo de espécies), riqueza de espécies (número de espécies), biomassa (o peso seco de plantas e animais), produtividade (taxa de conversão de energia e nutrientes em crescimento) e estabilidade (teias alimentares ao longo do tempo). Um diagrama ilustrando a composição da teia alimentar mostra como uma mudança em uma única espécies pode diretamente ou indiretamente influenciar muitas outras espécies.
Estudos de microcosmos são usados para simplificar as pesquisas com teias alimentares em unidades semi isoladas como pequenas molas, logs decadentes, e experimentos de laboratório usando organismos que se reproduzem rapidamente, como as Daphnia alimentando-se de algas em ambientes controlados. Princípios adquiridos em teias alimentares de modelos experientais de microcosmos são usados para extrapolar pequenas cinceitos dinâmicos em grandes sistemas. Food-chain length is another way of describing food-webs as a measure of the number of species encountered as energy or nutrients move from the plants to top predators.
Existem diferentes formas de cálculo de comprimento cadeia alimentar, dependendo do que os parâmetros da dinâmica da cadeia alimentar estão sendo considerados: conectância, energia ou interação. Em um simples exemplo de predador presa, um cervo é um passo removido em come plantas (comprimento de cadeia = 1) e um lobo que come o cervo é dois passos removido (comprimento de cadeia = 2). A quantidade relativa ou a força de influência que estes parâmetros são as questões acessadas da cadeia alimentar sobre:
As condições e recursos são dois fatores que determinam qual será o habitat dos organismos. Condições, são características físicas e químicas do ambiente, um elemento importante na diferenciação de condições e recursos é que as condições não diminuem pelas atividades dos indivíduos, já os recursos são consumidos pelos seres vivos. A partir daí surge um fator determinante, há uma competição interespecífica ou intraespecífica para obtenção de determinado recurso.
Links na teia alimentar primeiramente conectam relações alimentares entre espécies. Biodiversidade dentro do ecossistema pode se organizar em dimensões verticais e horizontais. A dimensão vertical representa as relações alimentares da base da cadeia alimentar até os predadores de topo. A dimensão horizontal representa a abundancia relativa ou biomassa de casa nível Quando a abundancia relativa ou biomassa de cada grupo alimentar é empilhada em seus respectivos grupos tróficos eles naturalmente formam uma espécie de ‘piramide de números’. Grupos funcionais são amplamente categorizados como autotróficos (ou produtores primários), heterotríficos (ou consumidores), e detritívoros (ou decompositores). Heterotrófagos podem ser subdivididos em diferentes grupos funcionais, incluindo: consumidores primários (herbívoros), consumidores secundários (predadores que consomem exclusivamente herbívoros) e consumidores terciários (predadores que consomem tanto herbívoros quanto outros predadores). Onívoros não se encaixam perfeitamente nessas categorias funcionais porque consomem tanto tecidos vegetais e tecidos animais. Tem sido sugerido, entretanto, que os onívoros têm uma maior influência funcional como predadores, porque em relação aos herbívoros são relativamente ineficientes na pastagem.
Ecólogos coletam dados em níveis tróficos e teias alimentares para modelar estatisticamente e calcular parâmetros matemáticos, tais como aqueles usados em outros tipos de análise de rede, para estudar os padrões emergentes e propriedades compartilhadas entre os ecossistemas. O arranjo piramidal emergente de níveis tróficos com quantidades de transferência de energia diminuindo à medida que as espécies se tornam mais distantes da fonte de produção é um dos vários padrões que repetem entre os ecossistemas. O tamanho de cada nível trófico na pirâmide geralmente representa a biomassa, que pode ser medida como o peso seco dos organismos. Autótrofos podem ter a maior proporção mundial de biomassa, mas eles são rivalizados de perto ou mesmo superados pelos microrganismos.
A decomposição da matéria orgânica morta, como folhas caindo no chão da floresta, se transforma em solo que a alimenta a produção de plantas. A soma total dos ecossistemas do planeta terra é chamado de pedosfera, onde é encontrada uma proporção muito grande da biodiversidade. Invertebrados que se alimentam e rasgam folhas maiores, por exemplo, criar pequenos pedaços que alimentam organismos menores na cadeia de alimentação. Coletivamente, estes são os detritívoros que regulam a formação do solo. As raízes das árvores, fungos, bactérias, minhocas, formigas, besouros, centopéias, mamíferos, aves, répteis e anfíbios todo o contribuem para criar a cadeia trófica da vida nos ecossistemas do solo. Como organismos se alimentam e deslocam fisicamente materiais para solos, este processo ecológico importante é chamado bioturbação. Biomassa de microrganismos do solo são influenciadas por feedback (retroalimentantação) na dinâmica trófica da superfície solar exposta. Estudos paleecológicos de solos colocam a origem da bioturbação a um tempo antes do período Cambriano. Outros eventos, como a evolução das árvores e anfíbios no período devoniano teve um papel significativo no desenvolvimento dos solos e trofismo ecológico.
Grupos tróficos funcionais separam hierarquicamente em uma piramide trófica porque requerem adaptações especializadas para realizar fotossíntese ou predação, mas raramente são eles tem uma combinação de ambas habilidades funcionais. Isso explica por que adaptações funcionais em trofismo organizam diferentes espécies emergente em um grupo funcional. Níveis tróficos são parte de um holístico ou complexo sistema visto no ecossistema. Cada nível trófico contém espécies independentes que se agrupam, porque compartilham funções ecológicas comuns. Agrupamento de espécies funcionalmente similar em um sistema trófico dá uma imagem macroscópica do amplo design funcional.
Links em uma teia alimentar ilustram diretas relações tróficas entre espécies, mas podem também efeitos indiretos que podem alterar a abundancia, distribuição ou biomassa do nível trófico. Por exemplo, predadores comendo herbívoros indiretamente influenciam a controle e regulação da produção primária nas plantas. Embora predadores não comem plantas diretamente, eles regulam a população de herbívoros que diretamente são ligados diretamente as plantas. A rede de relações de efeitos diretos e indiretos é clamada de cascata trófica. Cascata trófica são separadas em cascatas a nível de espécie, onde apenas um subconjunto da dinâmica da teia alimentar é impactado por uma mudança no número da população, e cascadas ao nível de comunidade, onde uma mudança no número da população pode ter um efeito dramático na teia alimentar inteira, como a distribuição de biomassa de plantas.
Uma espécie chave é uma espécie que ocupa um papel particularmente forte ou central em uma teia alimentar. Uma espécie chave ocupa um papel desproporcional em manter processos ecológicos. A perda de uma espécie chave resulta na extinção de outras espécies e um efeito cascata alterando o dinâmica trófica e conexões na teia alimentar. Espécies chaves, como os engenheiros de ecossistemas, tem um papel estruturador, apesar de ter níveis relativamente baixos de representação da biomassa na pirâmide trófica. Lontras do mar ("Enhydra lutris") são um exemplo clássico de espécies chave porque limitam o densidade de ouriços que se alimentam de algas. Se as lontras são removidas do sistema, os ouriços pastam até que as algas marinha desaparecer e isso tem um efeito dramático na estrutura da comunidade. A caça de lontras do mar, por exemplo, é considerado em ter indiretamente levado a extinção do dugongo-de-steller ("Hydrodamalis gigas"). Enquanto o conceito de espécies chaves tem sido muito usado como uma ferramenta de conservação biológica, ele foi criticado por estar mal definido. Diferentes ecossistemas expressam diferentes complexidades e por isso é
claro como aplicável que o modelo de espécies chave pode ser aplicado.
Unidades ecológicas de organização são definidas através de referência de algumas magnitudes de espaço e tempo no planeta. Comunidades de organismos, por exemplo, são muitas vezes arbitrariamente definidas, mas os processos de vida interagem com os diferentes níveis e organizam em conjuntos mais complexos.
Biomas, por exemplo, são uma grande unidade de organização que categorizam regiões de ecossistemas da Terra, de acordo com a fisionomia e composição da vegetação. Diferentes pesquisas tem aplicados diferentes métodos para definir limites continentais de domínios de biomas, por diferentes tipos de função da comunidade de vegetação, que são limitada na distribuição do clima, precipitação e outras variáveis ambientais. Exemplos de nomes de biomas incluem: florestas tropicais, florestas temperadas decíduas, taiga, tundra, desertos quentes e desertos polares. Outras pesquisas tem recentemente iniciado a categorizar outros tipos de biomas, como microbioma humano e oceânico. Para os microrganismos o corpo humano é o habitat e uma paisagem. O microbioma tem sido descoberto através de avanços na genética molecular, revelando uma desconhecida riqueza de microorganismos no planeta. O microbioma oceânico desempenha um significante papel na ecologia biogeoquímica dos oceanos.
A maior escala de organização ecológica é a biosfera. A biosfera é a soma total dos ecossistemas do planeta. Relações ecológicas regulam o fluxo de energia, nutrientes e clima, todos subindo até a escala planetária. Por exemplo, a história dinâmica da composição de CO e O na atmosfera foi em grande parte por fluxos de gases biogênicos provenientes da respiração e fotossíntese, com níveis flutuando no tempo em relação a ecologia e evolução dos animais e plantas. Quando partes de subcomponetes são organizadas em um todo, muitas vezes propriedades emergentes descrevem a natureza do sistema. Teorias ecológicas tem sido usadas para explicar os fenômenos emergentes de auto regulação na escala planetária. Isso é conhecido como Hipótese Gaia . The Gaia hypothesis is an example of holism applied in ecological theory. A ecologia do planeta age como uma única unidade regulatória e holística chamada de hipótese Gaia. A hipótese Gaia afirma que existe um feedback emergente gerado pelo metabolismo dos organismos vivos que mantem a temperatura da Terra e condições da atmosfera dentro de uma estreita escala de tolerância auto regulável.
A maioria dos seres vivos presentes nos mais diversos ambientes são ectodérmicos, ou seja, precisam de fontes externas de calor para regularização do seu metabolismo. Os endotérmicos por sua vez, necessitam de uma grande carga de energia para a manutenção da sua temperatura corporal já que, estes não regulam sua temperatura interna dependendo apenas do ambiente, porém os endotérmicos apresentam algumas vantagens quando se refere a mobilidade dos seus indivíduos, já que, estes não estão tão interligados ao ambiente, isso ajuda bastante na fuga dos predadores e também na obtenção de recursos, visto que essas espécies requerem uma grande quantidade de alimento para suprir suas necessidades. De acordo com a sazonalidade de determinados habitats, onde em um mesmo ano o ser vivo pode ficar exposto a temperaturas negativas em um período, e em outro à temperaturas bastante elevadas, surgiram-se ao longo do tempo vantagens evolutivas que permitiram a esses animais se adequarem ao clima predominante em um determinado momento, um exemplo desse avanço evolutivo é a raposa do ártico onde este apresenta uma pelagem espessa e branca (proteção e camuflagem) no inverno e fina e marrom no verão.
A migração é um conceito de constante movimentação de massas de populações. Esses movimentos são incentivados pela busca de recursos tais como: água, alimento e/ou acasalamento. Geralmente a estadia dessas espécies migratórias nestes habitats são passageiras, já que, devido ao grande número de indivíduos, estes ambientes não são capazes de suprir as necessidades desse grupo por muito tempo, estimulando novas migrações, o que irá depender também da sazonalidade de determinada região.
Ecologia e evolução são consideradas disciplinas irmãs, sendo ramos da ciência da vida. Seleção Natural, Historia de vida, desenvolvimentos, adaptação, populações, e herança estão presentes em teorias evolutivas e ecológicas. Morfologia, comportamento e/ou traços genéticos, por exemplo, podem ser mapeados em árvores evolutivas para estudar a desenvolvimento histórico da espécie e também organizar a informação em relação a adaptações ecológicas. Em outras palavras, adaptação é explicada em relação a origem histórica de traços e condições ecológicas e que está sujeita a forças da seleção natural. Nesse quadro, ferramentas analíticas de ecólogos e evolucionistas se sobrepõem para organizar, classificar e investigar a vida por meio de princípios sistemáticos comuns, como filogenéticos ou taxonômicos de Lineu As duas disciplinas frequentenmente aparecem juntas como no título do jornal "Trends in Ecology and Evolution". Não há uma fronteira nítida que separa a ecologia da evolução e que diferem suas áreas de aplicação. Ambas as disciplinas descobrem e explicam emergentes e únicos processos que operam em diferentes escalas espaciais e temporais da organização. Embora a fronteira entre a ecologia e evolução nem sempre é clara, é óbvio que os ecólogos estudam os fatores abióticos e bióticos que influenciam o processo evolutivo.

</doc>
<doc id="760" url="https://pt.wikipedia.org/wiki?curid=760" title="Embiruçu">
Embiruçu

Embiruçu ("Eriotheca candolleana" (K. Schum.) A. Robyns; Bombacaceae) é uma espécie de árvore brasileira. É uma das plantas à qual se atribui o nome Catuaba, sendo também conhecida como catuaba-branca.

</doc>
<doc id="762" url="https://pt.wikipedia.org/wiki?curid=762" title="Educação">
Educação

Educação engloba os processos de "ensinar" e "aprender". É um fenômeno observado em qualquer sociedade e nos grupos constitutivos dessas, responsável pela sua manutenção, perpetuação, transformação e evolução da sociedade a partir da instrução ou condução de conhecimentos, disciplinamentos (educar a ação), doutrinação, às gerações que se seguem, dos modos culturais de ser, estar e agir necessários à convivência e ao ajustamento de um membro no seu grupo ou sociedade, ou seja, é um processo de socialização que visa uma melhor integração do indivíduo na sociedade ou no seu próprio grupo.
Enquanto processo de sociabilização, a educação é exercida nos diversos espaços de convívio social, seja para a adequação do indivíduo à sociedade, do indivíduo ao grupo ou dos grupos à sociedade. Nesse sentido, educação coincide com os conceitos de socialização e endoculturação, mas não se resume a estes. A prática educativa formal — que ocorre nos espaços escolarizados, que sejam da Educação Infantil à Pós Graduação — dá-se de forma intencional e com objetivos determinados, como no caso das escolas. No caso específico da educação formal exercida na escola, pode ser definida como Educação Escolar.
De acordo com a UNESCO a educação também é exercida para além do ambiente formal das escolas e adentra em outras perspectivas caracterizadas como: educação não formal e educação informal. Segundo a organização, a partir das Conferências Internacionais de Educação de Adultos - CONFINTEA compreende-se por educação não formal todo processo de ensino e aprendizagem ocorrido a partir de uma intencionalidade educativa mas sem a obtenção de graus ou títulos, sendo comum em organizações sociais com vistas a participação democrática. E educação informal como aquela ocorrida nos processos cotidianos sociais, tais quais com a família, no trabalho, nos círculos sociais e afetivos.
No caso específico da educação exercida para a utilização dos recursos técnicos e tecnológicos e dos instrumentos e ferramentas de uma determinada comunidade, dá-se o nome de Educação Tecnológica. Outra prática seria a da Educação Científica, que dedica-se ao compartilhamento de informação relacionada à Ciência (no que tange a seus conteúdos e processos) com indivíduos que não são tradicionalmente considerados como parte da comunidade científica. Os indivíduos-alvo podem ser crianças, estudantes universitários, ou adultos dentro do público em geral. A educação sofre mudanças, das mais simples às mais radicais, de acordo com o grupo ao qual ela se aplica, e se ajusta a forma considerada padrão na sociedade.
De acordo com a Lei de Diretrizes e Bases da Educação Nacional a educação no Brasil se divide em:
No Brasil, a educação é regulamentada pela Lei de Diretrizes e Bases da Educação Nacional, pelo Fundo de Manutenção e Desenvolvimento da Educação Básica e pelo Fundo de Manutenção e Desenvolvimento do Ensino Fundamental e de Valorização do Magistério.
A principal meta do Plano de Desenvolvimento da Educação (PDE) é uma educação básica de qualidade, para isso deve-se investir na educação profissional e na educação superior. Para isso se tornar realidade deve acontecer o envolvimento de todos: pais, alunos, professores e gestores, em busca da permanência do aluno na escola. Com o PDE o Ministério da Educação pretende mostrar tudo o que se passa dentro e fora da escola e realizar uma grande prestação de contas. As iniciativas do MEC devem chegar a sala de aula para beneficiar a criança para atingir a qualidade que se deseja para a educação brasileira.
O PDE foi editado pelo Governo Federal, por premissas à visão sistêmica da educação, a sustentação da qualidade do ensino e a prioridade a educação básica.
Em Portugal o ensino curricular é um complemento ao ensino oficial.
Em Portugal, a educação é regulamentada pela Lei de Bases do Sistema Educativo que estabelece o quadro geral do sistema educativo nacional.
A nível institucional, a educação inicia-se num âmbito não obrigatório com o Pré-escolar. Destinado a crianças com idades compreendidas entre os 3 anos e a entrada na escolaridade obrigatória. 
A escolaridade obrigatória denomina-se como "ensino regular", tem a duração de 12 anos, e compreende a idades dos 6 anos até aos 18 anos e organiza-se em três ciclos sequenciais.
1.º ciclo:
O ensino é global e visa o desenvolvimento de competências básicas em Língua Portuguesa, Matemática, Estudo do Meio e Expressão Plástica. Com a implementação da escola a tempo inteiro, através do alargamento do horário de funcionamento para um mínimo de oito horas diárias, as escolas promovem actividades de enriquecimento curricular, nomeadamente o ensino obrigatório do Inglês, o apoio ao estudo para todos os alunos, a actividade física e desportiva, o ensino da Música e de outras expressões artísticas e de outras línguas estrangeiras. 
O 1º ciclo funciona em regime de monodocência, com recurso a professores especializados em determinadas áreas.
2.º ciclo:
Está organizado por disciplinas e áreas de estudo pluridisciplinares.
No 3.º ciclo, o ensino está organizado por disciplinas. Os principais objectivos deste ciclo são o desenvolvimento de saberes e competências necessários à entrada na vida activa ou ao prosseguimento de estudos.
3.º ciclo:
Funciona em regime de pluridocência, com professores especializados nas diferentes áreas disciplinares ou disciplinas.
Aos alunos que completam com sucesso o 3.º ciclo é atribuído o diploma do ensino básico.
Ensino secundário:
Está organizado segundo formas diferenciadas, orientadas quer para o prosseguimento de estudos quer para o mundo do trabalho. O currículo dos cursos de nível secundário tem um referencial de três anos lectivos e compreende quatro tipos de cursos:
Para conclusão de qualquer curso de nível secundário os alunos estão sujeitos a uma avaliação sumativa interna. Para além dessa avaliação, os alunos dos cursos científico-humanísticos são também submetidos a uma avaliação sumativa externa, através da realização de exames nacionais, em determinadas disciplinas previstas na lei.
Aos alunos que tenham completado este nível de ensino é atribuído um diploma de estudos secundários. Os cursos tecnológicos, artísticos especializados e profissionais conferem ainda um diploma de qualificação profissional de nível 3.
Ensino Pós-secundário não superior
Após a conclusão do ensino Secundário umas das opções que o sistema educacional português disponibiliza são os cursos de especialização tecnológica (CET) possibilitam percursos de formação especializada em diferentes áreas tecnológicas, permitindo a inserção no mundo do trabalho ou o prosseguimento de estudos de nível superior. 
A formação realizada nos CET é creditada no âmbito do curso superior em que o aluno seja admitido. A conclusão com aproveitamento de um curso de especialização tecnológica confere um diploma de especialização tecnológica (DET) e qualificação profissional de nível 4, podendo ainda dar acesso a um certificado de aptidão profissional (CAP).
Educação e Formação de Jovens e Adultos
A educação e formação de jovens e adultos oferece uma segunda oportunidade a indivíduos que abandonaram a escola precocemente ou que estão em risco de a abandonar, bem como àqueles que não tiveram oportunidade de a frequentar quando jovens e, ainda, aos que procuram a escola por questões de natureza profissional ou valorização pessoal, numa perspectiva de aprendizagem ao longo da vida.
No sentido de proporcionar novas vias para aprender e progredir surgiu a Iniciativa "Novas Oportunidades" que define como um dos objectivos principais alargar o referencial mínimo de formação ao 12.º ano de escolaridade e cuja estratégia assenta em dois pilares fundamentais:
• Elevar a formação de base da população activa;
• Tornar o ensino profissionalizante uma opção efectiva para os jovens.
As diferentes modalidades de educação e formação de jovens e adultos permitem adquirir uma certificação escolar e/ou uma qualificação profissional, bem como o prosseguimento de estudos de nível pós-secundário não superior ou o ensino superior.
A educação e formação de jovens e adultos compreendem as seguintes modalidades:
• Sistema de Reconhecimento, Validação e Certificação de Competências (RVCC).
Existe uma valorização e reconhecimentos das aprendizagens adquiridas ao longo da vida, por via formal, informal e não-formal, permitindo aos alunos obter uma dupla certificação académica e profissional. A formação adquirida permite o acesso a empregos mais qualificados e melhor perspectiva de formação ao longo da vida. Este Sistema tem lugar nos Centros Novas Oportunidades, disseminados por todo o país;
• Cursos de Educação e Formação (CEF) para alunos a partir dos 15 anos.
Os CEF são uma oportunidade para os jovens poderem concluir a escolaridade obrigatória, incentivando-os para o prosseguimento de estudos/formação, assim como para a aquisição de competências profissionais, através de soluções flexíveis, de acordo com os seus interesses e face às necessidades do mercado de trabalho.
São destinados a jovens com idade igual ou superior a 15 anos e inferior a 23 anos, em risco de abandono escolar ou que já abandonaram.
• Cursos de Educação e Formação de Adultos (EFA) e Formações Modulares.
Possibilitam a aquisição de habilitações escolares e/ou competências profissionais, com vista a uma reinserção ou progressão no mercado de trabalho a jovens com idade igual ou superior a 18 anos, que pretendam completarmos o 9º ou 12º ano de escolaridade e desejem obter uma qualificação profissional de nível 2 ou 3.
• "Acções de curta duração S@bER +"
Destinadas a maiores de 18 anos, procura, através de formações de curta duração, motivar a população adulta a melhorar as suas qualificações escolares ou profissionais e a encontrar as respostas adequadas aos contínuos desafios que enfrenta. Apresentam uma estrutura curricular flexível e diferenciada em função dos interesses e das necessidades do público-alvo.
Ensino Superior
O ensino superior actualmente está estruturado de acordo com os princípios de Bolonha e visa a assegurar uma sólida preparação científica, cultural, artística e tecnológica que habilite para o exercício de actividades profissionais e culturais e para o desenvolvimento das capacidades de concepção, de inovação e de análise crítica.
Em Portugal, organiza-se num sistema binário: o ensino universitário e o ensino politécnico, administrados por instituições do ensino superior públicas, privadas ou cooperativas.

</doc>
<doc id="765" url="https://pt.wikipedia.org/wiki?curid=765" title="Editor gráfico">
Editor gráfico

Editores gráficos ou editores de imagens são programas de computador que tem como objetivo facilitar a alteração e criação de imagens digitais. Existem três tipos de editores para cada necessidade. São eles:
Estes programas também possuem geralmente um vasto leque de filtros para exportação de arquivos. Alguns deles são BMP, JPG, GIF, TIFF, TGA, XPM, SVG, PostScript.

</doc>
<doc id="766" url="https://pt.wikipedia.org/wiki?curid=766" title="E-mail">
E-mail

Um ou, ainda, e-mail, é um método que permite compor, enviar e receber mensagens através de sistemas eletrônicos de comunicação. O termo "e-mail" é aplicado tanto aos sistemas que utilizam a Internet e que são baseados nos protocolos POP3, IMAP e SMTP, como àqueles sistemas conhecidos como intranets, que permitem a troca de mensagens dentro de uma empresa ou organização e que são, normalmente, baseados em protocolos proprietários.
O correio eletrônico é mais antigo que a internet, e foi, de fato, uma ferramenta crucial para criá-la, mas, na história moderna, os serviços de comunicação globais iniciaram no início da ARPANET. Padrões para codificação de mensagens de "e-mail" foram propostas em 1973 (RFC 561). A conversão da ARPANET à internet no início de 1980 produziu o núcleo dos serviços atuais. Um "e-mail" enviado no início de 1970 parece muito semelhante a uma mensagem de texto dos dias atuais.
O correio eletrônico é, frequentemente, chamado pelo seu nome em inglês, mesmo em textos em português. Existem diversas grafias, que, ocasionalmente, provocam discussões entre os adeptos de cada forma:
Também há variações na forma plural do termo. Em inglês americano, "email" é usado como um substantivo coletivo (como o termo correspondência para itens enviados pelo sistema postal), mas, no inglês britânico, é mais comumente usado como um substantivo comum, com a forma plural "emails".
A história do correio postal e a primeira menção à transmissão de mensagens têm origem na Grécia antiga, em 190 a.C., quando um general da cidade de Atenas enviou um mensageiro para comunicar aos atenienses a vitória de seu exército sobre os Persas.
É justamente daí que se origina a palavra "correio", do original "correr". Reza a história que o mensageiro de Atenas, Filípides, correu aproximadamente 42 quilômetros para levar a mensagem, e apenas balbuciou "Vitória" antes de cair morto de exaustão. Homenageou-se, posteriormente, essa distância como padrão das maratonas.
Há registros, do século XV a.C., de redes postais entre egípcios e babilônicos, transmitidas por meio de tábuas de argila. É também dos egípcios que vem o registro do primeiro sistema de correio. O historiador Xenofonte escreveu:
Já os romanos, para registrarem suas mensagens, utilizavam tábuas cobertas com cera quente (os "tabularis") ou pergaminhos e papiros. Essas informações eram trocadas continuamente entre Roma, seus exércitos e funcionários espalhados nos vastos territórios conquistados. No entanto, com a queda do Império Romano, os correios praticamente desapareceram.
Muitos povos trocavam mensagens utilizando pombos-correios, grous e andorinhas. Esses pássaros eram pintados com cores de determinado significado, de acordo com um código estabelecido, e depois soltos. Ou tinham mensagens amarradas aos seus pés e seguiam uma rota pré-ensinada.
O telégrafo, criado por Samuel Morse, que teve sua primeira transmissão em 1844, foi a primeira intervenção da eletricidade na mediação da comunicação entre pessoas.
Em 1876, Alexander Graham Bell descreve sua primeira experiência bem-sucedida com o telefone. Outra forma de transmissão de mensagem é o fax. Apesar de ter sido inventado antes do telefone, só se popularizou em 1966, quando foi lançado o aparelho de fax operado em linha telefônica.
O correio eletrônico é anterior ao surgimento da Internet. Os sistemas de "e-mail" foram uma ferramenta crucial para a criação da rede internacional de computadores.
O primeiro sistema de troca de mensagens entre computadores que se tem notícia foi criado em 1965, e possibilitava a comunicação entre os múltiplos usuários de um computador do tipo "mainframe". Apesar da história ser um tanto obscura, acredita-se que os primeiros sistemas criados com tal funcionalidade foram o Q32 da SDC e o CTSS do MIT.
O sistema eletrônico de mensagens transformou-se rapidamente em um ""e-Mail" em rede", permitindo que usuários situados em diferentes computadores trocassem mensagens. Também não é muito claro qual foi o primeiro sistema que suportou o "e-Mail" em rede. O sistema AUTODIN, em 1966, parece ter sido o primeiro a permitir que mensagens eletrônicas fossem transferidas entre computadores diferentes, mas é possível que o sistema SAGE tivesse a mesma funcionalidade algum tempo antes.
A rede de computadores ARPANET fez uma grande contribuição para a evolução do "e-Mail". Existe um relato que indica a transferência de mensagens eletrônicas entre diferentes sistemas situados nesta rede logo após a sua criação, em 1969. A data de 29 de Outubro de 1969 é a da primeira mensagem enviada para computadores situados em locais distantes. O texto dessa primeira mensagem continha apenas duas letras e um ponto - "LO.". O investigador da Universidade da Califórnia em Los Angeles (UCLA) Leonard Kleinrock queria escrever "LOGIN", mas o sistema foi abaixo a meio da transmissão. A mensagem seguiu do computador do laboratório de Kleinrock na UCLA para o de Douglas Engelbart no Stanford Research Institute, utilizando como suporte a recém-criada rede da ARPA (Advanced Research Projects Agency).
O programador Ray Tomlinson iniciou o uso do sinal @ para separar os nomes do usuário e da máquina no endereço de correio eletrônico em 1971. É considerado um dos inventores do e-mail, e foi de fato uma ferramenta crucial para criá-la, também criou outros programas parecidos com o "e-mail": SNDMSG e READMAIL. A primeira mensagem enviada por Ray Tomlinson não foi preservada; era uma mensagem anunciando a disponibilidade de um "e-Mail" em rede. A ARPANET aumentou significativamente a popularidade do correio eletrônico.
O Departamento de Informática da Universidade do Minho enviou pela primeira vez em Portugal um "e-mail" em 15 de agosto de 1986.
O conteúdo do "e-mail" eram "pormenores técnicos sobre uma tecnologia que estava a dar os primeiros passos - a Internet". O receptor da mensagem foi a Universidade de Manchester, no Reino Unido.
O envio e recebimento de uma mensagem de "e-mail" é realizada através de um sistema de correio eletrônico. Um sistema de correio eletrônico é composto de programas de computador que suportam a funcionalidade de cliente de "e-mail" e de um ou mais servidores de "e-mail" que, através de um endereço de correio eletrônico, conseguem transferir uma mensagem de um usuário para outro. Estes sistemas utilizam protocolos de Internet que permitem o tráfego de mensagens de um remetente para um ou mais destinatários que possuem computadores conectados à Internet.
O formato na Internet para mensagens de "e-mail" é definido na CRF 2822 e uma série de outras RFCs (RFC 2045 até a RFC 2049) que são conhecidas como MIME.
Mensagens de "e-mail" consistem basicamente de duas seções principais:
O corpo é separado do cabeçalho por uma linha em branco.
Hoje, os grandes sítios da Internet criaram uma série de facilidades para o usuário. Note que essa variação é só uma facilidade e não um novo tipo de "e-mail". Entre estas podemos citar:
Alguns sítios restringem alguns tipos de "e-mail". Esse tipo de restrição normalmente é usado a fim de evitar a atuação de um "spammer" ou divulgador não autorizado de mensagens em massa. Normalmente esse tipo de mensagem eletrônica é mais usado em empresas.
Normalmente, é usado por autoridades e seu uso é controlado.
Por medida de segurança, alguns organismos e entidades internacionais ou mesmo ligados a Governos categorizam o "e-mail" como:
Os norte-americanos chegam ao cúmulo de dar níveis e subníveis a esse tipo de mensagem;
Entretanto, vêm crescendo o uso da criação de chaves criptográficas pessoais (facilidade provida por aplicativos especializados), assegurando a privacidade das informações "de qualquer importância" de cada indivíduo.
Tais chaves possuem uma grande flexibilidade, escalabilidade e confiabilidade.
Algumas dicas de segurança:
Especial ou categorizado em níveis, que são de uso exclusivo dos provedores de Internet. Servem para testes e para verificar se funciona ou não o seu sistema anti-"spam" (contra as mensagens eletrônicas em massa).
Com a popularização da Internet através dos provedores gratuitos (cujos usuários ganhavam também uma caixa de correio eletrônico grátis), muitos sítios começaram a oferecer endereços de "e-mail" gratuitos desvinculados de qualquer outro serviço. Essas mensagens de "e-mail" podem ser lidas com o uso do próprio navegador, sem a necessidade de um programa específico, sendo por isso também chamados "webmail".
O correio eletrônico tornou-se popular devido a sua grande facilidade em quebrar barreiras geográficas. Pessoas que estão em diferentes continentes podem se comunicar livremente (desde que possuam computadores ou qualquer outro dispositivo com tal funcionalidade conectados a Internet), enviando e recebendo mensagens a qualquer hora do dia e para qualquer parte do mundo.
Observa-se que o correio eletrônico deixa de ser apenas um meio de troca de mensagens entre pessoas para se tornar um grande fator na produtividade das empresas. Grandes empresas estão, cada vez mais, usando o correio eletrônico para desempenhar papéis decisivos em suas negociações. Dentro disso, uma intranet pode ser estabelecida para tornar a comunicação de funcionários com outros grupos, tornando assim mais fácil o trabalho e eliminando mensagens em massa e outras mensagens indesejadas.
A Campaign Monitor, produtora de um "software" de mesmo nome, tem medido a popularidade de clientes de "e-mail" e "webmail" entre as bilhões de mensagens enviadas pelo seu sistema. Esta amostra pode dar uma panorama geral dos programas ou plataformas de correio-e mais utilizados atualmente. Em setembro de 2012, a medição apresentou os seguintes resultados:
Outra tendência que se verifica é o crescimento da leitura de correio eletrônico em aparelhos móveis. A popularidade destes dispositivos também é corroborada pelo relatório citado.
As aplicações de correio eletrônico normalmente oferecem ao usuário uma série de facilidades. A maior parte delas fornece um editor de textos embutido e a possibilidade do envio de arquivos anexados a correspondência. Além disso, a maioria das aplicações permite o envio de correspondências para um único destinatário ou o envio para mais de uma pessoa ou para um grupo de pessoas.
Embora não tenham sido desenvolvidos como uma ferramenta de trabalho cooperativo, os serviços de correio eletrônico adaptaram-se muito bem ao ambiente de grupos de trabalho, se tornando indispensáveis nas organizações, agilizando processos, democratizando o acesso as informações e diminuindo os custos. Esta é uma das formas mais usadas para o estabelecimento de comunicações por meio do computador.
Muitas organizações também usam o correio eletrônico como forma de troca de mensagens, mas, se quiserem usar recursos de "groupware", poderão incluí-los de forma simples e com baixo custo, com uma boa segurança.
A desvantagem está na falta de conhecimento da grande maioria dos internautas e, ainda, os "spammers" ou geradores de "spam", grandes remetentes de vírus. Como podemos ver em seguida:
É aconselhável nunca abrir "e-mail" desconhecido, exceto se for de um site confiável, não sem antes observar os procedimentos de segurança.
Com o grande aumento do uso da Internet e do correio eletrônico na vida das pessoas, tornou-se grande o número de pessoas maliciosas que tentam utilizar esses meios para realizar fraudes.
O grande foco desses fraudadores são pessoas que utilizam sítios de instituições financeiras na Internet. Os fraudadores eletrônicos utilizam a grande facilidade com que uma caixa de correio pode ser forjada e falsificada. Eles utilizam listas e programas para envio de "spam" em grande escala juntamente com arquivos executáveis e serviços de hospedagem gratuitos e que não necessitem de identificação legítima.
Esses fraudadores enviam mensagens de "e-mail" se passando por bancos e outras instituições financeiras, solicitando dados pessoais, número de conta corrente, cartão bancário e, às vezes, até mesmo o número de senhas de clientes. Esses clientes desavisados enviam esses dados pensando se tratar realmente de um pedido dessas instituições, sem saberem que estão a se tornar vítimas de fraudadores. Cada vez mais, cresce o número de pessoas que tem suas contas fraudadas, compras através de seus cartões e outros tipos de fraudes. A falta de legislação e meios de segurança que controlem esse tipo de ação tem se tornado um fator positivo para que esses fraudadores continuem a atuar. Além disso não há nenhum mecanismo que permita rastrear, identificar e coibir a ação desses fraudadores tornando assim cada vez mais difícil a atuação das autoridades nesses casos. Mensagens de "e-mail" indesejadas de instituições que queiram solicitar dados pessoais devem ser ignoradas, pois essas não enviam tais mensagens para seus clientes.
A melhor maneira de se prevenir contra fraudes ao utilizar o correio eletrônico é mesmo procurar o máximo de informações sobre sua origem e desconfiar de qualquer indício que possa levantar alguma suspeita. Mensagens de "e-mail" que foram enviadas por pessoas ou empresas desconhecidas encabeçam essa lista. Deve-se ter uma atenção especial com estes tipos de mensagem, pois podem instalar programas-espiões maliciosos, que podem capturar dados que estejam ou foram digitados no computador em que tais programas sejam executados, tornando assim fácil a obtenção de dados de seus usuários.

</doc>
<doc id="767" url="https://pt.wikipedia.org/wiki?curid=767" title="Etimologia">
Etimologia

Etimologia (do grego antigo ἐτυμολογία, composto de ἔτυμος "étymos" e -λογία "-logia") é a parte da gramática que trata da história ou origem das palavras e da explicação do significado de palavras através da análise dos elementos que as constituem. Por outras palavras, é o estudo da composição dos vocábulos e das regras de sua evolução histórica.
Algumas palavras derivam de outras línguas, possivelmente de uma forma modificada (as palavras-fontes são chamadas étimos). Por meio de antigos textos e comparações com outras línguas, os etimologistas tentam reconstruir a história das palavras - quando eles entram em uma língua, quais as suas fontes, e como a suas formas e significados se modificaram.
Os etimólogos também tentam reconstruir informações sobre línguas que são velhas demais para que uma informação direta (tal como a escrita) possa ser conhecida. Comparando-se palavras em línguas correlatas, pode-se aprender algo sobre suas línguas afins compartilhadas. Deste modo, foram encontrados radicais de palavras que podem ser rastreadas por todo o caminho de volta até a origem da família de línguas indo-europeias.
A própria palavra etimologia vem do grego ἔτυμον (étimo, o verdadeiro significado de uma palavra, de 'étymos', verdadeiro) e λόγος (lógos, ciência, tratado).
n" → "schatrayn" → "shadrayn" / "shadran" → (árabe) "al xedrech" → "alxedrez" → "ajedrez" (castelhano) e "xadrez" (português). No oriente se tornou "Xiangqi" (China) e ("xiangi" → "xongi") "Shogi" (Japão).
O estudo da origem das palavras pode, contudo, levar a armadilhas e a falácias etimológicas, que formam a pseudoetimologia ou a etimologia popular. Um exemplo, bastante discutido, é o da palavra cadáver que, segundo alguns autores, teria origem na inscrição latina "caro data vermibus" (carne dada aos vermes), que supostamente seria inscrita nos túmulos. Na verdade, não se encontrou, até hoje, nenhuma inscrição romana deste género. Hoje é defendido pelos etimologistas que a palavra deriva da raiz latina "cado", que significa "caído". A favor desta teoria está o facto de santo Isidoro de Sevilha referir que o corpo deixa de ser cadáver a partir do momento em que é sepultado.
Um exemplo de armadilha brasileira é a etimologia da palavra forró. Muitos acreditam que tenha vindo de "for all", do inglês, durante a Segunda Guerra Mundial, quando os estadunidenses tinham bases no nordeste brasileiro. Entretanto, a palavra é uma simples derivação de forrobodó e já existia há muito mais tempo.
Alguns religiosos acreditam que a palavra moleque vem de Moloque, um antigo deus que aceitava sacrifícios de crianças, porém, a palavra moleque vem de quimbundo (língua banta africana), e significa “garoto, criança pequena” (ver Houaiss).
Entretanto, pesquisadores concordam que devido a existência, mesmo destas "armadilhas", as palavras se tornam mais conhecidas, instigadas, e até mesmo ganham um significado mais fixo.
Ciências etimologicas

</doc>
<doc id="768" url="https://pt.wikipedia.org/wiki?curid=768" title="Editor de som">
Editor de som

Editor de som é um software que tem a função de manipular ondas sonoras e ficheiros de áudio.
A maioria tem funções básicas como:

</doc>
<doc id="770" url="https://pt.wikipedia.org/wiki?curid=770" title="Experiência de Miller e Urey">
Experiência de Miller e Urey

A experiência de Miller e Urey foi uma experimento cientifico concebida para testar a hipótese de Oparin e Haldane sobre a origem da vida.
Segundo o experimento, as condições na Terra primitiva favoreciam a ocorrência de reações químicas que transformavam compostos inorgânicos em compostos orgânicos precursores da vida. Em 1953, Stanley L. Miller e Harold C. Urey da Universidade de Chicago realizaram uma experiência para testar a hipótese de Oparin e Haldane que ficou conhecida pelos nomes dos cientistas. Esta experiência tornou-se na experiência clássica sobre a origem da vida.
A experiência de Miller consistiu basicamente em simular as condições da Terra primitiva postuladas por Oparin e Haldane. Para isso, criou um sistema fechado, sem oxigênio, onde inseriu os principais gases atmosféricos, tais como hidrogênio, amônia, metano, além de vapor d'água. Através de descargas elétricas, e ciclos de aquecimento e condensação de água, obteve após algum tempo, diversas moléculas orgânicas (aminoácidos). Deste modo, conseguiu demonstrar experimentalmente que seria possível aparecerem moléculas orgânicas através de reações químicas na atmosfera utilizando compostos que poderiam estar nela presentes. Estas moléculas orgânicas são indispensáveis para o surgimento da vida.
Reanálises publicadas em outubro de 2008 do material original da experiência, mostraram a presença de 22 aminoácidos ao contrário dos 5 que foram criados no aparelho. Antigos resultados mostram uma forte evidência de estas moléculas orgânicas específicas poderem ser sintetizadas de reagentes inorgânicos atmosféricos.
A primeira etapa das reações químicas da mistura de gases deu origem ao cianeto de hidrogênio (HCN), formaldeido (CHO) e outros compostos químicos como o acetileno, cianoacetileno, etc:
O formaldeido, a amônia e o HCN reagiram entre si em um processo conhecido como Síntese de aminoácido de Strecker para formar aminoácidos e outras biomoléculas:
Além disso, a água e o formaldeído reagiram pelo processo conhecido como Reação de Butlerov para produzir vários açúcares , tais como a ribose. 
As experiências mostraram que compostos orgânicos simples, proteínas e outras macromoléculas podem ser formados a partir de gases com a adição de energia.

</doc>
<doc id="771" url="https://pt.wikipedia.org/wiki?curid=771" title="Europa Ocidental">
Europa Ocidental

A Europa Ocidental ou Oeste Europeu é uma parte da Europa cujas fronteiras dependem da definição. Estas fronteiras, no entanto, estão sujeitas a consideráveis flutuações e sobreposições, o que dificulta a sua diferenciação. O conceito de Europa Ocidental também está associado à noção de Mundo Ocidental.
Antes da Segunda Guerra Mundial e a Guerra Fria, os termos "Europa Ocidental" eram muito usados para designar as partes da Europa que tinham raízes católicas ou protestantes, ou seja, as áreas ocupadas por Andorra, Alemanha, Áustria, Bélgica, Croácia, Dinamarca, Eslováquia, Eslovénia, Espanha, Finlândia, França, Hungria, Irlanda, Islândia, Itália, Letónia, Liechtenstein, Lituânia, Luxemburgo, Malta, Mónaco, Noruega, Países Baixos, Polônia, Portugal, Reino Unido, República Tcheca, San Marino, Suécia, Suíça e Vaticano. Foi nestes países que as culturas ocidentais nasceram e floresceram, acabando por disseminar-se por todo o mundo.
Durante a Guerra Fria, quando a Europa Ocidental designava os países membros da NATO e sob influência norte-americana, o termo era frequentemente usado como contraponto ao Leste Europeu, que estava sob influência soviética. As fronteiras entre os países do Ocidente e do Leste estavam bem defendidas e patrulhadas, especialmente do lado oriental. A estas fronteiras dava-se também o nome de Cortina de Ferro.
Até há pouco tempo, podia-se dizer com segurança que a Europa Ocidental correspondia aos países da União Europeia, adicionando-se a Islândia, a Suíça, o Liechtenstein, Andorra, a Noruega, San Marino, Mónaco e o Vaticano.
Segundo a Organização das Nações Unidas, utilizando o critério de divisão por regiões geográficas, a Europa ocidental atualmente compreenderia a Alemanha, a Áustria, a Bélgica, a França, Liechtenstein, Luxemburgo, Mónaco, os Países Baixos e a Suíça. Já para a Unesco, segundo critérios histórico-sócio-culturais, a Europa Ocidental compreenderia os atuais territórios da Alemanha, Andorra, Bélgica, Dinamarca, Espanha, Finlândia, França, Grécia, Islândia, Irlanda, Itália, Liechtenstein, Luxemburgo, Malta, Mónaco, Noruega, Países Baixos, Portugal, Reino Unido, São Marino, Suécia e Suíça. 
Note-se que, exceção à parte oriental da Alemanha (que foi reunificada em 1990), por qualquer dos 2 critérios (como pode-se observar nos mapas ao lado), estão excluídos do presente conceito de Europa Ocidental todos os países que, como acordado na Conferência de Ialta, caíram na zona de influência soviética, sendo governados por regimes comunistas durante a Guerra Fria, incluindo os que faziam então parte da não alinhada Yugoslávia.
A República Federal da Alemanha é o país com o maior produto interno bruto da Europa, e o terceiro a nível mundial em termos nominais e quinto em paridade do poder de compra. Membro-fundador da União Europeia e membro do NATO e do G8, tem uma grande importância na geopolítica e economia mundial.
Desde a revolução industrial que o país tem sido criador, inovador e beneficiário de uma economia globalizada. A exportação de bens produzidos na Alemanha é um dos principais fatores da riqueza alemã. A Alemanha é maior exportador mundial com 1130 bilhões de dólares exportados em 2006 (países da Eurozona incluído) e gerou um superavit comercial de 165 bilhões de euros. O setor de serviços contribui com 70% do PIB, a indústria 29,1% e a agricultura 0,9%. A maioria dos produtos alemães são em engenharia, especialmente automóvel,máquina, metal, e produtos químicos
Com mais de 85 milhões de habitantes, a Alemanha é o pais mais populoso da União Europeia, apesar de sua taxa de natalidade seja de 1,39 filhos por mulher, uma das mais baixas do mundo. A Alemanha tem um grande número de cidades grandes, sendo as mais populosas Berlim, Hamburgo, Munique, Colônia, Frankfurt am Main e Estugarda (Stuttgart). De longe a maior aglomeração é a região do Reno-Ruhr, que inclui Düsseldorf e cidades como Colônia (Köln), Essen, Dortmund, Duisburgo e Bochum.
Sua língua, o alemão é falado por aproximadamente 100 milhões de falantes nativos e mais 80 milhões de falantes não-nativos. O alemão é a língua principal de aproximadamente 90 milhões de pessoas (18%) na UE. 67% dos cidadãos alemães dizem serem capazes de comunicar-se em pelo menos uma língua estrangeira, 27% em pelo menos duas línguas além da materna.
A República da Áustria é um país montanhoso, com de extensão territorial. A língua oficial é o alemão, a primeira língua de 97% da população. A Áustria foi a terra natal de vários compositores famosos tais como Wolfgang Amadeus Mozart, Joseph Haydn, Johann Strauss I, entre outros. A sua capital e principal cidade, Viena, é desde o século XVIII um dos mais importantes centros culturais europeus e mundiais.
Como membro da União Europeia, a Áustria possui um produto interno bruto de US$, o 35º maior do mundo. A Áustria, em vários momentos, tentou unir-se à Alemanha, mas nunca o conseguiu.
O Reino da Bélgica tem uma área de , distribuídos por três regiões principais: a planície costeira (localizada a noroeste), o planalto central e as elevações das Ardenas (situadas a sudeste). A sua população é cerca de 10,4 milhões, entre os quais 6,2 milhões são flamengos (na Flandres e Bruxelas), 3,2 milhões de valões, 900 mil habitantes em Bruxelas e 70 mil germanófonos.
É membro da União Europeia e da (NATO). A base da sua economia é a metalurgia, produtos químicos (farmacêuticos), electrónico ,têxteis, vidros,chocolates, diamantes e móveis.
Espanha (em castelhano e galego: "España"; em catalão e valenciano: "Espanya"; em basco: "Espainia"; em aranês: "Espanha"), oficialmente , é um país situado na Europa meridional, na Península Ibérica. Com uma área de , a Espanha é, depois da França, o segundo maior país da Europa Ocidental e da União Europeia.
O país foi uma importante fonte de influência para outras regiões no mundo durante a Era Moderna quando se tornou um império mundial, que deixou como legado mais de 400 milhões de falantes do espanhol espalhados pelo mundo.
A Espanha contemporânea é uma democracia organizada sob a forma de um governo parlamentar sob uma monarquia constitucional. Sendo também membro das Organização das Nações Unidas (ONU), da União Europeia (UE), da Organização do Tratado do Atlântico Norte (OTAN), da Organização para a Cooperação e Desenvolvimento Econômico (OCDE) e da Organização Mundial do Comércio (OMC).
A Finlândia (em finlandês: e em sueco: ), oficialmente República da Finlândia, é um país nórdico situado na região da Fino-Escandinávia. Faz fronteira com a Suécia a oeste, com a Rússia a leste e com a Noruega ao norte, enquanto a Estônia está ao sul através do Golfo da Finlândia. A capital do país é Helsinque.
Cerca de 5,3 milhões de pessoas vivem na Finlândia, sendo que a maior parte da população está concentrada no sul do país. É o oitavo maior país da Europa em extensão e o país menos densamente povoado da União Europeia. A língua materna de quase toda a população é o finlandês, que é uma das línguas fino-úgricas e é mais estreitamente relacionado com o estoniano.
A França, foi o primeiro dos grandes Estados europeus a ser formado, sendo sua capital em Paris. Incluindo os territórios ultramarinos, a França tem uma superfície de 675 417 km² e por volta de 64,5 milhões de habitantes. O francês é o idioma oficial, segundo a constituição, outros 77 línguas e dialetos existem no país. Uma das grandes incentivadoras e membro-criador da União Europeia, o país foi uma potência colonial no passado, e ainda possui territórios e dependências ultramarinas, em diversos lugares ao redor do mundo.
A França é um país rico, que disputa com a Alemanha e o Reino Unido a liderança da economia na União Europeia, porque é a segunda economia da Europa e a quinta maior do mundo. Paris é a segunda cidade mais populosa do continente, e figura como uma cidade global. Seu monumento mais emblemático é a Torre Eiffel.
Grécia (, ), é um país europeu localizado na parte meridional da região balcânica. Localizada no sudeste da Europa, junto de Ásia e África, a Grécia é considerada o berço da civilização ocidental, por ser a região onde nasceram a democracia, a filosofia ocidental, os Jogos Olímpicos, a Literatura ocidental, bem como a ciência política, se definiu os primeiros princípios matemáticos, assim como o teatro e a historiografia modernos.
Irlanda ( e ), oficialmente República da Irlanda ( e ), é um Estado soberano da Europa que ocupa cerca de cinco sextos da ilha homônima. É uma república constitucional governada como uma democracia parlamentar, com um presidente eleito servir como chefe de Estado. A Irlanda tem o sétimo mais alto Índice de Desenvolvimento Humano (IDH) do mundo, além de ótimas classificações em índices que medem o grau de democracia e liberdades como a de imprensa, econômica e política. Além da União Europeia (UE), a Irlanda também é membro do Conselho da Europa, da Organização para a Cooperação e Desenvolvimento Econômico (OCDE), da Organização Mundial do Comércio (OMC) e das Organização das Nações Unidas (ONU). Sua capital é Dublin e sua população é estimada em 4,58 milhões de habitantes.
O Estado moderno irlandês foi fundado em 1922 como o Estado Livre Irlandês, um domínio dentro do Império Britânico, na sequência do Tratado Anglo-Irlandês que pôs fim à Guerra de Independência da Irlanda. Seis dos nove condados da província nortista do Ulster foram então estabelecidos como a Irlanda do Norte, uma parte do Reino Unido, com o qual o Estado irlandês divide a sua única fronteira terrestre.
Outro país insular europeu pertencente à Europa Ocidental pelo critério histórico-sócio-cultural, é a Islândia (; ), situada no Oceano Atlântico Norte. O seu território abrange a ilha homônima e algumas pequenas ilhas no Oceano Atlântico, localizadas entre a Europa continental e a Groenlândia. O país conta com uma população de quase 320 mil habitantes em uma área de cerca de 103 mil quilômetros quadrados. A sua capital e maior cidade é Reiquiavique, cuja área metropolitana abriga cerca de dois terços da população nacional. Devido à sua localização na Dorsal Meso-Atlântica, a Islândia tem uma grande atividade vulcânica e um importante gradiente geotérmico, o que afeta muito a sua paisagem. O interior é constituído principalmente por um planalto caracterizado por campos de areia, montanhas e glaciares. Aquecida pela corrente do Golfo, a Islândia tem um clima temperado em relação à sua latitude e oferece um ambiente habitável.
Itália (), oficialmente República Italiana (), é uma república parlamentar unitária localizada no centro-sul da Europa (Europa meridional). Ao norte, faz fronteira com França, Suíça, Áustria e Eslovênia ao longo dos Alpes. Ao sul, que consiste na totalidade da península Itálica, Sicília, Sardenha, as duas maiores ilhas no Mar Mediterrâneo, e muitas outras ilhas menores ficam no entorno do território italiano. Os Estados independentes de San Marino e do Vaticano são enclaves no interior de Itália, enquanto Campione d'Italia é um enclave italiano na Suíça. Com 60,6 milhões de habitantes, é a sexta nação mais populosa da Europa e a 23ª do mundo.
Roma, a capital italiana, foi durante séculos o centro político e religioso da civilização ocidental, como a capital do Império Romano, e como sede da Santa Sé. Após o declínio dos romanos, a Itália sofreu inúmeras invasões de povos estrangeiros. Séculos mais tarde, Itália tornou-se o berço das repúblicas marítimas e do "Renascimento", um movimento intelectual extremamente frutífero que viria a ser parte integrante na formação subsequente do pensamento europeu.
A Itália contemporânea nasceu como um Estado unitário, quando em 17 de março de 1861, a maioria dos estados da península e as duas principais ilhas foram unidas sob o comando do rei da Sardenha Vitor Emanuel II da casa de Saboia.
Liechtenstein ou Listenstaine (forma usada oficialmente pela União Europeia) é um minúsculo principado, localizado no centro da Europa, encravado nos Alpes, entre a Áustria, a leste, e a Suíça a oeste. Tem uma população de pouco mais de 34 mil habitantes que moram no principado de apenas 160 km².
O Grão-Ducado do Luxemburgo caracteriza-se por uma economia de boa renda e crescimento contínuo, tem o maior PNB (Produto Nacional Bruto) per capita do mundo ($US), além de baixíssimos índices de inflação e desemprego. O setor industrial era dominado praticamente pelo aço, mas recentemente se diversificou ao incluir o ramo químico e a borracha.
O Principado do é o segundo menor Estado independente do mundo (depois do Vaticano), constituindo um principado encravado no sul da França, (Costa Azul) a dezoito quilômetros de Nice e perto da fronteira com a Itália. Além das finanças, a economia monegasca é movimentada em grande parte pelo setor imobiliário: as duzentas empresas de construção civil são a força motriz da economia. O turismo é uma das mais importantes fontes de renda do país. O setor hoteleiro é dinâmico: quartos que recebem, ao ano, 225 mil visitantes.
Apenas 16% dos habitantes são monegascos. Os demais habitantes são franceses (47%), italianos (16%) e outros (21%). O idioma oficial é o francês, mas falam-se várias outras línguas devido às variadas origens de seus habitantes. Dentre estas as principais são o monegasco, o inglês e o italiano.
A Noruega (bokmål: "Norge"; nynorsk "Noreg"), oficialmente Reino da Noruega, é um país nórdico da Europa setentrional que ocupa a parte ocidental da Península Escandinava, a ilha de Jan Mayen e o arquipélago ártico de Svalbard, através do Tratado de Svalbard. A parte continental do país divide fronteira a leste com a Suécia e ao norte com a Finlândia e a Rússia. O Reino Unido e as Ilhas Faroe estão a oeste, através do Mar do Norte, a Islândia e a Groenlândia estão a oeste, através do mar da Noruega, e a Dinamarca fica próxima ao extremo sul do país, através do estreito de Skagerrak.
A Noruega mantém o modelo social escandinavo baseado na saúde universal, no ensino superior subsidiado e em um regime abrangente de previdência social. A Noruega foi classificada como o melhor país do mundo em desenvolvimento humano em todos os relatórios desde 2001 (com dados referentes entre 1999 e 2010)
Apesar de ter rejeitado a adesão à União Europeia em dois referendos, a Noruega mantém laços estreitos com a UE e com seus países membros, bem como com os Estados Unidos. A Noruega continua a ser um dos maiores contribuintes financeiros da Organização das Nações Unidas e participa com as forças da ONU em missões internacionais, como no Afeganistão, Kosovo e Darfur.
Os Países Baixos (incorretamente chamados de Holanda) é um dos países mais densamente povoados do globo. São popularmente conhecidos por seus diques, suas tulipas, seus moinhos, seus tamancos e sua tolerância social. Suas políticas liberais são frequentemente mencionadas e usadas como (bons ou maus) exemplos nos demais países.
Um dos fatores culturais que mais destaca os Países Baixos são os pintores renomados ao longo dos séculos. Durante o século XVII, quando o país era uma República e bem próspera, houve o surgimento de grandes artistas e aquela época ficou conhecida como a Era dos Mestres neerlandeses, entre eles, Rembrandt van Rijn, Johannes Vermeer, Jan Steen e Jacob van Ruysdael. Grandes Pintores do século XIX e XX foram Vincent van Gogh e Piet Mondriaan.
Portugal, oficialmente República Portuguesa, é um país soberano unitário localizado no Sudoeste da Europa, cujo território se situa na zona ocidental da Península Ibérica e em arquipélagos no Atlântico Norte. Portugal é a nação mais a ocidente do continente europeu. O nome do país provém da sua segunda maior cidade, Porto, cujo nome latino era "Portus Cale".
O território dentro das fronteiras actuais da República Portuguesa tem sido continuamente povoado desde os tempos pré-históricos: ocupado por celtas, como os galaicos e os lusitanos, foi integrado na República Romana e mais tarde colonizado por povos germânicos, como os suevos e os visigodos, e no século VIII as terras foram conquistadas pelos mouros. Durante a Reconquista cristã foi formado o Condado Portucalense, primeiro como parte do Reino da Galiza e depois integrado no Reino de Leão. Com o estabelecimento do Reino de Portugal em 1139, cuja independência foi reconhecida em 1143, e a estabilização das fronteiras em 1249, Portugal tornou-se o mais antigo Estado-nação da Europa.
Nos séculos XV e XVI, como resultado de pioneirismo na era dos Descobrimentos, Portugal expandiu a influência ocidental e estabeleceu um império que incluía possessões na África, Ásia, Oceania e América do Sul, tornando-se a potência económica, política e militar mais importante de todo o mundo. O Império Português foi o primeiro império global da história e também o mais duradouro dos impérios coloniais europeus, abrangendo quase 600 anos de existência, no entanto a importância internacional do país foi bastante reduzida a partir do século XVII, em consequência da União Ibérica. Após a Revolução de 1910, a monarquia foi deposta e iniciada a Primeira República Portuguesa, cuja instabilidade culminou na instauração de um regime autoritário, o Estado Novo. A democracia representativa foi instaurada após a Revolução dos Cravos, em 1974, que terminou a Guerra Colonial Portuguesa, quando as últimas províncias ultramarinas de Portugal se tornaram independentes, sendo as mais proeminentes Angola e Moçambique.
Reino Unido (), oficialmente Reino Unido da Grã-Bretanha e Irlanda do Norte (), é um país insular soberano localizado na costa noroeste da Europa continental. O Reino Unido inclui a ilha da Grã-Bretanha, a parte nordeste da ilha da Irlanda, além de muitas outras ilhas menores. A Irlanda do Norte é a única parte do Reino Unido com uma fronteira terrestre, sendo a mesma com a República da Irlanda. Rodeado pelo Oceano Atlântico, o Mar do Norte, o Canal da Mancha e o Mar da Irlanda, a maior ilha, a Grã-Bretanha, é conectada com a França pelo Eurotúnel.
O Reino Unido é uma união política de quatro nações constituintes: Escócia, Inglaterra, Irlanda do Norte e País de Gales. A nação é governada por um sistema parlamentar com a sede do governo em Londres, a capital, e é uma monarquia constitucional com a rainha Isabel II sendo a chefe de Estado. As dependências da Coroa das Ilhas do Canal (ou Ilhas Anglo-Normandas) e a Ilha de Man, formalmente possessões da Coroa, não fazem parte do Reino Unido, mas formam uma confederação com ele. O Reino Unido tem quatorze territórios ultramarinos, todos remanescentes do Império Britânico, que no seu ápice, possuía quase um quarto da superfície terrestre mundial, fazendo desse o maior império da história. Como resultado do império, a influência britânica pode ser vista na língua, cultura e sistemas judiciários de muitas de suas ex-colônias como o Canadá, Austrália, Índia e os Estados Unidos. A rainha Elizabeth II permanece como a chefe da Comunidade das Nações ("Commonwealth") e chefe de Estado de cada uma das monarquias na Commonwealth.
Suécia (), oficialmente Reino da Suécia (em sueco: "Konungariket Sverige"), é um país nórdico, localizado na Península Escandinava. A Suécia divide fronteiras terrestres com a Noruega, a oeste, e com a Finlândia, a nordeste, além de estar ligada à Dinamarca através da Ponte do Øresund, no sul.
Com km², a Suécia é o terceiro maior país da União Europeia em termos de área e possui uma população total de cerca de 9,2 milhões de habitantes. A Suécia tem uma baixa densidade populacional, com cerca de 21 habitantes por quilômetro quadrado, mas com uma densidade consideravelmente maior na metade sul do país. Cerca de 85% da população vive em áreas urbanas. A capital e maior cidade da Suécia é Estocolmo (com uma população de 1,3 milhões na área urbana e de 2 milhões na área metropolitana), centro do poder político e econômico do país. A Suécia é membro fundador da ONU, da União Europeia desde 1 de Janeiro de 1995, e da OCDE.
A Suécia é uma monarquia constitucional com um sistema parlamentar de governo e é uma economia altamente desenvolvida e diversificada. O país ocupa o quarto lugar do mundo no índice de democracia, depois da Islândia, da Dinamarca e da Noruega.
A Suíça, oficialmente Confederação Helvética é uma das economias mais ricas do mundo, e é sede de inúmeros bancos privados e de organizações internacionais. A sua história é marcada pela sua neutralidade política perante as outras nações e representa um marco de liberdade e de democracia para o mundo inteiro.

</doc>
<doc id="772" url="https://pt.wikipedia.org/wiki?curid=772" title="Europa">
Europa

A Europa é, por convenção, um dos seis continentes do mundo. Compreendendo a península ocidental da Eurásia, a Europa geralmente divide-se da Ásia a leste pela divisória de águas dos montes Urais, o rio Ural, o mar Cáspio, o Cáucaso, e o mar Negro a sudeste. A Europa é limitada pelo oceano Glacial Ártico e outros corpos de água no norte, pelo oceano Atlântico a oeste, pelo mar Mediterrâneo ao sul, e pelo mar Negro e por vias navegáveis interligadas ao sudeste. No entanto, as fronteiras para a Europa, um conceito que remonta à Antiguidade clássica, são um tanto arbitrárias, visto que o termo "Europa" pode referir-se a uma distinção cultural e política ou geográfica.
A Europa é o segundo menor continente em superfície do mundo, cobrindo cerca de ou 2% da superfície da Terra e cerca de 6,8% da área acima do nível do mar. Dos cerca de 50 países da Europa, a Rússia é o maior tanto em área quanto em população (sendo que a Rússia se estende por dois continentes, a Europa e a Ásia) e o Vaticano é o menor. A Europa é o quarto continente mais populoso do mundo, após a Ásia, a África e a(s) América(s), com 731 milhões de habitantes, cerca de 11% da população mundial. No entanto, de acordo com a Organização das Nações Unidas (estimativa média), o peso europeu pode cair para cerca de 7% em 2050. Em 1900, a população europeia representava 25% da população mundial.
A Europa, nomeadamente a Grécia Antiga, é considerada o berço da cultura ocidental. Tendo desempenhado um papel preponderante na cena mundial a partir do , especialmente após o início do colonialismo. Entre os séculos XVI e XX, as nações europeias controlaram em vários momentos as Américas, a maior parte da África, a Oceânia e grande parte da Ásia. Ambas as guerras mundiais foram em grande parte centradas na Europa, sendo considerado como o principal fator para um declínio do domínio da Europa Ocidental na política e economia mundial a partir de meados do , com os Estados Unidos e a União Soviética ganhando maior protagonismo. Durante a Guerra Fria, a Europa estava dividida ao longo da Cortina de Ferro entre a Organização do Tratado do Atlântico Norte, a oeste, e o Pacto de Varsóvia, a leste. A vontade de evitar outra guerra acelerou o processo de integração europeia e levou à formação do Conselho Europeu e da União Europeia na Europa Ocidental, os quais, desde a queda do Muro de Berlim e do fim da União Soviética em 1991, têm vindo a expandir-se para o leste.
O uso do termo "Europa" desenvolveu-se gradualmente ao longo da história. Na antiguidade, o historiador grego Heródoto provavelmente em referência a mapas de Hecateo de Mileto embora sem o nomear explicitamente, descreve o mundo como tendo sido dividido em três continentes, sendo eles a Europa, a Ásia e a Líbia (África), com o Nilo e o rio Fasis formando de suas fronteiras, embora também afirme que alguns consideravam o rio Don, em vez do Phasis, como a fronteira entre Europa e Ásia. Flavius Josephus e o Livro dos Jubileus descrevem os continentes como as terras dadas por Noé aos seus três filhos, sendo a Europa definida entre as Colunas de Hércules no Estreito de Gibraltar, separando-a da África, e o rio Don, separando-o da Ásia.
A definição cultural da Europa como terras da cristandade latina consolidou-se no , significando um novo local cultural criado através da confluência de tradições germânicas e da cultura cristã-latina, definidas em parte, em contraste com o Islão e Império Bizantino, e limitado a norte pela Ibéria (no Cáucaso), Ilhas Britânicas, França, Alemanha ocidental cristianizada, e as regiões alpinas do norte e no centro da Itália. Esta divisão, tanto geográfica como cultural, foi utilizada até a Baixa Idade Média, quando foi desafiada pela Era dos descobrimentos. O problema da redefinição da Europa, finalmente foi resolvido em 1730 quando, em vez de canais, o geógrafo e cartógrafo sueco von Strahlenberg propôs os Montes Urais como a fronteira mais importante do leste, uma sugestão que foi aceita na Rússia e em toda a Europa.
A Europa está agora em geral, definida pelos geógrafos, como a península ocidental da Eurásia, com seus limites marcados por grandes massas de água para o norte, oeste e sul; limites da Europa para o Extremo Oriente são normalmente tomadas para os Urais, o rio Ural, e o Mar Cáspio, a sudeste, as montanhas do Cáucaso, o Mar Negro e nas vias que ligam o Mar Negro ao Mar Mediterrâneo.
Às vezes, a palavra "Europa" é utilizada de forma geopoliticamente limitada para se referir apenas à União Europeia ou, ainda mais exclusiva, a um núcleo cultural definido. Por outro lado, o Conselho da Europa tem 47 países membros, e apenas 28 estados-membros estão na UE. Além disso, pessoas que vivem em áreas insulares, como a Irlanda, o Reino Unido, no Atlântico Norte e Mediterrâneo e ilhas também na Escandinávia podem rotineiramente se referir a parte "continental" ou ao "continente" da Europa ou simplesmente como "o continente".
Na mitologia grega, Europa era uma princesa fenícia que Zeus sequestrou depois de assumir a forma de um touro branco deslumbrante. Ele a levou para a ilha de Creta, onde ela deu à luz Minos, Radamanto e Sarpedão. Para Homero, Europa (em grego: , "") era uma rainha mitológica de Creta e não uma designação geográfica. Mais tarde, o termo "Europa" foi usado para se referir ao centro-norte da Grécia, e em 500 a.C., seu significado foi estendido para as terras ao norte.
O nome "Europa" é de etimologia incerta. Uma teoria sugere que a palavra é derivada do grego εὐρύς ("eurus"), que significa "largo, amplo" e ὤψ/ὠπ-/ὀπτ- ("ōps"/"ōp"-/"opt-") significa "olho, rosto, semblante", portanto "" seria algo como "ampla contemplação". "Amplo" era um epíteto da própria Terra na religião protoindo-europeia. Outra teoria sugere que o termo é baseado em uma palavra semita como o mesmo significado do acadiano "erebu", algo como "para ir para baixo, pôr-se" (cf. Ocidente), um cognato do fenício "ereb" "noite; oeste" e do árabe do Magreb, do hebraico "ma'ariv" (ver "Érebo", PIE "*hregʷos", "escuridão"). No entanto, M. L. West afirma que "fonologicamente, a correspondência entre o nome de Europa e qualquer forma da palavra semítica é muito pobre".
As principais línguas do mundo mais usam palavras derivadas de "Europa" para se referir ao "continente" (península). O chinês, por exemplo, usa a palavra ' (歐洲); este termo também é usado para se referir à União Europeia nas relações diplomáticas em língua japonesa, apesar do termo katakana ' ser mais comumente usado. No entanto, em algumas línguas turcas, o nome originalmente persa "Frangistan" (terra dos francos) é usado casualmente para se referir à grande parte da Europa, além de nomes oficiais, como "Avrupa" ou "Evropa".
Os "Homo erectus" e os Neanderthalis habitavam a Europa bem antes do surgimento dos humanos modernos, os "Homo sapiens". Os ossos dos primeiros europeus foram achados em Dmanisi, Geórgia, e datados de 1,8 milhões de anos. O primeiro aparecimento do povo anatomicamente moderno na Europa é datado de 35 000 a.C. Evidências de assentamentos permanentes datam do 7º milénio/milênio a.C. na Bulgária, Roménia e Grécia. O período neolítico chegou na Europa central no 6º milénio a.C. e em partes da Europa Setentrional no 5º e 4º milénio a.C. A civilização Tripiliana (5508-2750 a.C.) foi a primeira grande civilização da Europa e uma das primeiras do mundo; era localizada na Ucrânia moderna e também na Moldávia e Roménia. Foi provavelmente mais antiga que os Sumérios no Oriente Próximo, e tinha cidades com 15 000 habitantes que cobriam 450 hectares.
Começando no Neolítico, tem-se a civilização de Camunni no Val Camonica, Itália, que deixou mais de 350 000 petróglifos, o maior sítio arqueológico da Europa.
Também conhecido como Idade do Cobre, o Calcolítico europeu foi um tempo de mudanças e confusão. O fato mais relevante foi a infiltração e invasão de imensas partes do território por povos originários da Ásia Central, considerado pelos principais historiadores como sendo os originais indo-europeus, mas há ainda diversas teorias em debate. Outro fenómeno foi a expansão do Megalitismo e o aparecimento da primeira significante estratificação económica e, relacionado a isso, as primeiras monarquias conhecidas da região dos Balcãs. A primeira civilização bem conhecida da Europa foi as dos Minoicos da ilha de Creta e depois os Micenas em adjacentes partes da Grécia, no começo do 2º milénio a.C.
Embora o uso do ferro fosse de conhecimento dos povos egeus por volta de , não chegou à Europa Central antes de , levando ao início da Cultura de Hallstatt, uma evolução da Idade do Ferro (que até então se encontrava na Cultura dos Campos de Urnas). Provavelmente como subproduto desta superioridade tecnológica, pouco depois os indo-europeus consolidam claramente suas posições na Itália e na península Ibérica, penetrando profundamente naquelas penínsulas (Roma foi fundada em 
Os gregos e romanos deixaram um legado na Europa que é evidente nos pensamentos, leis, mentes e línguas actuais. A Grécia Antiga foi uma união de cidades-estado, na qual uma primitiva forma de democracia se desenvolveu. Atenas foi sua cidade mais poderosa e desenvolvida, e um berço de ensinamento nos tempos de Péricles. Fóruns de cidadãos aconteciam e o policiamento do estado deu ordem ao aparecimento dos mais notáveis filósofos clássicos, como Sócrates, Platão e Aristóteles. Como rei do Reino Grego da Macedónia, as campanhas militares de Alexandre o Grande espalharam a cultura helénica até às nascentes do rio Indo.
Mas a República Romana, alicerçada pela vitória sobre Cartago nas Guerras Púnicas, estava crescendo na região. A sabedoria grega passada às instituições romanas, assim como a própria Atenas foi absorvida sob a bandeira do senado e do povo de Roma. Os romanos expandiram seu império desde a Arábia até a Bretanha. Em quando atingiu o seu ápice, seu líder, Júlio César foi morto sob suspeitas de estar corrompendo a república para se tornar um ditador. Na sucessão, Otaviano usurpou as raízes do poder e dissolveu o senado romano. Quando proclamou o renascimento da república ele, de facto, transferiu o poder do senado romano quando república para um império, o Império Romano.
Quando o Imperador Constantino reconquistou Roma sob a bandeira da Cruz em 312, ele rapidamente editou o Édito de Milão em 313, declarando legal o cristianismo no Império Romano. Além disso, Constantino mudou oficialmente a capital do império, Roma, para a colónia grega de Bizâncio, que ele renomeou para Constantinopla ("Cidade de Constantino"). Em 395, Teodósio, que tornou o cristianismo religião oficial do Império Romano, iria ser o último imperador a comandar o Império Romano em toda a sua unidade, sendo depois o império dividido em duas partes: O Império Romano do Ocidente, centrado em Ravena, e o Império Romano do Oriente (depois referido como Império Bizantino) centrado em Constantinopla. A parte ocidental foi seguidamente atacada por tribos nómadas germânicas, e em 476 finalmente caiu sob a invasão dos Hérulos comandados por Odoacro.
A autoridade romana no Oeste entrou em colapso e as províncias ocidentais logo tornaram-se pedaços de reinos germânicos. Entretanto, a cidade de Roma, sob o comando da Igreja Católica Romana permaneceu como um centro de ensino, e fez muito para preservar o pensamento clássico romano na Europa Ocidental. Nesse meio-tempo, o imperador romano em Constantinopla, Justiniano I, conseguiu com sucesso, montar toda a lei romana no Corpus Juris Civilis . Por todo o , o Império Romano do Oriente esteve envolvido numa série de conflitos sangrentos, primeiro contra o Império Sassânida, depois contra o Califado Rashidun. Em 650, as províncias do Egito, Palestina e Síria foram perdidas para forças muçulmanas.
Na Europa Ocidental, uma estrutura política surgia: no vácuo do poder deixado pelo colapso de Roma, hierarquias locais foram construídas sob a união das pessoas nas terras que eram trabalhadas. Dízimos eram pagos ao senhor da terra e este senhor devia tributos ao príncipe regional. Os dízimos eram usados para financiar o estado e as guerras. Esse foi o sistema feudal, no qual novos príncipes e reis apareceram, no qual o maior deles foi o líder Franco Carlos Magno. Em 800, Carlos Magno, após as suas grandes conquistas territoriais, foi coroado Imperador dos Romanos ("Imperator Romanorum") pelo Papa Leão III, afirmando efectivamente o seu poder na Europa Ocidental. O reinado de Carlos Magno marcou o começo dum novo império germânico no oeste, o Sacro Império Romano. Para além das suas fronteiras novas forças estavam crescendo. O Principado de Kiev estava delimitando o seu território, a Grande Morávia estava crescendo, enquanto os anglos e os saxões estavam confirmando as suas fronteiras.
O Renascimento foi um movimento cultural que afectou profundamente a vida intelectual europeia no seu período pré-moderno. Começando em Itália, e espalhando-se de norte a oeste, o renascimento durou aproximadamente 250 anos e a sua influência afectou a literatura, filosofia, arte, política, ciência, história, religião entre outros aspectos de indagação intelectual.
O italiano Francesco Petrarca ("Francesco di Petracco"), suposto primeiro legítimo humanista, escreveu na década de 1330: "Estou vivo agora, ainda que eu prefira ter nascido noutro tempo". Ele era um entusiasta da antiguidade romana e grega. Nos séculos XV e XVI, o contínuo entusiasmo pela antiguidade clássica foi reforçado pela ideia de que a cultura herdada estava se dissipando e de que havia um conjunto de ideias e atitudes com que seria possível reconstruí-la. Matteo Palmieri escreveu em 1430: "Agora, com certeza, todo espírito pensante deve agradecer a Deus, porque a ele foi permitido nascer numa nova era". O Renascimento fez nascer uma nova era em que aprender era muito importante.
Importantes precedentes políticos aconteceram neste período. O político Nicolau Maquiavel escreveu "O Príncipe" que influenciou o posterior absolutismo e a política pragmática. Também foram importantes os diversos líderes que governaram estados e usaram a arte da Renascença como sinal de seus poderes.
Durante esse período, a corrupção da Igreja Católica levou a uma dura reação, na Reforma Protestante. E ela ganhou muitos seguidores, especialmente entre príncipes e reis buscando um estado forte para acabar com a influência da igreja católica. Figuras como Martinho Lutero começaram a surgir, assim também como João Calvino com o seu Calvinismo que teve influência em muitos países e o rei que rompeu com a igreja católica e fundou a Igreja Anglicana. Essas divisões religiosas trouxeram uma onda de guerras inspiradas e conduzidas religiosamente, mas também pela ambição dos monarcas na Europa Ocidental que se tornavam cada vez mais centralizadas e poderosas.
A reforma protestante também levou a um forte movimento reformista na igreja católica chamado Contra-Reforma, que tinha como objectivo reduzir a corrupção, assim como aumentar e fortalecer o dogma católico. Um importante grupo da igreja católica que surgiu nessa época foram os Jesuítas, que ajudaram a manter a Europa Oriental na linha católica de pensamento. Mesmo assim, a igreja católica foi fortemente enfraquecida pela reforma e, grande parte do continente não estava mais sob sua influência e os reis nos países que continuaram no catolicismo começaram a anexar as terras da igreja para os seus próprios domínios.
As numerosas guerras não impediram que os novos estados explorassem e conquistassem largas porções do mundo, particularmente na Ásia (Sibéria) e a recém-descoberta América. No , Portugal liderou a exploração geográfica, seguido pela Espanha no começo no . Eles foram os primeiros estados a fundar colónias/colônias na América e estações de troca nas costas da África e da Ásia, porém logo foram seguidos pela França, Inglaterra e Holanda. Em 1552, o czar Russo Ivan, o Terrível conquistou os dois maiores canatos tártaros, Casã e Astracã, e a viagem de Yermak em 1580, que levou a anexação da Sibéria pela Rússia.
A expansão colonial prosseguiu-se nos anos seguintes (mesmo com alguns empecilhos, como a Revolução Americana e as guerras pela independência em muitas colónias americanas). A Espanha controlou parte da América do Norte e grande parte da América Central e do Sul, as Caraíbas/o Caribe e Filipinas.; Portugal teve em suas mãos o Brasil e a maior parte dos territórios costeiros em África e na Ásia (Índia e pequenos territórios na China etc); Os britânicos comandavam a Austrália, Nova Zelândia, maior parte da Índia e grande parte da África e América do Norte; a França comandou partes do Canadá e da Índia (porém quase tudo foi perdido para os britânicos em 1763), a Indochina, grandes terras na África e Caribe; a Holanda ganhou as Índias Orientais (hoje Indonésia) e algumas ilhas nas Caraíbas/no Caribe; países como Alemanha, Bélgica, Itália e Rússia conquistaram colónias posteriormente.
Essa expansão ajudou a economia dos países que a fizeram. O comércio prosperou, por causa da menor estabilidade entre os impérios. No final do , a prata americana era responsável por 1/5 de todo o comércio da Espanha. Os países europeus travaram guerras que foram pagas através do dinheiro conseguido com a exploração das colónias/colônias. No entanto, os lucros com o tráfico de escravos e as plantações das Índias Ocidentais, a mais rentável das colônias britânicas naquele momento, representavam apenas 5% de toda a economia do Império Britânico no final do , tempo da Revolução Industrial.
A partir do início deste período, o capitalismo substituía o feudalismo como principal forma de organização económica, ao menos no oeste da Europa. A expansão das fronteiras coloniais resultou numa Revolução Comercial. Nota-se no período o crescimento da ciência moderna e a aplicação de suas descobertas em melhorias tecnológicas, que culminaram com a revolução Industrial. Descobertas ibéricas do Novo Mundo, que começaram com a jornada de Cristóvão Colombo ao oeste com a busca de uma rota fácil para as Índias Orientais em 1492, foram logo adaptadas por explorações inglesas e francesas na América do Norte. Novas formas de comércio e a expansão dos horizontes fizeram necessária uma mudança no direito internacional.
A reforma protestante produziu efeitos profundos na unidade europeia. Não apenas dividindo as nações uma das outras pela sua orientação religiosa, mas alguns estados foram afectados internamente por lutas religiosas, fortemente encorajadas por seus inimigos externos. A França viveu essa situação no com uma série de conflitos, como as guerras religiosas na França, que culminaram no triunfo da Dinastia Bourbon. A Inglaterra preveniu-se desse facto/fato com a consolidação sob a Rainha Elizabeth do moderado Anglicanismo. Quase toda a parte da atual Alemanha estava dividida em inúmeros estados sob o comando teórico do Sacro Império Romano Germânico, que também estava dividido dentro do próprio governo. A única exceção a isso era a Comunidade Polaco-Lituana, uma união criada pela União de Lublin, expressando uma grande tolerância religiosa. Esse embate religioso aconteceu até à Guerra dos Trinta Anos quando o nacionalismo substituiu a religião como principal motor dos conflitos na europa.
A Guerra dos Trinta Anos aconteceu entre 1618 e 1648, principalmente no território da atual Alemanha, e envolveu as principais potências europeias. Começou como um conflito religioso entre Protestantes e Católicos no Sacro Império Romano Germânico, e gradualmente desenvolveu-se numa guerra geral, envolvendo boa parte da europa, por razões não necessariamente ligadas à religião. O maior impacto da guerra, na qual exércitos de mercenários foram largamente utilizados, foi a devastação de regiões inteiras na busca do exército inimigo. Episódios como a disseminação da fome e das doenças devastaram a população dos estados germânicos e, em menor grau, dos Países Baixos e da Itália, onde levaram à falência muito dos poderes regionais envolvidos. Entre um quarto e um terço da população alemã pereceu por causas diretamente ligadas à guerra ou ainda de doenças e miséria causadas pelo conflito armado. A guerra durou trinta anos, mas os conflitos que ela deu início ainda continuaram sem solução por muito tempo.
Depois da Paz de Vestfália, que permitiu aos países que eles escolhessem a sua orientação religiosa, o Absolutismo tornou-se o padrão do continente, enquanto a Inglaterra caminhava rumo ao liberalismo com a Guerra Civil Inglesa e a Revolução Gloriosa. Os conflitos militares na europa não acabaram, mas tiveram menos impacto na vida dos seus cidadãos. No noroeste, o Iluminismo deu a base filosófica para um novo ponto de vista na sociedade, e a contínua difusão da literatura foi possível com a invenção da prensa, criando novas formas de avanço do pensamento humano. Ainda, nesse segmento, a Comunidade Polaco-Lituana foi uma exceção, com a sua quase democrática "liberdade dourada".
A Europa Oriental era uma arena de conflito disputada pela Suécia, Comunidade Polaco-Lituana e Império Otomano. Nesse período observou-se um gradual declínio destes três poderes que foram eventualmente substituídos pelas novas monarquias absolutistas, Rússia, Prússia e Áustria. Na virada para o , eles tornaram-se as novas potências, dividindo a Polónia entre si, com Suécia e Turquia perdendo territórios substanciais para a Rússia e a Áustria respetivamente/respectivamente. Uma grande parte de judeus polacos/poloneses emigrou para a Europa Ocidental, fundando comunidades judaicas em lugares de onde foram expulsos durante a Idade Média.
A intervenção francesa na Guerra de Independência dos EUA levou o estado francês à falência. Depois de diversas tentativas falhas de uma reforma financeira, foi forçado a reavivar a Assembleia dos Estados Gerais, um corpo representativo do país feito pelas três classes do estado: o clero, os nobres e o povo. Os membros dos Estados-Gerais reuniram-se no Palácio de Versalhes em maio de 1789, mas o debate e a forma de votação que seria usada criaram um impasse. Veio junho, e o terceiro estado, associado a membros dos dois outros estados, declarou-se uma Assembleia Nacional e prometeu não se dissolver até que França tivesse uma constituição e criasse, em julho, uma Assembleia Nacional Constituinte. No mesmo tempo, os parisienses revoltaram-se, celebremente derrubando a prisão da Bastilha em 14 de julho de 1789.
Nesse tempo, a assembleia criou uma monarquia constitucional, e nos dois anos que se passaram várias leis foram criadas como a Declaração dos direitos do Homem e do Cidadão, a abolição do feudalismo e uma mudança fundamental das relações entre a França e Roma. No início, o rei continuou no trono ao longo dessas mudanças e gozou de uma popularidade razoável com o povo, mas a anti-realeza crescia com o perigo de uma invasão estrangeira. Então o rei, sem poderes, decidiu fugir com a sua família, mas ele foi reconhecido de volta a Paris. Em 12 de janeiro de 1793, sendo condenada a sua traição, ele foi executado.
Em 20 de setembro de 1792, a convenção nacional aboliu a monarquia e declarou a França uma república. Devido à iminência das guerras, a convenção nacional criou o Comitê de Salvação Pública controlado por Maximilien Robespierre do Partido dos Jacobinos, para atuar como executivo do país. Sob Robespierre o comitê iniciava o Reino do terror, no qual cerca de 40 000 pessoas foram executadas em Paris, na maioria nobres, apesar de, frequentemente, faltarem evidências. Por todo o país, insurreições contra-revolução foram brutalmente reprimidas. O regime foi posto abaixo no golpe de 9 Termidor (27 de Julho de 1794) e Robespierre foi executado. O regime que se seguiu acabou com o Terror e afrouxou a maioria das regras extremas de Robespierre.
Napoleão Bonaparte foi o general francês que mais obteve sucesso nas guerras da Revolução, tendo conquistado grandes porções da península Itálica e forçado os austríacos à paz. Em 1799, retornou do Egito e em 18 de Brumário (9 de Novembro) subjugou o governo, substituindo-o pelo seu Consulado, do qual tornou-se o primeiro Cônsul. Em 2 de Dezembro de 1804, depois duma tentativa de assassinato, ele coroou-se imperador. Em 1805, Napoleão planeou invadir a Grã-Bretanha, mas a recém-criada aliança entre britânicos, russos e austríacos (Terceira Coalizão) forçou-o a direcionar a atenção para o continente, quando ao mesmo tempo ele tinha falhado em desviar a Armada Superior Britânica para longe do Canal da Mancha, ocasionando uma decisiva derrota francesa na batalha de Trafalgar em 21 de outubro, e colocando um fim às suas esperanças de invadir a Grã-Bretanha. Em 2 de dezembro de 1805, Napoleão derrotou o exército austro-russo, numericamente superior, em Austerlitz, forçando a Áustria desistir da coalizão e levando à fragmentação do Sacro Império Romano Germânico. Em 1806, a Quarta coalizão foi formada; em 14 de Outubro Napoleão derrotou os prussianos na Batalha de Jena-Auerstedt, marchando através da Alemanha e derrotando os russos em 14 de junho de 1807 em Friedland. Os Tratados de Tilsit dividiram a Europa entre França e Rússia e criaram o Ducado de Varsóvia.
Em 12 de junho de 1812, Napoleão invadiu a Rússia com a sua Grande Armée de aproximadamente 700 000 soldados. Após as vitórias em Smolensk e Borodino, Napoleão ocupou Moscovo, apenas para encontrá-la queimada pelo exército russo em retirada. Assim, ele foi forçado a bater com seu exército em retirada. Na volta o seu exército foi arrasado pelos cossacos e sofreu de doenças, fome e com o rigoroso inverno russo. Apenas 20 000 soldados sobreviveram a essa campanha. Em 1813, começou o declínio de Napoleão, sendo derrotado pelo Exército das Sete Nações na Batalha de Leipzig em outubro de 1813. Ele foi forçado a abdicar depois da Campanha dos Seis Dias e a ocupação de Paris. Sob o Tratado de Fontainebleau ele foi exilado na Ilha de Elba. Retornou à França em 1 de março de 1815 e convocou um exército leal, mas foi compreensivelmente derrotado por forças britânicas e prussianas na Batalha de Waterloo em 18 de junho de 1815.
Depois da derrota da revolucionária França, outras grandes forças tentaram restaurar a situação existente antes de 1789. Em 1815, no Congresso de Viena, as maiores forças da Europa organizaram-se para produzir um pacífico equilíbrio de poder entre os impérios depois das Guerrras Napoleónicas (embora estivessem ocorrendo movimentos internos revolucionários) sob o sistema de Matternich. Entretanto, os seus esforços foram incapazes de parar a propagação de movimentos revolucionários: a classe média foi profundamente influenciada pelos ideais de democracia da Revolução Francesa, a revolução Industrial trouxe importantes mudanças sócio-económicas/econômicas, as classes baixas começaram a ser influenciadas pelas ideias socialistas, comunistas e anarquistas (especialmente unidas por Karl Marx no Manifesto Comunista), e a preferência dos novos capitalistas era o liberalismo.
Uma nova onda de instabilidade veio da formação de diversos movimentos nacionalistas (na Alemanha, Itália, Polônia, etc.), buscando uma unidade nacional e/ou liberação do domínio estrangeiro. Como resultado, o período entre 1815 e 1871 foi palco de um grande número de conflitos e guerras de independência. Napoleão III, sobrinho de Napoleão I, retornou do exílio na Inglaterra em 1848 para ser eleito pelo parlamento francês, como o então "Presidente-Príncipe" e num golpe de estado eleger-se imperador, aprovado depois pela grande maioria do eleitorado francês. Ele ajudou na unificação da Itália lutando contra o Império Austríaco e lutou a Guerra da Crimeia com a Inglaterra e o Império Otomano contra a Rússia. Seu império ruiu depois duma infame derrota para a Prússia, na qual ele foi capturado. A França então se tornou uma fraca república que recusava-se a negociar e foi derrotada pela Prússia em poucos meses. Em Versalhes, o Rei Guilherme I da Prússia foi proclamado Imperador da Alemanha e a Alemanha moderna nasceu. Mesmo que a maioria dos revolucionários tenha sido derrotada, muitos estados europeus tornaram-se monarquias constitucionais, e em 1871 Alemanha e Itália se desenvolveram em estados-nação. Foi no também que se observou o Império Britânico emergir como o primeiro poder global do mundo devido, em grande parte, à Revolução Industrial e a vitória nas Guerras Napoleónicas.
A paz iria apenas durar até que o Império Otomano declinasse suficientemente para se tornar alvo de outros. Isso incitou a Guerra da Crimeia em 1854, e começou um tenso período de pequenos conflitos entre as nações dominantes da Europa que deram o primeiro passo para a posterior Primeira Guerra Mundial. Isso mudou uma terceira vez com o fim de várias guerras que transformaram o Reino da Sardenha e o Reino da Prússia nas nações da Itália e da Alemanha, mudando significativamente o balanço do poder na Europa. A partir de 1870, a hegemonia Bismarquiana na Europa pôs a França em uma situação crítica. Ela devagar reconstruiu suas relações internacionais, buscando alianças com a Grã-Bretanha e Rússia, para controlar o crescente poder da Alemanha sobre a Europa. Desse modo, dois lados opostos se formaram na Europa, incrementando suas forças militares e suas alianças ano a ano.
A Revolução Industrial foi um período compreendido entre o fim do e o começo do , no qual ocorreram grandes mudanças na agricultura, manufatura e transporte e foi produzido um profundo efeito socioeconómico/socioeconômico e cultural na Grã-Bretanha, que posteriormente se espalhou por toda a Europa, América do Norte, e depois para todo o mundo, num processo que ainda continua: a Industrialização. Na parte final dos anos de 1700 a economia baseada na força manual no Reino da Grã-Bretanha começou a ser substituída por outra dominada pela indústria e pelas máquinas. Começou com a mecanização das indústrias têxteis, o desenvolvimento de técnicas avançadas de produção de ferro e o aumento do uso de carvão refinado. A expansão do comércio foi possibilitada com a introdução de canais, rodovias e auto-estradas. A introdução das máquinas a vapor (abastecidas primeiramente com carvão) e maquinaria bruta (principalmente na manufatura têxtil) deram a base para grandes aumentos na capacidade produtiva inglesa. O desenvolvimento de máquinas de ferramentas nas duas primeiras décadas do facilitou a produção de mais máquinas para serem utilizadas noutras indústrias. Durante o , a industrialização se alastrou pelo resto da Europa Ocidental e América do Norte, afetando posteriormente grande parte do mundo.
Depois da relativa paz na maior parte do , a rivalidade entre as potências europeias explodiu em 1914, quando a Primeira Guerra Mundial começou. Mais de 60 milhões de soldados europeus foram mobilizados entre 1914 e 1918. De um lado estavam Alemanha, Áustria-Hungria, o Império Otomano e a Bulgária (Poderes Centrais/Tríplice Aliança), enquanto que no outro lado estavam a Sérvia e a Tríplice Entente – a elástica coligação entre França, Reino Unido e Rússia, que ganhou a participação da Itália em 1915 e dos Estados Unidos em 1917. Embora a Rússia tenha sido derrotada em 1917 (a guerra foi uma das maiores causas da Revolução Russa, levando à formação da comunista União Soviética), a Entente finalmente prevaleceu no outono de 1918.
No Tratado de Versalhes (1919) os vencedores impuseram severas condições à Alemanha e aos novos estados reconhecidos (tais como Polónia, Checoslováquia, Hungria, Áustria, Jugoslávia, Finlândia, Estónia, Letónia, Lituânia) criados na Europa Central a partir dos extintos impérios Alemão, Austro-Húngaro e Russo, supostamente na base da auto-definição. A maioria desses países entraria em guerras locais, sendo a maior delas a Guerra Polaco-Soviética . Nas décadas seguintes, o medo do comunismo e a Grande Depressão levaram grupos extremistas nacionalistas — sob a categoria do fascismo — na Itália (1922), Alemanha (1933), Espanha (depois da guerra civil, terminada em 1939) e em outros países como a Hungria.
Depois de aliar-se com a Itália de Mussolini no Pacto de Aço e assinar o pacto de não-agressão com a União Soviética, o ditador alemão Adolf Hitler começou a Segunda Guerra Mundial em 1 de Setembro de 1939 invadindo a Polónia, depois de uma expansão militar ocorrida no final da década de 1930. Após sucessos iniciais (principalmente a conquista do oeste da Polónia/Polônia, grande parte da Escandinávia, França e os Balcãs antes de 1941), as forças do Eixo começaram a enfraquecer-se em 1941. Os principais oponentes ideológicos de Hitler eram os comunistas da Rússia, mas por causa da falha alemã em derrotar o Reino Unido e das falhas italianas no norte da África e no Mediterrâneo, as forças do Eixo se resumiram à Europa Ocidental, Escandinávia, além de ataques a África. O ataque feito posteriormente à União Soviética (que junto com a Alemanha dividiu a Europa central em 1939-1940) não foi feito com a força necessária. Apesar de um sucesso inicial, o exército alemão foi parado perto de Moscovo em dezembro de 1941.
Apenas no ano seguinte é que o avanço alemão seria parado e eles começariam a sofrer uma série de derrotas, como por exemplo, nas batalhas de Stalingrado e Kursk. Nesse ínterim, o Japão (aliado de Alemanha e Itália desde setembro de 1940) atacou os britânicos no Sudeste Asiático e os Estados Unidos no Havaí em 7 de Dezembro de 1941; a Alemanha então completou a sua expansão declarando guerra aos Estados Unidos. A guerra aumentou a tensão entre o Eixo (Alemanha, Itália e Japão) e os Aliados (Reino Unido, União Soviética e os Estados Unidos). As forças Aliadas venceram no norte da África e invadiram a Itália em 1943, e a ocupada França em 1944. Na primavera de 1945, a Alemanha foi invadida pelo leste pela União Soviética e pelo oeste pelos Aliados; Hitler cometeu suicídio e a Alemanha se rendeu no começo de maio acabando com a guerra na Europa.
O período foi marcado também por um industrializado e planeado genocídio de mais de 11 milhões de pessoas, incluindo a maioria dos judeus da Europa e ciganos, assim como milhões de polacos e eslavos soviéticos. O sistema soviético de trabalho forçado, as expulsões da população da União Soviética e a grande fome da Ucrânia tiveram semelhante carga de mortes. Durante e depois da guerra, milhões de civis foram afetados pelas forçadas transferências da população.
A Primeira e especialmente a Segunda Guerra Mundial acabaram com a preponderante posição da Europa Ocidental. O mapa do continente foi redesenhado na Conferência de Yalta e dividido se tornou a principal zona de contenção na Guerra Fria entre dois blocos, os países ocidentais e o bloco Oriental. Os Estados Unidos e a Europa Ocidental (Reino Unido, França, Itália, Países Baixos, Alemanha Ocidental, etc.) estabeleceram a aliança da OTAN como proteção contra uma possível invasão soviética. Depois, a União Soviética e o Leste Europeu (Polónia, Checoslováquia, Hungria, Roménia, Bulgária e Alemanha Oriental) estabeleceram o Pacto de Varsóvia como proteção contra uma possível invasão dos Estados Unidos.
Na mesma época, a Europa Ocidental lentamente começou um processo de integração política e económica/econômica, desejando um continente unido e integrado para prevenir outra guerra. Esse processo resultou naturalmente no desenvolvimento de organizações como a União Europeia e o Conselho da Europa. O movimento Solidarność que aconteceu na década de 1980 enfraqueceu o governo comunista na Polônia, foi o começo do fim do domínio comunista na Europa Oriental e o declínio da União Soviética. O líder soviético Mikhail Gorbachev instituiu a Perestroika e a Glasnost, que enfraqueceram oficialmente a influência soviética na Europa Oriental. Os governos que davam suporte aos soviéticos entraram em colapso e a Alemanha Ocidental anexou a Oriental em 1990. Em 1991, a própria União Soviética ruiu, dividindo-se em 15 estados, com a Rússia tomando o lugar da União Soviética no Conselho de Segurança da ONU. Entretanto, a separação mais violenta aconteceu na Jugoslávia, nos Bálcãs. Quatro (Eslovénia, Croácia, Bósnia e Herzegóvina e Macedónia/Macedônia) das seis repúblicas jugoslavas declararam independência e para a maioria delas uma violenta guerra se seguiu, em algumas partes até 1995. Em 2006, Montenegro se separou e declarou independência, seguido por Kosovo, formalmente uma província autónoma/autônoma da Sérvia, em 2008, e descaracterizando completamente o antigo mapa da Jugoslávia/Iugoslávia. Na era pós-guerra fria, OTAN e a União Europeia foram gradualmente admitindo a maioria dos antigos estados membros do Pacto de Varsóvia.
Em 1992, o Tratado de Maastricht foi assinado pelos então membros da União Europeia. Isso transformou o "Projeto Europeu" de ser uma comunidade económica/econômica com certos aspectos políticos, numa união com uma intensa cooperação e prosperidade baseada numa união de soberanias nacionais. Em 1985, o Acordo de Schengen criou uma área sem fronteiras e sem controle de passaporte entre os estados que o assinaram.
Uma moeda comum para a maioria dos estados membros da União Europeia, o euro, foi estabelecida eletronicamente em 1999, oficialmente partilhando todas as moedas de cada participante com os outros. A nova moeda foi posta em circulação em 2002 e as velhas foram retiradas dos mercados. Apenas três países dos quinze estados membros decidiram não aderir ao euro (Reino Unido, Dinamarca e Suécia). Em 2004, a UE deu ordem à sua maior expansão, admitindo 10 novos membros (oito dos quais antigos estados comunistas). Outros dois ingressaram no grupo em 2007, num total de 27 nações.
Um tratado estabelecendo uma constituição para a UE foi assinado em Roma em 2004, com a intenção de substituir todos os antigos tratados com apenas um só documento. Entretanto, a sua ratificação nunca foi feita devido à rejeição de franceses e holandeses, via referendo. Em 2007, concordou-se em substituir aquela proposta com um novo tratado reformado, o Tratado de Lisboa, que iria entrar como uma emenda em vez de substituir os tratados existentes. Esse tratado foi assinado em 13 de dezembro de 2007 e entraria em vigor em janeiro de 2009, se ratificado até essa data. Isso daria à União Europeia seu primeiro presidente e ministro de relações exteriores.
Os Balcãs são a parte da Europa que mais deseja aderir à União Europeia, com a Croácia notadamente esperando ser aceite antes de 2010.
Fisiograficamente, a Europa é o componente noroeste da maior massa de terra do planeta, conhecida como a Eurásia, ou Eurafrásia: a Ásia ocupa a maior parte leste dessa porção de terra contínua e todos partilham uma plataforma continental comum. A fronteira oriental da Europa agora é comumente definida pelos montes Urais, na Rússia. O geógrafo do Estrabão, considerava o rio Don "Tanais" como o limite para o mar Negro, como diziam as primeiras fontes judaicas.
A fronteira sudeste com a Ásia não é universalmente definida, sendo que o rio Ural, ou, alternativamente, o rio Emba servem mais comummente como limites possíveis. O limite continua até ao mar Cáspio, a crista das montanhas do Cáucaso, ou, alternativamente, o rio Kura no Cáucaso, e o mar Negro, Bósforo, o mar de Mármara, o estreito de Dardanelos, o mar Egeu concluem o limite com a Ásia. O mar Mediterrâneo ao sul separa a Europa da África. A fronteira ocidental é o oceano Atlântico, a Islândia, embora mais perto da Gronelândia (América do Norte) do que da Europa continental, são geralmente incluídos na Europa.
Por causa das diferenças sócio-políticas e culturais, existem várias descrições de fronteira da Europa, sendo que em algumas fontes alguns territórios não estão incluídos na Europa, enquanto outras fontes incluem-nos. Por exemplo, os geógrafos da Rússia e de outros países pós-soviéticos geralmente incluem os Urais na Europa, incluindo o Cáucaso na Ásia. Da mesma forma, o Chipre é mais próximo da Anatólia (ou Ásia Menor), mas é muitas vezes considerado parte da Europa e atualmente é um estado membro da UE. Além disso, Malta já foi considerado uma ilha da África ao longo de vários séculos.
O relevo europeu mostra grande variação dentro de áreas relativamente pequenas. As regiões do sul são mais montanhosas, e enquanto se move a norte o terreno desce dos altos Alpes, Pirenéus e Cárpatos, através de planaltos montanhosos e baixas planícies do norte, que são vastas a leste. Esta planície estendida é conhecida como a Grande Planície Europeia, e em seu coração encontra-se a Planície do Norte da Alemanha. Um arco de terras altas, também existe ao longo da costa norte-ocidental, que começa na parte ocidental da ilha da Grã-Bretanha e da Irlanda, e continua ao longo da montanhosa coluna, com fiordes cortados, da Noruega.
Esta descrição é simplificada. Sub-regiões como a península Ibérica e a península Itálica contêm suas próprias características complexas, como faz a própria Europa Central continental, onde o relevo contém muitos planaltos, vales de rios e bacias que complicam a tendência geral. Sub-regiões como a Islândia, a Grã-Bretanha e a Irlanda são casos especiais. A primeira é uma terra independente no oceano do norte, que é considerada como parte da Europa, enquanto as outras duas são zonas de montanha que outrora foram parte do continente até o nível do mar cortá-las da massa de terra principal.
O continente apresenta uma complexa rede hidrográfica, com grandes rios como o Volga, na Rússia, e o Danúbio, que atravessa territórios (ou delimita fronteiras) da Alemanha, Áustria, República Checa, Croácia, Hungria, Sérvia, Romênia, Bulgária e Ucrânia. O rio Volga é o maior rio da Europa. Começa no Lago Ládoga e atravessa no sentido norte-sul a região oeste da Rússia até desaguar no mar Cáspio.
Entre os lagos europeus destacam-se o mar Cáspio, localizado na divisa com a Ásia e que possui 371 mil km²; e o lago Ládoga, na Federação Russa, este último o maior localizado totalmente no continente, com 17 700 km² de área. Outros lagos extensos são o Onega, o Vänern, o Saimaa, o Vättern, entre outros.
A Europa encontra-se principalmente nas zonas de clima temperado, sendo submetido a correntes de ventos do oeste.
O clima é mais ameno em comparação com outras áreas da mesma latitude de todo o mundo devido à influência da Corrente do Golfo. A Corrente do Golfo é o apelido de "aquecimento central da Europa", porque torna o clima da Europa mais quente e mais húmido do que seria de outra maneira. A Corrente do Golfo não só leva água quente à costa da Europa, mas também aquece os ventos que sopram de oeste em todo o continente do Oceano Atlântico.
Portanto, a temperatura média durante todo o ano de Nápoles, é de 16 °C (60,8 °F), enquanto ela fica a apenas 12 °C (53,6 °F), em Nova York, que é quase na mesma latitude. Berlim, na Alemanha; Calgary, no Canadá, e Irkutsk, na parte asiática da Rússia, estão em torno da mesma latitude, as temperaturas de janeiro, em Berlim, são em média em torno de 8 °C (15 °F), mais elevadas do que aquelas registradas em Calgary, e são quase 22 °C (40 °F) mais elevadas do que as temperaturas médias em Irkutsk.
Desde o Renascimento, a Europa teve uma grande influência na cultura, economia e movimentos sociais no mundo. As invenções mais significativas tiveram origem no mundo ocidental, principalmente na Europa e nos Estados Unidos. Algumas questões atuais e passadas na demografia europeia incluíram emigração religiosa, relações raciais, imigração econômica, a taxa de natalidade decrescente e o envelhecimento da população.
Em alguns países, como a Irlanda e a Polónia, o acesso ao aborto é atualmente limitado. No passado, tais restrições e também as restrições sobre o controle artificial da natalidade eram comuns em toda a Europa. O aborto continua sendo ilegal na ilha de Malta, onde o catolicismo é a religião do Estado. Além disso, três países europeus (Países Baixos, Bélgica e Suíça) e a Comunidade Autónoma da Andaluzia (Espanha) têm permitido uma forma limitada de eutanásia voluntária para doentes terminais.
Em 2005, a população da Europa era estimada em 731 milhões de acordo com as Nações Unidas, que é um pouco mais do que um nono da população mundial. Um século antes, a Europa tinha quase um quarto da população mundial. A população da Europa cresceu no passado, mas nas outras regiões do mundo (especialmente na África e na Ásia), a população tem crescido muito mais rapidamente. Dentre os continentes, a Europa tem uma densidade populacional relativamente alta, perdendo apenas para a Ásia. O país mais densamente povoado da Europa são os Países Baixos, terceiro no ranking mundial após a Coreia do Sul e Bangladesh. Pan e Pfeil (2004) contam 87 distintos "povos da Europa", dos quais 33 formam a maioria da população em pelo menos um Estado soberano, enquanto os 54 restantes constituem minorias étnicas.
Segundo a projeção de população da ONU, a população da Europa pode cair para cerca de 7% da população mundial até 2050, ou 653 milhões de pessoas (variante média, 556 a 777 milhões em baixa e alta variante, respetivamente/respectivamente). Neste contexto, existem disparidades significativas entre regiões em relação às taxas de fertilidade. O número médio de filhos por mulher em idade reprodutiva é de 1,52. De acordo com algumas fontes, essa taxa é maior entre os europeus muçulmanos. A ONU prevê que o declínio contínuo da população de vastas áreas da Europa Oriental. A população da Rússia está diminuindo em pelo menos 700 mil pessoas a cada ano. O país tem hoje 13 mil aldeias desabitadas.
A Europa é o lar do maior número de migrantes de todas as regiões do mundo, em 70,6 milhões de pessoas, segundo um relatório da OIM. Em 2005, a UE teve um ganho líquido global de imigração de 1,8 milhão de pessoas, apesar de ter uma das maiores densidades populacionais do mundo. Isso representou quase 85% do crescimento populacional total da Europa. A União Europeia pretende abrir centros de emprego para trabalhadores migrantes legais da África.
Emigração da Europa começou com os colonos espanhóis e portugueses no , e com colonos franceses e ingleses no . Mas os números mantiveram-se relativamente pequenas até ondas de emigração em massa no , quando milhões de famílias pobres, deixaram a Europa.
Hoje, uma grande população de ascendência europeia é encontrada em todos os continentes. A ascendência europeia predomina na América do Norte e, em menor grau, na América do Sul (principalmente na Argentina, Chile, Uruguai e Centro-Sul do Brasil). Além disso, a Austrália e a Nova Zelândia têm grandes populações de descendentes europeus. A África não tem países de maioria de descendentes de europeus, mas há minorias significativas, como a dos brancos sul-africanos. Na Ásia, as populações descendentes de europeus (mais especificamente russos) predominam no Ásia Setentrional.
As línguas europeias pertencem principalmente a três grupos de Línguas indo-europeias: as línguas românicas, derivadas do latim do Império Romano, as línguas germânicas, cujos ancestrais vieram de língua do sul da Escandinávia, e as línguas eslavas. Apesar de ter a maioria de seu vocabulário descendente de línguas românicas, o idioma Inglês é classificado como uma língua germânica.
As línguas românicas são faladas principalmente no sudoeste da Europa, bem como na Roménia e na Moldávia. As línguas germânicas são faladas no noroeste da Europa e algumas partes da Europa Central. As línguas eslavas são faladas na Europa Central, Oriental e sudeste da Europa.
Muitas outras línguas fora dos três grupos principais grupos existem na Europa. Outras línguas indo-europeias incluem o grupo do Báltico (ie, Letã e Lituana), o grupo Céltico (ie, Irlandês, Gaélico Escocês, Manês, Galês, Córnico e Bretão), Grego, Albanês, e Arménio. Um grupo diferente de línguas urálicas são o Estónio, Finlandês e Húngaro, falado nos respetivos/respectivos países, bem como em partes da Roménia, Rússia, Sérvia e Eslováquia.
Outras línguas não indo-europeias são o maltês (a única língua oficial semita da UE), o Basco, Geórgio, Azerbaijão, Turco no leste da Trácia Oriental e as línguas das nações minoritárias na Rússia.
O multilinguismo e a proteção das línguas regionais e minoritárias são objetivos políticos reconhecidos na Europa de hoje. A Convenção para a Proteção das Minorias Nacionais e a Carta Europeia das Línguas Regionais ou Minoritárias do Conselho da Europa estabelecem um quadro jurídico para os direitos linguísticos na Europa.
Historicamente, a religião na Europa tem tido uma grande influência na arte, cultura, filosofia e direito europeu. A religião maioritária na Europa é o cristianismo praticado por católicos, ortodoxos orientais e protestantes.
Na sequência, é o Islão, concentrado principalmente no sudeste (Bósnia e Herzegovina, Albânia, Kosovo, Cazaquistão, Chipre do Norte, Turquia e Azerbaijão), e o Budismo Tibetano encontrado em Kalmykia. As outras religiões, incluindo o Judaísmo e o Hinduísmo, são religiões minoritárias.
A Europa é um continente relativamente secular e tem o maior número e proporção de pessoas sem religião, agnósticas e ateias no mundo ocidental, com um número particularmente elevado de pessoas que se autodescrevem como não-religiosas na República Checa, Estónia, Suécia, Alemanha (Oeste) e França.
Uma união constituída por mais de uma dezena de países, que fazem transações comerciais utilizando uma moeda única - Euro - e cujos interesses são representados por instituições comuns. Essa nova Europa começou a ganhar corpo em dezembro de 1991, quando os 12 países-membros da União Europeia concluíram o Tratado de Maastricht, que objetivava a união política, económica/econômica e monetária dos participantes, sem fechar espaço para novas adesões.
Através desse acordo, Alemanha, Bélgica, Dinamarca, Espanha, França, Grécia, Irlanda, Itália, Luxemburgo, Países Baixos, Portugal e Reino Unido iniciaram a caminhada da integração europeia. Áustria, Finlândia e Suécia são uns dos mais novos membros e vários outros países já entraram com seu pedido de adesão.
A reunião na cidade neerlandensa de Maastricht - que, em dezembro de 1991, consolidou a formação da União Europeia - representou um capítulo de várias etapas, cujas iniciativas pioneiras surgiram logo após a Segunda Guerra Mundial.
A Comunidade Económica Europeia (CEE) ou Mercado Comum Europeu (MCE) foi o embrião da atual União Europeia (UE). Seus países membros são: Alemanha, Áustria, Bélgica, Dinamarca, Espanha, Finlândia, França, Grécia, Irlanda, Itália, Luxemburgo, Países Baixos, Portugal, Reino Unido e Suécia.
Quando de sua formação, em 1957, a entidade era constituída apenas por Alemanha, Bélgica, França, Itália, Luxemburgo e Países Baixos. Em 1973, ingressaram a Dinamarca, a Irlanda e o Reino Unido; em 1981, a Grécia, e em 1986, Espanha e Portugal. Em 1995, a chamada Europa dos Doze cresceu ainda mais, ganhando a adesão de Áustria, Finlândia e Suécia.
A partir de 1994, os países-membros da Comunidade Económica Europeia, que adotou então o nome de União Europeia, se integrariam para formar um mercado único, em que seriam abolidos os sistemas alfandegários e as diferentes taxas de impostos, além das restrições ao comércio, serviços e à circulação de capitais. Isso significaria, entre outras coisas, que os habitantes da União Europeia teriam trânsito livre em todos os países-membros, inclusive para trabalho; os impostos seriam aos poucos unificados e haveria livre acesso às mercadorias e serviços de todos os países-membros dentro da comunidade.
Desde 1995, para facilitar a circulação de pessoas por alguns países da União Europeia, entrou em vigor um acordo entre Portugal, Espanha, França, Bélgica, Países Baixos, Luxemburgo e Alemanha para eliminar as barreiras alfandegárias e a obrigação da apresentação do passaporte entre esses países. Essa área recebeu o nome de Espaço Schengen, tirado da cidade luxemburguesa onde o acordo foi assinado.
No sentido da integração económica/econômica, outro passo importante seria a utilização de uma moeda comum. O ECU (European Currency Unity ou Unidade Monetária Europeia) circula, desde 1993, como padrão em operações financeiras e, apesar da discordância de alguns membros, pretendeu-se que, gradualmente, ele fosse adotado nas operações cotidianas até 1999, quando o euro entrou em vigor como moeda escritural e como moeda oficial desde 2002.
Todos os países que integram a União Europeia apresentam economia desenvolvida, ainda que existam diferenças extraordinárias entre eles, como entre Irlanda e Alemanha, por exemplo, ou Grécia e Dinamarca. A meta, no entanto, é reduzir esses contrastes, tornando a comunidade cada vez mais homogénea/homógena/homogênea.
Apesar das metas em comum, há divergências entre os países-membros da União Europeia e são frequentes os atritos e necessários os ajustes para garantir a execução de tais metas. O ano de 1994 foi de provas para a integridade da União Europeia, já que ocorreram, nos países, plebiscitos para ratificar seus objetivos e confirmar ou não a adesão à União.
Na Dinamarca e no Reino Unido, as opiniões estavam muito divididas, mas o apoio à comunidade prevaleceu. Na Noruega, entretanto, sua população decidiu não ingressar na União Europeia, apesar da solicitação de adesão feita anteriormente.
Os países europeus ocidentais estão vinculados a importantes organizações que agregam países de outros continentes, como a OTAN e a OCDE.
A Organização do Tratado do Atlântico Norte (OTAN), criada em 1949, tem caráter militar. Além de países europeus, inclui outros dois banhados pelo oceano Atlântico Norte: Canadá e Estados Unidos. Seu objetivo fundamental é a cooperação militar e a defesa de seus membros, no caso de agressâo internacional.
Com o fim da Guerra Fria, o papel da OTAN tem estado em segundo plano. A aliança assumiu um caráter preponderantemente político em 1990, desenvolvendo o papel de resolver crises localizadas. Vários países do Leste Europeu solicitaram o ingresso à OTAN.
A OCDE (Organização para a Cooperação e Desenvolvimento Económico) foi estabelecida em 1961 para promover bem-estar econômico e social entre seus membros e harmonizar a qualidade de vida nos países em desenvolvimento. Além de 18 países europeus, engloba também Austrália, Canadá, Japão, Nova Zelândia e Estados Unidos.
De acordo com definições diferentes, os territórios podem ser sujeitos a várias categorizações. Os 27 Estados Membros da União Europeia são altamente integrados economicamente e politicamente, a própria União Europeia faz parte da geografia política da Europa. A tabela abaixo mostra o esquema de sub-regiões geográficas utilizado pela Organização das Nações Unidas, ao lado do grupo regional publicado no CIA World Factbook.
Dentro dos referidos Estados existem várias regiões, desfrutando de ampla autonomia, bem como de vários países independentes de facto com reconhecimento internacional limitado ou reconhecido, nenhum deles é membro da ONU:
De acordo com os pontos de vista espacial e económico, podemos dividir o continente em: Europa Ocidental, Europa Setentrional, Europa Centro-Oriental e Europa Meridional. Sendo:
Como um continente, a economia da Europa é atualmente a maior do planeta e é a região mais rica como medido por ativos sob gestão, com mais de 32,7 trilhões de dólares em relação ao 27,1 trilhões de dólares da América do Norte. Tal como acontece com outros continentes, a Europa tem uma grande variação da riqueza entre os seus países. Os países mais ricos tendem a estar no Ocidente, enquanto algumas das economias do Leste ainda estão emergindo do colapso da União Soviética e da Iugoslávia.
A União Europeia, um organismo intergovernamental composto por 27 estados europeus, compreende o maior espaço económico/econômico único no mundo. Atualmente, para 16 países da UE, o euro é a moeda comum. Cinco países europeus classificam-se entre as dez maiores economias nacionais do mundo por PIB (PPC). Isso inclui (classificação de acordo com a CIA): Alemanha (5), Reino Unido (6), Rússia (7), França (8) e Itália (10).
O capitalismo tem sido dominante no mundo ocidental desde o fim do feudalismo. Da Grã-Bretanha, que gradualmente se espalhou pela Europa. A Revolução Industrial começou na Europa, mais concretamente ao Reino Unido no final do , e no impulsionou a industrialização da Europa ocidental. Economias foram interrompidas pela Primeira Guerra Mundial, mas até o início da Segunda Guerra Mundial já tinham se recuperado e estavam tendo que competir com a crescente força económica dos Estados Unidos. A Segunda Guerra Mundial, novamente, danificados muito as indústrias europeias.
Após a Segunda Guerra Mundial, a economia do Reino Unido estava em estado de ruína, e continuou a sofrer um relativo declínio econômico nas décadas seguintes. A Itália também estava em má condição económica/econômica, mas recuperou um elevado nível de crescimento na década de 1950. A Alemanha Ocidental recuperou-se rapidamente e dobrou a produção de níveis pré-guerra na década de 1950. A França também organizou um retorno notável a um crescimento rápido e a modernização e, mais tarde a Espanha, sob a liderança de Franco, também recuperou-se, e a nação obteve um enorme crescimento econômico sem precedentes no início da década de 1960, em que é chamado de milagre espanhol. A maioria dos estados da Europa Oriental ficou sob o controle da URSS e, portanto, eram membros do Conselho para Assistência Econômica Mútua (COMECON).
Os estados que mantiveram um sistema de livre mercado foram agraciados com uma grande quantidade de ajuda dos Estados Unidos ao abrigo do Plano Marshall. Os Estados ocidentais mudaram para ligar as suas economias em conjunto, fornecendo a base para a UE e o aumento do comércio transfronteiriço. Isso ajudou-os a desfrutar de uma rápida melhora de suas economias, enquanto os estados da COMECON estavam lutando em grande parte devido ao custo da Guerra Fria. Até 1990, a Comunidade Europeia foi ampliado de 6 para 12 membros fundadores. A ênfase na ressurreição da economia da Alemanha Ocidental levou a ultrapassagem do Reino Unido como a maior economia da Europa.
Com a queda do comunismo na Europa Oriental, em 1991, os estados do Leste tiveram de se adaptar a um sistema de mercado livre. Havia vários graus de sucesso com os países centro-europeus, como Polónia, Hungria e Eslovénia, que se adaptaram razoavelmente rápido, enquanto estados do Leste como a Ucrânia e a Rússia, estão levando muito mais tempo. A Europa Ocidental ajudou a Europa Oriental, formando laços ao nível da economia.
Após o Leste e o Oeste da Alemanha se reunirem em 1990, a economia da Alemanha Ocidental, apoiou a reconstrução da infra-estrutura da Alemanha Oriental. A Jugoslávia mostrou um atraso maior, sendo devastada pela guerra e em 2003 ainda havia muitas tropas de paz da e da OTAN no Kosovo, na República da Macedónia, na Bósnia e Herzegovina, sendo apenas a Eslovénia que conseguiu fazer algum progresso real.
Na mudança do milênio, a União Europeia dominou a economia da Europa, que inclui os cinco maiores economias europeias da época a Alemanha, Reino Unido, França, Itália e Espanha. Em 1999, 12 dos 15 membros da UE aderiram à Zona Euro substituindo suas antigas moedas nacionais pelo euro comum. Os três que optaram por permanecer fora da zona euro foram Reino Unido Dinamarca e Suécia.
A Zona Euro entrou em sua primeira recessão oficial no terceiro trimestre de 2008, os números oficiais confirmados em janeiro de 2009. A crise econômica do final dos anos 2000, que teve início nos Estados Unidos, propagou-se de forma rápida para a Europa e afetou grande parte da região. A taxa de desemprego oficial nos 16 países que usam o euro subiu para 9,5% em maio de 2009. Os jovens trabalhadores da Europa têm sido especialmente atingidos. No primeiro trimestre de 2009, a taxa de desemprego na UE-27 para pessoas entre 15-24 anos foi de 18,3%.
A cultura europeia pode ser melhor descrita como uma série de culturas sobrepostas e que envolve questões de Ocidente contra Oriente e Cristianismo contra Islão. Existem várias linhas de ruptura culturais através do continente e movimentos culturais inovadores discordam uns dos outros. De acordo com Andreas Kaplan, o continente Europeu pode ser definido como "diversidade cultural máxima a uma distância geográfica mínima". Assim, uma "cultura comum europeia" ou "valores comuns europeus", é algo cuja definição é mais complexa do que parece. 
Na Europa pratica-se uma considerável quantidade de modalidades desportivas. O desporto mais popular é o futebol, representado pela UEFA. O torneio mais importante de seleções é o Campeonato Europeu de Futebol, enquanto que o de clubes é a Liga dos Campeões da UEFA. Em relação ao Campeonato do Mundo de Futebol, em dez edições países europeus sediaram o evento, e em dez seleções de países europeus venceram o torneio.

</doc>
<doc id="775" url="https://pt.wikipedia.org/wiki?curid=775" title="Espírito Santo (estado)">
Espírito Santo (estado)

O Espírito Santo é uma das 27 unidades federativas do Brasil. Está localizado na região Sudeste. Faz fronteira com o oceano Atlântico a leste, com a Bahia ao norte, com Minas Gerais a oeste e noroeste e com o estado do Rio de Janeiro ao sul. Sua área é de 46 095,583 km². É o quarto menor estado do Brasil, maior apenas que Sergipe, Alagoas e Rio de Janeiro. Sua capital é o município de Vitória, e sua cidade mais populosa, o município da Serra. O Espírito Santo é, ao lado de Santa Catarina, um dos únicos entre os estados do Brasil no qual a capital não é a maior cidade. Outros importantes municípios são Cariacica, Cachoeiro de Itapemirim, Colatina, Guarapari, Linhares, São Mateus e Vila Velha. O gentílico do estado é capixaba ou espírito-santense.
Em 1535, os colonizadores portugueses chegaram na Capitania do Espírito Santo e desembarcaram na região da Prainha. Naquela época, teve início a construção do primeiro povoado que recebeu o nome de Vila do Espírito Santo. Por causa dos índios terem atacado a Vila do Espírito Santo, o líder Vasco Fernandes Coutinho fundou outra vila, naquela vez em uma das ilhas. Esta vila passou a ser chamada de Vila Nova do Espírito Santo, atual . Enquanto isso, a antiga recebeu o nome de Vila Velha. Houve um tempo, que poucas pessoas conhecem, em que houve a anexação do Espírito Santo à Bahia. Isso ocorreu no ano de 1715. Então, a capital da extinta Capitania do Espírito Santo passou a ser Salvador. A Capitania do Espírito Santo somente recuperou sua autonomia da Capitania da Bahia em 1809. Com a proclamação da Independência do Brasil, em 7 de setembro de 1822, o seu "status" foi alterado para província, permanecendo assim até a Proclamação da República Brasileira, em 15 de novembro de 1889, quando se transformou no atual estado do Espírito Santo.
Atualmente, a capital Vitória é um importante porto exportador de minério de ferro. Na agricultura, merecem destaque os seguintes produtos econômicos: o café, arroz, cacau, cana-de-açúcar, feijão, frutas e milho. Na pecuária, há criação de gado de corte e leiteiro. Na indústria, são fabricados produtos alimentícios, madeira, celulose, têxteis, móveis e siderurgia. O estado também possui festas famosas. Entre elas podemos citar: a Festa da Polenta em Venda Nova do Imigrante, a Festa da Penha em Vila Velha e o Festival de Arte e Música de Alegre. O Vital (carnaval fora de época, em novembro) foi extinto.
O nome do estado é uma denominação dada pelo donatário Vasco Fernandes Coutinho que ali desembarcou em 1535, num domingo dedicado ao Espírito Santo. Como curiosidade dessa etimologia, merece destaque o Convento de Nossa Senhora da Penha, símbolo da religiosidade capixaba que abriga em seu acervo a tela mais antiga da América Latina, a imagem de Nossa Senhora das Alegrias.
Em junho de 1534 foram concedidas cinquenta léguas de litoral entre os rios Mucuri e Itapemirim. A concessão foi feita pelo rei de Portugal Dom João III entregando o lote da capitania ao veterano das Índias. Vasco Fernandes Coutinho, um português, desembarcou no território da capitania, a 23 de maio de 1535, e deu o nome ao futuro estado por ser domingo do Espírito Santo. No mesmo dia foi fundada uma vila, denominada pelo donatário como Vila do Espírito Santo (atual cidade de Vila Velha). Em 1535, a vila deu o nome à capitania, à província em 1822 e ao estado (1889). Tal fato ocorreu 35 anos após o Descobrimento do Brasil, conforme tenha sido explicado que a capitania hereditária foi um dos estados mais antigos do Brasil.
Os habitantes naturais do estado do Espírito Santo são denominados "capixabas" (ou "espírito-santenses"). O gentílico foi dado aos futuros cidadãos do Espírito Santo devido às roças de milho que ficavam na ilha de Vitória. As roças de milho pertenciam aos índios, os primeiros habitantes da região quando os portugueses aí chegaram. Tudo leva a crer que a referida assertiva intelectual ajuda a evitar a confusão do nome da unidade federativa brasileira com o nome da terceira pessoa da Santíssima Trindade.
Inicialmente, a região era habitada por diversas tribos indígenas, todas pertencentes ao tronco Tupi; as tribos do interior eram chamadas de Botocudos, sendo-lhes atribuído comportamento hostil e belicoso, além da prática de antropofagia. No litoral, as tribos também eram hostis, porém de hábitos um pouco diferentes.
Na região Sul do actual estado e na região da serra do Caparaó, as tribos não eram hostis, e o seu nome deriva de seu hábito de levar os visitantes para "ouvir o silêncio" da Serra do Castelo. As demais tribos eram os aimorés e os goitacás.
Em 23 de maio de 1535, o fidalgo português Vasco Fernandes Coutinho, veterano das campanhas da África e da Índia, aportou em terras da capitania, que lhe destinara o rei D. João III. Como era um domingo do Espírito Santo, chamou de vila do Espírito Santo a povoação que mandou construir nas terras que lhe couberam: cinquenta léguas de costa, entre os rios Mucuri e Itapemirim, com outro tanto de largo, sertão adentro, a partir do ponto em que terminava, ao norte, o quinhão concedido a Pero de Campos Tourinho, donatário da capitania de Porto Seguro. A Vila do Espírito Santo é hoje a cidade de Vila Velha. Ainda em 1535, a vila passou à capitania, em 1822 província e em 1889 a estado.
A fixação da vila foi uma história de lutas, pois os índios não entregaram aos portugueses, sem resistência, suas roças e malocas. Recuaram até a floresta, onde se concentraram para iniciar uma luta de guerrilhas que se prolongou, com pequenas tréguas, até meados do . Foi assim das mais duras a empresa cometida a Vasco Fernandes Coutinho. Para o patriarca do Espírito Santo a capitania foi um prêmio que se transformou em castigo; teve de empenhar todos os haveres para conservar sua vila; acabou por morrer pobre e desvalido.
Além da insubmissão dos indígenas, o donatário teve de enfrentar as dissensões entre os portugueses. A seus companheiros Jorge de Meneses e Duarte Lemos concedera extensas sesmarias, usando os poderes que recebera juntamente com a carta de doação. Com isso, criou dois rivais implacáveis.
Duarte de Lemos fundou Vitória — chamada de Vila Nova — na ilha de Santo Antônio, em posição estratégica, mais vantajosa que Vila Velha para a defesa contra os constantes ataques dos silvícolas. Para lá se transferiu a sede da capitania. À mesma época, chegaram os missionários jesuítas, empenhados na catequese, o que provocou choques com os colonos, que preferiam a dominação do gentio pela escravidão. A presença do padre José de Anchieta deu um sentido muito especial à ação dos padres da Companhia de Jesus em terras do Espírito Santo. Desde 1561, Anchieta elegera para seu refúgio a aldeia de Reritiba, de onde teve de se afastar constantemente, em virtude de seus encargos, ora em São Paulo, no Rio de Janeiro ou na Bahia. Dois poemas escreveu ele em Reritiba: "De Beata Virgine dei Marte Maria" ("Da Santa Virgem Maria Mãe de Deus") e "De gestis Mendi de Saa" ("Dos feitos de Mem de Sá"). Neste último, está descrita a epopeia de uma esquadra enviada da Bahia por Mem de Sá, governador-geral do Brasil, em socorro a Vasco Fernandes Coutinho e sua gente, que estavam sob cerco dos tamoios na ilha de Vitória. A maior força dos gentios estava concentrada numa aldeia forrificada junto ao rio Cricaré. Ali ocorreu a batalha decisiva, em 22 de maio de 1558. Os portugueses, embora vitoriosos, sofreram pesadas baixas. Entre os mortos estavam o próprio filho de Mem de Sá, Fernão de Sá, que comandava a esquadra; e dois filhos de Caramuru (Diogo Álvares Correia) com a índia Paraguaçu.
A posição estratégica da capitania, dada a proximidade com o Rio de Janeiro, ocasionou algumas tentativas estrangeiras de invasão. Em 1592, os capixabas rechaçaram uma investida dos ingleses, sob o comando de Thomas Cavendish. Em 1625, o donatário Francisco de Aguiar Coutinho enfrentou a primeira investida dos holandeses, comandados por Pieter Pieterszoon Heyn, luta em que se destacou a heroína capixaba Maria Ortiz. Em 1640, com sete navios, os holandeses atacaram novamente o Espírito Santo, sob o comando do coronel Koin. Conseguiram desembarcar 400 homens, mas foram repelidos pelo capitão-mor João Dias Guedes e não se firmaram em Vitória. Atacaram então Vila Velha, de onde foram também rechaçados. O governo colonial, diante de tão repetidos ataques, resolveu destacar para Vitória quarenta infantes da tropa regular. Nessa oportunidade a capitania progride e Koin captura duas naus carregadas de açúcar que, atingidas pelo fogo de terra, ficam com a carga quase toda avariada.
O esgotamento da população, que nos primeiros tempos, por diversas vezes, ameaçara desertar a capitania, bem como a incapacidade de dar seguimento a sua incipiente agricultura, denunciavam a fraqueza dos alicerces em que se baseava a colonização local. Também aí os recursos particulares revelaram-se insuficientes para manter empresa tão árdua e onerosa.
Em 1627, morreu o donatário Francisco de Aguiar Coutinho, cujo sucessor, Ambrósio de Aguiar Coutinho, não se interessou pelo senhorio e continuou como governador nos Açores. Sucederam-se os capitães-mores, com frequentes e sérias divergências entre eles e os oficiais da câmara. Ao atingir a maioridade, em 1667, Antônio Luís Gonçalves da Câmara Coutinho, último descendente do primeiro donatário, conseguiu a nomeação para capitão-mor de Antônio Mendes de Figueiredo, governante operoso e estimado. Em 1674 efetuou-se a compra do território ao último donatário da família Câmara Coutinho pelo fidalgo baiano Francisco Gil de Araújo, por quarenta mil cruzados, transação confirmada por carta régia de 18 de março de 1675.
No governo do novo donatário, o comércio e a lavoura se desenvolveram, mas foi totalmente frustrado o motivo principal da compra da capitania: o descobrimento das "pedras verdes" — as esmeraldas. Essa busca começara por iniciativa do governo-geral. As expedições iniciais, denominadas por alguns historiadores "ciclo espírito-santense", incluem-se na categoria das entradas. Na verdade, o ciclo limitou-se a poucas expedições relevantes, cuja importância está menos nos resultados obtidos, do que na dinamização do interesse pela área e em um maior conhecimento do interior. Entre as mais destacadas, contam-se as de Diogo Martins Cão (1596), Marcos de Azeredo (1611) e Agostinho Barbalho de Bezerra (1664), que vasculharam as imediações do rio Doce. Francisco Gil de Araújo fundou a vila de Nossa Senhora de Guarapari e construiu os fortes do Monte do Carmo e de São Francisco Xavier; o de São João, encontrado em ruínas, foi reconstruído.
Gil de Araújo promoveu 14 entradas através do rio Doce, dirigidas à serra das Esmeraldas, as quais podem ter travado contato com os paulistas de Fernão Dias Pais. Da grande atividade e do vultoso emprego de capital realizados por Francisco Gil não resultou qualquer descoberta metalífera, embora se tenham produzido alguns frutos na valorização das terras, pelo estabelecimento de povoadores e criação de novos engenhos. Os lucros, de qualquer modo, não compensaram o investimento feito. Seu filho e herdeiro, talvez por esse motivo, preferiu conservar-se ausente do senhorio e, por morte deste, a capitania tornou-se devoluta, sendo vendida à coroa por Cosme Rolim de Moura, primo do último donatário. Em consequência, ficou o Espírito Santo submetido à jurisdição da Bahia, e seu governo sempre a cargo de displicentes capitães-mores.
Durante o ainda perdurou o interesse pela mineração, reanimado pela descoberta de Antônio Rodrigues Arzão de pequena quantidade de ouro no rio Doce, em 1692. Seguiram-se numerosas entradas, dando início à abertura do caminho para as Minas Gerais, enquanto as jazidas do Castelo e outras atraíam moradores de capitanias vizinhas. Assistiu-se a um novo impulso de conquista e ocupação do interior, e as concessões de sesmarias favoreceram a fixação dos colonos mais empreendedores. O movimento desperrou a atenção das auroridades baianas, e acabou prejudicado pelos cuidados do monopólio real e receio de invasão estrangeira às Minas Gerais a partir do Espírito Santo. Tomaram-se então medidas para fortificar melhor a capitania, enquanto por ordem do rei ficou proibido o prosseguimento das explorações. Impediu-se a abertura de entradas para as minas. A capitania defendia-se de surpresas marítimas e ficava isolada pelas defesas naturais: florestas cerradas e selvagens inimigos. A colonização, portanto, continuou sem maiores progressos, embora em 1741 fosse criada a comarca de Vitória, que abrangia São Salvador de Campos e São João da Barra. Em 1747 o ouvidor Manuel Nunes Macedo assim descrevia a situação de Vitória: 
É certo que a obstinação dos mineradores e as melhorias efetuadas no sistema de defesa acabaram por diminuir o rigor das proibições e, em 1758, de acordo com ordem régia, abriu-se um caminho para as minas e estabeleceu-se um posto de quitação na vila de Campos.
Em 1797, o regente D. João dirigiu-se ao governador da Bahia nesses termos: 
O novo governador assumiu o cargo em 29 de março de 1800. A obra de recuperação teve como objetivo principal melhores comunicações com a de Minas Gerais. Em 8 de outubro do mesmo ano, Silva Pontes assinou o auto, conjuntamente com o representante do governo de Minas, que regulou a cobrança de impostos entre as duas capitanias. Interessou-se também pela navegação do rio Doce, por abertura de estradas, pela ampliação dos cultivos e pelo povoamento da terra. Em 1810 a capitania tornou-se autônoma em relação à Bahia, e passou a depender diretamente do governo-geral. Governou na época Manuel Vieira de Albuquerque Tovar, que não se afastou do programa de Silva Pontes. Deu o nome de Linhares às antigas ruínas da aldeia de Coutins.
O período colonial encerrou-se sob melhores auspícios, sobretudo em função da diligência de Francisco Alberto Rubim, nomeado governador em 1812. Rubim foi o autor da "Memória estatística da capitania do Espírito Santo", realizada em 1817, na qual afirmou haver na época na capitania 24.587 habitantes, seis vilas, oito povoados e oito freguesias. Consolidara-se a ocupação do território e ampliara-se a base demográfica. Em face das dificuldades enfrentadas, esses dados revelam um progresso nada desprezível.
Em 20 de março de 1820 foi empossado como governador Baltazar de Sousa Botelho de Vasconcelos, a quem coube enfrentar os dias agitados da independência e passar a administração à junta do governo provisório. Antes mesmo de promulgada a constituição do império, foi nomeado presidente da província o ouvidor Inácio Acióli de Vasconcelos.
Durante o movimento de independência, em março e abril de 1821, ocorreram várias comoções políticas no Espírito Santo, enquanto se procedia à escolha de seus representantes às cortes de Lisboa. Após a proclamação da autonomia brasileira, foi dado total apoio à nova realidade política, e em 1º de outubro de 1822, reconhecido imediatamente D. Pedro na condição de imperador do Brasil.
O governo provincial enfrentou séria crise econômica nos primeiros anos da década de 1820, ocasionada pelo estrangulamento da produção agrícola em razão da prolongada estiagem. Mesmo assim, iniciou a cultura cafeeira. Para tanto, incentivou o aproveitamento de terras por colonos estrangeiros, o que se deu simultaneamente à chegada de fazendeiros fluminenses, mineiros e paulistas. A exemplo das demais províncias do sul, no Espírito Santo essa experiência colonizadora baseou-se na pequena propriedade agrícola, que logo se estendeu ao longo da zona serrana central, em contraste com as áreas do sul daquela região, onde predominava a grande propriedade.
Em 1846 fundou-se a colônia de Santa Isabel (Campinho) com imigrantes alemães de Hunsrück e em 1855 uma sociedade particular — depois encampada pelo governo — criou a colônia do Rio Novo com famílias suíças, alemãs, holandesas e portuguesas. Entre 1856 e 1862 houve considerável afluência de imigrantes alemães para a colônia de Santa Leopoldina, que tinha por sede o porto de Cachoeiro de Itapemirim, no rio Itapemirim, a cinquenta quilômetros da foz, no sul do estado. Rapidamente as antigas áreas de pastoreio pontilharam-se de pequenos estabelecimentos agrícolas, que demonstraram grande força expansiva. As colônias de Santa Isabel e Santa Leopoldina,por exemplo, criaram desdobramenros através de todo o planalto, entre os rios Jucu e Santa Maria, e mais tarde atravessaram o rio Doce.
No processo de colonização enfrentaram os imigrantes, a par de outras dificuldades, o sério problema indígena na região do rio Doce. Malgrado os esforços de aldeamento e as tentativas de utilização de sua mão-de-obra, sucediam-se os choques com os colonos, e chegou mesmo a verificar-se grave contenda entre índios e moradores de Cachoeiro de Itapemirim, como elevado número de mortos e feridos, em 1825. Duas décadas depois, o comendador e futuro barão de Itapemirim, Joaquim Marcelino da Silva Lima, ainda tentou organizar um grande aldeamento à base de terras devolutas.
Os canaviais haviam sido substituídos pelos cafeeiros. Ainda não tinha sido fundada nenhuma usina. Os engenhos centrais pouco a pouco desapareciam. Além de fazendeiros capixabas, que passam a cultivar o café, vieram também, com o mesmo propósito, fluminenses, mineiros e até paulistas, como o barão de Itapemirim.
Graças ao trabalho profícuo desses colonos, quando se aboliu a escravidão dos negros — o que derrocou as grandes fazendas, de imediato ou não — a economia do Espírito Santo resistiu e proporcionou aos seus presidentes, depois de proclamada a república, os meios necessários para empreendimentos como a construção de estradas de ferro, expansão do ensino e organização de planos urbanos, com Muniz Freire; instalação de água, luz, esgoto, bondes elétricos, de um parque industrial, de uma usina elétrica e de uma usina de açúcar em Cachoeiro de Itapemirim e na vila de Itapemirim, de uma fazenda-modelo em Cariacica, além de reforma da instrução pública e construção de grupos escolares e de pontes entre Vitória e o litoral e Colatina e o norte do rio Doce. Essas e outras obras foram realizadas com recursos provenientes sobretudo do café produzido pelas colônias de imigrantes europeus organizadas desde a monarquia.
Com a irradiação ferroviária que o café suscitou em meados do , o Espírito Santo beneficiou-se da rede de leitos, cujo centro estava em Campos dos Goitacases e que estabelecia comunicações entre duas importantes áreas cafeeiras: a Zona da Mata, em Minas, e o sul capixaba. Apesar de situada fora da região de cultivo, a cidade de Vitória foi a que mais progrediu sob o surto daquela lavoura, e já em 1879 processaram-se os primeiros estudos destinados à construção do porto, que deveria escoar toda a produção da província. Atendendo às novas exigências, em meados do século começou a funcionar a imprensa capixaba, com a circulação do jornal "O Correio da Vitória", de propriedade de Pedro Antônio de Azeredo, a partir de 1849.
Em 1850 a configuração territorial do Espírito Santo já assinalava a existência de dez municípios: Vitória, Serra, Nova Almeida, Linhares, São Mateus, Espírito Santo, Guarapari, Benevente (hoje Anchieta) e Itapemirim. Pouco antes a província perdera parte de suas terras, em virtude da desanexação de Campos dos Goitacases e São João da Barra, restituídas ao Rio de Janeiro em 1832.
No final do , os capixabas, sobretudo a intelectualidade, aderiram ao movimento abolicionista. A exemplo do que aconteceu nas demais províncias, surgiram associações ligadas à emancipação, como a Sociedade Abolicionista do Espírito Santo (1869) ao lado de acirrada campanha jornalística e parlamentar. No próprio edifício da Câmara Municipal de Vitória fundou-se uma sociedade libertadora (1883). Durante a propaganda, evocava-se a crueldade dos castigos infligidos aos escravos, como sucedera após a insurreição de cerca de 200 negros no distrito de Queimados, em 1849.
A abolição da escravatura, no entanto, conduziu os grandes proprietários à ruína, em virtude da privação da tradicional mão-de-obra. Assim, com o advento da república, o primeiro governador do estado não encontrou condições materiais para levar a efeito os planos preconizados pela propaganda republicana. As finanças da antiga província encontravam-se exauridas.
Ainda no final do , coincidindo com a fixação da constituição estadual (1891 e 1892), o governador eleito recorreu a reformas e incentivos econômicos que deram novo impulso ao estado. A fim de assegurar uma receita mais sólida, levantou empréstimos externos, que favoreceram a lavoura cafeeira e permitiram maiores investimentos agrícolas. O Espírito Santo obteve assim uma arrecadação cinco vezes mais alta que a da antiga província. Efetuou-se o saneamento de Vitória e em 1895 foi inaugurado o primeiro trecho da Estrada de Ferro Sul do Espírito Santo, entre Porto de Argolas e Jabaeté.
A ocupação do norte do Espírito Santo só começou nas primeiras décadas do , e ganhou novo impulso depois da construção da ponte de Colatina sobre o rio Doce, inaugurada em 1928. A economia capixaba contou com a migração de contingentes do sul e do centro do país para aquela área, e assim firmou-se o cultivo do café, que respondeu por 95% da receita em 1903. Durante a primeira guerra mundial, o porto de Vitória figurava como o segundo grande exportador nacional.
Com a Revolução de 1930 assumiu a direção do estado, na qualidade de interventor, João Punaro Bley, mantido pelo Estado Novo até 1943, e sob cuja administração se iniciaram obras para ampliar o porto de Vitória e para construção de cais de minério, este arrendado em 1942 pela Companhia Vale do Rio Doce. No governo de Jones dos Santos Neves, em 1945, foi criada a Universidade Federal do Espírito Santo (UFES), primeira iniciativa referente ao ensino superior no estado. Para ampliar a exportação de minério de ferro oriundo de Minas Gerais, a Companhia Vale do Rio Doce construiu o porto de Tubarão, em Vitória, com capacidade para estocar um milhão de toneladas de minério, receber navios de até cem mil toneladas e carregá-los a um ritmo de seis mil toneladas por hora. As obras foram iniciadas em 1966 e terminadas em tempo recorde. Situado dez quilômetros ao norte da capital, é um dos maiores portos de minério do mundo. Com a transferência para Tubarão da maior parte da exportação de minério de ferro, o porto de Vitória ficou liberado para outras aplicações.
Com a instalação de Tubarão a região foi dotada de uma infraestrutura que propiciou o surgimento de um novo complexo industrial, do qual faz parte uma usina de pelotização de minério de ferro, com capacidade de produção de dois milhões de toneladas anuais. Inaugurada em 1976, entrou em atividade em 29 de novembro de 1983, dez anos depois de iniciadas as obras, a Usina Siderúrgica de Tubarão, que representou um investimento total de três bilhões de dólares. A fase foi marcada por um intenso esforço de industrialização provomido pela Companhia de Desenvolvimento Econômico do Espírito Santo (Codes), mais tarde transformada no Banco de Desenvolvimento do Espírito Santo (Bandes). No início da década de 70 foi criado o FUNDAP (Fundo de Desenvolvimento para Atividades Portuárias) que consistia de um incentivo financeiro para a instalação de empresas importadoras, incentivando as atividades portuárias. Instalaram-se fábricas de café solúvel, massas alimentícias, chocolates, azulejos e conservas de frutas, e aprovaram-se projetos para a implantação de fábricas de laticínios, calçados, material elétrico, óleos comestíveis e sucos cítricos.
Em novembro de 2007, é inaugurada a expansão da siderúrgica Arcelor Mittal Tubarão (ex-Companhia Siderúrgica de Tubarão) para ampliar a produção anual de placas de aço de 5 milhões para 7,5 milhões de toneladas. O estado é o maior produtor de placas de aço do país.
Em abril de 2008, a Polícia Federal realiza a Operação Auxílio-Sufrágio, que desmantela uma quadrilha especializada em fraudes contra a Previdência Social no estado. O deputado estadual Wolmar Campostrini (PDT) é acusado de ser líder do esquema. Por causa de trâmites burocráticos, as investigações ainda não foram concluídas e Campostrini mantém o cargo. Em outubro do mesmo ano, o prefeito da capital, João Coser (PT) é reeleito em primeiro turno. Em 2010, Renato Casagrande (PSB) é eleito governador no primeiro turno, com 82,3% dos votos. Em 2014, Paulo Hartung (PMDB) foi eleito governador do estado e César Colnago (PSDB) eleito vice-governador.
A partir de 2006, a precariedade dos presídios passou a ser noticiada, pois provocou rebeliões, assassinatos e até esquartejamentos (na Casa de Custódia de Viana); em 2009, presos são mantidos em contêineres de aço, sem ventilação adequada, por falta de celas. Em março de 2010, essa situação é discutida em um painel na Comissão de Direitos Humanos das Nações Unidas. Cumprindo parcialmente compromissos assumidos, o governo desativa as celas metálicas e demole a Casa de Custódia de Viana, em maio de 2010. Em outubro, sete penitenciárias foram vistoriadas por uma comissão liderada pelo Conselho de Defesa dos Direitos da Pessoa Humana e da Ordem dos Advogados do Brasil. O relatório, a ser entregue à Procuradoria Geral da República, sugere providências urgentes e intervenção federal no sistema penitenciário do estado.
O estado do Espírito Santo ocupa uma área de no litoral do Brasil, localiza-se a oeste do Meridiano de Greenwich e a sul da Linha do Equador e com fuso horário de menos três horas em relação à hora mundial GMT. No Brasil, o estado faz parte da região Sudeste, fazendo divisa com os estados de Minas Gerais, Bahia e Rio de Janeiro. O estado é banhado pelo oceano Atlântico.
Cerca de 40% do território do estado encontra-se em uma faixa de planície, porém a variação das altitudes é bem grande. O relevo apresenta-se dividido em duas regiões distintas: A Baixada Espírito-Santense e a Serra do Castelo, na qual fica o Pico da Bandeira com 2.892 m, na serra de Caparaó. Seu clima predominante é o tropical de Altitude do tipo Cwb. O bioma (dominío morfoclimático) do estado são os chamados "Mares de Morros" caracterizados pela vegetação tropical, em climas mais amenos, formados por serras fortemente erodidas. Os principais rios capixabas são o Doce, o São Mateus, o Itaúnas, o Itapemirim e o Jucu. Os cinco integram as Bacias Costeiras do Sudeste.
O clima é tropical litorâneo úmido, influenciado pela massa de ar tropical atlântica. As chuvas concentram-se no verão. A temperatura média varia entre 22 °C e 24 °C, e a pluviosidade, entre 1.000 mm e 1.500 mm anuais.
A maior parte do estado caracteriza-se como um planalto, parte do maciço Atlântico. A altitude média é de seiscentos a setecentos metros, com topografia bastante acidentada e terrenos arqueozoicos, onde são comuns os picos isolados, denominados pontões e os pães-de-açúcar. Na região fronteiriça com Minas Gerais, transforma-se em área serrana, com altitudes superiores a mil metros, na região onde se eleva a Serra do Caparaó ou da Chibata. Aí, se ergue um dos pontos culminantes do Brasil, o Pico da Bandeira, com 2 890m.
De forma mais esquemática, pode-se compor um quadro morfológico do relevo em cinco unidades:
Ao contrário do que ocorre nos estados do Rio de Janeiro e de São Paulo, onde constitui um escarpamento quase contínuo, no Espírito Santo o rebordo do planalto apresenta-se como zona montanhosa muito recortada pelo trabalho dos rios, que, nela, abriram profundos vales. A partir do centro do estado para norte, esses terrenos perdem altura e a transição entre as terras baixas do litoral e as terras altas do interior vai se fazendo mais lenta, até alcançar o topo do planalto no estado de Minas Gerais. Dessa forma, ao norte do Rio Doce, a serra é substituída por uma faixa de terrenos acidentados, mas de altura reduzida, em meio aos quais despontam picos que formam alinhamentos impropriamente denominados serras.
Ocorrem no Espírito Santo dois tipos principais de climas, o tropical chuvoso e o mesotérmico úmido. O primeiro domina nas terras baixas e caracterizam-se por temperaturas elevadas durante todo o ano e médias térmicas superiores a 22 °C. O tipo "Am", das florestas pluviais, com mais de 1.250mm anuais de chuvas e com uma estação seca pouco pronunciada, ocorre no litoral norte, no sopé da serra e na região de Vitória; o tipo "Aw", com cerca de 1.000mm de chuva e estação seca bem marcada, ocorre no resto das terras baixas.
O clima mesotérmico úmido, sem estação seca, surge na região serrana do sul do estado. Caracteriza-se por temperaturas baixas no inverno (média do mês mais frio abaixo de 18 °C). Observam-se, entretanto, bruscas alterações climáticas.
O Espírito Santo está incluído em sua totalidade no bioma da Mata Atlântica, apresentando desde fitofisionomias florestais em áreas com altitude menor, até fitofisionomias abertas, em áreas com maior altitude. Entre as fitosionomias florestais destacam-se a floresta ombrófila densa, que ocupava quase 70% do estado, e a floresta estacional semidecidual, que ocupava cerca de 23%. A floresta ombrófila aberta, mais rara, ocupava cerca de 3% do estado, sendo encontrada no sudeste e noroeste. Do ponto de vista geológico, o Espírito Santo é dividido em zona de tabuleiros, zona serrana e planície costeira, com extrema influência na vegetação encontrada nessas zonas.
As floresta úmidas da zona de tabuleiros (abaixo de 300 m de altitude) do norte do Espírito Santo e sul da Bahia frequentemente são chamadas de "mata de tabuleiro", e apresentam pouca vegetação rasteira, muitas epífitas e lianas. As árvores podem ter até 30 m de altura e a primeira vista, essa floresta apresenta semelhanças com a Floresta Amazônica. Hoje em dia, a mata de tabuleiro só é encontrada em bom estado de conservação na Reserva Biológica de Sooretama e na Reserva Natural Vale. No litoral, também observa-se a presença de restingas e mangues, principalmente ao norte do rio Doce. Muitas vezes, as restingas limitam-se apenas às praias, mas podem avançar para o interior, unindo-se com as matas de tabuleiros.
A zona serrana, localizada em terras altas e vales do interior ao sul do rio Doce principalmente, possui desde florestas com muita vegetação rasteira (entre 300 e 2 000 m de altitude), até campos de altitude, acima dos 2 000 m. Alguns autores denominam essa vegetação de "floresta pluvial atlântica". Principalmente na Serra do Caparaó, encontra-se uma vegetação aberta denominada campo rupestre, ainda muito pouco estudada pela ciência e que vem se mostrando ser um ecossistema único. 
Atualmente, a vegetação nativa do Espírito Santo está reduzida a menos de 15% da cobertura original: em 2011, calculava-se que havia apenas 5 107,53 km² de florestas, o que totalizava cerca de 11,07%. Por conta de sua semelhança, principalmente na parte norte do estado, com o sul da Bahia, a Mata Atlântica capixaba está incluída em um projeto de corredor ecológico que visa integrar as unidades de conservação desse estado com os do sul baiano, o chamado "Corredor Central da Mata Atlântica". 
Os principais rios do estado são, de norte para o sul, o Itaúnas, o São Mateus, o Doce e o Itapemirim, que correm de oeste para leste, isto é, da serra para o litoral. O mais importante deles é o Doce, que nasce em Minas Gerais e divide o território espírito-santense em duas partes quase iguais. Em seu delta formam-se numerosas lagoas, das quais a mais importante é a de Juparanã.
O litoral capixaba é rochoso ao sul, com falésias de arenito, e também na parte central, com grandes morros e afloramentos graníticos a beira mar, o litoral sul-central é muito recortado com muitas enseadas e baias protegidas por rochas e afloramentos rochosos a beira mar, é arenoso ao norte, com praias cobertas por uma vegetação rasteira e extensas dunas, principalmente em Itaúnas e Conceição da Barra. 
A 1.140 quilômetros da costa, em pleno Oceano Atlântico, encontram-se a Ilha da Trindade (12,5 km²) e as Ilha de Martim Vaz, situadas a 30 quilômetros de Trindade. Essas ilhas estão sob a administração do Espírito Santo.
O estado possui um litoral mais recortado no centro-sul, e mais mar aberto no norte, o que faz a maior parte das ilhas se concentrarem na parte central do estado, porém o estado possui várias ilhas. Ao todo, são 73 ilhas localizadas na costa do estado, sendo 50 localizadas na capital Vitória.
No Espírito Santo, o Instituto Brasileiro do Meio Ambiente e dos Recursos Naturais Renováveis (IBAMA) administra dezessete unidades de conservação: dois parques nacionais, seis reservas biológicas, três reservas particulares do patrimônio natural, duas áreas de proteção ambiental, uma estação ecológica e três florestas nacionais.
O estado também é conhecido por possuir diversos locais que servem para armazenamento dos ovos de Tartarugas-marinhas ("Cheloniidae"). No estado, o TAMAR, um projeto conservacionista brasileiro dedicado à preservação de espécies de tartarugas-marinhas ameaçadas de extinção, mantém sete bases do projeto no estado: Itaúnas, Guriri, Pontal do Ipiranga, Povoação, Vila de Regência, Ilha da Trindade e Anchieta. Os trabalhos de monitoramento das praias realizados pelas equipes do TAMAR normalmente são realizados entre os meses de setembro e março, no fim do período reprodutivo. As tartarugas marinhas demoram até 20 anos para chegar à idade reprodutiva e de cada mil filhotes que nascem apenas um chega à fase adulta. Ou seja, das 100 mil tartarugas nascidas no último ano, daqui a vinte anos, provavelmente, estima-se que apenas 100 retornem para desovar.
Segundo o censo demográfico de 2010 realizado pelo IBGE, em 2010, o estado do Espírito Santo possuía habitantes, sendo o décimo quarto estado mais populoso do Brasil, representando 1,8% da população brasileira. Segundo o mesmo censo, habitantes eram homens e habitantes eram mulheres. Ainda segundo o mesmo censo, habitantes viviam na zona urbana e na zona rural. Em dez anos, o estado registrou uma taxa de crescimento populacional de 13,59%.
Em relação ao ano de 1991, quando a população era de , esses números mostram uma taxa de crescimento anual de 2% ao ano, inferior a do Brasil como um todo (1,6%) para o mesmo período (1991-2000). Ainda segundo o censo demográfico de 2000, o Espírito Santo é o décimo quarto estado mais populoso do Brasil e concentra 1,82% da população brasileira. Do total da população do estado em 2000, habitantes são mulheres e habitantes são homens. Para 2006, a estimativa é de habitantes.
Nos últimos anos, o crescimento da população urbana intensificou muito, ultrapassando o total da população rural. Segundo a estimativa de 2000, 67,78 dos habitantes viviam em cidades. Dois municípios capixabas mantêm o pomerano como segunda língua oficial (além do português): Vila Pavão e Santa Maria de Jetibá. Também foi aprovada em agosto de 2011 a PEC 11/2009, emenda constitucional que inclui no artigo 182 da Constituição Estadual a língua pomerana, junto com a língua alemã, como patrimônios culturais do Estado.
A densidade demográfica no estado, que é uma divisão entre sua população e sua área, é de habitantes por quilômetro quadrado, sendo a sétima segunda maior do Brasil e com uma densidade comparada à do país asiático Malásia. A distribuição da população estadual é desigual, apresentando maior concentração na região serrana, no interior. Nessa área, a densidade demográfica atinge a média de 50 hab./km² e a ultrapassa no extremo sudoeste. A Baixada Litorânea, faixa que acompanha o litoral, apresenta quase sempre densidades inferiores à média estadual. Apenas nas proximidades de Vitória observa-se uma pequena área com mais de 50 hab./km². A parte norte da baixada litorânea é a menos povoada do estado. Sete municípios (Vila Velha, Cariacica, Cachoeiro de Itapemirim, Colatina, São Mateus e Linhares) concentram mais de 45% da população do Espírito Santo (1975).
O Índice de Desenvolvimento Humano (IDH) do estado, considerado como "elevado" pelo Programa das Nações Unidas para o Desenvolvimento (PNUD), é de , segundo dados do ano de 2010, sendo naquele período, o sétimo mais alto entre as unidades federativas do Brasil. Naquele ano, considerando apenas a educação, o índice era de 0,653, considerado "médio"; o índice de longevidade era de 0,835, considerado "muito alto" e o índice de renda era de 0,743, considerado como "alto". A renda per capita é de reais. Entre 1991 e 2000, o estado registrou uma forte evolução tanto no seu IDH geral quanto na educação, longevidade e renda, critérios utilizados para calcular o índice. A educação foi o critério que mais evoluiu em nove anos, de 0,304 em 1991 para 0,491 em 2000, e em 2010 o valor passou a ser 0,653. Depois da educação, vem a longevidade, que em 1991 tinha um valor de 0,686, passando para 0,777 em 2000 e 0,835 em 2010. E, por último, vem a renda, o critério que menos evoluiu entre 1991, quando era de 0,619, e 2000, ano em que foi calculado como sendo de 0,687, avançando para o valor de 0,743 em 2010. Quanto ao IDH, que é uma média aritmética dos três subíndices, a evolução também foi significativa, passando de 0,505 em 1991 (considerado como "baixo" pela ONU) para 0,64 em 2000 (considerado "médio" pela ONU), e para 0,74 em 2010 (considerado "elevado" pela ONU).
Em 2010, o município com o maior IDH era a capital, Vitória, com um valor de 0,845, considerado como "muito elevado" pelo PNUD no período, posicionado na primeira posição entre os municípios capixabas naquele ano e na quarta posição entre todos os municípios do país, empatado com Balneário Camboriú (SC), e ficando atrás somente de São Caetano do Sul (SP), Águas de São Pedro (SP) e Florianópolis (SC). Já dentre as capitais estaduais do país, Vitória foi posicionada naquele período em segundo lugar, perdendo apenas para Florianópolis, Santa Catarina. Concomitantemente, o município com menor IDH foi Ibitirama, situado na Mesorregião do Sul Espírito-Santense, possuindo o índice no valor de 0,622, que possuindo todos os indicadores sociais abaixo da média estadual no período, estava posicionado na 78° e último lugar entre os municípios do estado e no 3653° lugar entre todos os municípios brasileiros, com um IDHM considerado "médio" pelo PNUD. No ano 2000, o município capixaba mais bem avaliado de acordo com o IDH era mais uma vez a capital, Vitória, com o índice no valor de 0,759, considerado como "elevado" no período, estando ranqueado na sétima posição na época entre todos os municípios do Brasil, ficando atrás apenas de São Caetano do Sul (SP), Águas de São Pedro (SP), Santos (SP), Balneário Camboriú (SC), Niterói (RJ) e Florianópolis (SC). No mesmo período, o município com menor valor de IDH era Santa Leopoldina, situado na Mesorregião Central Espírito-Santense, com um índice de 0,468 no período, considerado como "baixo" à época. Já no ano de 1991, o município com melhor IDH do estado era igualmente a capital, Vitória, com um índice de 0,644, considerado como "médio" pela ONU e sendo posicionado na sexta posição entre todos os municípios do Brasil, ficando atrás somente de São Caetano do Sul (SP), Santos (SP), Florianópolis (SC), Niterói (RJ) e Porto Alegre (RS).
O coeficiente de Gini, que mede a desigualdade social, é de 0,50, sendo que 1,00 é o pior número e 0,00 é o melhor. A incidência da pobreza, medida pelo IBGE, é de %, o limite inferior da incidência de pobreza é de %, o superior é % e a subjetiva é %.
Apesar de tradicionalmente o Catolicismo ser a religião mais professada no Espírito Santo, nas últimas décadas houve grande aumento no número de evangélicos. Segundo o Censo 2010, a Igreja Católica é a religião de 53,4% dos capixabas. Divide-se administrativamente em uma arquidiocese, a Arquidiocese de Vitória, e três dioceses sufragâneas: Cachoeiro de Itapemirim, Colatina e São Mateus. Na Igreja Católica, destaca-se o Convento da Penha, que é um dos principais monumentos históricos do estado e a Basílica de Santo Antônio.
Ainda segundo o Censo IBGE 2010, as Igrejas evangélicas são seguidas por 33,1% dos capixabas, o que faz do Espírito Santo o estado mais evangélico do Brasil. São muitas as igrejas evangélicas, sendo a maior a Assembleia de Deus em suas várias ramificações, seguida da Igreja Cristã Maranata, fundada no estado há 43 anos e da multifacetada Igreja Batista e da Igreja Universal do Reino de Deus. É possível encontrar também praticantes de religiões de origem africana, além de espíritas e outros. O luteranismo também está presente em todo o estado, mas é nas regiões serranas, onde há maior quantidade de descendentes de alemães e pomeranos, que sua presença é mais forte.
É no Espírito Santo que se encontra o Mosteiro Zen Morro da Vargem, primeiro da América Latina, localizado em Ibiraçu e aberto a visitação, no estado também foram construídos o Convento da Penha, 1º convento do Brasil em 1555, e a primeira igreja luterana da América Latina.
De acordo com dados do censo de 2010 realizado pelo Instituto Brasileiro de Geografia e Estatística (IBGE), a população do Espírito Santo está composta por: católicos (53,4%), evangélicos (33,1%), pessoas sem religião (9,61%), espíritas (0,72%), budistas (0,02%), muçulmanos (0,00%), umbandistas (0,14%) e judeus (0,01%).
O censo do IBGE de 2010 revelou os seguintes números: 1,7 milhão brancos (48,6%), 1,5 milhão Pardos (42,2%), 293 mil Negros (8,4%) e 0,8% amarelos (21,9 mil) ou Indígenas (9 mil).
A população do estado, assim como no resto do Brasil, foi formada por elementos indígenas, africanos e europeus. O Espírito Santo, no , contava com uma grande população de origem indígena e africana. Depois da colonização portuguesa, a partir do o estado recebeu levas consideráveis de imigrantes, na maioria italianos, mas também alemães, portugueses e espanhóis.
O desenvolvimento social e econômico do Espírito Santo, a par de transformar o estado em um dos mais ricos do Brasil, acarretou também os seguintes fenômenos:
O Espírito Santo é a segunda unidade federativa mais violenta do Brasil, perdendo apenas para Alagoas, e lidera o maior índice de criminalidade da Região Sudeste do país, superando ainda mais o Rio de Janeiro, Minas Gerais e São Paulo. A taxa de homicídios é de 45,6 a cada mil.
O município mais violento do Espírito Santo e da Região Sudeste do Brasil é Serra, na Região Metropolitana de Vitória; é também o quarto mais violento do Brasil (102,4), registrando, em 2006, taxas médias de homicídio superiores apenas às dos municípios de Vitória, Viana, Cariacica, Linhares e Pedro Canário. O município com a menor taxa média de homicídios é Marechal Floriano, na Mesorregião Central Espírito-Santense, mais precisamente na Microrregião de Afonso Cláudio.
O estado do Espírito Santo é governado por três poderes, o executivo, representado pelo governador, o legislativo, representado pela Assembleia Legislativa do Estado do Espírito Santo, e o judiciário, representado pelo Tribunal de Justiça do Estado do Espírito Santo e outros tribunais e juízes. Também é permitida a participação popular nas decisões do governo através de referendos e plebiscitos.
A atual constituição do estado do Espírito Santo foi promulgada em 1989, acrescida das alterações resultantes de posteriores emendas constitucionais.
O Poder Executivo capixaba está centralizado no governador do estado, que é eleito em sufrágio universal e voto direto e secreto, pela população para mandatos de até quatro anos de duração, e podem ser reeleitos para mais um mandato. Sua sede é o "Palácio Anchieta", que desde o é a sede do governo capixaba. A residência oficial do governador fica na Praia da Costa, localizada no município de Vila Velha.
O Poder Legislativo do Espírito Santo é unicameral, constituído pela Assembleia Legislativa do Estado do Espírito Santo, localizado na Enseada do Suá. Ela é constituída por 30 deputados, que são eleitos a cada 4 anos. No Congresso Nacional, a representação capixaba é de 3 senadores e 10 deputados federais. A maior corte do Poder Judiciário capixaba é o Tribunal de Justiça do Estado do Espírito Santo, localizado na Enseada do Suá. Compõem o poder judiciário os desembargadores e os juízes de direito.
O Espírito Santo está dividido politicamente em 78 municípios. O mais populoso deles é Vila Velha, com 416 mil habitantes, sendo o município mais antigo do estado. Sua região metropolitana possui aproximadamente 1,7 milhão de habitantes.
Uma mesorregião é uma subdivisão dos estados brasileiros que congrega diversos municípios de uma área geográfica com similaridades econômicas e sociais. Foi criada pelo IBGE e é utilizada para fins estatísticos e não constitui, portanto, uma entidade política ou administrativa. Oficialmente, as quatro mesorregiões do estado são:
Além da mesorregião, existe a microrregião, que é, de acordo com a Constituição brasileira de 1988, um agrupamento de municípios limítrofes, com a finalidade de integrar a organização, o planejamento e a execução de funções públicas de interesse comum, definidas por lei complementar estadual. O Espírito Santo é dividido em treze microrregiões. São elas: Vitória, Afonso Cláudio, Guarapari, Santa Teresa, Linhares, Montanha, São Mateus, Barra de São Francisco, Colatina, Nova Venécia, Alegre, Cachoeiro do Itapemirim e Itapemirim.
Por último, existem os municípios (as menores unidades autônomas da federação), que são circunscrições territoriais dotadas de personalidade jurídica e com certa autonomia administrativa. Em geral, o Espírito Santo está dividido em 78 municípios, sendo a vigésima unidade de federação com o maior número de municípios e a quarta e última do Sudeste (atrás de Minas Gerais, São Paulo e Rio de Janeiro).
Durante a década de 2000, por sucessivas leis estaduais, foram criadas e alteradas regiões de gestão e planejamento, estabelecidas com o objetivo de centralizar a atividades das secretarias estaduais. Seus limites nem sempre coincidem com os das mesorregiões e microrregiões do Espírito Santo. As onze regiões administrativas do estado são: Metropolitana (Grande Vitória), Pólo Linhares, Litoral Sul, Pólo Afonso Cláudio (Sudoeste Serrana), Litoral Norte, Extremo Norte, Pólo Colatina, Noroeste 1, Noroeste 2, Pólo Cachoeiro de Itapemirim, Caparaó (Microrregião de Alegre).
Na economia do Espírito Santo, têm destaque a agricultura, a pecuária e a mineração.
Na produção agrícola, destacam-se a cana-de-açúcar (2,5 milhões de toneladas), a laranja (175 milhões de frutos), o coco-da-baía (148 milhões de frutos) e o café (1 milhão de toneladas). O total de galináceos no estado é de aproximadamente 9,2 milhões de aves, e o de gado bovino ultrapassa 1,8 milhão de cabeças. Há reservas importantes de granito e uma incipiente extração de gás natural e petróleo. Areias e mármores também são importantes produtos do extrativismo capixaba. Embora relativamente pequeno, o parque industrial do Espírito Santo abriga indústrias químicas, metalúrgicas, alimentícias e de papel e celulose.
Em 2012, a pauta de exportação do Espírito Santo se baseou em Minério de Ferro (52,49%), Petróleo Cru (10,87%), Pastas Químicas de Madeira Á Soda ou Sulfato (10,01%), Pedras de Cantaria ou Construção (5,58%) e Café (4,42%).
O Espírito Santo é sede de importantes cooperativas agropecuárias, entre as quais se destacam: a Capil, de Itarana; a Ceaq, de São Domingos do Norte; a Cooaprucol de Colatina; a Coop-Forgrande, de Castelo; a Cocaes, de Brejetuba; a Cavil, de Bom Jesus do Norte; e a Coopeves, de Vila Velha.
A atividade turística do estado concentra-se no litoral, onde há belas praias, como a de Itaúnas e a de Guarapari. O pico da Bandeira, terceiro mais alto do país, é outro destino turístico bastante procurado. Ultimamente, tem ganhado destaque um novo tipo de turismo: o gastronômico, em que se aprecia a típica culinária capixaba, herdeira de diversas culturas.
O sistema rodoviário se organiza a partir da BR-101, que corta o Espírito Santo de norte a sul, margeando o litoral. O estado possui 30,1 mil quilômetros de estradas de rodagem, mas apenas 10% são pavimentados.
O produto agrícola tradicional do estado é o café, cultura que orientou a ocupação de praticamente todo o território capixaba. Após uma fase de decadência no estado, o café recuperou uma posição de relativo destaque nacional. Seguem-se a ele, em ordem de importância, as culturas de milho, banana, mandioca, feijão, arroz e cacau.
A criação de bovinos serviu-se de solos virgens no norte do estado, em terrenos desmatados. Nessa área cria-se e engorda-se gado de corte, e ali desenvolveu-se a indústria frigorífica, cuja carne é enviada principalmente para o Rio de Janeiro, além de abastecer a região de Vitória. No sul pratica-se muito a pecuária leiteira, e o leite é comercializado, por meio de cooperativas, nos mercados do Rio de Janeiro e Vitória. 
De desenvolvimento mais recente são a silvicultura e a fruticultura, com aproveitamento para conservas de frutas e para a produção de celulose, destacando-se nessa última atividade alguns projetos de reflorestamento, que poderão compensar em parte o desmatamento avassalador sofrido pelo estado.
O subsolo do estado é rico em minerais, inclusive petróleo. Há consideráveis reservas de calcário, mármore, manganês, ilmenita, bauxita, zircônio, monazitas e terras raras, embora nem todas em exploração. No extrativismo mineral, destaca-se a exploração, na área de Cachoeiro de Itapemirim, de reservas de mármores, calcário e dolomita.
Nos centros urbanos da capital e de Cachoeiro de Itapemirim concentram-se praticamente todas as principais unidades da indústria de transformação capixaba. Na grande Vitória localizam-se as indústrias siderúrgicas: Companhia Ferro e Aço de Vitória, usina de pelotização de minério de ferro da Companhia Vale do Rio Doce; madeireira, têxtil, de louças, de café solúvel, de chocolates e frigorífica. No vale do rio Itapemirim, desenvolvem-se indústrias de cimento, de açúcar e álcool e de conservas de frutas.
As 10 maiores empresas industriais do Espírito Santo são a Companhia Vale do Rio Doce, ArcelorMittal, Samarco Mineração, Aracruz Celulose, Fertilizantes Heringer, ArcelorMittal Brasil, Escelsa, Garoto (a maior fábrica de chocolates da América Latina e a mais importante empresa industrial de alimentos do estado) e Sol Coqueria.
É deficitário o comércio do estado com as demais unidades federativas do Brasil. O valor da exportação por cabotagem, em junho de 2010, foi da ordem de US$ 1.075.429 e o da importação de US$ 642.997. Quanto ao seu comércio exterior, devido à exportação de minério, a situação é completamente inversa do comércio por cabotagem. O valor total da exportação para o exterior, em 2009, foi de US$ 6.510.241 e a da importação, de US$ 5.484.252.
O setor terciário é pouco desenvolvido em todo o Estado. No entanto, a atividade comercial adquire certa importância com as exportações de minério de ferro proveniente de Minas Gerais, através da Estrada de Ferro Vitória a Minas e é embarcado nos portos de Atalaia e ponta do Tubarão. Por outro lado, a ligação de Cachoeiro de Itapemirim à cidade do Rio de Janeiro, por rodovia pavimentada, permitiu a incorporação da região à bacia leiteira fluminense e facilitou a exportação de produtos agrícolas, como café, milho, mandioca, arroz e hortigranjeiros.
Nos últimos anos, o Espírito Santo vem se destacando na produção de petróleo e gás natural. Com várias descobertas realizadas, principalmente pela Petrobras, o Estado saiu da quinta posição no ranking brasileiro de reservas, em 2002, para se tornar a segunda maior província petrolífera do País, com reservas totais de 2,5 bilhões de barris. São cerca de 140 mil barris diários. Os campos petrolíferos se localizam tanto em terra quanto em mar, em águas rasas, profundas e ultraprofundas, contendo óleo leve e pesado e gás não associado.
Dentre os destaques da produção está o campo de Golfinho, localizado a norte do estado, com reserva de 450 milhões de barris de óleo leve, considerado o mais nobre. O primeiro módulo de produção do local já está em operação, com o FPSO Capixaba, e o segundo deve iniciar a operação até o final deste ano, com o FPSO Cidade de Vitória.
Há ainda os campos de Jubarte, Cachalote, Baleia Franca, Baleia Azul, Baleia Anã, Caxaréu, Mangangá e Pirambu, que fazem parte do denominado Parque das Baleias, no Sul, que somam uma reserva de 1,5 bilhão de barris. O Espírito Santo é atualmente responsável por 40% das notificações de petróleo e gás natural brasileiras, conforme levantamento da Agência Nacional do Petróleo, Gás Natural e Biocombustível (ANP) desde sua criação, em janeiro de 1998.
A indústria de petróleo no Espírito Santo possibilita o pagamento de royalties relacionados à exploração de petróleo e gás natural aos municípios nos quais estão localizados os campos produtores e as instalações das empresas. Para beneficiar os 68 municípios capixabas que não recebem royalties petrolíferos, o Governo do Estado criou o Fundo para Redução das Desigualdades Regionais, o primeiro projeto desta natureza aprovado no país. Os recursos são provenientes do repasse de 30% dos royalties creditados no cofre público estadual. Em vigor desde junho de 2006, a distribuição do dinheiro do fundo leva em consideração a população, o percentual de repasses do ICMS e a condição de não ser grande recebedor de royalties. As cidades que têm participação acima de 10% no ICMS e mais de 2% dos royalties não têm acesso aos recursos do Fundo.
Em 2005, existiam, no Estado, 1.755 estabelecimentos hospitalares, com 7.684 leitos e 378 médicos, 35 enfermeiros diplomados e 210 auxiliares de enfermagem. Em 2010, dos 1.755 hospitais existentes, 125 eram de adultos e crianças, 88 eram exclusivamente de crianças, sendo 98 gerais e 22 especializados. Em 2005, da população, 84,4% dos capixabas tinham acesso à rede de água, enquanto 75,7% se beneficiam da rede de esgoto sanitário.
Atualmente a situação energética do Estado do Espírito Santo é de confiabilidade, por se conectar ao Sistema Interligado Sul/Sudeste/Centro-oeste através de um anel de transmissão. O estado produz 33% de suas necessidades, importando, consequentemente, 67% da energia requerida de FURNAS Centrais Elétricas S.A. As concessionárias de distribuição de energia elétrica operando no Espírito Santo são a Espírito Santo Centrais Elétricas S/A (Escelsa), atualmente uma empresa do grupo EDP, e Empresa Luz e Força Santa Maria (ELFSM).
Com seu franco desenvolvimento, expansão e a crescente demanda por fontes energéticas que sustentem de maneira consistente este processo, o Espírito Santo vem utilizando como principal energia alternativa a energia eólica. O processo consiste na conversão do vento em energia elétrica através de aerogeradores - gigantes turbinas em forma de cata-vento colocadas em pontos estratégicos onde a ação do vento é intensa.
O Estado dispunha em 2008 de uma rede de de 2.733 escolas de ensino fundamental, das quais 482 estaduais, 1.986 municipais, 1.157 particulares e 6 federais. O corpo docente era constituído de 29.282 professores, sendo que 6.777 trabalhavam nas escolas públicas estaduais, 18.146 nas escolas públicas municipais e 4.359 nas escolas particulares. Estudavam nestas escolas 553.396 alunos, dos quais 491.342 nas escolas públicas e 62.054 nas escolas particulares. O ensino médio foi ministrado em 438 estabelecimentos, com a matrícula de 139.984 alunos. Dos 139.984 discentes, 119.478 estavam nas escolas públicas e 20.506 nas particulares. Quanto ao ensino superior, em 2008, o estado possuía 91 estabelecimentos, com 6.490 professores e 89.610 discentes.
Em 2004 a taxa de analfabetismo no estado era de 9,5%, uma das mais baixas do Brasil. Da população, 21,0% dos capixabas são analfabetos funcionais. O Espírito Santo é a 12ª melhor educação do Brasil, com um Índice de Desenvolvimento Humano de 0,887.
As principais universidades do Espírito Santo são a Escola Agrotécnica Federal de Alegre, o Instituto Federal do Espírito Santo, a Universidade Federal do Espírito Santo e o Centro Universitário Norte do Espírito Santo.
Os principais jornais diários editados em Vitória são a "Gazeta", o mais antigo e de instalações mais modernas; o "Diário", "Diário Oficial do Estado" e "A Tribuna". Em Cachoeiro de Itapemirim, circula o Correio do Sul; em Colatina, a "Folha do Norte". As principais emissoras de radiodifusão da capital são a Rádio Espírito Santo, que emite em ondas médias, tropicais e de frequência modulada, a Rádio Vitória e a Rádio Capixaba, ambas em ondas médias e curtas. Os municípios de Cariacica, Colatina, Mimoso do Sul e Santa Teresa também possuem emissoras de rádio. Na capital, funcionam a TVE Espírito Santo, a TV Gazeta, a TV Vitória, a TV Tribuna, a TV Capixaba e a RedeTV! ES. Há torres repetidoras de emissoras do Rio de Janeiro.
No estado existe apenas um aeroporto administrado pela Infraero, o Aeroporto Eurico de Aguiar Salles (Vitória), além dos aeroportos como o de Baixo Guandu/Aimorés, o de Cachoeiro de Itapemirim, o de Guarapari, o de Linhares e o Tancredo de Almeida Neves (São Mateus), que são de responsabilidade das suas respectivas administrações municipais.
A Estrada de Ferro Vitória a Minas escoa minério de ferro de Itabira (MG) até o porto de Tubarão, e volta com carvão para siderurgia. Também faz transporte de passageiros e carga geral no vale do rio Doce. A Ferrovia Centro-Atlântica serve ao sul do estado e comunica Vitória com o estado do Rio de Janeiro. As principais rodovias são a BR-101, que corta o estado de norte a sul, pelo litoral, e a BR-262, que liga Vitória a Belo Horizonte (MG) e ao extremo oeste do país. Outras rodovias importantes são a BR-482, que atravessa Alegre e Jerônimo Monteiro e entronca com a BR-101 no distrito de Safra; a BR-342, que liga Ecoporanga a Nova Venécia, no norte do estado; e a BR-381, que liga o município de São Mateus ao município de São Paulo, passando por Nova Venécia e Barra de São Francisco. O estado possui dois portos, ambos na capital: o cais comercial de Vitória e o porto de exportação de minério de ferro de Tubarão.
As principais unidades das Forças Armadas com sede no Espírito Santo são: no Exército Brasileiro, o Espírito Santo integra a 1ª Região Militar (juntamente com o estado do Rio de Janeiro) destacando aí o 38º Batalhão de Infantaria; na Marinha do Brasil, o Espírito Santo faz parte do 1º Distrito Naval (com sede no Rio de Janeiro), destacando-se no Estado a Escola de Aprendizes-Marinheiros; e na Força Aérea Brasileira, o Espírito Santo integra o III Comando Aéreo Regional, com sede na cidade do Rio de Janeiro, destacando-se o Estado como parte integrante do Cindacta I, que forma o quadrilátero com as cidades do Rio de Janeiro, São Paulo, Belo Horizonte e Brasília.
A Polícia Militar do Estado do Espírito Santo (PMES) é uma das forças de polícia militar do Brasil, sendo responsável pelo policiamento ostensivo no Estado do Espírito Santo. Seu Quartel do Comando Geral (QCG) é situado na Avenida Maruípe, na cidade de Vitória, capital do Estado.
O Corpo de Bombeiros Militar do Estado do Espírito Santo (CBMES) é uma Corporação cuja missão primordial consiste na execução de atividades de defesa civil, prevenção e combate a incêndios, buscas, salvamentos e socorros públicos no âmbito do estado do Espírito Santo. Ele é Força Auxiliar e Reserva do Exército Brasileiro, e integra o Sistema de Segurança Pública e Defesa Social do Brasil. Seus integrantes são denominados Militares dos Estados pela Constituição Federal de 1988, assim como os membros da Polícia Militar do Estado do Espírito Santo.
A Polícia Civil do Estado do Espírito Santo é uma das polícias do Espírito Santo, Brasil, órgão do sistema de segurança pública ao qual compete, nos termos do artigo 144, § 4º, da Constituição Federal e ressalvada competência específica da União, as funções de polícia judiciária e de apuração das infrações penais, exceto as de natureza militar. As principais instituições penitenciárias do estado são o Instituto de Readaptação Social (em Vila Velha) e Colônia Penal (em Viana).
A Superintendência do Departamento de Polícia Federal no Espírito Santo está localizada no bairro vilavelhense do São Torquato e é responsável pelo cadastro de passaportes brasileiros de capixabas e outras pessoas residentes no Estado, controles de passageiros nacionais e estrangeiros no aeroportos internacionais e defesa mútua e obrigatória das fronteiras do Brasil como outros países sul-americanos ao lado do Exército Brasileiro, da Marinha do Brasil e da Força Aérea Brasileira.
As principais entidades culturais do estado encontram-se na capital: a Universidade Federal do Espírito Santo (UFES), o Instituto Histórico e Geográfico, a Associação Espírito-Santense de Imprensa, a Academia Espírito-Santense de Letras, a Associação Espírito-Santense de Juristas, a Arcádia Espírito-Santense, a Associação Médica do Espírito Santo, a Academia Feminina de Letras, o Instituto dos Advogados, o Centro Capixaba de Folclore e o Instituto Espírito-Santense de História, Geografia e Arte Religiosa. Em Cachoeiro de Itapemirim há a Academia Cachoeirense de Letras.
A capital conta com as bibliotecas Estadual, Municipal, do Tribunal de Justiça, dos Comerciários, Embaixador Macedo Soares (da delegacia da Fundação IBGE), Central da Universidade Federal do Espírito Santo e da Companhia Vale do Rio Doce, entre outras. Em Cachoeiro de Itapemirim destacam-se as Bibliotecas Municipal, do Centro Espírita Fraternidade e Luz, do Colégio Estadual Muniz Freire e da Casa dos Braga — pequeno museu dedicado aos irmãos escritores Newton e Rubem Braga, na casa onde nasceram. Muitos outros municípios do interior possuem também pequenas bibliotecas.
O teatro mais relevante da capital é o Teatro Carlos Gomes, inaugurado em 1927 e inovado em 1970, sob a responsabilidade da Fundação Cultural do Espírito Santo, com 311 poltronas e 40 camarotes.
Na capital, o museu histórico mais relevante é o Museu Solar Monjardim, antigo Museu de Arte e História e Museu Capixaba, anteriormente vinculado à Universidade Federal do Espírito Santo e na atualidade, administrado pelo Instituto Brasileiro de Museus (Ibram). O museu encontra-se instalado no Solar Monjardim, tombado pelo Instituto do Patrimônio Histórico e Artístico Nacional e antiga Casa-Grande da Fazenda, hoje bairro, de Jucutuquara. No centro histórico da capital encontram-se o Museu de Arte do Espírito Santo Dionísio del Santo (Maes) e o Museu Capixaba do Negro Verônica da Paz (Mucane). No município vizinho de Vila Velha, o Museu Ferroviário da Vale, na antiga sede da Estação Pedro Nolasco, oferece vista para o centro de Vitória.
Em Santa Teresa, há o Museu de Biologia Professor Mello Leitão, instituição criada pelo ilustre naturalista capixaba Augusto Ruschi em sua própria residência, onde também existe uma das melhores bibliotecas do mundo especializadas na fauna e na flora do país.
São tombados pelo Instituto do Patrimônio Histórico e Artístico Nacional os seguintes monumentos: a igreja de Nossa Senhora da Assunção (1587) e residência contígua, em Anchieta, onde morou o clérigo José de Anchieta; a igreja de Nossa Senhora da Ajuda, em Viana; a igreja dos Reis Magos (1558) e residência contígua, em Nova Almeida, município da Serra. Em Vitória, está localizados o Solar de Monjardim, a igreja de São Gonçalo Garcia (1766), a igreja de Nossa Senhora do Rosário (1765) e a igreja de Santa Luzia (1547). Em Vila Velha, o célebre convento e igreja de Nossa Senhora da Penha, localizado a 135m de altura sobre a entrada da baía de Vitória, e a igreja matriz de Nossa Senhora do Santo Rosário, todos do .
Em Vitória, as festas populares tradicionais mais distintas são as de Nossa Senhora da Penha, as comemorações católicas de Santo Antônio, em 13 de junho, de São Pedro dos Pescadores, na praia do Suá, em 29 de junho, e de Nossa Senhora da Vitória, em 8 de setembro. Em Guarapari e Conceição da Barra, realizam-se as festas de Nossa Senhora da Conceição, em 8 de outubro, e o alardo, realizada no ciclo de Natal ou nos dias 19 e 20 de janeiro. Em Cachoeiro de Itapemirim, o Dia de Cachoeiro, 29 de junho, é celebrado com uma semana de eventos em que ocorrem exposição agropecuária, bailes, shows populares, desfiles e caxambu da ilha da Luz. Em diversas cidades e aldeias litorâneas, como Guarapari, Marataízes, Anchieta, Piúma e Conceição da Barra, o dia de São Pedro, 29 de junho, padroeiro dos pescadores, é festejado também com procissões marítimas. Em Conceição da Barra, acontece a festa do Reis de Bois, no ciclo natalino.
As praias de areia monazítica de Guarapari, aconselhadas para a cura de reumatismo e artrose, e o convento de Nossa Senhora da Penha, em Vila Velha, são os maiores pontos turísticos do estado. Em Vitória, são locais importantes o palácio Anchieta, prédio onde funciona o governo estadual; as igrejas tombadas de Santa Luzia, do Rosário e de São Gonçalo Garcia; o Parque Moscoso, com concha acústica com capacidade para atrair 400 espectadores sentados; o porto, com seu terminal de exportação de minério; as praias: Comprida, Suá, Camburi e do Canto;
A costa capixaba é margeada de belas praias, que recebem muitos turistas — principalmente mineiros que aproveitam o sol e a água do mar e que são trajados de sunga e biquíni — no verão, sobressaindo-se Guriri, em São Mateus, Marataízes, Guarapari, Piúma, Iriri, Anchieta e Conceição da Barra, onde se situam as célebres dunas da barra do rio Itaúnas.
Nas serras capixabas também são encontrados pontos de grande atração turística, sobressaindo-se Domingos Martins, Santa Teresa, Rio Novo e Venda Nova do Imigrante.No interior, junto à divisa com Minas Gerais, localiza-se o Parque Nacional do Caparaó. O pico do Itabira e as pedras do Frade e da Freira (310m), em Cachoeiro de Itapemirim, são o símbolo maior da cidade, onde se pode visitar também a tradicional fábrica de pios de pássaros em madeira.
O prato típico mais lembrado do estado é a torta capixaba, feita tradicionalmente nas casas de Vitória durante a semana santa, mas também oferecida durante todo o ano aos turistas nos melhores restaurantes da capital. Sobressai-se ainda a moqueca capixaba, de peixes e frutos do mar cozidos em panelas de barro artesanais, ao molho de urucum.
A cultura do estado sofre forte influência de alemães, italianos e afro-descendentes, o que gera diversas manifestações culturais e festas singulares. Os principais eventos no estado, são de entretenimento, culturais e musicais, o maior evento do estado é a Vitória Stone Fair, maior exposição de Rochas Ornamentais do mundo, porém existem vários outros de importância quase igual, voltados ao setor agropecuário e ao setor alimentício. A maioria dos eventos, de pequeno, médio e grande porte, ocorre no Pavilhão de Carapina, espaço construído pelo governo do estado, para sediar eventos, no município de Serra.
Existe em Itapemirim a Tradicional Festa do Atum e do Dourado, sendo uma das principais festas da cultura pesqueira do Brasil, onde há anexado a festa o Festival de Frutos do Mar Capixaba, no distrito de Itaipava. Reúne mais de 50 mil pessoas por dia, onde tem a oportunidade de experimentar tradicionais pratos em frente ao mar, além da tradicional volta dos barcos, em que pecorrem a ilha dos Franceses e o preparo do Peixe no Rolete. Há também a tradicional festa de Corpus Christi, realizada por volta dos meses de maio e junho, onde em Castelo são confeccionados tapetes artesanais em um perímetro aproximado de um quilômetro pelo entorno do centro da cidade. Esse tapetes com vários quadro e passadeiras de desenho e muito colorido são de inspiração religiosa e feitos basicamente de flores, serragem colorida e grãos. Outro importante evento é a Festa do Cafona, em Colatina, evento que reúne pessoas de todo o Brasil, que se vestem de forma inusitada e propositalmente ridícula para ouvir músicas com letras provocativas e também ridículas e fazerem coisas bizarras e obscenas. Também há o Festival de Alegre, na cidade de Alegre, importante evento do cenário musical nacional, reúne as maiores e mais populares bandas brasileiras e as vezes, até bandas estrangeiras. Há também a tradicional e italiana festa da polenta realizada em Venda Nova do Imigrante. O maior rodeio do estado é o de Ibiraçu, onde a um encontro de música Sertaneja. O Festival de Inverno de Domingos Martins e a Festa do Vinho, são os maiores eventos da região serrana do estado.
Há também várias manifestações culturais importantes, como a festa de Exposição Municipal Afonso-Claudense e a festa do Afonso-Claudense Ausente e Presente, que comemora o aniversário do município de Afonso Cláudio; o Boi Pintadinho, em Muqui; a Sömmerfest em Domingos Martins; a Festa do Imigrante em Santa Teresa; a Festa do Morango em Domingos Martins; a Festa de São Benedito, na cidade de Serra; e a Festa da Penha, maior festa religiosa do estado que reúne cerca de 900 mil fiéis durante a Semana Santa, no Convento da Penha em Vila Velha, durante o período são celebradas muitas missas e romarias.
Na capital acontece o desfile das escolas de samba capixabas, que reúne no Sambão do Povo, como é conhecido o Sambódromo Capixaba, mais de cinquenta mil pessoas, fora os que desfilam, prestigiam as 14 escolas da Grande Vitória que desfilam em três dias de muita festa e animação. O desfile das escolas de samba capixabas acontece sempre uma semana antes do carnaval oficial e tem como atual campeã a Independentes de Boa Vista. A Liga Espírito-santense de Escolas de Samba (LIESES) é o órgão organizador dos desfiles em parceria com a prefeitura. Depois de dois anos em grupo único, os desfiles voltarão, em 2011, a serem divididos em dois grupos que desfilarão em 3 dias distintos.
No setor esportivo, a secretaria responsável por atuar nessa área é a "Secretaria de Esportes e Lazer", que tem como secretário Vanderson Alonso Leite, apelidado de Vandinho, natural de Baixo Guandu e formado em administração com ênfase em análise de sistemas. O estado é sede de diversos clubes de futebol conhecidos nacionalmente, como, por exemplo, o Rio Branco Atlético Clube, a Desportiva Ferroviária, Sociedade Desportiva Serra Futebol Clube e o Vitória Futebol Clube. O Campeonato Capixaba de Futebol é organizado pela Federação de Futebol do Estado do Espírito Santo e realizado ininterruptamente desde 1917, sendo um dos mais antigos torneios de futebol organizados no Brasil. O estado possui diversos estádios de futebol, como o Salvador Venâncio da Costa, o Governador Bley (todos em Vitória), o Mário Monteiro (em Cachoeiro do Itapemirim), o Engenheiro Alencar de Araripe (em Cariacica), o Municipal Justiniano de Mello e Silva (em Colatina), entre muitos outros. Em 2010, segundo a Confederação Brasileira de Futebol, o estado aparece na décima-quinta colocação no ranking nacional das federações estaduais.
Outros esportes também têm popularidade no estado. No vôlei, o órgão responsável pela atuação no esporte é a Federação Espírito-Santense de Voleibol, que possui diversos clubes filiados e organiza todos os torneios oficiais que envolvam as equipes do estado. No basquete, a federação responsável é a Federação Capixaba de Basquetebol. No skate, existe a Associação Capixaba de Skate (ACSK) responsável pela organização de eventos e afins relacionados ao esporte. Todos os anos, o estado realiza os "Jogos Escolares do Espírito Santo", evento da secretaria de esportes do governo estadual, que reúne diversas modalidades esportivas.
No Espírito Santo há dois feriados estaduais que são eles o dia da Colonização do solo espírito-santense, no dia 23 de maio, e o Dia do Servidor Público, no dia 28 de outubro.

</doc>
<doc id="776" url="https://pt.wikipedia.org/wiki?curid=776" title="Estatística">
Estatística

Estatística é a ciência que utiliza-se das teorias probabilísticas para explicar a frequência da ocorrência de eventos, tanto em estudos observacionais quanto em experimentos para modelar a aleatoriedade e a incerteza de forma a estimar ou possibilitar a previsão de fenômenos futuros, conforme o caso.
Algumas práticas estatísticas incluem, por exemplo, o planejamento, a sumarização e a interpretação de observações. Dado que o objetivo da estatística é a produção da melhor informação possível a partir dos dados disponíveis, alguns autores sugerem que a estatística é um ramo da teoria da decisão.
Devido às suas raízes empíricas e seu foco em aplicações, a estatística geralmente é considerada uma disciplina distinta da matemática, e não um ramo dela.
A estatística é uma ciência que se dedica à coleta, análise e interpretação de dados. Preocupa-se com os métodos de recolha, organização, resumo, apresentação e interpretação dos dados, assim como tirar conclusões sobre as características das fontes donde estes foram retirados, para melhor compreender as situações.
O termo "estatística" surge da expressão em latim "statisticum collegium" palestra sobre os assuntos do Estado, de onde surgiu a palavra em língua italiana "statista", que significa "homem de estado", ou político, e a palavra alemã "Statistik", designando a análise de dados sobre o Estado. A palavra foi proposta pela primeira vez no século XVII, em latim, por Schmeitzel na Universidade de Jena e adotada pelo acadêmico alemão Godofredo Achenwall. Aparece como vocabulário na Enciclopédia Britânica em 1797, e adquiriu um significado de coleta e classificação de dados, no início do século XIX.
De acordo com a Revista do Instituto Internacional de Estatística, "Cinco homens, Hermann Conring, Gottfried Achenwall, Johann Peter Süssmilch, John Graunt e William Petty já receberam a honra de serem chamados de fundadores da estatística por diferentes autores."
Alguns autores dizem que é comum encontrar como marco inicial da estatística a publicação do "Observations on the Bills of Mortality" (Observações sobre os Censos de Mortalidade, 1662) de John Graunt. As primeiras aplicações do pensamento estatístico estavam voltadas para as necessidades de Estado, na formulação de políticas públicas, fornecendo dados demográficos e econômicos. A abrangência da estatística aumentou no começo do século XIX para incluir a acumulação e análise de dados de maneira geral. Hoje, a estatística é largamente aplicada nas ciências naturais, e sociais, inclusive na administração pública e privada.
Seus fundamentos matemáticos foram postos no século XVII com o desenvolvimento da teoria das probabilidades por Pascal e Fermat, que surgiu com o estudo dos jogos de azar. O método dos mínimos quadrados foi descrito pela primeira vez por Carl Friedrich Gauss cerca de 1794. O uso de computadores modernos tem permitido a computação de dados estatísticos em larga escala e também tornaram possível novos métodos antes impraticáveis.
Ligações para estatística observacional fenômeno são coletados pelos "fenômenos estatísticos".
A estatística não é uma ferramenta matemática que nos informa sobre o quanto de erro nossas observações apresentam sobre a realidade pesquisada. A estatística baseia-se na medição do erro que existe entre a estimativa de quanto uma amostra representa adequadamente a população da qual foi extraída. Assim o conhecimento de teoria de conjuntos, análise combinatória e cálculo são indispensáveis para compreender como o erro se comporta e a magnitude do mesmo. É o erro (erro amostral) que define a qualidade da observação e do delineamento experimental.
A faceta dessa ferramenta mais palpável é a "estatística descritiva". A descrição dos dados coletados é comumente apresentado em gráficos ou relatórios e serve tanto a prospecção de uma ou mais variáveis para posterior aplicação ou não de testes estatísticos bem como a apresentação de resultados de delineamentos experimentais.
Nós descrevemos o nosso conhecimento de forma matemática e tentamos aprender mais sobre aquilo que podemos observar. Isto requer:
Em algumas formas de estatística descritiva, nomeadamente mineração de dados ("data mining"), os segundo e terceiro passos tornam-se normalmente mais importantes que o primeiro.
A probabilidade de um evento é definida como um número entre zero e um.
Normalmente aproximamos a probabilidade de alguma coisa para cima ou para baixo porque elas são tão prováveis ou improváveis de ocorrer, que é fácil de reconhecê-las como probabilidade de um ou zero. Entretanto, isso pode levar a desentendimentos e comportamentos perigosos, porque é difícil distinguir entre, uma probabilidade de 10 e uma de 10, a despeito da grande diferença numérica entre elas. Por exemplo, se você espera atravessar uma estrada 10 ou 10 vezes na sua vida, definir o risco de atravessá-la em 10 significa que você está bem seguro pelo resto da sua vida. Entretanto, um risco de 10 significa que é bem provável que você tenha um acidente, mesmo que intuitivamente um risco de 0,01% pareça muito baixo.
O crescimento rápido e sustentados no poder de processamento dos computadores a partir da segunda metade do século XX teve um forte impacto na prática da estatística. Os modelos estatísticos mais antigos eram quase sempre lineares, mas os computadores modernos, junto com algoritmos numéricos apropriados, causaram um aumento do interesse nos modelos não-lineares (especialmente redes neurais e árvores de decisão) assim como na criação de novos tipos, como o modelo linear generalizado e o modelo multi-nível.
O aumento na capacidade de computação também tem levado à popularização de métodos que demandam muitos cálculos baseados em reamostragem (em inglês e no jargão do meio "resampling"), como testes de permutação e bootstrap, enquanto técnicas como a amostragem de Gibbs tem feito com que os métodos de Bayes fiquem mais fáceis. A revolução informática também tem levado a um aumento na ênfase na estatística "experimental" e "empírica". Um grande número de softwares estatísticos, de uso tanto geral como específico estão disponíveis no mercado.
Algumas ciências usam a estatística aplicada tão extensivamente que elas têm uma terminologia especializada. Estas disciplinas incluem:
Estatística forma uma ferramenta chave nos negócios e na industrialização como um todo. É utilizada a fim de entender sistemas variáveis, controle de processos (chamado de "controle estatístico de processo" ou CEP), custos financeiros (contábil) e de qualidade e para sumarização de dados e também tomada de decisão baseada em dados. Em nessas funções ela é uma ferramenta chave, e é a única ferramenta segura.

</doc>
<doc id="777" url="https://pt.wikipedia.org/wiki?curid=777" title="Escultura">
Escultura

Escultura é uma arte que representa ou ilustra imagens plásticas em relevo total ou parcial. Existem várias técnicas de trabalhar os materiais, como a cinzelação, a fundição, a moldagem ou a aglomeração de partículas para a criação de um objeto.
Vários materiais se prestam a esta arte, uns mais perenes como o bronze ou o mármore, outros mais fáceis de trabalhar, como a argila, a cera ou a madeira.
Embora possam ser utilizadas para representar qualquer coisa, ou até coisa nenhuma, tradicionalmente o objetivo maior foi sempre representar o corpo humano, ou a divindade numa forma antropomórfica.
É considerada a quarta das artes clássicas.
Através da maior parte da história, permaneceram as obras dos artistas que utilizaram-se dos materiais mais perenes e duráveis possíveis como a pedra (mármore, pedra calcária, granito) ou metais (bronze, ouro, prata). Ou que usavam técnicas para melhorar a durabilidade de certos materiais (argila, terracota) ou que empregaram os materiais de origem orgânica mais nobres possíveis (madeiras duráveis como ébano, jacarandá, materiais como marfim ou âmbar). Mas de um modo geral, embora se possa esculpir em quase tudo que consiga manter por pelo menos algumas horas a forma idealizada (manteiga, gelo, cera, gesso, areia molhada), essas obras efêmeras não podem ser apreciadas por um público que não seja coevo.
A escolha de um material normalmente implica a técnica a se utilizar. A cinzelação, quando de um bloco de material se retira o que excede a figura utilizando ferramentas de corte próprias, para pedra ou madeira; a modelagem, quando se agrega material plástico até conseguir o efeito desejado, para cera ou argila; a fundição, quando se verte metal quente em um molde feito com outros materiais.
Modernamente, novas técnicas, como dobra e solda de chapas metálicas, moldagens com resinas, betão armado ou plásticos, ou mesmo a utilização da luz coerente para dar uma sensação de tridimensionalidade, tem sido tentadas e só o tempo dirá quais serão perenes.
Através do tempo, algumas formas especificas de esculturas foram mais utilizadas que outras: O busto, espécie de retrato do poderoso da época; a estátua eqüestre, tipicamente mostrando um poderoso senhor em seu cavalo; Fontes de água, especialmente em Roma, para coroar seus fabulosos aquedutos e onde a água corrente tinha um papel a representar; estátua, representando uma pessoa ou um deus em forma antropomórfica; Alto ou Baixo-relevo, o modo de ilustrar uma história em pedra ou metal ; mobiliário, normalmente utilizado em jardins.
As primeiras esculturas na Índia são atribuídas à civilização do vale do Indo, onde trabalhos em pedra e bronze foram descobertos, sendo uma das mais antigas esculturas do mundo. Mais tarde, com o desenvolvimento do hinduismo, do budismo, e do jansenismo, esta região produziu alguns dos mais intricados e elaborados bronzes. Alguns santuários, como o de Ellora, apresentam grandes estátuas esculpidas diretamente na rocha. Durante o século II a.C. no noroeste da Índia, onde hoje é o Paquistão e o Afeganistão, as esculturas começaram a representar passagens da vida e os ensinamentos de Buda. Embora a Índia tivesse uma longa tradição de esculturas religiosas, Buda nunca tinha sido representado na forma humana antes, apenas por símbolos. Este fato reflete já uma influencia artística persa e grega na região. A Índia influenciou ainda, através do budismo, boa parte da Ásia, como as existentes na localidade de Angkor, no Camboja
Artefactos chineses datam do século X a.C., mas alguns períodos selecionados tiveram destaque: Dinastia Zhou (1050-771 a.C.) produziu alguns intrincados vasos em bronze fundido; Dinastia Han (206-220 a.C.) apresentou o espectacular "Exército de terracota" de Xian, em tamanho natural, defendendo a tumba do imperador; As primeiras esculturas de influencia budista aparecem no período dos "Três reinos" (século III) ; Dinastia Wei (séculos 5 e 6 ) nos da a escultura dos "Gigantes grotescos", reconhecidas por suas qualidades e elegância. O período considerado a idade de ouro da China é a Dinastia Tang, com suas esculturas budistas, algumas monumentais, considerados tesouros da arte mundial.
Após este período a qualidade da escultura chinesa caiu muito. É interessante notar que a arte chinesa não tem nus, como é comum na arte ocidental, à exceção de pequenas estátuas para uso dos médicos tradicionais. Também tem poucos retratos, exceto nos mosteiros, onde eram mais comuns. E nada do que se produziu após a Dinastia Ming ( após século XVII) foi reconhecido como bom pelos museus e colecionadores de arte. No século passado, a influencia do realismo socialista de origem soviética arruinou o que restava da arte chinesa. Espera-se que o ressurgimento e abertura para o mundo ocidental traga a arte chinesa ao seu lugar de mérito.
Os japoneses faziam muitas estátuas associadas a religião, a maioria sob patrocínio do governo. Notáveis foram as chamadas ‘’haniva’’, esculturas em argila colocadas sobre tumbas, no período ‘’Kofun’’. A imagem em madeira do século IX de ‘’Shakyamuni’’, um Buda histórico é a típica escultura da era ‘’Heian’’, com seu corpo curvado, coberto com um denso drapeado e com uma austera expressão facial. A escola Key criou um novo estilo, mais realista.
Existem poucos exemplares de esculturas pré-colombianas no continente americano, entre elas as famosas estátuas da Ilha de Páscoa, algumas esculturas, principalmente em alto-relevo, decorando edificações Maia e Asteca do Peru ao México e algumas peças primitivas em madeira ou argila, geralmente com significado religioso, dos povos nativos de toda América.
No restante, só se começou a produzir arte a partir do século XVI, já sob influência do Barroco, com destaque para imagens religiosas em madeira, terracota e pedra macia nos locais de influência católica. Nos países de religião protestante, por sua maior resistência ao uso religioso de imagens, foi mais tardio o aparecimento de artistas, entrando diretamente no Neoclássico por influência da cultura européia. A partir daí, com a facilidade de transporte e comunicações, a arte nas Américas ficou muito semelhante à desenvolvida na Europa.
A escultura popular em argila do Nordeste brasileiro, as obras em madeira e argila dos povos da Amazônia, figuras religiosas em todas as regiões católicas da América também possuem sua relevância no contexto atual.
A arte da África tem uma ênfase especial pela escultura, especialmente em ébano e outras madeiras nobres. Além das divindades antropomórficas, tem especial interesse as máscaras rituais. As esculturas mais antigas são da cultura Nok (cerca de 500 a. C.), no território onde atualmente se encontra a Nigéria.
A escultura no antigo Egito visava dar uma forma física aos deuses e seus representantes na terra, os faraós. Regras rígidas deviam ser seguidas: homens eram mais escuros que mulheres; as mãos de figuras sentadas deveriam estar nos joelhos; e cada deus tinha suas regras especificas de representação. Por esse motivo, poucas modificações ocorreram em mais de três mil anos, embora tivessem resultado em peças maravilhosas como a cabeça de Nefertiti ou a máscara mortuária de Tutancâmon.
A Grécia clássica é com certeza o berço ocidental da arte de esculpir, desde seus primeiros artefatos a partir do século X a.C., em mármore ou bronze, até o apogeu da era de Péricles (século V a.C.), com as esculturas da Acrópole de Atenas. Foi também quando alguns escultores começaram a receber reconhecimento individual, como Fídias. Produziu obras impares,como a Vitória de Samotrácia, os mármores de Elgin ou a Vénus de Milo.
A partir dos gregos, os romanos, depois de um começo na tradição etrusca, abraçaram a cultura clássica e continuaram a produzir esculturas até o fim do império, numa escala monumental e numa quantidade impressionante, espalhando principalmente o trabalho em mármore por todo o império.
Após o fim do império e a idade média, onde pouco se fez, tivemos algumas esculturas góticas (séculos 12 e13), basicamente como decoração de igrejas, como a porta da catedral de Chartres, arte fúnebre com suas tumbas elaboradas e as famosas gárgulas.
Tudo pareceu culminar no Renascimento, com mestres como Donatello e seu "Davi" em bronze, a estátua eqüestre do "Gattamelata" ou suas inúmeras esculturas em mármore, abrindo caminho para a obra maior de Michelangelo, com seu magnífico "David" em mármore, a Pietá, ou Moisés. Provavelmente o "David" de Florença seja a escultura mais famosa do mundo desde que foi revelada em 8 de setembro de 1504. É um exemplo do contrapposto, estilo de posicionar figuras humanas.
Quando Benvenuto Cellini criou um saleiro em ouro e ébano em 1540, mostrando Netuno e Anfitrite em formas alongadas e posições desconfortáveis, transformou o Naturalismo e criou a obra maior do Maneirismo que em sua forma mais exagerada virou o Barroco, que acrescenta elementos exteriores, como efeitos de iluminação. Bernini foi sem duvida o mais importante escultor desse período, com obras como O Êxtase de Santa Teresa.
Após os excessos do Barroco, o Neoclassicismo é uma volta ao modelo helenista clássico, antes dos anos confusos do Modernismo, que teve a magnífica obra em bronze do francês Auguste Rodin e seu "O Pensador", e depois enterrou a tradição clássica com o Cubismo, o Futurismo, o Minimalismo, as Instalações e a Pop Art.
Algumas das obras de escultura mais famosas são:

</doc>
<doc id="778" url="https://pt.wikipedia.org/wiki?curid=778" title="Estrela (desambiguação)">
Estrela (desambiguação)


</doc>
<doc id="779" url="https://pt.wikipedia.org/wiki?curid=779" title="Euclides">
Euclides

Euclides de Alexandria ( "Eukleidēs"; "fl." "c." 300 AC) foi um professor, matemático platónico e escritor possivelmente grego, muitas vezes referido como o "Pai da Geometria". Além de sua principal obra, Os Elementos, Euclides também escreveu sobre perspectivas, seções cônicas, geometria esférica, teoria dos números e rigor.
A geometria euclidiana é caracterizada pelo espaço euclidiano, imutável, simétrico e geométrico, metáfora do saber na antiguidade clássica e que se manteve incólume no pensamento matemático medieval e renascentista, pois somente nos tempos modernos puderam ser construídos modelos de geometrias não-euclidianas. 
Euclides é a versão portuguesa da palavra grega Εὐκλείδης, que significa "Boa Glória". 
Pouco se sabe sobre a vida de Euclides pois há apenas poucas referências fundamentais a ele, tendo sido escritas séculos depois que ele viveu, por Proclo e Pappus de Alexandria. Proclo apresenta Euclides apenas brevemente no seu "Comentário sobre os Elementos", escrito no século V, onde escreve que Euclides foi o autor de "Os Elementos", que foi mencionado por Arquimedes e que, quando Ptolomeu I perguntou a Euclides se não havia caminho mais curto para a geometria que "Os Elementos", ele respondeu: "não há estrada real para a geometria". Embora a suposta citação de Euclides por Arquimedes foi considerada uma interpolação por editores posteriores de suas obras, ainda se acredita que Euclides escreveu suas obras antes das de Arquimedes. Além disso, a anedota sobre a "estrada real" é questionável, uma vez que é semelhante a uma história contada sobre Menecmo e Alexandre, o Grande. Na outra única referência fundamental sobre Euclides, Pappus mencionou brevemente no século IV que Apolônio "passou muito tempo com os alunos de Euclides em Alexandria, e foi assim que ele adquiriu um hábito de pensamento tão científico". Também se acredita que Euclides pode ter estudado na Academia de Platão, na Grécia.
As datas de nascimento (inclusive o local) e morte (inclusive suas circunstâncias) de Euclides são desconhecidas e estimadas pela comparação com as figuras contemporâneas mencionadas nas referências. Nenhuma imagem ou descrição da aparência física de Euclides foi feita durante sua vida portanto as representações de Euclides em obras de arte são o produtos da imaginação artística.
Convidado por Ptolomeu I para compor o quadro de professores da recém fundada Academia, que tornaria Alexandria o centro do saber da época, tornou-se o mais importante autor de matemática da Antiguidade greco-romana e talvez de todos os tempos, com seu monumental "Stoichia" ("Os elementos", "c." 300 a.C.).
Depois da queda do Império Romano, os seus livros foram recuperados para a sociedade européia pelos estudiosos muçulmanos da península Ibérica. Escreveu ainda "Optica" (295 a.C.), sobre a óptica da visão e sobre astrologia, astronomia, música e mecânica, além de outros livros sobre matemática. Entre eles citam-se "Lugares de superfície", "Pseudaria", "Porismas" e mais algumas outras.
Algumas das suas obras como "Os elementos", "Os dados" (uma espécie de manual de tabelas de uso interno na Academia e complemento dos seis primeiros volumes de Os Elementos), "Divisão de figuras" (sobre a divisão geométrica de figuras planas), "Os Fenômenos" (sobre astronomia), e "Óptica" (sobre a visão), sobreviveram parcialmente e hoje são, depois de "A Esfera" de Autólico, os mais antigos tratados científicos gregos existentes. Pela sua maneira de expor nos escritos deduz-se que tenha sido um habilíssimo professor.
A obra Os Elementos, atribuída a Euclides, é uma das mais influentes na história da matemática, servindo como o principal livro para o ensino de matemática (especialmente geometria) desde a data da sua publicação até o fim do século XIX ou início do século XX. Nessa obra, os princípios do que é hoje chamado de geometria euclidiana foram deduzidos a partir de um pequeno conjunto de axiomas.
A obra composta por treze volumes, sendo:
Escrita em grego, a obra cobre toda a aritmética, a álgebra e a geometria conhecidas até então no mundo grego, reunindo o trabalho de predecessores de Euclides, como Hipócrates e Eudóxio. Sistematizou todo o conhecimento geométrico dos antigos, intercalando os teoremas já então conhecidos com a demonstração de muitos outros, que completavam lacunas e davam coerência e encadeamento lógico ao sistema por ele criado. Após sua primeira edição foi copiado e recopiado inúmeras vezes, tendo sido traduzido para o árabe em (774). A obra possui mais de mil edições desde o advento da imprensa, sendo a sua primeira versão impressa datada de 1482 (Veneza, Itália). Essa edição foi uma tradução do árabe para o latim. Tem sido − segundo George Simmons − “considerado como responsável por uma influência sobre a mente humana maior que qualquer outro livro, com exceção da Bíblia".
Embora muitos dos resultados descritos em "Os Elementos" originarem-se em matemáticos anteriores, uma das reconhecidas habilidades de Euclides foi apresentá-los em uma única estrutura logicamente coerente, tornando-a de fácil uso e referência, incluindo um sistema rigoroso de provas matemáticas que continua a ser a base da matemática 23 séculos mais tarde.
Não há menção de Euclides nas primeiras cópias ainda remanescentes de "Os Elementos", e a maioria das cópias dizem que são "a partir da edição de Teão" ou as "palestras de Teão", enquanto o texto considerado primário, guardado pelo Vaticano, não menciona qualquer autor. A única referência que os historiadores se baseiam para Euclides ter escrito "Os Elementos" veio de Proclo, que brevemente em seu "Comentário sobre Os Elementos" atribui Euclides como o seu autor. Euclides foi a peça chave em toda a história da Geometria.
Os estudos de Euclides sobre a geometria da visão foi a primeira elaboração em torno da atualmente denominada óptica geométrica.
Diferentemente das análises filosóficas e de suas suposições físicas sobre a natureza da visão, as quais eram isentas de qualquer consideração geométrica, a óptica de Euclides fundamentou-se na análise geométrica da visão e, à primeira vista, parece desprovida de qualquer consideração física acerca da operação da visão. Noções como a cor, a luz ou o transparente, a forma sensível, a luz solar, a natureza do olho e a estrutura física dos órgãos sensoriais envolvidos na visão estão excluídas da óptica de Euclides, uma vez que essas entidades não poderiam ser geometricamente analisáveis ou melhor não poderiam ser tratadas pela sua geometria. 
A análise geométrica da visão elaborada por Euclides supõe uma teoria física mínima acerca da operação da visão e funda-se na redução da visão a um modelo geométrico, no qual o campo visual é tomado como uma coleção, ou agregado, de “raios visuais” concebidos como linhas retas geométricas discretas e divergentes, as quais aparecem como o último termo da análise. Essa coleção de linhas retas “visuais” divergentes, em cuja origem encontra-se o olho, assume a forma de um cone geométrico, conhecido na tradição como “cone visual”, em cuja base encontra-se a figura daquilo que é visto, isto é, a superfície interceptada pelo feixe divergente de linhas retas visuais – entidades estas que possuem uma natureza híbrida, geométrico-sensível. 
O que aparece ao olho é determinado como uma função das propriedades e relações geométricas que são derivadas dessa construção, a qual, ao reduzir o cone visual a uma projeção plana que resulta em triângulos definidos por um vértice situado no olho e por dois raios visuais que unem as extremidades daquilo que é visto, permite calcular a aparência do tamanho, da figura e do movimento daquilo que é visto. Essa construção da estrutura geométrica do “cone visual” é delineada por Euclides quando postula que o aspecto retilíneo dos raios visuais, o cone visual constituído pela divergência desses raios visuais discretos e a condição geral da visibilidade ou seja, que para ser visto, um objeto deve ser interceptado pela radiação ocular.

</doc>
<doc id="780" url="https://pt.wikipedia.org/wiki?curid=780" title="Eusebiozinho">
Eusebiozinho

Eusebiozinho Rocha é uma personagem do romance "Os Maias", de Eça de Queirós. Eça faz a caricatura do pequeno Eusébio através do uso expressivo do adjectivo, do verbo, de figura de estilo. E usa o diminutivo para minorar (com ironia) o personagem.
Representa a educação retrógrada portuguesa, habitualmente conhecido por Silveirinha, devido a ser o primogénito de uma das Silveiras, Eugénia Silveira, senhoras ricas e beatas. Amigo de infância de Carlos da Maia com quem brincava em Santa Olávia, levando pancada continuamente, e com quem contrastava na educação. Desde cedo se interessou pelos algarismos e letras, mas quando cresceu, rapidamente os esqueceu. Para além disso, também cresceu tísico, molengão, tristonho e corrupto. Casou-se na Régua, mas enviuvou cedo, por isso procurava, para se distrair, bordéis ou aventureiras de ocasião pagas à hora. 

</doc>
<doc id="781" url="https://pt.wikipedia.org/wiki?curid=781" title="Edwin Willis">
Edwin Willis

Edwin O'Neill Willis (Russellville, -Rio Claro, ) foi um ornitólogo estadunidense. Estudou e pesquisou aves nos Estados Unidos, Panamá, Colômbia, Peru, na Amazônia e em todo o Brasil. Ele foi um dos mais destacados cientistas da ornitologia brasileira.
Edwin Willis se graduou em biologia no Instituto Politécnico da Virgínia em 1956 e em 1958 concluiu mestrado em zoologia na Universidade do Estado da Louisiana. Seu doutorado em zoologia na Universidade da Califórnia de Berkeley foi obtido em 1964. Depois ele fez pós-doutorado no Museu Americano de História Natural, em 1966.
Passou a residir no Brasil, onde lecionou na Unicamp e casou-se com a também ornitóloga Yoshika Oniki, com quem ele publicou em 2003 o livro "Aves do estado de São Paulo", em que descrevem todas as espécies de aves do estado de São Paulo e apresentam pranchas coloridas de cada ave feitas por Tomas Sigrist. Também foi co-autor junto com sua esposa, do livro "Bibliography of Brazilian Birds": "1500-2002", em relacionam todas as obras sobre aves do Brasil publicadas ao longo de cinco séculos.
Willis era professor titular da Universidade Estadual Paulista Júlio de Mesquita Filho e se aposentou em 2005. Tinha grande experiência na área de zoologia, especialmente comportamento animal. Ele atuava principalmente nos temas thamnophilidae, dendrocolaptidae, comportamento, ecologia e formigas de correição. Sua extensa obra expandiu o conhecimento científico sobre a ecologia de inúmeras aves dos neotrópicos.
"Willisornis" é um gênero de ave da família Thamnophilidae que homenageia Edwin Willis.

</doc>
<doc id="782" url="https://pt.wikipedia.org/wiki?curid=782" title="Conjunção lógica">
Conjunção lógica

A conjunção é uma operação na lógica matemática, que pode ser ligada à operação de interseção de conjuntos. A conjunção é representada pelo conectivo lógico ∧, e em programação por AND ou &&.
A conjunção lógica pode ainda ser representada pelo símbolo do produto.
Em lógica binária, ocorrem apenas dois estados:
A conjunção é uma operação que verifica a seguinte tabela de verdade: 
ou de forma equivalente
Portanto pode ainda ser representada pela multiplicação, que dá o mesmo resultado, se a e b forem 0 ou 1.
Outra interpretação é a da lógica fuzzy, que generaliza pela equivalência com o mínimo(a,b).
A operação de conjunção lógica está ainda relacionada com a interseção de conjuntos. 
Um elemento está na intersecção dos conjuntos apenas se for verdade que está em ambos.
Segue a representação dessa operação no diagrama de Venn.
A operação lógica da conjunção funciona da mesma forma que a conjunção semântica e. 
Suponham-se duas frases quaisquer:
A conjunção só é verdadeira se ambas as frases forem. Se não estiver chovendo, a conjunção é falsa (se não estiver dentro de casa, também).
Convém notar que na linguagem vulgar a conjunção "e" pode ter um significado aditivo, não relacionado com o significado lógico.
A conjunção relaciona dois valores, mas usando o seu resultado podem ser feitas operações com mais valores.
Com uma tabela de verdade pode demonstrar-se a propriedade associativa 
e portanto neste caso basta escrever 
sem necessidade de parentesis, já que o resultado é o mesmo.
A conjunção lógica tem diversas propriedades. Destacam-se:

</doc>
<doc id="783" url="https://pt.wikipedia.org/wiki?curid=783" title="Evolução">
Evolução

Na biologia, Evolução (também conhecida como evolução biológica, genética ou orgânica) é a mudança das características hereditárias de uma população de seres vivos de uma geração para outra. Este processo faz com que as populações de organismos mudem e se diversifiquem ao longo do tempo. O termo "evolução" pode referir-se à evidência observacional que constitui o fato científico intrínseco à teoria da evolução biológica, ou, em acepção completa, à teoria em sua completude. Uma teoria científica é por definição um conjunto indissociável de todas as evidências verificáveis conhecidas e das ideias testáveis e testadas àquelas atreladas.
Do ponto de vista genético, a evolução pode ser definida como qualquer alteração no número de genes ou na frequência dos alelos de um ou um conjunto de genes em uma população e ao longo das gerações. Mutações em genes podem produzir características novas ou alterar as que já existiam, resultando no aparecimento de diferenças hereditárias entre organismos. Estas novas características também podem surgir pela transferência de genes entre populações, como resultado de migração, ou entre espécies, resultante de transferência horizontal de genes. A evolução ocorre quando estas diferenças hereditárias tornam-se mais comuns ou raras numa população, quer de maneira não-aleatória, através de seleção natural, ou aleatoriamente, através de deriva genética.
A seleção natural é um processo pelo qual características hereditárias que contribuem para a sobrevivência e a reprodução se tornam mais comuns numa população, enquanto que características prejudiciais tornam-se mais raras. Isto ocorre porque indivíduos com características vantajosas tem mais sucesso na reprodução, de modo que mais indivíduos na próxima geração herdem tais características. Ao longo de muitas gerações, adaptações ocorrem através de uma combinação de mudanças sucessivas, pequenas e aleatórias nas características, mas significativas em conjunto, em virtude da seleção natural dos variantes mais adequados - adaptados - ao seu ambiente. Em contraste, a deriva genética produz mudanças aleatórias na frequência das características numa população. A deriva genética reflete o papel que o acaso desempenha na probabilidade de um determinado indivíduo sobreviver e reproduzir-se. Na década de 1930, a seleção natural darwiniana foi combinada com a hereditariedade mendeliana em uma síntese moderna, onde foi feita a ligação entre as "unidades" de evolução - os genes - e o "mecanismo" central de evolução - fundado na deriva genética e seleção natural. Tal teoria, denominada Síntese Evolutiva Moderna e detentora de um grande poder preditivo e explanatório, por oferecer uma unificadora e inigualável explicação natural para toda a diversidade da vida na Terra, tornou-se o pilar central da biologia moderna .
Uma espécie pode ser definida como o agrupamento dos espécimes capazes de compartilhar material genético - usualmente por via sexuada - a fim de reproduzirem-se gerando descendência fértil. No entanto, quando uma espécie é separada em várias populações que por algum motivo não mais se possam cruzar, mecanismos como mutações, deriva genética e a selecção de características novas provocam a acumulação de diferenças ao longo de gerações, diferenças que, acumuladas, podem implicar desde curiosidades biológicas como os denominados anéis de espécies até a emergência de espécies novas e distintas. As semelhanças entre organismos sugere que todas as espécies conhecidas descenderam de um ancestral comum (ou "pool" genético ancestral) através deste processo de divergência gradual.
Estudos do registro fóssil permitem reconstruir de forma satisfatória precisa o processo de evolução da vida na Terra, desde os primeiros registros de sua presença no planeta - que datam de 3,4 mil milhões de anos atrás - até hoje . Tais fósseis, juntamente com o reconhecimento da fabulosa diversidade de seres vivos atrelada - a grande maioria hoje extinta - já em meados do século dezenove mostravam aos cientistas que as espécies encontram-se cronologicamente relacionadas, e que essas mudam ao longo do tempo. Contudo, os mecanismos que levaram a estas mudanças permaneceram pouco claros até o reconhecimento científico de que o próprio planeta tem uma história geológica muito rica - implicando mudanças ambientais constantes - e até a publicação do livro de Charles Darwin - "A Origem das Espécies" - detalhando a teoria de evolução por selecção natural. O trabalho de Darwin levou rapidamente à aceitação da evolução pela comunidade científica.
A herança em organismos ocorre por meio de caracteres discretos – características particulares de um organismo. Em seres humanos, por exemplo, a cor dos olhos é uma característica herdada dos pais. As características herdadas são controladas por genes e o conjunto de todos os genes no genoma de um organismo é o seu genótipo.
O conjunto das características observáveis que compõem a estrutura e o comportamento de um organismo é denominado o seu fenótipo. Estas características surgem da interação do genótipo com o ambiente. Desta forma, não são todos os aspectos de um organismo que são herdados. O bronzeamento da pele resulta da interação entre o genótipo de uma pessoa e a luz do sol; assim, um bronzeado não é hereditário. No entanto, as pessoas têm diferentes respostas à radiação solar, resultantes de diferenças no seu genótipo; um exemplo extremo são os indivíduos com a característica hereditária do albinismo, que não se bronzeiam e são altamente sensíveis a queimaduras de sol, devido à inexistência do pigmento melanina na pele.
Os genes são regiões nas moléculas de ácido desoxirribonucleico (DNA) que contêm informação genética. O DNA é uma molécula comprida com quatro tipos de bases ligadas umas às outras. Genes diferentes apresentam uma sequência diferente de bases; é a sequência destas bases que codifica a informação genética. Dentro das células, as longas cadeias de DNA estão associadas com proteínas formando estruturas chamadas cromossomas. Um local específico dentro de um cromossoma é conhecido como locus. Uma vez que normalmente existem duas cópias do mesmo cromossoma no genoma, os locus correspondentes em cada um destes (cuja sequência de DNA pode ser igual ou diferente) são denominados alelos. As sequências de DNA podem mudar através de mutações, produzindo novos alelos. Se uma mutação ocorrer dentro de um gene, o novo alelo pode afectar a característica que o gene controla, alterando o fenótipo de um organismo. No entanto, enquanto que esta simples correspondência entre alelo e uma característica funciona em alguns casos, a maioria das características são mais complexas e são controladas por múltiplos genes que interagem uns com os outros.
Como o fenótipo de um indivíduo resulta da interação de seu genótipo com o ambiente, a variação nos fenótipos de uma população reflete, em certa medida, a variação nos genótipos dos indivíduos. A síntese evolutiva moderna define evolução como a mudança nas frequências gênicas ao longo do tempo, ou seja, a flutuação na frequência de um ou mais alelos, se tornando mais ou menos prevalecente relativamente a outras formas do mesmo gene. Forças evolutivas atuam direcionando essa mudança de diferentes formas. A variação em determinado locus desaparece quando algum alelo se fixa na população, ou seja, quando um mesmo alelo passa a estar presente em todos os indivíduos.
A origem de toda a variação genética são mutações no material genético. Essa variação pode ser reorganizada por meio da reprodução sexuada, e distribuída entre populações por meio de migração. A variação também pode vir de trocas de genes entre espécies diferentes, como por exemplo na transferência horizontal de genes em bactérias, e hibridização, principalmente em plantas. Apesar da constante introdução de variação por meio desses processos, a maior parte do genoma de uma espécie é idêntica em todos os indivíduos. No entanto, até mesmo relativamente poucas mudanças no genótipo podem levar a mudanças dramáticas no fenótipo: chimpanzés e humanos possuem apenas cerca de 5% de diferença em seu genoma.
A variação genética se origina de mutações aleatórias que ocorrem no genoma dos organismos. Mutações são mudanças na sequência dos nucleotídeos do genoma de uma célula, sendo causadas por radiação, vírus, transposons e substâncias químicas mutagênicas, assim como erros que ocorrem durante a meiose ou replicação do DNA. Esses agentes produzem diversos tipos de mudança nas sequências de DNA, que podem ser sem efeito, podem alterar o produto de um gene, ou alterar o quanto um gene é produzido. Estudos com a mosca-das-frutas, "Drosophila melanogaster", apontam que cerca de 70% das mutações são deletérias (prejudiciais), sendo as restantes neutras (sem efeito) ou com pequeno efeito benéfico. Devido aos efeitos danosos das mutações sobre o funcionamento das células, os organismos desenvolveram ao longo do tempo evolutivo mecanismos responsáveis pelo reparo do DNA para remover mutações. Assim, a taxa ótima de mutação é resultado do balanço entre as demandas conflitantes de reduzir danos a curto prazo, como risco de câncer, e aumentar os benefícios a longo prazo de mutações vantajosas.
Grandes porções de DNA também podem ser duplicadas, fenômeno que funciona como fonte de material para a evolução de novos genes, sendo estimado que dezenas a centenas de genes são duplicados nos genomas de animais a cada milhão de anos. A grande maioria dos genes pertence a famílias de genes homólogos, que partilham um ancestral comum, de forma semelhante ao que ocorre com linhagens de espécies. Novos genes podem ser produzidos tanto por duplicação e mutação de um gene ancestral como por recombinação de partes de genes diferentes para formar novas combinações com funções distintas. Por exemplo, quatro dos genes utilizados no olho humano para a produção de estruturas responsáveis pela percepção de luz, derivam de um ancestral comum, sendo que três desses genes atuam na visão em cores e um na visão noturna. Uma vantagem na duplicação de genes (ou mesmo de genomas inteiros por poliploidia) é que sobreposição ou redundância funcional em vários genes pode permitir que alelos que seriam deletérios sem essa redundância sejam mantidos na população, aumentando assim a diversidade genética.
Mudanças em número de cromossomos também podem envolver a quebra e rearranjo de DNA entre cromossomos. Por exemplo, no gênero "Homo", dois cromossomos se fundiram, formando o cromossomo 2 humano. Essa fusão não ocorreu na linhagem dos outros grandes primatas (orangotango, chimpanzé, e gorila), e eles mantêm esses cromossomos separados. O papel mais importante desse tipo de rearranjo dos cromossomos na evolução pode ser o de acelerar a divergência de uma população em novas espécies, por meio de uma redução na chance de cruzamento entre as populações, preservando as diferenças genéticas entre elas.
Sequências de DNA que têm a capacidade de se mover pelo genoma, como transposons, constituem uma fração significativa do material genético de plantas e animais, e podem ter sido importantes na evolução de genomas. Por exemplo, mais de um milhão de cópias de um padrão denominado sequência Alu estão presentes no genoma humano, e tem sido demonstrado que essas sequências podem desempenhar um papel da regulação da expressão gênica. Outro efeito dessas sequências de DNA é que, ao se moverem dentro do genoma, elas podem mudar ou deletar genes existentes, gerando assim diversidade genética.
Em organismos de reprodução assexuada, os genes são herdados todos juntos, ou ligados, dado que eles não podem se misturar com genes de outros organismos durante a reprodução. Por outro lado, a prole de organismos sexuados contêm uma mistura aleatória dos cromossomos de seus pais, produzida por meio da segregação independente durante a meiose. No processo relacionado de recombinação gênica, organismos sexuados também podem trocar DNA entre cromossomos homólogos. Esses processos de embaralhamento podem permitir que mesmo alelos próximos numa cadeia de DNA segreguem independentemente. No entanto, como ocorre cerca de um evento de recombinação para cada milhão de pares de bases em humanos, genes próximos num cromossomo geralmente não são separados, e tendem a ser herdados juntos. Essa tendência é medida encontrando-se com qual frequência dois alelos ocorrem juntos, medida chamada de desequilíbrio de ligação. Um conjunto de alelos que geralmente é herdado em grupo é chamado de haplótipo, e essa co-herança pode indicar que o locus está sob seleção positiva (veja abaixo).
A recombinação em organismos sexuados ajuda a remover mutações deletérias e manter mutações benéficas. Consequentemente, quando alelos não podem ser separados por recombinação - como no cromossomo Y humano, que passa intacto de pais para filhos - mutações deletérias se acumulam. Além disso, a recombinação pode produzir indivíduos com combinações de genes novas e vantajosas. Esses efeitos positivos da recombinação são balanceados pelo fato de que esse processo pode causar mutações e separar combinações benéficas de genes. A taxa ótima de recombinação para uma espécie é, portanto, o resultado do balanço entre essas demandas conflitantes.
A transferência horizontal de genes é um processo pelo qual um organismo transfere material genético para outra célula que não a sua prole, em contraste à transferência vertical em que um organismo recebe material genético de seu ancestral. A maior parte do pensamento em genética tem se focado na transferência vertical, mas recentemente a transferência horizontal tem recebido maior atenção.
De um ponto de vista genético, evolução é uma "mudança de uma geração para a outra nas frequências de alelos de uma população que compartilha um conjunto de genes". Uma população é um grupo de indivíduos pertencentes a determinada espécie e que ocupa um espaço delimitado. Por exemplo, todas as mariposas da mesma espécie que vivem numa floresta isolada representam uma população. Um determinado gene nessa população pode ter diversas formas alternativas, que respondem por variações entre os fenótipos dos organismos. Um exemplo pode ser um gene para coloração em mariposas que tenha dois alelos: preto e branco. O conjunto de todos os genes presentes em todos os organismos de uma determinada população é conhecido como "pool" gênico, sendo que no "pool" gênico cada alelo ocorre várias vezes. A fração de genes dentro desse conjunto que é um alelo em particular é uma quantidade denominada frequência alélica, ou frequência gênica. A evolução ocorre quando há mudanças nas frequências de alelos de uma população de organismos intercruzantes. Por exemplo, quando o alelo para a cor preta se torna mais comum numa população de mariposas.
Para entender os mecanismos que fazem com que uma população evolua, é útil considerar quais as condições necessárias para que a população não evolua. Segundo o princípio de "Hardy-Weinberg", as frequências de alelos numa população suficientemente grande irá se manter constante apenas se as únicas forças atuando na população forem a recombinação aleatória dos alelos na formação dos gametas e a combinação aleatória dos alelos nessas células sexuais durante a fecundação. Uma população em que as frequências dos alelos é constante "não" está evoluindo: a população está em "Equilíbrio de Hardy-Weinberg".
Há três mecanismos básicos de mudanças evolutivas: selecção natural, deriva genética e fluxo génico. A selecção natural favorece genes que melhoram a capacidade para a sobrevivência e reprodução. A deriva genética é mudança aleatória na frequência de alelos, causada pela amostragem aleatória dos genes de uma geração durante a reprodução, e o fluxo génico é a transferência de genes entre (e dentro de) populações. A importância relativa da selecção natural e deriva genética numa população varia conforme a intensidade da selecção e do efectivo populacional, que é o número de indivíduos capazes de se reproduzir. A seleção natural costuma predominar em grandes populações. A predominância de derivação genética em pequenas populações é capaz até mesmo de levar a fixação de suaves mutações deletérias. Como resultado, mudanças no tamanho da população podem influenciar dramaticamente o rumo da evolução. Os efeitos de gargalo, onde a população encolhe temporariamente e portanto perde variação genética, resultam numa população mais uniforme. Efeitos de gargalo surgem também de alterações no fluxo génico tais como uma diminuição da migração, expansões para outros habitats ou subdivisão populacional.
Selecção natural é o processo pelo qual mutações genéticas que melhoram a reprodução tornam-se, ou permanecem, mais comuns em gerações sucessivas de uma população. Este mecanismo tem sido muitas vezes chamado de "autoevidente" porque segue forçosamente a partir de três simples factos:
Estas condições geram competição entre organismos para a sua sobrevivência e reprodução. Por isso, organismos com características que lhes trazem alguma vantagem sobre os seus competidores transmitem estas características vantajosas, enquanto que características que não conferem nenhuma vantagem não são passadas para a geração seguinte.
O conceito central da selecção natural é a aptidão evolutiva de um organismo. Isto mede a contribuição genética de um organismo para a geração seguinte. Contudo, não é o mesmo que o número total de descendentes: a aptidão mede a proporção de gerações subsequentes que carregam os genes de um organismo. Por consequência, se um alelo aumenta a aptidão mais do que outros alelos do mesmo gene, então em cada geração esse alelo tornar-se-á mais comum dentro da população. Diz-se que estas características são "seleccionadas "a favor"" ou "positivamente". Exemplos de características que podem aumentar a aptidão são sobrevivência melhorada e aumento da fecundidade. Pelo contrário, aptidão mais baixa causada por ter um alelo menos beneficial resulta na diminuição da frequência deste alelo; são "seleccionados "contra"" ou "negativamente". É importante notar que a aptidão de um alelo não é uma característica fixa. Se o ambiente muda, características que previamente eram neutras ou prejudiciais podem tornar-se benéficas ou vice-versa.
Selecção natural dentro de uma população, de uma característica que pode variar dentro de uma gama de valores, tal como a altura, pode ser categorizada em três tipos diferentes. A primeira é selecção direccional, que é um desvio do valor médio de uma característica ao longo do tempo - por exemplo, certos organismos que vão lentamente ficando mais altos de geração para geração. A segunda é selecção disruptiva, que é a selecção a favor de valores extremos das características e resulta frequentemente em que dois valores diferentes se tornem mais comuns, com selecção contra valores médios. Isto aconteceria quando quer indivíduos altos ou baixos têm certa vantagem, mas não os que têm altura média. Por último, existe selecção estabilizadora em que há selecção contra valores extremos das características em ambos os lados do espectro, o que causa uma diminuição da variância à volta do valor médio. Isto provocaria, usando o mesmo exemplo, que os organismos se fossem tornando todos da mesma altura.
Um caso especial de selecção natural é selecção sexual, que é selecção sobre qualquer característica que aumente o sucesso reprodutor, incrementando a capacidade de atracção de um organismo a potenciais parceiros. As características que evoluíram através de selecção sexual são particularmente proeminentes em machos de algumas espécies animais, apesar de algumas características como hastes muito elaboradas, chamamentos ou cores vivas poderem atrair predadores, diminuindo por isso a sobrevivência desses machos. Esta desvantagem é compensada pelo maior sucesso reprodutivo em machos que apresentam estas características seleccionadas sexualmente.
Uma área de pesquisa activa actualmente refere-se à unidade de selecção, com propostas de que a selecção natural actua no nível dos genes, células, indivíduos, populações ou mesmo espécies. Nenhum destes modelos são mutuamente exclusivos e a selecção pode actuar em vários níveis simultaneamente. Abaixo do nível do indivíduo, genes chamados transposões tentam copiar-se a si próprios ao longo do genoma. Selecção acima do nível do indivíduo, tal como selecção de grupo, pode permitir a evolução de cooperação, como discutido mais abaixo.
Deriva genética é a mudança na frequência alélica de uma geração para a outra que acontece porque os alelos nos descendentes são amostras aleatórias dos presentes nos progenitores. Em termos matemáticos, os alelos estão sujeitos a erros de amostragem. Como resultado disto, quando forças selectivas estão ausentes ou são relativamente fracas, frequências alélicas tendem a "andar à deriva" para cima ou para baixo ao acaso (numa caminhada aleatória). Esta deriva termina quando um alelo eventualmente fique fixado, quer por desaparecer da população, ou por substituir completamente todos os outros alelos. A deriva genética pode assim eliminar alguns alelos de uma população meramente devido ao acaso, e duas populações separadas que começaram com a mesma estrutura genética podem divergir para duas populações com um conjunto diferente de alelos.
O tempo necessário para que um alelo se fixe por deriva genética depende do tamanho da população, com a fixação acontecendo mais rapidamente em populações mais pequenas. A medida mais importante para este caso é o efectivo populacional, que foi definido por Sewall Wright como o número teórico que representa o número de indivíduos reprodutores que exibem o mesmo grau de consanguinidade.
Apesar da selecção natural ser responsável pela adaptação, a importância relativas das duas forças, selecção natural e deriva genética, como motores de mudança evolutiva em geral, é uma área de pesquisa actual em biologia evolutiva. Estas investigações foram despoletadas pela teoria neutral da evolução molecular, que propôs que a maioria das mudanças evolutivas resultam da fixação de mutações neutrais que não têm efeitos imediatos na aptidão de um organismo. Daí que, neste modelo, a maioria das mudanças genética resulte da constante pressão mutacional e deriva genética.
Fluxo génico é a troca de genes entre populações, que são normalmente da mesma espécie. Exemplos de fluxo génico entre espécies incluem a migração seguido de cruzamento de organismos, ou a troca de pólen. A transferência de genes entre espécies inclui a formação de híbridos e transferência lateral de genes.
Migração para dentro ou para fora de uma população pode mudar as frequências alélicas. Imigração pode adicionar material genético novo para o pool genético já estabelecido de uma população. Por outro lado, emigração pode remover material genético. Barreiras à reprodução são necessárias para que as populações se tornem em novas espécies, sendo que o fluxo génico pode travar este processo, espalhando as diferenças genéticas entre as populações. Fluxo génico é impedido por barreiras como cadeias montanhosas, oceanos ou desertos ou mesmo por estruturas artificiais como a Grande Muralha da China, que tem prejudicado o fluxo de genes de plantas.
Dependendo de quanto é que duas espécies divergiram desde o seu ancestral comum mais recente, pode ainda ser possível que produzam descendência, tais como é exemplificado pelo cruzamento entre cavalos e burros, produzindo mulas. Tais híbridos são geralmente inférteis, devido à impossibilidade dos dois conjuntos de cromossomas se emparelharem durante a meiose. Neste caso, espécies próximas são capazes de se cruzar regularmente, mas os híbridos serão seleccionados contra e as espécies permanecerão separadas. Contudo, híbridos viáveis podem formar-se ocasionalmente e mesmo formar novas espécies. Estas novas espécies podem ter propriedades intermédias entre as espécies parentais ou possuir fenótipos totalmente novos. A importância da hibridização no processo de criação de novas espécies de animais não é clara, apesar de haver alguns casos conhecidos em muitos tipos de animais, sendo a espécie "Hyla versicolor" um exemplo particularmente bem estudado.
No entanto, a hibridação é um importante meio de especiação em plantas, uma vez que a poliploidia (ter mais do que duas cópias de cada cromossoma) é tolerada em plantas mais prontamente do que em animais. A poliploidia é importante em híbridos porque permite a reprodução, com cada um dos conjuntos de cromossomas capaz de emparelhar com um par idêntico durante a meiose. Os poliplóides também têm mais diversidade genética, o que permite que evitem depressão de consanguinidade em populações pequenas.
A transferência génica horizontal é a transferência de material genético de um organismo para outro que não é seu descendente. Isto é mais comum em bactérias. Em medicina, isto contribui para a disseminação de resistência a antibióticos, porque assim que uma bactéria adquire genes de resistência eles podem-se transferir rapidamente para outras espécies. Também é possível que tenha ocorrido transferência horizontal de genes de bactérias para eucariontes como a levedura "Saccharomyces cerevisiae" e para o escaravelho "Callosobruchus chinensis", por exemplo. Os vírus também podem transportar DNA entre organismos, permitindo a transferência de genes mesmo entre domínios. A transferência de genes também ocorreu entre os ancestrais das células eucarióticas e procariontes, durante a aquisição do cloroplasto e da mitocôndria.
A evolução influencia cada aspecto da estrutura e comportamento dos organismos. O mais proeminente é o conjunto de adaptações físicas e comportamentais que resultam do processo de seleção natural. Essas adaptações aumentam a aptidão por contribuírem com atividades como busca por alimento, defesa contra predadores ou atração de parceiros sexuais. Outro resultado possível da seleção é o surgimento de cooperação entre organismos, evidenciada geralmente no auxílio a organismos aparentados, ou em interações mutualísticas ou simbióticas. A longo prazo, a evolução produz novas espécies, por meio da divisão de populações ancestrais entre novos grupos que se tornam incapazes de intercruzarem.
Essas consequências da evolução são comummente divididas entre macroevolução, que é a evolução que ocorre acima do nível de espécies, e trata de fenómenos como a especiação, e microevolução, que trata das mudanças evolutivas que ocorrem dentro de uma espécie, como a adaptação a um ambiente específico por determinada população. Em geral, macroevolução é o resultado de longos períodos de microevolução. Assim, a distinção entre micro e macroevolução não é absoluta, havendo apenas uma diferença de tempo entre os dois processos. No entanto, na macroevolução, as características de toda a espécie é que são consideradas. Por exemplo, uma grande quantidade de variação entre indivíduos permite que uma espécie se adapte rapidamente a novos habitats, diminuindo as possibilidade de se tornar extinta, enquanto que uma grande área de distribuição aumenta a possibilidade de especiação, por fazer com que seja mais provável que parte da população fique isolada. Neste sentido, microevolução e macroevolução podem por vezes estar separadas.
Um problema conceptual muito comum é acreditar-se que a evolução é progressiva, mas a seleção natural não tem um objetivo final, e não produz necessariamente organismos mais complexos. Apesar de espécies complexas terem evoluído, isso ocorre como consequência indireta do aumento no número total de organismos, e formas de vida simples continuam sendo mais comuns. Por exemplo, a esmagadora maioria das espécies constitui-se de procariotos microscópicos, que são responsáveis por cerca de metade da biomassa do planeta, apesar de seu pequeno tamanho, e compõem uma grande parte da biodiversidade na Terra. Assim, organismos simples continuam sendo a forma de vida dominante no planeta, sendo que a formas de vida mais complexas parecem mais diversas apenas porque são mais evidentes para nós.
Adaptações são estruturas ou comportamentos que melhoram uma função específica dos organismos, aumentando sua chance de sobreviver e reproduzir. Elas são produzidas por uma combinação da produção contínua de pequenas mudanças aleatórias nas características (mutações), e da selecção natural das variantes melhor ajustadas ao seu ambiente. Esse processo pode causar tanto o ganho de uma nova propriedade, como a perda de uma propriedade ancestral. Um exemplo que demonstra esses dois tipos de mudança é a adaptação bacteriana a antibióticos. Mutações que causam resistência a antibióticos podem modificar o alvo da droga ou remover os transportadores que permitem que a droga entre na célula. Outros exemplos notáveis são a capacidade adquirida pela bactéria "Escherichia coli" em utilizar o ácido cítrico como nutriente em experiências de laboratório de evolução a longo prazo, a aquisição de novas enzimas pela "Flavobacterium" que permitem que estas bactérias cresçam nos produtos da manufactura do náilon, ou a evolução na bactéria do solo "Sphingobium" de um via metabólica completamente nova que degrada o pesticida sintético pentaclorofenol. Uma interessante mas ainda controversa ideia é que algumas adaptações poderiam aumentar a capacidade dos organismos em gerar diversidade genética e adaptarem-se por seleção natural (aumentando a "evolucionabilidade" do organismo).
No entanto, muitas características que parecem ser simples adaptações podem ser exaptações: estruturas que originalmente surgiram como adaptações para desempenhar determinada função, mas que durante o processo evolutivo, coincidentemente se tornaram úteis no desempenho de uma outra função. Um exemplo é o lagarto africano "Holaspis guentheri", que desenvolveu uma cabeça extremamente fina para se esconder em pequenas cavidades, como pode ser percebido ao olhar-se para espécies aparentadas. No entanto, nessa espécie a cabeça se tornou tão fina que auxilia o animal a planar quando saltando entre árvores - uma exaptação.
Uma adaptação ocorre pela modificação gradual de estruturas existentes. Estruturas com organização interna semelhante podem ter funções muito diferentes em organismos aparentados. Isso é resultado de uma única estrutura ancestral que se adaptou para funcionar de formas diferentes em cada linhagem. Os ossos nas asas de morcegos, por exemplo, são estruturalmente similares tanto com as mãos humanas como com as barbatanas de focas, devido à descendência dessas estruturas de uma ancestral comum que também tinha cinco dedos na extremidade de cada membro anterior. Outras características anatômicas únicas, como ossos no pulso do panda, que formam um falso "polegar", indicam que a linhagem evolutiva de um organismo pode limitar que tipo de adaptação é possível.
Durante a adaptação, algumas estruturas podem perder a sua função e se tornarem estruturas vestigiais. Essas estruturas podem ter pouca ou nenhuma função numa espécie, apesar de terem uma função clara em espécies ancestrais ou relacionadas. Exemplos incluem os remanescentes não funcionais de olhos em alguns peixes de cavernas, asas em aves incapazes de voar e a presença de ossos do quadril em baleias e cobras. Exemplos de estruturas vestigiais em humanos incluem o dente do siso, o cóccix e o apêndice vermiforme.
Uma área de pesquisa atual em biologia do desenvolvimento evolutiva é a base desenvolvimental de adaptações e exaptações. Essa linha de pesquisa busca compreender a origem e evolução de desenvolvimento embrionário e como modificações nos processos do desenvolvimento produzem novas características de forma gradualista, onde as mudanças ocorrem com a presença de intermédiarios, ou ainda pelo modelo de saltos evolutivos, onde uma mudança "abrupta" pode correr de uma geração para outra e com um passar do tempo aquela nova estrutura pode ser torna-se vantajosa para a população da espécies. Esses estudos têm demonstrado que a evolução pode alterar o desenvolvimento para criar novas estruturas, como as estruturas embrionárias que formam ossos da mandíbula em outros animais formando parte do ouvido médio em mamíferos. É também possível que estruturas perdidas ao longo da evolução reapareçam devido a mudanças em genes do desenvolvimento, como uma mutação em galinhas que faz com que os embriões produzam dentes similares aos de crocodilos.
Interações entre organismos podem produzir tanto conflito como cooperação. Quando a interação ocorre entre pares de espécies, como um patógeno e um hospedeiro, ou um predador e uma presa, essas espécies podem desenvolver séries de adaptações combinadas. Nesses casos, a evolução de uma espécie causa adaptações numa outra. Essas mudanças na segunda espécie, por sua vez, causam novas adaptações na primeira. Esse ciclo de seleção e resposta é chamado de co-evolução. Um exemplo é a produção de tetrodotoxina numa espécie de salamandra "(Taricha granulosa)" e a evolução de resistência à tetrodotoxina em seu predador, uma serpente "(Thamnophis sirtalis)". Nesse par de presa e predador, uma corrida armamentista evolutiva produziu altos níveis de toxina na salamandra e correspendentemente altos níveis de resistência na cobra.
No entanto, nem todas as interações entre espécies envolvem conflito. Muitos casos de interações mutuamente benéficas evoluiram. Por exemplo, existe uma cooperação extrema entre plantas e micorrizas que crescem sobre as raízes, auxiliando na absorção de nutrientes do solo. Essa é uma interação recíproca, já que as plantas provêm à micorriza açúcares da fotossíntese. Nesse caso o fungo geralmente cresce dentro das células da planta, permitindo a troca de nutrientes, enquanto envia sinais que reprimem o sistema imunitário da planta.
A cooperação também evoluiu entre organismos da mesma espécie. Um caso extremo é a eussocialidade, que pode ser observada em insetos sociais, como abelhas, cupins e formigas, onde insetos estéreis alimentam e defendem um pequeno número de organismos da colônia que são capazes de se reproduzir. Numa escala ainda menor, as células somáticas que formam o corpo de um animal são limitadas em sua capacidade de se reproduzir para que se mantenha a estabilidade no organismo e permita que um pequeno número de células germinativas produza prole. Nesse caso, células somáticas respondem a sinais específicos que as instruem a crescer ou destruir a si próprias. Se as células ignoram esses sinais e tentam se multiplicar de forma desordenada, seu crescimento descontrolado causa câncer.
Imagina-se que esses exemplos de cooperação dentro de uma espécie evoluíram pelo processo de seleção de parentesco, que consiste em um organismo agir de forma a aumentar a probabilidade de parentes produzirem prole. Essa atividade é selecionada porque se o indivíduo que ajuda possui alelos que promovem a atividade de ajudar, é provável que seus parentes também possuam esses alelos e, assim, esses alelos são passados adiante. Outros processos que podem promover a cooperação incluem seleção de grupo, onde a cooperação fornece benefícios para um grupo de organismos.
Especiação é o processo pelo qual uma espécie diverge, produzindo duas ou mais espécies descendentes. Eventos de especiação foram observados diversas vezes, tanto em condições controladas de laboratório como na natureza. Em organismos de reprodução sexuada, a especiação resulta do isolamento reprodutivo seguido por divergência entre as linhagens. Há quatro tipos de mecanismos de especiação, sendo a especiação alopátrica considerada a mais comum em animais. Esse tipo de especiação ocorre quando populações são isoladas geograficamente, por fragmentação de habitat ou migração, por exemplo. Como as forças evolutivas passam a atuar independentemente nas populações isoladas, a separação vai, eventualmente, produzir organismos incapazes de se intercruzarem.
O segundo mecanismo de especiação a ser considerado é a especiação peripátrica, que ocorre quando pequenas populações de organismos são isoladas num novo ambiente. Ela difere da especiação alopátrica pelo fato de as populações isoladas serem muito menores do que a população parental. Nesse caso, o efeito fundador causa uma especiação rápida tanto pela deriva genética oriunda do efeito fundador como pela rápida ação da seleção natural sobre um conjunto de genes pequeno.
O terceiro mecanismo de especiação é a especiação parapátrica. Ela é similar à especiação peripátrica na medida em que uma população pequena ocupa um novo habitat, mas difere porque não há separação física entre essas populações. O que ocorre é que a especiação resulta da evolução de mecanismos que reduzem o fluxo gênico entre as duas populações. Geralmente isso ocorre quando há alguma mudança drástica no ambiente da espécie parental. Um exemplo é a gramínea "Anthoxanthum odoratum", que pode passar por especiação parapátrica em resposta a poluição localizada de metais de minas. Neste caso, plantas com resistência a altos níveis de metais no solo evoluem. A seleção contra cruzamentos com a população parental sensível a metais produz uma mudança no tempo de floração das plantas resistentes, causando isolamento reprodutivo. A seleção contra híbridos entre as duas populações pode causar o que é chamado de "reforço", que é a evolução de características que promovem o cruzamento dentro de determinada espécie, assim como deslocamento de caráter, que ocorre quando duas espécies se tornam mais distintas em aparência.
Finalmente, quando há especiação simpátrica, espécies divergem sem uma barreira geográfica entre elas ou mudanças drásticas no ambiente. Esse tipo de especiação é considerado raro, já que uma pequena quantidade de fluxo gênico pode remover as diferenças genéticas entre partes de uma população. Em geral, a especiação simpátrica em animais exige a evolução tanto de diferenças genéticas como de acasalamento preferencial, para permitir que o isolamento reprodutivo evolua.
Um tipo de evolução simpátrica envolve o cruzamento entre duas espécies aparentadas, produzindo uma nova espécie híbrida. Esse tipo de especiação não é comum em animais, já que híbridos são comumente inviáveis ou estéreis, porque não há pareamento entre os cromossomos homólogos de cada progenitor durante a meiose. Ela é mais comum em plantas, porque plantas frequentemente dobram o número de cromossomos, formando poliplóides. Isso permite o pareamento de cada cromossomo com seu homólogo durante a meiose, já que os cromossomos de cada progenitor já se apresentam em pares. Um exemplo desse tipo de especiação ocorreu quando as espécies "Arabidopsis thaliana" e "Arabidopsis arenosa" se hibridizaram para formar a nova espécie "Arabidopsis suecica". Isso ocorreu há cerca de 20.000 anos atrás e o processo de especiação foi reproduzido em laboratório, permitindo o estudo dos mecanismos genéticos envolvidos no processo. De fato, eventos de poliploidização numa espécie podem ser uma causa comum de isolamento reprodutivo, já que metade dos cromossomos duplicados não irá parear quando ocorrer cruzamento com organismos sem essa duplicação.
Eventos de especiação são importantes na teoria do equilíbrio pontuado, que explica a existência do padrão observado no registro fóssil de "explosões" de evolução entre longos períodos de estase, em que as espécies se mantém relativamente sem mudanças. Nessa teoria, a especiação e a rápida evolução são relacionadas, com seleção natural e deriva genética atuando mais fortemente em organismos especiando em novos habitats ou com pequeno tamanho populacional. Como resultado, os períodos de estase no registro fóssil correspondem à população parental, e os organismos passando por especiação e rápida evolução são encontrados em pequenas populações geograficamente restritas., sendo raramente preservados como fósseis.
Barreiras reprodutivas ao cruzamento podem ser classificadas em "pré-zigóticas" ou "pós-zigóticas". A distinção entre as duas é definida se a barreira previne a formação de prole antes ou depois da fertilização do óvulo.
Barreiras pré-zigóticas são aquelas que impedem a cópula entre as espécies, ou então impedem a fertilização do óvulo caso a espécie tente cruzar.
Alguns exemplos são:
Barreiras pós-zigóticas são aquelas que ocorrem após a fertilização, geralmente resultando na formação de um zigoto híbrido que é infértil ou inviável. Isso geralmente é resultado de incompatibilidade nos cromossomos do zigoto. Um zigoto é um óvulo fertilizado antes de se dividir, ou o organismo que se origina desse óvulo fertilizado. Inviável significa incapaz de chegar à idade adulta.
Exemplos incluem:
Extinção é o desaparecimento de toda uma espécie. A extinção não é um evento incomum, já que espécies normalmente surgem por especiação e desaparecem por extinção. De fato, quase todas as espécies de planta e animal que já existiram hoje estão extintas. Essas extinções aconteceram continuamente durante toda a história da vida, apesar de haver picos nas taxas de extermínio em eventos de extinção em massa. A extinção entre o Cretáceo e o Terciário (Extinção K-T), na qual os dinossauros desapareceram, é a mais conhecida. No entanto, um evento anterior, a extinção do Permiano-Triássico, foi ainda mais severa, levando cerca de 96% das espécies então existentes ao extermínio. A extinção do Holoceno é um processo de desaparecimento de espécies em massa ocorrendo atualmente, em decorrência da expansão da espécie humana pelo globo nos últimos milhares de anos. Taxas de extinção atuais são de 100 a 1000 vezes maiores do que as taxas normais, e até 30% das espécies pode estar extinta até o meio deste século. Atividades humanas são hoje a principal causa da extinção em massa atual e o aquecimento global pode acelerar ainda mais essa extinção no futuro.
O papel da extinção na evolução depende do tipo de extinção que é considerada. As causas das baixas taxas de evolução, que atuam continuamente e são responsáveis pela maior parte das extinções, não são bem conhecidas, e podem ser o resultado da competição entre as espécies por recursos compartilhados. Se a competição de outras espécies pode alterar a chance de determinada espécie sobreviver, isso poderia produzir seleção natural no nível de espécies, em contraposição à que ocorre no nível de organismos. As extinções em massa intermitentes também são importantes, mas ao invés de agir como força seletiva, elas reduzem drasticamente a diversidade, de forma não específica, promovendo picos de radiação adaptativa e especiação nas espécies sobreviventes.
A origem da vida é o precursor necessário para a evolução biológica, mas perceber que a evolução ocorreu depois de os organismos aparecerem pela primeira vez, e investigar como isto acontece, não depende na compreensão exacta de como a vida começou. O consenso científico actual é de que a bioquímica complexa que constitui a vida provém de reacções químicas mais simples, mas que não é claro como ocorreu esta transição. Não há muitas certezas sobre os primeiros desenvolvimentos da vida, a estrutura dos primeiros seres vivos, ou a identidade ou natureza do último ancestral comum ou do pool genético ancestral. Como consequência, não há consenso científico sobre como a vida surgiu. Algumas propostas incluem moléculas capazes de auto-replicação, como o RNA e a construção de células simples.
Todos os seres vivos da Terra descendem de um ancestral comum ou de um pool genético ancestral. E as espécies actuais são um estádio no processo de evolução, e a sua diversidade resulta de uma longa série de eventos de especiação e extinção. A origem comum dos seres vivos foi inicialmente deduzida a partir de quatro simples factos sobre seres vivos: Primeiro, eles têm distribuições geográficas que não podem ser explicadas por adaptações locais. Segundo, a diversidade da vida não é uma série de organismos completamente únicos, mas os seres vivos têm semelhanças morfológicas. Terceiro, características vestigiais com nenhuma utilidade evidente são parecidas com características ancestrais funcionais e finalmente, que organismos podem ser classificados usando estas semelhanças numa hierarquia de grupos aninhados uns nos outros.
Espécies passadas também deixaram registos da sua história evolutiva. Fósseis, juntamente com a anatomia comparada de seres vivos existentes actualmente, constituem o registo morfológico ou anatómico. Comparando as anatomias de espécies modernas e extintas, paleontólogos podem inferir as linhagens dessas espécies. Contudo, esta metodologia tem maior sucesso em organismos com partes duras, tais como conchas, ossos ou dentes. Além disso, como os procariontes como bactérias e archaea partilham uma série limitada de morfologias comuns, os seus fósseis não fornecem informação sobre a sua ascendência.
Mais recentemente, evidências de origem comum provieram do estudo de semelhanças bioquímicas entre organismos. Por exemplo, todas as células vivas usam os mesmos ácidos nucleicos e aminoácidos. O desenvolvimento da genética molecular revelou o registo da evolução deixado nos genomas dos seres vivos: datando quando as espécies divergiram através do relógio molecular produzido pelas mutações. Por exemplo, comparações entre sequências de DNA revelaram a estreita semelhança genética entre humanos e chimpanzés e revelou quando existiu um ancestral comum às duas espécies.
Apesar da incerteza sobre como a vida começou, é claro que os procariontes foram os primeiros seres vivos a habitar a Terra, há aproximadamente 3-4 mil milhões de anos. Não ocorreram nenhumas mudanças óbvias em morfologia ou organização celular nestes organismos durante os próximos milhares de milhão de anos.
A próxima grande inovação na evolução foram os eucariontes. Estes surgiram a partir de bactérias antigas terem sido rodeadas por antecessores de células eucarióticas, numa associação cooperativa chamada de endossimbiose. A bactéria encapsulada e a célula hospedeira sofreram evolução, com a bactéria a evoluir em mitocôndrias ou em hidrogenossomas. Uma segunda captura de seres semelhantes a cianobactérias levou à formação de cloroplastos em algas e plantas.
A história da vida foi a história de procariontes, archae e eucariontes unicelulares até há cerca de um milhar de milhão de anos atrás quando seres multicelulares começaram a aparecer nos oceanos durante o período Ediacarano. A evolução de organismos multicelulares ocorreu múltiplas vezes, de forma independente, em organismos tão diversos como esponjas, algas castanhas, cianobactérias, mycetozoa e mixobactérias.
Depois do aparecimento dos primeiros seres multicelulares, ocorreu um notável diversificação biológica num período de 10 milhões de anos, num evento chamado explosão cambriana quando a maioria dos grupos de animais modernos apareceram entre 540 e 520 milhões de anos atrás. Durante este evento, evoluiram a maior parte dos tipos de animais modernos, assim como linhagens únicas que se extinguiram entretanto. Têm sido propostos vários "detonadores" para esta explosão, incluindo a acumulação de oxigénio na atmosfera resultante da fotossíntese. Um estudo conduzido por pesquisadores em 2013 estimou, pela primeira vez, as taxas de evolução durante a "explosão cambriana". Os resultados, solucionam o "dilema de Darwin": o súbito aparecimento de um grande número de grupos de animais modernos no registro de fóssil durante o início do período Cambriano.. Há cerca de 500 milhões de anos, plantas e fungos colonizaram a terra, e foram logo seguidos por artrópodes e outros animais. Os anfíbios apareceram pela primeira vez há cerca de 300 milhões de anos, seguidos pelos primeiros amniotas, os mamíferos há volta de 200 milhões de anos e as aves há cerca de 100 milhões de anos (ambos a partir de linhagens semelhantes a répteis. Contudo, apesar da evolução destes grandes animais, seres vivos mais pequenos semelhantes aos que evoluíram cedo no processo, continuam a ser bem sucedidos e a dominar a Terra, formando a maioria da biomassa e das espécies procariontes.
Na natureza existem exemplos de espécies que mesmo sem ter ancestral comum quando comparado com a outra, desenvolveram tamanha similaridade quando se diz respeito a forma e comportamento, essas espécies similares irão apresentar estruturas análogas quando estas apresentam similaridade na forma superficial ou na função, o que difere de estruturas homólogas que se originam estruturas de um ancestral em comum com as espécies comparadas. Um exemplo desse tipo de evolução no reino animal é encontrado quando comparado as asas dos morcegos e das aves.
Certa forma de evolução foi acrescentada na história, através de isolamentos entre indivíduos de um grupo. Um exemplo de evolução paralela se apresenta nos mamíferos, em que se diferem entre placentários e marsupiais, sendo que geralmente, alguns pares de animais tais como: Canis (Placentário) e Thylacinus (marsupial), Felis (placentário) e Dasyurus (marsupial), Glaucomys (placentário) e Petaurus (marsupial), Marmota (placentário) e Vombatus (marsupial), Myrmecophaga (placentário) e Myrmecabius (marsupial), Talpa (placentário) e Notoryctes (marsupial), apresentam similaridades tanto na aparência quanto em hábitos. Ao contrário da evolução convergente, a evolução paralela ocorre conforme uma mesma linhagem ancestral evolui. 
Ideias evolutivas como origem comum e de transmutação de espécies existiram pelo menos desde o século VI a.C., quando foram examinadas pelo filósofo grego Anaximandro de Mileto. Outros que consideraram estas ideias incluem o filósofo grego Empédocles, o filósofo-poeta romano Lucrécio, o biólogo árabe Al-Jahiz, o filósofo persa Ibn Miskawayh, e o filósofo oriental Zhuang Zi.
À medida que o conhecimento biológico aumentou no século XVIII, ideias evolutivas foram propostas por alguns filósofos como Pierre Louis Maupertuis em 1745, Erasmus Darwin em 1796, e Georges-Louis Leclerc (conde de Buffon) entre 1749 e 1778. As ideias do biólogo Jean-Baptiste Lamarck acerca da transmutação das espécies teve grande influência. Charles Darwin formulou a sua ideia de selecção natural em 1838 e ainda estava desenvolvendo a sua teoria em 1858 quando Alfred Russel Wallace lhe enviou uma teoria semelhante, e ambas foram apresentadas na Linnean Society of London em dois artigos separados. No final de 1859, a publicação de "A Origem das Espécies" por Charles Darwin, explicava a selecção natural em detalhe e apresentava provas que levaram a uma aceitação cada vez mais geral da ocorrência da evolução.
O debate sobre os mecanismos da evolução continuaram, e Darwin não foi capaz de explicar a fonte das variações hereditárias sobre as quais a selecção natural actuaria. Tal como Lamarck, ele pensava que os progenitores passavam à descendência as adaptações adquiridas durante a sua vida, uma teoria subsequentemente nomeada de Lamarckismo. Na década de 1880, as experiências de August Weismann indicaram que as mudanças pelo uso e desuso não eram hereditárias, e o Lamarckismo entrou gradualmente em descrédito. Mais importante do que isso, Darwin não consegui explicar como características passam de geração para geração. Em 1865, Gregor Mendel descobriu que as características eram herdadas de uma maneira previsível. Quando o trabalho de Mendel foi redescoberto em 1900, a discórdia sobre a taxa de evolução prevista pelos primeiros geneticistas e biometristas levou a uma ruptura entre os modelos de evolução de Mendel e de Darwin.
Esta contradição só foi reconciliada nos anos 1930 por biólogos como Ronald Fisher. O resultado final foi a combinação da evolução por selecção natural e hereditariedade mendeliana, a síntese evolutiva moderna. Na década de 1940, a identificação do DNA como o material genético por Oswald Avery e colegas, e a subsequente publicação da estrutura do DNA por James Watson e Francis Crick em 1953, demonstraram o fundamento físico da hereditariedade. Desde então, a genética e biologia molecular tornaram-se partes integrais da biologia evolutiva e revolucionaram o campo da filogenia.
Na sua história inicial, a biologia evolutiva atraiu primariamente cientistas vindos de campos tradicionais de disciplinas orientadas para a taxonomia, cujo treino em organismos particulares os levava a estudar questões gerais em evolução. Assim que a biologia evolutiva se expandiu como disciplina académica, particularmente depois do desenvolvimento da síntese evolutiva moderna, começou a atrair cientistas de um leque mais alargado das ciências biológicas. Actualmente, o estudo da biologia evolutiva envolve cientistas de campos tão diversos como bioquímica, ecologia, genética e fisiologia, e conceitos evolutivos são usados em disciplinas ainda mais distantes como psicologia, medicina, filosofia e ciência dos computadores.
Mesmo antes da publicação d"'A Origem das Espécies", a ideia que a vida evolui era fonte de debate. A evolução ainda é um conceito contencioso em algumas secções da sociedade fora da comunidade científica. O debate tem-se centrado nas implicações filosóficas, sociais e religiosas da evolução, não na ciência em si; a proposta de que a evolução biológica ocorre através do mecanismo de selecção natural é padrão na literatura científica.
Apesar de muitas religiões terem reconciliado as suas crenças com a evolução através de vários conceitos de evolução teísta, há muitos criacionistas que acreditam que a evolução é contraditória com as histórias de criação encontradas nas respectivas religiões. Tal como Darwin reconheceu desde cedo, o aspecto mais controverso do pensamento evolutivo é a sua implicação para a origem dos seres humanos. Em alguns países, notavelmente os Estados Unidos, as tensões entre os ensinamentos científicos e religiosos têm alimentado a controvérsia da criação vs. evolução, um conflito religioso que foca na política do criacionismo e no ensino da evolução nas escolas públicas. Apesar de outros campos da ciência como cosmologia e ciências da Terra também entrarem em conflito com a interpretação literal de muitos textos religiosos, muitos crentes religiosos opõem-se à biologia evolutiva.
A evolução tem sido usada para posições filosóficas que propõe discriminação e o racismo. Por exemplo, as ideias eugénicas de Francis Galton foram desenvolvidas para argumentar que o pool genético humano podia ser melhorado através de políticas de cruzamentos selectivos, incluindo incentivos para aqueles considerados como "bom stock" para se reproduzirem, e esterilização compulsória, testes pré-natais, controlo da natalidade e inclusive homicídio dos considerados "mau stock". Um outro exemplo de uma extensão da teoria evolutiva que é reconhecida actualmente como indevida é o "Darwinismo social", um termo dado à teoria Malthusiana dos Whig, desenvolvida por Herbert Spencer em ideias de "sobrevivência do mais apto" no comércio e nas sociedades humanas em geral, e por outros que reclamavam que a desigualdade social, racismo e imperialismo eram justificados. Contudo, cientistas e filósofos contemporâneos consideram que estas ideias não são nem mandatadas pela teoria evolutiva nem sustentadas por quaisquer dados.
Uma grande aplicação tecnológica da evolução é a selecção artificial, que é a selecção intencional de certas características em populações de seres vivos. Os seres humanos têm usado a selecção artificial há milhares de anos na domesticação de plantas e animais. Mais recentemente, tal selecção tornou-se uma parte vital da engenharia genética, com o uso de marcadores selecionáveis tais com a resistência a antibióticos para manipular DNA na biologia molecular.
Como a evolução é capaz de produzir processos e redes altamente optimizados, tem muitas aplicações em ciência dos computadores. Aqui, simulações de evolução usando algoritmos genéticos e vida artificial foram iniciadas com o trabalho de Nils Aall Barricelli na década de 1960, e depois estendidas por Alex Fraser, que publicou uma série de artigos sobre simulação de evolução artificial. A evolução artificial tornou-se um método de optimização largamente reconhecido como resultado do trabalho de Ingo Rechenberg na década de 1960 e 70, que usou estratégias evolutivas para resolver problemas de engenharia complexos. Algoritmos genéticos em particular tornaram-se populares pelos escritos de John Holland. À medida que o interesse académico cresceu, o aumento dramático no poder computacional permitiu aplicações práticas. Algoritmos evolutivos são agora usados para resolver problemas multi-dimensionais mais eficientemente do que por software produzido por programadores humanos, e também para optimizar o desenho de sistemas.

</doc>
<doc id="784" url="https://pt.wikipedia.org/wiki?curid=784" title="Etileno">
Etileno

O etileno ou eteno é o hidrocarboneto alceno mais simples da família das olefinas, constituído por dois átomos de carbono e quatro de hidrogênio (CH). Existe uma ligação dupla entre os dois carbonos. A existência de uma ligação dupla significa que o etileno é um "hidrocarboneto insaturado". Pela nomenclatura IUPAC recebe a denominação de eteno.
A molécula não pode rodar em torno da ligação dupla, e os seis átomos dispõem-se no mesmo plano. O ângulo das duas ligações carbono-hidrogênio é de 117º, muito próximo dos 120º preditos pela hibridização sp² ideal.
É um gás incolor, odor etéreo, levemente adocicado que liquefaz a -103°C e solidifica a -169°C, sendo o composto químico de maior utilização no setor químico industrial. 
A hulha é aquecida a uma temperatura de 1000°C/1300°C em presença de uma corrente de ar. Obtém-se uma fração gasosa que contém entre 3% a 5% de etileno.
Industrialmente o etileno é preparado pela desidrogenação do etano (retirada de hidrogênio). A desidrogenação ocorre entre 500°C e 750°C, utilizando catalisadores como óxido de crômio, de molibdênio, de vanádio e de urânio suspensos em alumina.
Várias indústrias propõem a fabricação de plástico verde ou ecológico a partir do álcool etílico produzido a partir da cana de açúcar. O método é antigo e semelhante a fabricação de éter etílico (antigamente chamado sulfúrico):
O método é catalisado por ácido sulfúrico ou alumina. A baixa temperatura favorece a produção do éter etílico e alta temperatura favorece o etileno.
Quando moléculas grandes constituintes do petróleo (geralmente alcanos) são quebradas (inglês "to crack" = quebrar) através de um processo simples de aquecimento utilizando catalisadores (pode ser silica, alumina Al2O3), forma-se uma fração gasosa que contém na sua composição etileno. Esse processo é um dos mais simples que ocorrem com a transformação do petróleo.
O etileno é usado como:
A maior aplicação do etileno é através do emprego de derivados obtidos a partir dele:
Biossíntese
A rota completa de síntese do etileno é um ciclo (ciclo de Yang).O primeiro precursor do etileno nesta via é o aminoácido metionina, o qual é adenilado pela AdoMet sintetase, formando a S-adenosilmetionina. O precursor imediato do etileno é o ácido 1-aminociclopropano-1-carboxílico (ACC) que é sintetizado a partir da AdoMet pela enzima ACCsintase, nesta reação, a adenina é liberada da AdoMet e é ligada à outra molécula de metionina através do ciclo de Yang. A última etapa de síntese do etileno é a conversão do ACC em etileno catalisada pela enzima ACC oxidase. 
A etapa limitante para a produção do etileno é a síntese do ACC a partir de AdoMet, que é catalisada pela ACCsintase. Esta enzima tem seus níveis regulados por fatores ambientais e internos, como ferimentos, inundação, estresse hídrico e presença de auxina e é codificada por uma família multigênica divergente, na qual os genes são regulados de formas distintas por indutores diferentes.
Inicialmente, o Etileno liga-se a um receptor proteico na membrana do Retículo Endoplasmático. Em seguida, esse receptor deixa de ativar uma proteína, a CTR1, que atua como reguladora negativa da cadeia de sinais químicos que produz a resposta biológica do etileno. Em outras palavras, a presença do etileno inativa uma proteína que atua como inibidora, fazendo então com que a resposta ocorra. Na ausência do etileno, a CTR1 inibe a formação dos fatores de transcrição que irão regular a expressão de genes de resposta ao etileno na planta. .
Vem sendo demonstrado que o Etileno regula diversas respostas nos vegetais . O etileno é conhecido como “hormônio do amadurecimento”, pois promove o amadurecimento de frutos. Outros efeitos biológicos promovidos pelo etileno são: germinação de sementes; epinastia (curvatura para baixo)de folhas; abscisão (queda) de frutos maduros, órgãos senescentes ou danificados e folhas; expansão celular horizontal e crescimento lateral do caule; quebra de dormência de gemas e sementes em algumas espécies; alongamento do caule de espécies vegetais aquáticas submersas; formação de raízes e pêlos absorventes; indução floral e expressão sexual, como por exemplo em Cucurbitaceae (família das abóboras), o etileno induz a preferência de flores femininas. Embora o etileno iniba o florescimento na maioria das espécies, em plantas de abacaxi ele induz o florescimento .

</doc>
<doc id="785" url="https://pt.wikipedia.org/wiki?curid=785" title="Espanha">
Espanha

Espanha (; ), também conhecido como Reino de Espanha ou Reino da Espanha, é um país situado na Europa meridional, na península Ibérica. Seu território principal é delimitado a sul e a leste pelo mar Mediterrâneo, com exceção a uma pequena fronteira com o território britânico ultramarino de Gibraltar; ao norte pela França, Andorra e pelo golfo da Biscaia e ao noroeste e oeste pelo oceano Atlântico e por Portugal.
O território espanhol inclui ainda as ilhas Baleares, no Mediterrâneo, as ilhas Canárias, no oceano Atlântico, próximas da costa Africana e duas cidades autônomas no norte de África, Ceuta e Melilla, que fazem fronteira com o Marrocos. Com uma área de , a Espanha é, depois da França, o segundo maior país da Europa Ocidental e da União Europeia.
Devido à sua localização, o território da Espanha foi sujeito a muitas influências externas, muitas vezes simultaneamente, desde os tempos pré-históricos até quando a Espanha se tornou um país. Por outro lado, o próprio país foi uma importante fonte de influência para outras regiões, principalmente durante a Era Moderna, quando se tornou um império mundial que deixou como legado mais de 400 milhões de falantes do espanhol espalhados pelo mundo.
A Espanha é uma democracia organizada sob a forma de um governo parlamentar sob uma monarquia constitucional. É um país desenvolvido com a nono PIB nominal mais elevado do mundo e elevado padrão de vida (a Espanha possui o 23.º melhor Índice de Desenvolvimento Humano (IDH) do mundo). É um membro das Organização das Nações Unidas (ONU), da União Europeia (UE), da Organização do Tratado do Atlântico Norte (OTAN), da Organização para a Cooperação e Desenvolvimento Econômico (OCDE) e da Organização Mundial do Comércio (OMC).
O nome Espanha deriva de Hispânia, nome com o qual os romanos designavam geograficamente a península Ibérica. O nome "Ibéria" era o que os gregos davam à península embora houvesse outras designações dadas pelos povos antigos. O facto do termo "Hispânia" não ter uma raiz latina resultou na formulação de diversas teorias sobre a sua origem, algumas controversas. A opção mais consensual seria a de que o nome Hispânia provém do fenício "i-spn-ea". Os romanos tomaram essa denominação dos vencidos cartaginenses, interpretando o prefixo "i" como "costa", "ilha" ou "terra", e o sufixo "ea" com o significado de "região". O lexema "spn" foi traduzido como "coelhos" (na realidade dassies, animais comuns no norte da África).
O nome de Espanha, evolução da designação do Império Romano Hispânia era, até ao , apenas descritivo da península Ibérica, não se referindo a um país ou Estado específico, mas sim ao conjunto de todo o território ibérico e dos países que nele se incluíam. A Espanha é unificada durante o Iluminismo, até então era um conjunto de reinos juridicamente e politicamente independentes governados pela mesma monarquia. Até à data da unificação a monarquia era formada por um conjunto de reinos associados por herança e união dinástica ou por conquista. A forma de governo era conhecida como "aeque principaliter", os reinos eram governados cada um de forma independente, como se tivesse cada reino o seu próprio rei, cada reino mantinha o seu próprio sistema legal, a sua língua, os seus foros e os seus privilégios.
As "Leyes de extranjeria" determinavam que o natural de qualquer um dos reinos era estrangeiro em todos os outros reinos ibéricos.
A constituição de 1812 adota o nome "As Espanhas" para a nova nação.
A constituição de 1876 adota pela primeira vez o nome "Espanha".
Os termos "as Espanhas" e "Espanha" não eram equivalentes, e eram usados com muita precisão. O termo "As Espanhas" referia-se a um conjunto de unidades jurídico-políticas, ou seja, referia-se a um conjunto de reinos independentes, primeiramente apenas aos reinos cristãos da península Ibérica, depois apenas aos reinos unidos sobre a mesma monarquia. O termo "Espanha" referia-se a um espaço geográfico e cultural que englobava diversos reinos independentes. A partir de Carlos V o uso do título "Rei das Espanhas", referia-se à parte da Espanha que não incluía Portugal, mas esta designação era apenas uma forma de designar coletivamente um extenso número de reinos, uma abreviação, que não tinha validade jurídica, para uma longa lista de títulos reais cuja forma oficial era rei de Castela, de Leão, de Aragão, de Navarra, de Granada, de Toledo, de Valência, da Galiza, de Maiorca, de Menorca, de Sevilha, etc. (da mesma forma utilizava-se o título Sua Majestade Lusitana para o rei de Portugal, ou rei Lusitano)
O uso do da designação de "reis de Espanha" pelos reis Fernando e Isabel foi considerado uma ofensa pelo rei de Portugal que considerava que o nome designava a península. A última vez que Portugal protestou oficialmente o uso do termo "coroa de Espanha" ou "monarquia de Espanha" pelo governo de Madrid foi, supõe-se, durante o Tratado de Utrecht em 1714.
Atualmente o nome "península hispânica" não é aceite pelos portugueses, sendo que a designação usada é a de península Ibérica.
A partir de 1640, com a Restauração da Independência de Portugal, a designação "Rei da Espanha" manteve-se, apesar de a união dinástica já não englobar toda a Península.
A "História de Espanha" é a própria de uma nação europeia, que compreende o período entre a pré-história e a época atual, passando pela formação e queda do primeiro Império espanhol.
Os primeiros humanos chegaram à península Ibérica no território da atual Espanha há 35 mil anos. No período histórico o território foi invadido e colonizado por celtas, fenícios, cartagineses, gregos e cerca de , a maior parte da península Ibérica começou a formar parte do Império Romano, sendo o rio Ebro a fronteira entre a Espanha romana e cartaginesa.
Durante a Segunda Guerra Púnica, uma expansão do Império Romano capturou colônias comerciais cartaginesas ao longo da costa do Mediterrâneo, cerca de Os romanos levaram quase dois séculos para completar a conquista da península Ibérica, apesar de terem o controle de boa parte dela há mais de 600 anos. O domínio romano era unido pela lei, idioma e as estradas romanas.
As culturas das populações celtas e ibéricas foram gradualmente romanizadas (latinizadas) em diferentes níveis e em diferentes partes da Hispânia (o nome romano para a península). Os líderes locais foram admitidos na classe aristocrática romana. A "Hispania" serviu como um celeiro para o mercado romano e seus portos exportavam ouro, lã, azeite e vinho. A produção agrícola aumentou com a introdução de projetos de irrigação, alguns dos quais permanecem em uso. Os imperadores Trajano e Teodósio I e o filósofo Sêneca nasceram na Hispânia. O cristianismo foi introduzido na província no e tornou-se popular nas cidades no O termo "Espanha", as línguas, a religião e a base das leis atuais da Espanha se originaram a partir deste período.
O enfraquecimento da jurisdição do Império Romano do Ocidente em Hispânia começou em 409, quando os povos germânicos suevos e vândalos, juntamente com os alanos sármatas, cruzaram o Reno e devastaram a Gália e a península Ibérica. Os visigodos atacaram a Ibéria no mesmo ano. Os suevos estabeleceram um reino no que hoje é a moderna Galiza e o Norte de Portugal. O império romano ocidental se desintegrava, mas a sua base social e econômica continuou, ainda que de forma modificada. Os seus regimes sucessores mantiveram muitas das instituições e das leis do Império, incluindo o cristianismo.
Os aliados dos alanos, os vândalos asdingos, estabeleceram um reino na Galécia, ocupando grande parte da região, mas indo mais ao sul do rio Douro. Os vândalos silingos ocuparam a região que ainda tem o seu nome - Vandalúsia, a moderna Andaluzia, na Espanha. Os bizantinos estabeleceram um enclave, Espânia, no sul, com a intenção de reviver o Império Romano ao longo da península Ibérica. Eventualmente, entretanto, Hispânia foi reunida sob o domínio visigótico.
No século VIII, quase toda a península Ibérica foi conquistada por exércitos de mouros muçulmanos provenientes principalmente do Norte de África. Essas conquistas fizeram parte da expansão do Califado Omíada. Apenas uma pequena área montanhosa no noroeste da península conseguiu resistir à invasão inicial muçulmana.
Sob a lei islâmica, os cristãos e os judeus receberam o estatuto subordinado de "dhimmi". Esse estatuto permitia que cristãos e judeus praticassem suas religiões como "povos do livro", mas eles eram obrigados a pagar um imposto especial e eram sujeitos a certas discriminações. A conversão ao islamismo prosseguiu a um ritmo cada vez maior. Acredita-se que os "muladi" (muçulmanos de origem étnica ibérica) compreendiam a maioria da população de "Al-Andalus" até o final do .
A comunidade muçulmana na península Ibérica era diversificada e atormentado por tensões sociais. Os povos berberes do Norte de África, que tinham fornecido a maior parte dos exércitos invasores, entraram em choque com a liderança árabe do Oriente Médio. Ao longo do tempo, grandes populações árabes se estabeleceram, especialmente no vale do rio Guadalquivir, na planície costeira de Valência, no vale do rio Ebro (no final deste período) e na região montanhosa de Granada.
Córdova, a capital do califado, era a maior, mais rica e sofisticada cidade na Europa Ocidental na época. O comércio e o intercâmbio cultural no Mediterrâneo floresceram. Os muçulmanos importaram uma rica tradição intelectual do Oriente Médio e do Norte da África. Estudiosos muçulmanos e judeus desempenharam um papel importante na renovação e ampliação da aprendizagem clássica grega na Europa Ocidental. As culturas romanizados da península Ibérica interagiram com as culturas muçulmanas e judaicas de forma complexa, dando, à região, uma cultura distinta.
No século XI, os territórios muçulmanos fragmentaram-se em reinos rivais (as chamadas taifas), permitindo, aos pequenos Estados cristãos, a oportunidade de ampliar enormemente seus territórios.
A chegada das seitas islâmicas dominantes dos Almorávidas e Almóadas, do Norte da África, restaurou a unidade na península Ibérica muçulmana, com uma aplicação mais rigorosa e menos tolerante do islã, provocando uma recuperação das fortunas muçulmanas. Este Estado islâmico reunido experimentou mais de um século de sucessos que reverteram parcialmente as vitórias cristãs.
As contínuas disputas entre muçulmanos e cristãos tiveram, como consequência, a Reconquista Cristã, começando no com a resistência cristã no norte da Espanha e através dos séculos seguintes com o avanço dos reinos cristãos ao sul, culminando com a conquista de Granada e com a expulsão dos últimos mouros em 1492.
Durante este período, os reinos e principados cristãos se desenvolveram notavelmente, incluídos os mais importantes: a Coroa de Castela e o Reino de Aragão. A união destes dois reinos através do casamento em 1469 da rainha Isabel I de Castela com o rei Fernando II de Aragão levou à criação do Reino da Espanha.
A unificação das coroas de Aragão e Castela lançou as bases para a Espanha moderna e para o Império Espanhol. A Espanha era a maior potência da Europa durante o e a maior parte do , uma posição reforçada pelo comércio e pela riqueza de suas possessões coloniais. Ela atingiu o seu apogeu durante os reinados dos dois primeiros habsburgos espanhóis - Carlos I (1516-1556) e Filipe II (1556-1598). Este período foi marcado pelas Guerras Italianas, Revolta dos Comuneiros, Revolta Holandesa, Rebelião das Alpujarras, conflitos com os otomanos, a Guerra Anglo-Espanhola e as guerras com a França.
O Império Espanhol se expandiu até incluir grande parte da América, ilhas na região Ásia-Pacífico, áreas da Itália, cidades do Norte de África, bem como partes do que hoje são parte de França, Alemanha, Bélgica, Luxemburgo e Países Baixos. Foi o primeiro império do qual se dizia que "o Sol nunca se punha".
A chamada "Era dos Descobrimentos" foi marcada por explorações ousadas por mar e por terra, a abertura de novas rotas comerciais pelos oceanos, conquistas e os primórdios do colonialismo europeu. Junto com a chegada dos metais preciosos, especiarias, luxos e novas plantas agrícolas, exploradores espanhóis trouxeram o conhecimento do Novo Mundo e desempenharam um papel de liderança na transformação da compreensão europeia do mundo. O florescimento cultural testemunhado é agora referido como o "Século de Ouro Espanhol". A ascensão do humanismo, da Reforma Protestante e de novas descobertas geográficas levantaram questões abordadas pelo movimento influente intelectual agora conhecida como a Escola de Salamanca.
Com a morte de Carlos II, a dinastia de Habsburgo se extinguiu, para deixar lugar aos Borbões, após a Guerra de Sucessão. Como consequência dessa guerra, a Espanha perdeu sua preponderância militar e, após sucessivas bancarrotas, o país foi reduzindo paulatinamente seu poder, convertendo-se, no final do , em uma potência menor.
O século XIX foi testemunha de grandes mudanças na Europa, acompanhadas pela Espanha. Na primeira parte desse século, a Espanha sofreu a independência da maioria de suas colônias no Novo Mundo. O século também esteve marcado pelas intervenções estrangeiras e os conflitos internos. Napoleão chegou a colocar seu irmão José Bonaparte no governo da Espanha. Após a expulsão dos franceses, a Espanha entrou em um extenso período de instabilidade: se sucederam continuas lutas entre liberais, republicanos e partidários do Antigo Regime.
A chegada da Revolução Industrial nas últimas décadas do século, levou algo de riqueza a uma classe média que se ampliava em alguns centros principais, porém a Guerra Hispano-Americana, em 1898 levou à perda de quase todas as colônias restantes, restando apenas os territórios na África.
Apesar de um nível de vida crescente e uma integração maior com o resto de Europa, no primeiro terço do , seguiu a instabilidade política. Espanha permaneceu neutral durante a Primeira Guerra Mundial.
O século XX trouxe um pouco de paz; a Espanha desempenhou um papel menor na partilha da África, colonizando o Sahara Ocidental, Marrocos Espanhol e a Guiné Equatorial. As pesadas perdas sofridas durante a guerra do Rif, no Marrocos, ajudaram a minar a monarquia. Um período de governo autoritário do general Miguel Primo de Rivera (1923-1931) terminou com o estabelecimento da Segunda República Espanhola. A República ofereceu autonomia política ao País Basco, Catalunha e à Galiza e deu direito de voto às mulheres.
Então, em 1936, a Guerra Civil Espanhola (1936-39) iniciou-se. Três anos mais tarde, as forças nacionalistas, lideradas pelo general Francisco Franco, saíram vitorioso com o apoio da Alemanha nazista e da Itália fascista. A Frente Popular governista foi apoiada pela União Soviética, o México e pelas Brigadas Internacionais, mas não foi apoiada oficialmente pelas potências ocidentais, devido à política britânica, liderada pelos Estados Unidos, de não intervencionismo.
A Guerra Civil tirou a vida de mais de 500.000 pessoas e causou a fuga de cerca de meio milhão de cidadãos espanhóis. A maioria de seus descendentes vivem agora em países da América Latina, com cerca de 300.000 apenas na Argentina.
O Estado espanhol estabelecido por Francisco Franco após a Guerra Civil foi nominalmente neutro na Segunda Guerra Mundial, embora fosse simpático às Potências do Eixo. O único partido legal sob o regime pós-guerra civil de Franco era o "Falange Española Tradicionalista y de las JONS", formado em 1937. O partido enfatizava o anti-comunismo, o catolicismo e o nacionalismo. Dada a oposição à Franco de partidos políticos concorrentes, o partido passou a se chamar Movimento Nacional ("Movimiento Nacional") em 1949.
Após a Segunda Guerra Mundial, a Espanha ficou isolada politicamente e economicamente e foi mantida fora das Nações Unidas. Isso mudou em 1955, durante o período da Guerra Fria, quando o país se tornou estrategicamente importante para os Estados Unidos para estabelecer sua presença militar na península Ibérica como base para qualquer possível transferência pela União Soviética para a bacia do Mediterrâneo. Na década de 1960, a Espanha registrou uma taxa sem precedentes de crescimento econômico no que ficou conhecido como o milagre espanhol, que retomou a transição, bastante interrompida, para uma economia moderna.
Com a morte de Franco, em novembro de 1975, Juan Carlos assumiu o cargo de Rei de Espanha e de chefe de Estado, em conformidade com a lei. Com a aprovação da nova Constituição espanhola de 1978 e a restauração da democracia, o Estado descentralizou muito da sua autoridade para as regiões com governo local e criou uma organização interna baseada em comunidades autónomas.
No País Basco, o nacionalismo moderado tem coexistido com um movimento radical nacionalista liderado pela organização armada "Euskadi Ta Askatasuna" (ETA). O grupo foi formado em 1959 durante o governo de Franco, mas continuou a travar a sua violenta campanha mesmo após a restauração da democracia e do retorno de um elevado grau de autonomia regional.
Em 23 de fevereiro de 1981, elementos rebeldes entre as forças de segurança apreenderam Cortes em uma tentativa de impor um governo militar apoiado pelos Estados Unidos. O Rei Juan Carlos assumiu o comando pessoal dos militares e, com êxito, ordenou que os golpistas, através da televisão nacional, se rendessem.
Em 30 de maio de 1982 a Espanha aderiu à Organização do Tratado do Atlântico Norte (OTAN), após um referendo. Nesse ano, o Partido Socialista Operário Espanhol (PSOE) chegou ao poder, o primeiro governo de esquerda em 43 anos. Em 1986 a Espanha aderiu à Comunidade Europeia, que posteriormente tornou-se a União Europeia (UE). O PSOE foi substituído no governo pelo Partido Popular (PP) em 1996.
Em 1 de janeiro de 2002, a Espanha deixou de usar a peseta como moeda e substituí-a pelo euro, que compartilha com outros 15 países da zona euro. O país experimentou um forte crescimento econômico, bem acima da média da UE, mas as preocupações divulgadas e emitidas por muitos comentaristas econômicos no auge do "boom" dos preços imobiliários e dos elevados défices de comércio exterior de que o país estava susceptível a passar por um doloroso colapso econômico foram confirmadas por uma grave recessão que assola o país desde 2008.
Em 11 de março de 2004, uma série de bombas explodiram em trens de Madrid. Depois de um julgamento de cinco meses em 2007, concluiu-se os atentados foram perpetrados por um grupo islâmico militante local inspirado pela organização Al-Qaeda. As explosões mataram 191 pessoas e feriram mais de 1800, e a intenção dos autores do atentado terrorista podem ter sido influenciadas o resultado da eleição geral espanhola, realizada três dias depois.
Embora as suspeitas iniciais tenham se focado no grupo basco ETA, logo surgiram evidências indicando um possível envolvimento de grupos extremistas islâmicos. Devido à proximidade da eleição, a questão da responsabilidade rapidamente se tornou uma controvérsia política, com os principais partidos concorrentes, PP e PSOE, trocando de acusações sobre a manipulação do resultado. Em 14 de março de eleições, o PSOE, liderado por José Luis Rodríguez Zapatero, obteve uma pluralidade suficiente para formar um novo gabinete, portanto, suceder a administração anterior do PP.
Nas eleições de 20 de novembro de 2011 o partido liderado por Mariano Rajoy obteve mais de votos e elegeu 186 deputados, conquistando a maioria absoluta e o melhor resultado de sempre do Partido Popular, que voltou ao poder.
Situada na Europa Ocidental, a Espanha ocupa a maior parte da península Ibérica e, fora dela, dois arquipélagos principais (ilhas Canárias no oceano Atlântico e as ilhas Baleares no mar Mediterrâneo), duas cidades (Ceuta e Melilla, no Norte da África), a ilha de Alborão e uma série de ilha e ilhotas que se encontram frente às costas peninsulares, como as ilhas Columbretes. Ademais, consta de possessões menores continentais, como as ilhas Chafarinas, o ilhote de Vélez de la Gomera e o ilhote de Alhucemas, todas elas frente à costa africana.
Em extensão territorial, é o quarto maior país da Europa, atrás apenas da Rússia (que é o maior país do mundo, tendo em conta apenas a parte europeia), Ucrânia e França, e o segundo maior da União Europeia, atrás apenas da França.
Os limites físicos da Espanha são os seguintes: Portugal e o oceano Atlântico a oeste; o mar Mediterrâneo a leste, o Estreito de Gibraltar, mar Mediterrâneo e oceano Atlântico a sul; os Pirenéus a nordeste e o golfo da Biscaia e o mar Cantábrico a norte.
A Espanha tem um clima variado ao longo do seu território. Predomina o tipo mediterrânico em quase toda a sua geografia. As costas mediterrânicas do sul e o vale do Rio Guadalquivir têm um clima denominado mediterrânico costeiro: temperaturas e precipitações suaves quase todo o ano, exceto no verão.
À medida que se avança para o interior, o clima é mais extremo, passando o clima a ser do tipo clima mediterrânico continental, predominante em quase toda a península: temperaturas altas no verão, baixas no inverno e precipitações irregulares (dependendo da posição geográfica).
Desde 1996 o índice de emissões de CO subiu notavelmente na Espanha, descumprindo os objetivos do Protocolo de Quioto sobre emissões geradoras do efeito estufa e contribuintes da mudança climática. Ban Ki-moon, secretário geral da ONU, pediu à Espanha uma ‘‘liderança mais ativa’‘ na luta contra a mudança climática.
A Espanha é um país especialmente afetado pelo fenômeno da seca: durante o período 1880-2000, mais da metade dos anos foram classificados como secos ou muito secos. Sete anos da década dos 80 e cinco da década de 90 foram considerados secos ou muito secos. A mudança climática prevê para a Espanha gravíssimos problemas meio ambientais, agravando as características mais extremas.
Segundo Al Gore, a Espanha é o país europeu mais vulnerável ao efeito estufa.
Em 2012, a população de Espanha oficialmente alcançou os 47 milhões de pessoas, conforme registrado pelo "Padrón municipal". A densidade populacional do país, em , é menor do que a da maioria dos países da Europa Ocidental e sua distribuição através do país é bastante desigual. Com exceção da região do entorno da capital, Madrid, as áreas mais povoadas ficam em torno da costa. A população da Espanha mais que dobrou desde 1900, quando se situava em 18,6 milhões, principalmente devido ao espetacular crescimento demográfico vivido pelo país na década de 1960 e início de 1970.
Os espanhóis nativos compõem 88% da população total da Espanha. Depois da taxa de natalidade ter caído na década de 1980, a taxa de crescimento populacional da Espanha diminuiu, mas a população novamente cresceu baseada inicialmente no regresso de muitos espanhóis que emigraram para outros países europeus durante os anos 1970 e, mais recentemente, alimentada por um grande número de imigrantes que constituem 12% da população. Os imigrantes são originários principalmente na América Latina (39%), Norte da África (16%), Europa Oriental (15%) e África subsaariana (4%). Em 2005, a Espanha instituiu um programa de anistia de três meses através do qual foi concedida residência legal à imigrantes ilegais.
Em 2008, o país concedeu a cidadania a pessoas, principalmente para pessoas vindas do Equador, Colômbia e Marrocos. Uma parte considerável dos residentes estrangeiros na Espanha também vêm de outros países da Europa Ocidental e Central. Estes são em sua maioria britânicos, franceses, alemães, holandeses e noruegueses. Eles residem principalmente na costa do Mediterrâneo e nas ilhas Baleares, onde muitos escolhem para viver sua aposentadoria.
Populações substanciais descendentes de colonos espanhóis e imigrantes existem em outras partes do mundo, com destaque para a América Latina. Começando no final do , um grande número de colonos ibéricos estabeleceram-se no que se tornou a América Latina e no momento a maior parte dos latino-americanos brancos (que representam cerca de um terço da população da América Latina) são de origem espanhola ou portuguesa. No , estima-se que espanhóis emigraram, principalmente para Peru e México. A eles se juntaram 450.000 que emigraram no século seguinte. Entre 1846 e 1932 estima-se que cerca de 5 milhões de espanhóis emigraram para a América, especialmente para Argentina, Brasil e Cuba. Cerca de dois milhões de espanhóis migraram para outros países da Europa Ocidental entre 1960 e 1975. Durante o mesmo período, cerca de foram para a América Latina.
A Espanha é o país mais tolerante em relação à homossexualidade em todo o mundo. Apenas 6% dos espanhóis dizem que a homossexualidade é "moralmente inaceitável", ao passo que 55% a consideram "moralmente aceitável" e 38% dizem que a homossexualidade "não é uma questão moral". Desde 2004 o casamento entre pessoas do mesmo sexo na Espanha é legal.
Os movimentos migratórios, tanto internos quanto externos, foram determinantes na composição demográfica moderna da Espanha. Entre o final do e início do , houve uma significativa corrente imigratória da Espanha para países ibero-americanos. Entre os principais destinos estavam Cuba, Argentina e Brasil. A densidade populacional da Espanha é menor que a da maioria dos países europeus. As populações rurais estão se movendo para as cidades. Nos últimos anos a Espanha apresenta uma considerável diminuição na taxa de imigração neta, deixando de possuir a maior taxa de imigração de Europa (em 2005 de 1,5% anual somente superado na UE pelo Chipre) atualmente sua taxa de imigração neta chega a 0,99%, ocupando a 15ª posição na União Europeia. além disso, o 9° país com maior porcentagem de imigrantes dentro da UE, abaixo de países como Luxemburgo, Irlanda, Áustria e Alemanha.
Em 2005 a Espanha recebeu 38,6% da migração para a União Europeia, principalmente de cidadãos de origem latino-americana, de outros países da Europa Ocidental, da Europa Oriental e do Magrebe. A população estrangeira na Espanha em 2007 cifrava-se em 4144166, um incremento de 11,1% em reação ao ano anterior. Este valor representa 9,3% dos 44 708964 habitantes na Espanha. A comunidade marroquina, com 563 mil residentes, é a mais numerosa, seguindo-se os equatorianos (461 mil), romenos (407 mil) e britânicos (274 mil).
A Espanha é abertamente um país multilingue. O idioma oficial e o mais falado no conjunto da Espanha, por 98.9% da população, é o espanhol, língua materna de 89% dos espanhóis, que pode receber a denominação alternativa de castelhano. A estimativa do número de falantes em todo o mundo vai desde os 450 aos 500 milhões de pessoas, sendo a segunda língua materna mais falada depois do Chinês. Há previsões que se torne a segunda língua de comunicação internacional depois do inglês no futuro, e, após este, é a segunda língua mais estudada.
Além disso, falam-se outras línguas que podem ser oficiais em suas regiões, de acordo com a Constituição e os Estatutos de Autonomia de cada Comunidade Autônoma, e co-oficiais para o resto do país. Ordenadas por número de falantes, estas Línguas são:
Também se falam uma série de línguas ou dialetos românicos que não tem estatuto de língua oficial: o asturiano, falado nas Astúrias (chamado "Bable"), Leão, Zamora (chamado "leonês"), Salamanca e Estremadura (chamado "estremenho") e o aragonês no norte de Huesca.
O aranês, variante do occitano, é considerado co-oficial na Catalunha, onde é falado nos municípios do Vale de Arão (Lérida).
Igualmente, o português é falado em algumas localidades fronteiriças estremenhas, principalmente por portugueses ali residentes.
A Espanha ratificou em 9 de abril de 2001 a Carta Europeia das Línguas Regionais ou Minoritárias. do Conselho Europeu.
O artigo 16.3 da Constituição Espanhola vigente define o país como um Estado sem confissão: ‘‘"Nenhuma confissão terá caráter estatal"‘‘. Porém, é garantida a liberdade religiosa e de culto dos indivíduos e é assegurada uma relação de cooperação entre os poderes públicos e todas as confissões religiosas.
De acordo com um estudo de 2015, cerca de 68% dos espanhóis classificaram-se como católicos romanos, 3,8% como aderentes de outras religiões (incluindo islamismo, protestantismo, budismo etc.), e cerca de 25% como ateus ou não religiosos.
De acordo com pesquisa de 2010 do "Eurobarometer", 59% da população espanhola acredita na existência de algum deus. 20% dos espanhóis acreditam na existência de algum tipo de espírito ou força vital, ao passo que 19% não acredita que exista qualquer tipo de espírito, deus, ou força vital.
A maioria dos espanhóis não frequentam templos religiosos regularmente. O estudo apontou que, dos espanhóis que se dizem religiosos, 61% raramente frequenta a missa, 14% frequenta a missa algumas vezes ao ano, 10% algumas vezes ao mês e 14% todos os domingos ou várias vezes na semana. Embora uma maioria dos espanhóis seja católica, a maior parte, especialmente os jovens, ignora as doutrinas morais conservadoras em assuntos como sexo antes do casamento, orientação sexual e métodos contraceptivos.
A segunda religião em número de membros é a muçulmana. Calcula-se que há cerca de fiéis, vindos fundamentalmente das recentes ondas de imigração. Há também um número crescente de igrejas protestantes, que somam cerca de fiéis (a estatística própria dos protestantes em Espanha indica , dos quais são espanhóis e o resto são estrangeiros que residem na Espanha durante pelo menos seis meses ao ano). Em terceiro lugar vêm as Testemunhas de Jeová com 103 784 fiéis e logo após, com cerca de fiéis, o mormonismo. A comunidade judia na Espanha não supera os fiéis.
A Espanha é uma monarquia parlamentarista, com um monarca hereditário que exerce como Chefe de Estado – o Rei da Espanha, e um parlamento bi-cameral, as "Cortes Generales". O poder executivo é formado por um Conselho de Ministros presidido pelo Presidente do Governo, que exerce como Chefe de Governo, e o poder judicial está formado pelo conjunto de Juizados e Tribunais, integrado por Juízes e Magistrados, que têm a potestade de administrar justiça em nome do Rei. O poder legislativo se estabelece nas Cortes Gerais, que é o órgão supremo de representação do povo espanhol. As Cortes Gerais são compostas de uma câmara baixa, o Congresso dos Deputados, e uma câmara alta, o Senado.
O Congresso dos Deputados é formado por 350 membros eleitos por votação popular, em listas fechadas e através de representação proporcional mediante circunscrições provinciais, para servir em legislaturas de quatro anos. O sistema não é absolutamente proporcional, já que existe um número mínimo de cadeiras por circunscrição (3) e se usa um sistema proporcional levemente corrigido para favorecer as listas majoritárias (o Sistema d'Hondt).
O Senado possui 259 membros, dos quais 208 são eleitos diretamente mediante voto popular, por circunscrições provinciais, em cada uma das quais se elegem 4 senadores, seguindo um sistema majoritário (3 para a lista majoritária, 1 para a seguinte), exceto nas ilhas Baleares e nas ilhas Canárias, onde cada circunscrição é uma ilha. Os outros 51 são designados pelos órgãos regionais para servir, também, por períodos de quatro anos.
Na Espanha o sistema de votação é diferente de países como o Brasil: não se vota no candidato, mas sim no partido, que já tem listas provinciais predefinidas. À medida que cada partido recebe seus votos, os integrantes da lista vão sendo eleitos. Em 2011, uma série de protestos pede uma democracia direta e mais livre no país.
No dia 2 de junho de 2014, o rei Juan Carlos I renunciou a favor do seu filho, Felipe de Bourbon, foi a primeira vez em mais de 50 anos que um rei abdica do trono na Espanha.
O único litígio internacional diz respeito ao município de Olivença. Português desde 1297, o município de Olivença foi cedido à Espanha no âmbito do Tratado de Badajoz, em 1801, após a Guerra das Laranjas. Portugal alegou que lhe pertencia, em 1815, no âmbito do Tratado de Viena. No entanto, as relações diplomáticas bilaterais entre os dois países vizinhos são cordiais, bem como no âmbito da União Europeia.
O Tratado de Alcanizes, de 1297, estabelecia Olivença como parte de Portugal. Em 1801, através do Tratado de Badajoz, denunciado em 1808 por Portugal, o território foi anexado a Espanha. Em 1817 a Espanha reconheceu a soberania portuguesa subscrevendo o Congresso de Viena de 1815, comprometendo-se à retrocessão do território o mais prontamente possível.
As forças armadas da Espanha são conhecidas como as Forças Armadas Espanholas (). Seu comandante-em-chefe é o rei da Espanha, Felipe VI.
As Forças Armadas espanholas estão divididas em três ramos:
Desde a Constituição de 1978 que a Espanha está dividida em 17 comunidades autônomas e as duas cidades autônomas de Ceuta e Melilla, gozando estas de estatuto intermediário entre o município e a Comunidade. Das 17 comunidades autônomas, quatro delas (Galiza, País Basco, Andaluzia e Catalunha) possuem condição de "Nacionalidades Históricas" reconhecidas na Constituição, juntamente com um "Estatuto de autonomia", o que reverte num maior poder e capacidade de decisão e soberania com respeito às outras comunidades.
As comunidades dividem-se ainda em cinquenta províncias.
Lista das comunidades e cidades autônomas:
A Espanha é na atualidade o que se denomina um "Estado de Autonomias", um país formalmente unitário, mas que funciona como uma federação descentralizada de comunidades autônomas, cada uma delas com diferentes níveis de autonomia. As diferenças dentro deste sistema são provocadas pelo processo de transferência de responsabilidades do governo central para as regiões foi pensado em um princípio como um processo, que garantisse um maior grau de autonomia somente àquelas comunidades que buscavam um tipo de relação mais federalista com o resto da Espanha (as chamadas "comunidades autônomas de regime especial": Andaluzia, Catalunha, Galiza, Navarra e País Basco). Por outro lado, o resto de comunidades autônomas ("comunidades autônomas de regime comum") teria uma menor autonomia. Porém, estava previsto que ao longo dos anos, estas comunidades fossem adquirindo gradativamente maior autonomia.
Hoje em dia, a Espanha está considerada como um dos países europeus mais descentralizados, pois todos os seus diferentes territórios administram de forma local seus sistemas de saúde e educativos, assim como alguns aspetos do orçamento público; alguns deles, como o País Basco e Navarra, administram seu orçamento sem praticamente contar, excetuado em alguns aspetos, com a supervisão do governo central espanhol. Catalunha, Navarra e o País Basco possuem suas próprias polícias totalmente operativas e completamente autônomas. Excetuando Navarra (cuja polícia se chama "Policía Foral de Navarra"), tanto a policia da Catalunha ("Mossos d'Esquadra") como a polícia do País Basco ("Ertzaintza") substituem as funções da Polícia Nacional da Espanha em seus respetivos territórios. Navarra ainda está em processo de transferência de funções.
Existem na Espanha diversos movimentos políticos de posição separatista, ligados a nacionalismos periféricos, como o nacionalismo basco, o nacionalismo galego, o nacionalismo catalão, que reclamam a independência da Espanha dos territórios em que são ativos. Estes movimentos acontecem na Catalunha, Galiza, Navarra e no País Basco, onde existem partidos explicitamente separatistas como a "União do Povo Galego" (UPG), "Esquerda Republicana da Catalunha", "Aralar", o "Eusko Alkartasuna", assim como os seguidores da chamada "esquerda abertzale" que não se desvinculam do ETA (sua última denominação formal é Batasuna, partido ilegalizado em Espanha, mas legal em França). Por outro lado, partidos como o "Bloco Nacionalista Galego" (BNG), "Partido Nacionalista Basco" (PNV) e "Convergència i Unió" (CiU) oscilam entre posturas autonomistas e abertamente separatistas.
A economia mista capitalista da Espanha é a décima segunda maior economia do mundo em PIB (PPC), a nona maior por PIB nominal e a quinta maior na União Europeia, bem como a quarta maior da Zona Euro. O país é também o terceiro maior investidor do mundo.
O governo de centro-direita do ex-primeiro-ministro José María Aznar teve sucesso para ser admitido no grupo de países que lançaram o euro em 1999. A taxa de desemprego situava-se em 7,6% em outubro de 2006, uma taxa que comparavelmente favorável a de muitos outros países europeus e especialmente com o início dos anos 1990 quando se situava em mais de 20%. Os pontos fracos perenes da economia espanhola incluem alta inflação, uma grande economia informal e um sistema educativo que os relatórios da OCDE classificam entre os piores entre os países desenvolvidos, em conjunto com os Estados Unidos e o Reino Unido.
No entanto, a bolha imobiliária que começou a se formar a partir de 1997, alimentada por taxas de juros historicamente baixas e uma onda imensa de imigração, implodiu em 2008 e levou a economia a um rápido enfraquecimento e a um aumento do desemprego. Até o final de maio de 2009, o desemprego atingiu 18,7% (37% para os jovens).
Antes da atual crise, a economia espanhola era creditada por ter evitado uma taxa de crescimento virtual zero como alguns de seus maiores parceiros na União Europeia apresentaram. Na verdade, a economia do país criou mais de metade de todos os novos postos de trabalho na União Europeia durante cinco anos até 2005, um processo que está sendo rapidamente revertido. A economia espanhola, até pouco tempo, era considerada uma das mais dinâmicos da União Europeia, atraindo uma quantidade significativa de investimentos estrangeiros.
O crescimento econômico mais recente foi grandemente beneficiado pelo "boom" imobiliário mundial, com o setor de construção civil representando surpreendentes 16% do PIB do país e 12% dos empregos no seu último ano.
Segundo cálculos do jornal alemão "Die Welt", a Espanha estava a caminho de ultrapassar países como a Alemanha em renda per capita até 2011. No entanto, o PIB per capita da Espanha ainda era inferior à média da União Europeia, que era de US$ 29.875 dólares em 2010, tornando-se o segundo mais baixo da Europa Ocidental, depois do de Portugal. O lado negativo do agora extinto "boom" imobiliário é também um correspondente aumento nos níveis de endividamento pessoal: o nível médio de endividamento das famílias triplicou em menos de uma década. Isto pôs grande pressão em cima de uma renda mais baixa para os grupos de renda média; até 2005, o nível médio de endividamento em relação a renda havia crescido para 125%, devido principalmente ao "boom" de hipotecas caras, que hoje muitas vezes excedem o valor da propriedade.
De 1869 a 2002,a moeda da Espanha foi a peseta. O país é um dos membros fundadores do euro,que entrou em circulação em 2002. As moedas de euro espanholas designadas para circulação mostra a efígie do Rei Juan Carlos.
Em 2008/2009, o arrocho do crédito e a recessão mundial manifestaram-se na Espanha através de uma enorme recessão no setor imobiliário. Contudo, os bancos da Espanha e os serviços financeiros evitaram os problemas mais graves dos seus congéneres nos Estados Unidos e no Reino Unido, devido principalmente a um regime financeiro conservador e regulamentado rigorosamente respeitado. Na verdade, o maior banco da Espanha, o Banco Santander, participou da ajuda do governo do Reino Unido ao setor bancário britânico.
A Comissão Europeia previu que a Espanha iria entrar em recessão econômica até o final de 2008. Segundo o Ministro das Finanças da Espanha, "a Espanha enfrenta a sua pior recessão em meio século".
Durante as últimas quatro décadas, a indústria turística espanhola cresceu e se tornou a segunda maior do mundo, alcançando o valor de cerca de 40 bilhões de euros, cerca de 5% do PIB do país, em 2006. Hoje, o clima da Espanha, a história e os monumentos culturais e sua posição geográfica, juntamente com as suas instalações, fazem do turismo uma das principais indústrias nacionais da Espanha e uma grande fonte de emprego estável e de desenvolvimento.
O território espanhol carece de petróleo, o que faz das fontes alternativas de energia um fator estratégico para o país, sendo registrados importantes recordes pela Espanha. Em 2010, os espanhóis superaram os Estados Unidos como líderes mundiais em energia solar, com uma planta de grande potência na estação chamada La Florida, perto de Alvarado, Badajoz. Em 2009, mais de 50% da energia produzida em Espanha foi gerada por moinhos de vento e o registro de maior produção total de energia eólica foi alcançado com megawatts.
O sistema viário principal espanhol é centralizado, com 6 auto-estradas ligando Madrid ao País Basco, Catalunha, Valência, Andaluzia Ocidental, Estremadura e Galiza. Além disso, existem auto-estradas ao longo das costas do Atlântico (Ferrol a Vigo), Cantábria (Oviedo para San Sebastián) e Mediterrâneo (Girona para Cádis).
A Espanha tem atualmente um total de de comboio de alta velocidade que ligam Málaga, Sevilha, Madrid, Barcelona e Valladolid. Se os objetivos do ambicioso programa AVE (comboios de alta velocidade espanhóis) forem cumpridos, em 2020, a Espanha terá de trens de alta velocidade que ligarão quase todas as cidades da província de Madrid em menos de 3 horas e Barcelona, dentro de 4 horas.
O aeroporto mais movimentado na Espanha é o Aeroporto de Madrid-Barajas, com 50,8 milhões de passageiros em 2008, sendo 11º aeroporto mais movimentado do mundo. O Aeroporto de Barcelona também é importante, com 30 milhões de passageiros em 2008. Outros aeroportos estão localizados em Gran Canaria, Málaga, Valência, Sevilha, Maiorca, Alicante e Bilbau.
A Espanha pretende colocar um milhão de carros elétricos na estrada até 2014, como parte do plano do governo para economizar energia e aumentar a eficiência energética. O Ministro da Indústria, Miguel Sebastian, disse que "o veículo elétrico é o futuro e o motor de uma revolução industrial."
A Espanha é conhecida pelo seu patrimônio cultural diversificado, tendo sido influenciado por muitas nações e povos ao longo de sua história. A cultura espanhola tem suas origens nas culturas ibérica, celta, celtibera, latina, visigótica, católica romana, e islâmica.
A definição de uma cultura nacional espanhola tem sido caracterizada pela tensão entre o estado centralizado, dominado nos últimos séculos por Castela, e muitas regiões e povos minoritários. Além disso, a história da nação e de seu ambiente mediterrânico e atlântico desempenharam papéis importantes na formação de sua cultura. Depois da Itália, a Espanha é o país com o maior número de Patrimônios da Humanidade da UNESCO no mundo, com um total de 40.
Devido à diversidade histórica, geográfica e de gerações, a literatura espanhola tem passado por um grande número de influências e é muito diversificada. Alguns grandes movimentos literários podem ser identificados dentro dela.
Miguel de Cervantes é provavelmente o autor mais famoso da Espanha, e sua obra "Dom Quixote" é considerado a obra mais emblemática no cânone da literatura espanhola e um clássico fundador da literatura ocidental.
A música espanhola é muitas vezes considerada exterior como sinônimo de flamenco, um gênero musical do oeste da Andaluzia que, ao contrário da crença popular, não é muito comum fora dessa região. Vários estilos regionais de música folclórica abundam em Aragão, Catalunha, Valência, Castela, País Basco, Galiza e Astúrias. Pop, rock, hip hop e heavy metal também são populares.
No campo da música clássica, a Espanha produziu uma série de compositores notáveis como Isaac Albéniz, Manuel de Falla e Enrique Granados e cantores e artistas como Plácido Domingo, José Carreras, Montserrat Caballé, Alicia de Larrocha, Alfredo Kraus, Pablo Casals, Ricardo Viñes, José Iturbi, Pablo de Sarasate, Jordi Savall e Teresa Berganza. Na Espanha, existem mais de 40 orquestras profissionais, incluindo o Orquestra Sinfônica de Barcelona e Nacional da Catalunha, Orquestra Nacional de Espanha e a Orquestra Sinfônica de Madrid. As casas de ópera mais importantes incluem o Teatro Real, o "Gran Teatre del Liceu", o Teatro Arriaga, o Palácio Euskalduna e o Palácio das Artes Rainha Sofia.
Milhares de fãs de música também viajam para a Espanha a cada ano para o festival de música reconhecido internacionalmente "Sónar" que muitas vezes apresenta os próximos artistas pop e techno, e "Benicàssim", que tende a característica de rock alternativo e atos de dança. Ambos os festivais marcam uma presença internacional de música e refletir o gosto dos jovens no país.
O mais popular instrumento musical tradicional, a guitarra, tem origem na Espanha. Típicos do norte são os "gaiteros", principalmente nas Astúrias e Galiza.
Artistas da Espanha têm sido altamente influentes no desenvolvimento de vários movimentos artísticos europeus. Devido à diversidade histórica, geográfica e de gerações, a arte espanhola tem conhecido um grande número de influências.
A herança mourisca na Espanha, especialmente na Andaluzia, é ainda hoje evidente em cidades como Córdova, Sevilha e Granada. Influências europeias incluem Itália, Alemanha e França, especialmente durante os períodos barroco e neoclássico.
Devido à sua diversidade histórica e geográfica, a arquitetura espanhola tem atraído a partir de uma série de influências. Uma cidade importante da província fundada pelos romanos e com uma infraestrutura extensa da era romana, Córdova se tornou a capital cultural, incluindo uma arquitetura em estilo árabe, feita durante a época do Califado Omíada. A arquitetura de estilo árabe mais tarde continuou a ser desenvolvida sob as sucessivas dinastias islâmicas, terminando com os Nasridas, que construíram seu famoso complexo do palácio em Granada.
Simultaneamente, os reinos cristãos gradualmente surgiram e desenvolveram seus próprios estilos, desenvolvendo um estilo pré-românico, quando por um tempo isolado das principais influências arquitetônicas contemporâneas europeias durante o início da Idade Média, que mais tarde integraram os fluxos românico e gótico. Houve então um extraordinário florescimento do estilo gótico, que resultou em inúmeras construções que forma sendo construídas em todo o território. O estilo mudéjar, a partir dos séculos XII a XVII, foi desenvolvido através da introdução de motivos de estilo árabe, padrões e elementos em arquitetura europeia.
A chegada do modernismo na área acadêmica produziu grande parte da arquitetura do . Um estilo influente no centro de Barcelona, conhecido como modernismo catalão, produziu uma série de importantes arquitetos, dos quais Gaudí é um deles. O estilo internacional foi liderado por grupos como GATEPAC. A Espanha está atualmente a viver uma revolução na arquitetura contemporânea e arquitetos espanhóis como Rafael Moneo, Santiago Calatrava, Ricardo Bofill, entre outros, ganharam renome mundial.
A Volta a Espanha ("Vuelta a España" ou simplesmente "Vuelta") é um dos principais eventos esportivos do país, que junto ao Giro d’Italia e o Tour de France, é uma das três "Grandes Voltas" do ciclismo mundial. A "Vuelta" teve sua primeira edição em 1935, porém não houve edições durante a Segunda Guerra Mundial. Teve seu retorno em 1955 até atualmente. Até foram realizadas 2009 foram 63 edições da "Vuelta a España".
Os esportes na Espanha são dominados, principalmente, pelo ciclismo, o futebol (desde o ), o basquete, o ténis, o andebol, e pelos esportes de motor, principalmente o Motociclismo. A partir dos Jogos Olímpicos de 1992, disputados na cidade de Barcelona, o país entrou na elite mundial em diversos esportes. Tem como maior ídolo no esporte Alberto Contador, da equipe Astana Pro Cycling Team. Contador é vencedor do Tour de France 2007 e 2009, além do Giro d'Italia 2008 e Volta a Espanha também em 2008, entre outras vitórias em voltas. É considerado o melhor ciclista da atualidade, e um dos grandes nomes do esporte de todos os tempos. Em 2010 a Espanha consagrou-se campeã de futebol mundial, tendo vencido a Copa do Mundo de Futebol, na África do Sul e tornou-se a única seleção de futebol a ser campeã do Mundo e bicampeã da Europa, tendo vencido o Campeonato Europeu de 2008, realizado na Suíça e na Áustria e o Campeonato Europeu de 2012, realizado na Polónia e Ucrânia.
Na Espanha se conserva a tradição de realizar diversos espetáculos taurinos, tais como os "encierros" (corridas nas quais as pessoas correm junto aos touros pelas ruas) e as ‘‘corridas de toros’‘ (touradas), que fazem parte da identidade de numerosas festas populares. As praças de touros com maior relevância na temporada taurina são a de "Las Ventas" em Madrid, a "Monumental" em Pamplona, a "Maestranza" em Sevilha e a de Valência.
A televisão é o principal meio de comunicação audiovisual do país, com emissoras nacionais, regionais e locais. As principais emissoras são a , , , Cuatro, Telecinco e .
Na imprensa, os principais jornais de circulação nacional são "El País", ', "ABC", "La Razón" e . Na imprensa esportiva, destacam-se os jornais "Marca" e "As".

</doc>
<doc id="786" url="https://pt.wikipedia.org/wiki?curid=786" title="Ernest Rutherford">
Ernest Rutherford

"Rutherford é redirecionado para esta página. Se procura outros significados de Rutherford, consulte Rutherford (desambiguação)."
Ernest Rutherford, o 1º Barão Rutherford de Nelson, (Brightwater, Nova Zelândia, — Cambridge, ), foi um físico e químico neozelandês naturalizado britânico, que se tornou conhecido como o pai da física nuclear. Num trabalho no começo da carreira, descobriu o conceito de meia-vida radioativa, provou que a radioatividade causa a transmutação de um elemento químico em outro, e também distinguiu e nomeou as radiações alfa e beta. Foi premiado com o Nobel de Química em 1908 "por suas investigações sobre a desintegração dos elementos e a química das substâncias radioativas".
Rutherford realizou sua obra mais famosa após ter recebido esse prêmio. Em 1911, ele defendeu que os átomos têm sua carga positiva concentrada em um pequeno núcleo, e, desse modo, criou o modelo atômico de Rutherford, ou modelo planetário do átomo, através de sua descoberta e interpretação da dispersão de Rutherford em seu experimento da folha de ouro. A ele é amplamente creditada a primeira divisão do átomo, em 1917, liderando a primeira experiência de "dividir o núcleo" de uma forma controlada por dois alunos sob sua direção, John Cockcroft e Ernest Walton em 1932.
Dedicada à sua memória , a Medalha e Prêmio Rutherford foi instituída pelo Conselho da Sociedade de Física em 1939. A primeira palestra ocorreu em 1942. A palestra foi convertida em uma medalha e prêmio em 1965, sendo a primeira Medalha e Prêmio Rutherford concedida no ano seguinte.
O prêmio é concedido para pesquisa de destaque em física ou tecnologia nuclear. A medalha é de bronze e acompanhada de um prêmio de £ 1000 e um certificado.
Ernest Rutherford nasceu em Spring Grove (atual Brightwater), cidade portuária da ilha sul da Nova Zelândia, o quarto filho e segundo homem de uma família de sete filhos e cinco filhas. Seu pai, James Rutherford, um mecânico escocês, emigrou para a Nova Zelândia com toda a família em 1842. Sua mãe, nascida Martha Thompson, uma professora de inglês, com sua mãe viúva, também se mudou em 1855.
Ernest recebeu a sua educação em escolas públicas. Aos 16 anos entrou em Nelson Collegiate School. Graduou-se em 1893 em Matemática e Ciências Físicas na Universidade da Nova Zelândia. Após ter concluído os estudos, ingressou no Trinity College, Cambridge, como um estudante na investigação do Laboratório Cavendish sob a coordenação de J. J. Thomson. Foi na Inglaterra que Rutherford estudou as radiações de Urânio em pesquisas feitas em colaboração com o Frederick Soddy. Em 1902, ambos distinguem os raios alfa e beta e desenvolvem a teoria das desintegrações radioativas espontâneas. Uma oportunidade surgiu quando o lugar de professor de Física na Universidade McGill, em Montreal ficou vago. Em 1898 partiu para o Canadá, para assumir o posto. No mesmo ano, foi nomeado professor de Física da Universidade McGill, em Montreal, e em 1907 na Universidade Victoria em Manchester. Nessa época, Ernest formulou a hipótese de que a radiatividade não se tratava de um fenômeno comum a todos os átomos, mas somente de uma certa categoria. Esses estudos resultaram o livro Radiatividade, verdadeiro marco na história do progresso científico.
Apesar de ser um físico, recebeu o Nobel de Química de 1908, por suas investigações sobre a desintegração dos elementos e a química das substâncias radioativas.
Ainda em Manchester, trabalhando em conjunto com Hans Geiger e Thomas Royds, Rutherford elucidou a natureza da chamada radiação alfa. Após comprovar que esta é formada por partículas com o dobro da carga elétrica de um elétron, em 1907 Rutherford e seus colegas elaboraram um experimento engenhoso no qual partículas alfa foram acumuladas em um tubo de vidro evacuado. Ao passar uma corrente elétrica pelo tubo, puderam observar claramente o espectro do gás hélio, provando assim que as partículas alfa eram na verdade átomos de hélio ionizados, mais tarde identificados como núcleos de hélio.
Rutherford realizou seus trabalhos mais famosos depois de receber o prêmio Nobel de 1908. Sob sua direção, em 1909 Hans Geiger e Ernest Marsden realizaram o famoso experimento (muitas vezes chamado no Brasil de "Experimento de Rutherford"), o qual demonstrou a natureza nuclear dos átomos através da deflexão de partículas alfa atravessando uma fina folha de ouro. Nesse experimento, Rutherford pediu a Geiger e Marsden que procurassem por partículas alfa defletidas por ângulos muito grandes, algo que não seria esperado dadas as teorias atômicas da época. Embora raras, tais deflexões foram de fato observadas, algo que Rutherford mais tarde descreveu como "... o evento mais incrível que aconteceu comigo em toda a minha vida. Foi quase tão incrível quanto se você atirasse um projétil de 15 polegadas num lenço de papel e ele ricocheteasse de volta e o atingisse". Para conseguir explicar a forma precisa com que as deflexões dependiam do ângulo, Rutherford foi levado em 1911 a formular o modelo atômico que leva seu nome - no qual concebeu o átomo como constituído de um núcleo minúsculo de carga positiva, contendo quase toda a massa do átomo, e orbitado por elétrons. Baseado na concepção de Rutherford, o físico dinamarquês Niels Bohr idealizaria mais tarde um novo modelo atômico.
Em 1919, antes de deixar Manchester para assumir a direção do Laboratório Cavendish em Cambridge, Rutherford se tornou a primeira pessoa a deliberadamente transmutar um elemento em outro. Bombardeando nitrogênio puro com radiação alfa, ele foi capaz de converter núcleos de nitrogênio em oxigênio. Nos produtos dessa reação nuclear, identificou partículas idênticas a núcleos de hidrogênio, demonstrando que estes eram partes constituintes do núcleo de nitrogênio - e, por inferência, provavelmente de outros núcleos também. Tal construção já havia sido suspeitada há tempos devido ao fato de a massa atômica de todos os elementos serem aproximadamente um múltiplo da do hidrogênio (Hipótese de Prout). Por conta dessas considerações, em 1920 Rutherford postulou então que o núcleo de hidrogênio deveria ser uma partícula fundamental, que ele denominou próton, a qual seria o elemento constituinte de todos os demais núcleos. Tais fatos levaram a que Rutherford fosse considerado como o fundador da Física Nuclear.
Rutherford dirigiu o Laboratório Cavendish desde 1919 até à sua morte, período em que foi Professor Cavendish de Física. Sua liderança e trabalho inspiraram duas gerações de cientistas.
Foi presidente da Royal Society de 1925 a 1930.
Recebeu a Ordem de Mérito em 1925 e em 1931 foi condecorado Baron Rutherford de Nelson, Cambridge, um título que foi extinto depois da sua inesperada morte, enquanto aguardava uma cirurgia de hérnia umbilical. Após tornar-se um Lord, ele só poderia ser operado por um médico também nobre (uma exigência do protocolo britânico) e essa demora custou-lhe a vida. Morreu em 19 de outubro de 1937 em Cambridge, e suas cinzas foram enterradas na Abadia de Westminster, perto das tumbas de Isaac Newton e outros grandes cientistas.
Participou da 1ª, 2ª, 3ª, 4ª e 7ª Conferência de Solvay.

</doc>
<doc id="787" url="https://pt.wikipedia.org/wiki?curid=787" title="Enrico Fermi">
Enrico Fermi

Enrico Fermi (Roma, — Chicago, ) foi um físico italiano naturalizado estadunidense.
Destacou-se pelo seu trabalho sobre o desenvolvimento do primeiro reator nuclear, e pela sua contribuição ao desenvolvimento da teoria quântica, física nuclear e de partículas, e mecânica estatística. Doutorou-se na Universidade de Pisa e recebeu o Prémio Nobel de Física em 1938.
Foi um dos poucos físicos da era moderna a combinar a teoria com a experiência. Após alguns anos na Alemanha, regressou à Universidade de Roma, onde, em 1926, dedicou-se à mecânica estatística de partículas que obedecem ao princípio de exclusão de Pauli, como os electrões. O resultado é a chamada estatística de Fermi-Dirac, uma vez que Dirac chegou independentemente às mesmas conclusões. Em 1933 Fermi introduziu o conceito de interação fraca, que em conjunto com o recém postulado neutrino, entrariam na teoria do decaimento beta. Juntamente com um grupo de colaboradores, Fermi começou uma série de experiências nas quais foram produzidos artificialmente núcleos radioativos, pelo bombardeamento com neutrões de vários elementos. Alguns dos seus resultados sugeriram a formação de elementos transuranianos. De facto, o que eles observaram, e que mais tarde foi comprovado por Otto Hahn, foi a fissão nuclear, feito que, em 1938, lhe rendeu o Prêmio Nobel de Física. Foi então para os Estados Unidos, onde viria a participar no projeto Manhattan. Dirigiu o projecto de construção do primeiro reator nuclear na Universidade de Chicago. Depois da Segunda Guerra Mundial, Fermi dedicou-se à Física de partículas, a que deu contribuições importantes. O elemento químico de número atômico 100, criado sinteticamente em 1952, recebeu o nome de Férmio em sua honra.
Enrico Fermi nasceu em Roma, Itália. Ele era o terceiro filho de Alberto Fermi, inspetor-chefe do Ministério das Comunicações da Itália, e sua mãe era Ida de Gattis, professora de uma escola primária. Sua irmã, Maria, era dois anos mais velha que ele, enquanto seu irmão, Giulio, era um ano mais velho. Desde jovem Fermi gostava de estudar física e matemática, interesses também de seu irmão mais velho. Sua família nunca foi muito religiosa, e Fermi foi um agnóstico sua vida inteira. Quando Giulio morreu inesperadamente de um abcesso na garganta em 1915, Enrico ficou emocionalmente arrasado, e refugiou-se em estudos científicos para se distrair. De acordo com ele mesmo, todos os dias caminhava em frente ao hospital onde Giulio morreu, até se acostumar com a dor. Numa banca do Campo de' Fiori, Fermi comprou e leu o livro intitulado "Elementorum physicae mathematicae" (900 páginas), escrito em latim pelo padre Andrea Caraffa, professor do Collegio Romano, que abordava matemática, mecânica clássica, astronomia, óptica e acústica. Mais tarde, Fermi e seu melhor amigo, outro estudante inclinado para a ciência, chamado Enrico Persico, empenharam-se em projetos científicos, tais como construir giroscópios e medir o campo magnético da Terra. O interesse de Fermi pela física foi ainda mais incentivado quando um amigo de seu pai, o engenheiro Adolfo Amidei, lhe deu vários livros sobre física e matemática, que Fermi leu e assimilou rapidamente.
Em 1918 Fermi matriculou-se na "Escola Normal Superior" em Pisa, onde mais tarde recebeu o seu diploma de graduação e de doutorado. Para entrar na prestigiada instituição, havia um exame para os candidatos, que incluía um ensaio. Pelo seu ensaio sobre o tema dado, "Características do som", Fermi, com 17 anos de idade, escolheu derivar e resolver a transformada de Fourier baseada na equação diferencial parcial das ondas numa corda. O examinador, professor Giulio Pittato, entrevistou Fermi e concluiu que o seu ensaio teria sido digno de louvor mesmo para um doutorado. Enrico Fermi ficou com o primeiro lugar na classificação do exame de entrada. Durante os anos na Scuola Normale Superiore, Fermi formou equipe com um colega estudante Franco Rasetti, que mais tarde, se tornou o mais próximo amigo e colaborador de Fermi.
Além de frequentar as aulas, Enrico Fermi encontrou tempo para trabalhar nas suas atividades extracurriculares, particularmente com a ajuda de seu amigo Enrico Persico, que permaneceu em Roma para estudar numa universidade. Entre 1919 e 1923 Fermi estudou, por si mesmo, relatividade geral, mecânica quântica e física atômica.
Os seus conhecimentos de física quântica atingiram um nível tão elevado que o chefe do Instituto de Física, professor Luigi Puccianti, pediu-lhe para organizar seminários sobre o assunto. Durante esse tempo ele aprendeu cálculo tensorial, um instrumento matemático inventado por Gregorio Ricci-Curbastro e Tullio Levi-Civita, e necessário para demonstrar os princípios da relatividade geral.
Em setembro de 1920, Fermi ingressou no Instituto de Física. Como só havia, além de Fermi, mais dois estudantes nesse departamento, Puccianti deixava-os usar o laboratório livremente para os fins que desejassem. Fermi decidiu então que deviam começar a pesquisar a cristalografia de raios-X. Os três estudantes trabalharam para produzir uma Fotografia de Laue - uma fotografia de um cristal feita por raios-X.
Em 1921, seu terceiro ano na universidade, publicou os seus primeiros trabalhos científicos no periódico italiano "Il Nuovo Cimento". O primeiro foi intitulado: "Sobre a dinâmica de um rígido sistema de cargas elétricas em condições transientes" ; o segundo: "Sobre a eletrostática de um campo gravitacional uniforme de cargas eletromagnéticas e sobre o peso de cargas eletromagnéticas" . Um sinal de que as concepções na Física estavam mudando foi que a massa começou, então, a ser expressa como um tensor, uma ferramenta matemática usada, geralmente, para descrever algo que se move e varia no espaço tridimensional. Na mecânica clássica, a massa é uma grandeza escalar, mas na relatividade ela muda com a velocidade. Usando a relatividade, Fermi provou que uma carga possui um peso igual a U/c², sendo U a energia do sistema e c a velocidade da luz. Porém, à primeira vista, a primeira publicação parecia apontar para uma contradição entre a teoria eletrodinâmica e a relativística em relação ao cálculo das massas eletromagnéticas, visto que o valor anteriormente previsto era de 4/3 U/c². Um ano depois, com um trabalho intitulado "Correção da discrepância entre a teoria eletrodinâmica e um relativista de cargas eletromagnéticas, Enrico Fermi mostrou que essa discrepância era consequência da relatividade. Esta publicação teve tanto sucesso que foi traduzida para o alemão e publicada no famoso periódico científico alemão "Physikalische Zeitschrift".
Em 1922 publicou o seu importante trabalho científico no periódico italiano "I Rendiconti dell'Accademia dei Lincei" intitulado "Sobre os fenômenos que ocorrem nas proximidades de uma linha de mundo" ). Nesse artigo, Fermi examinou o Princípio da Equivalência e introduziu as chamadas Coordenadas de Fermi. Ele provou que, para uma linha de mundo próxima a uma linha do tempo, o espaço comporta-se como um Espaço Euclidiano. Finalmente, em 1922, Fermi recebeu o seu diploma de graduação na Scuola Normale Superiore ao apresentar a sua tese chamada "Um teorema de probabilidade e suas aplicações", obtendo laurea com impressionantes 21 anos. Nessa época, a física teórica ainda não era considerada uma disciplina na Itália, portanto a única tese aceita seria de física experimental. Por isso, Fermi usou imagens de difração de raios-X para enriquecer seu trabalho. Os físicos italianos também levaram algum tempo para assimilar as ideias da relatividade geral vindas da Alemanha.
Enquanto escrevia um apêndice para a versão italiana do livro "The Mathematical Theory of Relativity, "de August Kopff em 1923, Fermi descobriu um enorme potencial energético nuclear escondido na famosa equação de Einstein (E=mc²), e que podia ser explorado. "Não parece possível, pelo menos num futuro próximo", ele escreveu, "achar uma maneira de liberar essas enormes quantidades de energia - o que é algo bom, pois a primeira consequência desse fenômeno seria reduzir a pó o físico que tivesse o azar de realizá-lo."
O orientador de doutorado de Fermi foi Luigi Puccianti. Em 1924, Fermi passou um semestre em Göttingen estudando com Max Born, onde também conheceu Werner Heisenberg e Pascual Jordan. Fermi então foi para Leiden para estudar com Paul Ehrenfest de setembro a dezembro de 1924, conhecendo Albert Einstein, Hendrik Lorentz e também Samuel Goudsmit e Jan Tinbergen, que se tornaram seus bons amigos. Do início de 1925 ao final de 1926, Fermi lecionou física matemática e mecânica teórica na Universidade de Florença, onde se juntou com Rasetti para conduzir uma série de experimentos sobre os efeitos do campo magnético no vapor de mercúrio. Fermi também participou de seminários na Sapienza University of Rome, dando palestras sobre mecânica quântica e física dos estados sólidos.
Depois que Wolfgang Pauli anunciou seu princípio da exclusão, em 1925, Fermi respondeu-o com um artigo "Sobre a quantização do gás perfeito monoatômico", no qual ele aplicou o princípio de Pauli a um gás ideal. O mesmo raciocínio desse artigo foi desenvolvido independentemente por outro físico chamado Paul Dirac. Juntos e, ao mesmo tempo, separados, os dois cientistas formaram a famosa estatística de Fermi-Dirac. De acordo com Dirac, as partículas que obedecem o princípio da exclusão são chamadas de "férmions" e as que não obedecem são denominadas "bósons".
Os cargos de professores, na Itália, eram concedidos via concurso, sendo as publicações dos candidatos avaliadas por um comitê de professores. Fermi se inscreveu para a cadeira de física matemática na Universidade de Cagliari, na Sardenha, mas foi dispensado em favor de Giovanni Giorgi.
Com 24 anos, Fermi tornou-se professor da Universidade de Roma em uma nova cadeira de física teórica criada pelo Ministério da Educação a pedido do professor Orso Mario Corbino, que era professor de física experimental, diretor do Instituto de Física e membro do gabinete de Benito Mussolini. Corbino esperava que a nova cadeira conferisse um maior prestígio à física na Itália. Ele também ajudou Fermi a selecionar sua equipe, que logo foi ingressada por mentes notáveis como Edoardo Amaldi, Bruno Pontecorvo, Franco Rasetti e Emilio Segrè. Para os estudos teóricos apenas, Ettore Majorana também participou do que logo foi apelidado de "o Grupo da rua Panisperna" (em relação ao nome da rua em que o instituto tinha seus laboratórios).
Fermi se casou com Laura Capon, uma estudante de ciência da Universidade, em 19 de julho de 1928. Eles tiveram dois filhos: Nella, nascida em janeiro de 1931 e Giulio, nascido em fevereiro de 1936. Em 18 de março de 1929, Fermi se tornou membro da Academia Real da Itália, indicado por Mussolini, e se tornou membro do Partido Fascista em 27 de abril, embora tenha se oposto à ideologia em 1938 quando Mussolini criou as leis raciais de forma a aproximar mais o fascismo do nazismo de Hitler. Essas leis ameaçavam Laura, esposa do cientista, que era judia, e tiraram o trabalho de muitos de seus assistentes de laboratório.
O grupo continuou com os experimentos que vieram a ficar famosos, no entanto, o grupo se desmantelou, em 1933 Rasetti deixou a Itália e foi para o Canadá, Pontecorvo foi para a França, e Segrè partiu para lecionar em Palermo.
Durante seu tempo em Roma, Fermi e seu grupo fizeram importantes contribuições a muitos aspectos práticos e teóricos da física. Essas incluem a teoria do decaimento beta, com a inclusão do postulado do neutrino em 1930 por Wolfgang Pauli, e a descoberta dos nêutrons lentos, que foi fundamental para o funcionamento dos reatores nucleares. Em 1928, ele publicou um trabalho chamado Introdução à Física Atômica, que apresentava uma abordagem mais acessível e atualizada para os estudantes. Fermi também produziu palestras e artigos públicos para professores e cientistas para promover e divulgar a nova física tanto quanto possível. Parte do seu método de ensino era se reunir com estudantes de graduação e professores ao final do dia para trabalhar num problema, geralmente sobre uma pesquisa do grupo. Um sinal de que o trabalho de divulgação estava dando resultado era que estudantes estrangeiros estavam indo à Itália. Um deles foi Hans Bethe, que colaborou com Fermi num artigo de 1932 sobre a interação entre dois elétrons.
Os físicos, na época, ainda possuíam muitas dúvidas acerca do decaimento beta, no qual um elétron é emitido de um núcleo atômico. Para satisfazer a lei da conservação da energia, Pauli postulou a existência de uma partícula invisível com carga zero e uma massa muito pequena que era emitida ao mesmo tempo que o elétron. Fermi pegou essa ideia e, em 1934, escreveu um artigo que decretava a existência do neutrino. Essa teoria, que também pode ser chamada de interação de Fermi ou fraca interação, descrevia uma das quatro forças fundamentais da natureza. O neutrino só foi detectado após a morte de Fermi, pois é uma partícula extremamente difícil de detectar. Quando o cientista submeteu seu artigo à renomada revista britânica "Nature", o editor a rejeitou pois achava que suas especulações eram "muito afastadas da realidade para serem interessantes aos leitores". Fermi então viu a teoria ser publicada em italiano e alemão antes de ser publicada em inglês.
Em janeiro de 1934, Irène Joliot-Curie e Frédéric Joliot anunciaram que eles haviam bombardeado elementos com partículas alfa e, com isso, induzido radioatividade. Em março, Gian-Carlo Wick (integrante do Grupo da rua Panisperna) formulou uma explicação teórica para isso usando a teoria do decaimento beta. Fermi, então, recorreu à física experimental e usou o nêutron, descoberto em 1932. A partícula escolhida não possuía carga e, portanto, não seria defletida pelo núcleo. Isso causou uma grande redução nos custos do experimento (caso contrário ele seria inviável) pois eliminou a necessidade de se ter um acelerador de partículas, o que era (e ainda é) muito custoso. Para criar uma forte fonte de nêutrons, Fermi encheu um bulbo de vidro com pó de berílio, evacuando todo o ar, e então adicionando 50mCi de radônio gasoso. Porém, a eficiência da fonte decaía com a meia-vida do radônio (3,8 dias). Era sabido também que a fonte iria emitir raios-gama, mas isso não iria afetar muito os resultados do experimento. O que Fermi fez foi bombardear diferentes elementos (ao todo 22) e, em todos eles, conseguiu induzir radioatividade. A descoberta foi rapidamente reportada para a revista italiana "La Ricerca Scientifica "em 25 de março de 1934.
A radioatividade natural de elementos como tório e urânio tornou difícil a determinação do que estava acontecendo durante o bombardeamento desses elementos. Porém, após ter removido corretamente a presença de elementos mais leves que urânio e mais pesados que chumbo, Fermi concluiu que eles haviam criado novos elementos, e os denominou espério e ausônio. Seu trabalho, no entanto, foi criticado pela química Ida Noddack, que sugeriu que esses experimentos poderiam ter criado elementos mais leves ao invés de elementos novos mais pesados, mas Fermi e sua equipe não levaram a sério a crítica, pois a equipe da química ainda não havia feito nenhum experimento com urânio. Naqueles anos, a fissão nuclear era tomada como improvável (senão impossível) nos campos teóricos, e ninguém esperava que nêutrons tivessem energia o suficiente para quebrar um núcleo em dois fragmentos mais leves da maneira que Noddack havia sugerido.
O Grupo da Via Panisperna também descobriu outras coisas interessantes. Fazendo o experimento em diferentes superfícies, eles notaram que a colisão com átomos de hidrogênio atrasava os nêutrons. Quanto menor o número atômico do núcleo que a partícula colide, mais energia ela perde por colisão, e portanto menos colisões são necessárias para desacelerá-la. Fermi descobriu que isso produzia uma maior indução de radioatividade, visto que nêutrons com baixa velocidade são mais facilmente capturados. Ele, então, desenvolveu uma equação de difusão para descrever isso.
Fermi era bem conhecido por sua simplicidade na solução de problemas. Suas aptidões de formidável cientista, combinando física nuclear teórica e aplicada, foram amplamente reconhecidas. Ele influenciou muitos físicos que trabalharam com ele, como Hans Bethe, que passou dois semestres trabalhando com Fermi no início da década de 1930.
Fermi permaneceu em Roma até 1938.
Em 1938, com 37 anos, Fermi foi laureado com o Nobel de Física, por suas "demonstrações da existência de novos elementos radioativos produzidos pela irradiação de nêutrons, e por sua descoberta relacionada de reações nucleares provocadas por nêutrons lentos".
Depois que Fermi recebeu o Prêmio Nobel em Estocolmo, ele, sua mulher Laura e seus filhos emigraram para Nova Iorque. Isso foi principalmente por causa das leis anti-semitas promulgadas pelo regime fascista de Benito Mussolini que ameaçavam Laura, que era judia. Além disso, as novas leis colocaram a maior parte dos assistentes de pesquisa de Fermi fora de trabalho.
Logo após sua chegada em Nova Iorque, Fermi começou a trabalhar na Universidade de Columbia.
Fermi se mudou para o Laboratório Nacional de Los Alamos, em etapas posteriores do Projeto Manhattan, para servir de consultor geral.
Durante a explosão da primeira bomba atômica, realizada em Alamogordo, Fermi estava presente. Na ocasião, como se era esperado, havia muitos equipamento de ponta para mensurar a energia liberada pela bomba na atmosfera. Haviam cálculos para isso, porém a bomba real teria perdas consideráveis de rendimento. Entretanto, como esta foi a primeira bomba atômica testada na história, não era certo que os equipamentos de medição funcionariam. Pensando nisso Fermi fez um pequeno experimento para medir a energia liberada: no momento da explosão jogou no chão alguns pedaços de papel. "...no ar parado, os pedacinhos de papel cairiam aos seus pés, mas quando a onda de choque chegou (alguns segundos após o clarão), foram transportados por alguns centímetros na direção da onda. " Como era conhecido a distancia entre o centro da explosão e onde ele estava, Fermi poderia calculara energia.
Tornou-se cidadão naturalizado dos Estados Unidos em 1944.
Em seus últimos anos, Fermi fez trabalhos importantes em física de partículas, especialmente a relacionada com mésons pi, e múons. Ele também era conhecido por ser um professor inspirador na Universidade de Chicago (embora não tenha deixado o Laboratório de Los Alamos até dezembro de 1945), e era conhecido por sua atenção aos detalhes, simplicidade e preparação cuidadosa das aulas. A curta distância entre Argonne e Chicago permitia a participação ativa do cientista tanto nas aulas da universidade quanto na física experimental em Argonne, estudando dispersão de nêutrons com Leona Marshall. Mais tarde, suas notas de aula, especialmente as de mecânica quântica, física nuclear, e termodinâmica, foram transcritas em livros que ainda são impressos. Enrico Fermi também discutiu aspectos em física teórica com Maria Mayer, ajudando-a em seu trabalho sobre a interação spin-órbita, o que a levaria ao Prêmio Nobel.
O Projeto Manhattan foi substituído pela Comissão de Energia Atômica (CAE) no primeiro dia de janeiro de 1947. Fermi fez parte de uma importante subdivisão científica da CAE encabeçada por Robert Oppenheimer. Ele também gostava de passar algumas semanas de cada ano no Laboratório de Los Alamos, onde ajudou Nicholas Metropolis e John von Neumann na instabilidade de Rayleigh-Taylor, a ciência do que ocorre na fronteira entre dois fluidos de diferentes densidades.
Logo após a detonação da primeira bomba nuclear soviética em agosto de 1949, Fermi, junto com Isidor Rabi, escreveu um forte manifesto ao comitê, se opondo fortemente ao desenvolvimento de uma bomba de hidrogênio tanto em aspectos morais quanto técnicos. Mesmo assim, continuou trabalhando no desenvolvimento dessa bomba como consultor.
Nos anos que se seguiram, Fermi continuou lecionando na Universidade de Chicago. Seus alunos de PhD no período pós-guerra incluíam Owen Chamberlain, Geoffrey Chew, Jerome Friedman, Marvin Goldberger, Tsung-Dao Lee, Arthur Rosenfeld e Sam Treiman. Jack Steinberger era seu aluno de graduação. Fermi conduziu importantes experimentos na física de partículas, especialmente os relacionados a píons e múons. Ele fez as primeiras predições da ressonância píon-núcleon, se baseando em métodos estatísticos, pois achava que resultados exatos não eram necessários para uma teoria que não estava completamente correta. Em um artigo com a co-autoria de Chen Ning Yang, ele especulou que píons poderiam ser partículas compostas, uma ideia anteriormente formulada por Shoichi Sakata. Foi então postulado, após anos de estudo, que os píons eram feitos de quarks, que completava o modelo de Fermi e criava o modelo quark.
Fermi também escreveu um artigo "Sobre a origem da Radiação Cósmica" no qual ele propôs que os raios cósmicos provinham de um material acelerado por campos magnéticos no espaço interestelar, o que levou a uma divergência de opiniões entre ele e Teller. O cientista italiano também examinou assuntos relacionados a campos magnéticos nos braços de uma galáxia espiral. Ele também criou o paradoxo de Fermi, um raciocínio muito interessante sobre civilizações extraterrestres.
Perto de sua morte, Fermi questionou sua fé na sociedade e também a capacidade de tomarmos uma decisão prudente em relação às armas nucleares. Ele disse:
"Algum de vocês pode perguntar: o que de bom há em trabalhar tanto para coletar meramente alguns fatos que não trazem prazer a ninguém - exceto a alguns professores de cabelos longos que amam esse tipo de coisa - e que ninguém irá entender pois somente alguns especialistas são capazes de fazê-lo? Para responder a essas perguntas, eu arrisco uma previsão: a história da ciência e da tecnologia tem nos ensinado, constantemente, que avanços científicos em conhecimentos básicos têm, cedo ou tarde, nos levado a aplicações técnicas e industriais que revolucionaram o nosso modo de vida. Me parece improvável que todo esse esforço para chegar à estrutura básica da matéria seja uma exceção a essa regra. O que é incerto - e é pelo que todos torcemos - é que o homem irá em breve se tornar suficientemente adulto para fazer bom uso dos poderes que ele adquire da natureza."
Fermi morreu prematuramente, aos 53 anos de idade, vítima de câncer no estômago, provavelmente causado pela exposição a materiais radioativos. Foi sepultado no "Oak Woods Cemetery", Chicago, Illinois, Estados Unidos.

</doc>
<doc id="788" url="https://pt.wikipedia.org/wiki?curid=788" title="Efeito fotoelétrico">
Efeito fotoelétrico

O efeito fotoelétrico é a emissão de elétrons por um material, geralmente metálico, quando exposto a uma radiação eletromagnética (como a luz) de frequência suficientemente alta, que depende do material. Ele pode ser observado quando a luz incide numa placa de metal, literalmente arrancando elétrons da placa. Os elétrons ejetados são denominados fotoelétrons, e a radiação eletromagnética usada é, geralmente, a radiação ultravioleta. Observado pela primeira vez por A. E. Becquerel em 1839 e confirmado por Heinrich Hertz em 1887, o fenômeno é também conhecido por "efeito Hertz", não sendo porém este termo de uso comum.
De acordo com o modelo ondulatório da luz, as expectativas eram:
Qualquer superfície metálica deveria ejetar elétrons quando excitada com uma radiação eletromagnética, de qualquer frequência, desde que essa radiação demorasse um tempo suficiente para o átomo armazenar energia e liberar, posteriormente, esse elétron;
Os elétrons que giram à volta do núcleo atômico são aí mantidos por forças de atração. Se a estes for fornecida energia suficiente, eles abandonarão as suas órbitas. O efeito fotoelétrico implica que, normalmente sobre metais, se faça incidir um feixe de radiação com energia superior à energia de remoção dos elétrons do metal, provocando a sua saída das órbitas: sem energia cinética (se a energia da radiação for igual à energia de remoção) ou com energia cinética, se a energia da radiação exceder a energia de remoção do elétrons. 
Para testar essas ideias, os cientistas montaram um experimento.
A grande dúvida que se tinha a respeito do efeito fotoelétrico era que quando se aumentava a intensidade da luz, ao contrário do esperado, a luz não arrancava os elétrons do metal com maior energia cinética. O que acontecia era que uma maior quantidade de elétrons era ejetado.
Por exemplo, a luz vermelha de baixa frequência estimula os elétrons para fora de uma peça de metal. Na visão clássica, a luz é uma onda contínua cuja energia está espalhada sobre a onda. Todavia, quando a luz fica mais intensa, mais elétrons são ejetados, contradizendo, assim a visão da física clássica que sugere que os mesmos deveriam se mover mais rápido (energia cinética) do que as ondas.
Quando a luz incidente é de cor azul, essa mudança resulta em elétrons muito mais rápidos. A razão é que a luz pode se comportar não apenas como ondas contínuas, mas também como feixes discretos de energia chamados de fótons. Um fóton azul, por exemplo, contém mais energia do que um fóton vermelho. Assim, o fóton azul age essencialmente como uma "bola de bilhar" com mais energia, desta forma transmitindo maior movimento a um elétron. Esta interpretação corpuscular da luz também explica por que a maior intensidade aumenta o número de elétrons ejetados - com mais fótons colidindo no metal, mais elétrons têm probabilidade de serem atingidos.
Aumentar a intensidade de radiação que provoca o efeito fotoelétrico não aumenta a velocidade dos fotoelétrons, mas aumenta o número de fotoelétrons. Para se aumentar a velocidade dos fotoelétrons, é necessário excitar a placa com radiações de frequências maiores e, portanto, energias mais elevadas.
A explicação satisfatória para esse efeito foi dada em 1905, por Albert Einstein, e em 1921 deu ao cientista alemão o prêmio Nobel de Física.
Analisando o efeito fotoelétrico quantitativamente usando o método de Einstein, as seguintes equações equivalentes são usadas:
Energia do fóton = Energia necessária para remover um elétron + Energia cinética do elétron emitido
Algebricamente:
onde
"Nota"s:

</doc>
<doc id="790" url="https://pt.wikipedia.org/wiki?curid=790" title="Estados Unidos">
Estados Unidos

Os Estados Unidos da América (; ), ou simplesmente Estados Unidos (), são uma república constitucional federal composta por 50 estados e um distrito federal. A maior parte do país situa-se na região central da América do Norte, formada por 48 estados e Washington, D.C., o distrito federal da capital. Banhado pelos oceanos Pacífico e Atlântico, faz fronteira com o Canadá ao norte e com o México ao sul. O estado do Alasca está no noroeste do continente, fazendo fronteira com o Canadá no leste e com a Rússia a oeste, através do estreito de Bering. O estado do Havaí é um arquipélago no Pacífico Central. O país também possui vários outros territórios no Caribe e no Oceano Pacífico. Com 9,37 milhões de km² de área e uma população de mais de 300 milhões de habitantes, o país é o quarto maior em área total, o quinto maior em área contígua e o terceiro em população. Os Estados Unidos são uma das nações mais multiculturais e etnicamente diversas do mundo, produto da forte imigração vinda de muitos países. Sua geografia e sistemas climáticos também são extremamente diversificados, com desertos, planícies, florestas e montanhas que abrigam uma grande variedade de espécies.
Os paleoindígenas que migraram da Ásia há quinze mil anos, habitam o que é hoje o território dos Estados Unidos até os dias atuais. Esta população nativa foi muito reduzida após o contato com os europeus devido a doenças e guerras. Os Estados Unidos foram fundados pelas treze colônias do Império Britânico localizadas ao longo da sua costa atlântica. Em 4 de julho de 1776, foi emitida a Declaração de Independência, que proclamou o seu direito à autodeterminação e a criação de uma união cooperativa. Os estados rebeldes derrotaram a Grã-Bretanha na Guerra Revolucionária Americana, a primeira guerra colonial bem sucedida da Idade Contemporânea. A Convenção de Filadélfia aprovou a atual Constituição dos Estados Unidos em 17 de setembro de 1787; sua ratificação no ano seguinte tornou os estados parte de uma única república com um forte governo central. A Carta dos Direitos, composta por dez emendas constitucionais que garantem vários direitos civis e liberdades fundamentais, foi ratificada em 1791.
Guiados pela doutrina do destino manifesto, os Estados Unidos embarcaram em uma vigorosa expansão territorial pela América do Norte durante o século XIX que resultou no deslocamento de tribos indígenas, aquisição de territórios e na anexação de novos Estados. Os conflitos entre o sul agrário e o norte industrializado do país sobre os direitos dos estados e a expansão da instituição da escravatura provocaram a Guerra de Secessão, que decorreu entre 1861 e 1865. A vitória do Norte impediu a separação do país e levou ao fim da escravatura nos Estados Unidos. No final do século XIX, sua economia tornou-se a maior do mundo e o país expandiu-se para o Pacífico. A Guerra Hispano-Americana e a Primeira Guerra Mundial confirmaram o estatuto do país como uma potência militar. A nação emergiu da Segunda Guerra Mundial como o primeiro país com armas nucleares e como membro permanente do Conselho de Segurança das Nações Unidas. O fim da Guerra Fria e a dissolução da União Soviética deixaram-no como a única superpotência restante.
Os Estados Unidos são um país desenvolvido e formam a maior economia nacional do mundo, com um produto interno bruto que em 2012 foi de de dólares, equivalente a 19% do PIB mundial por paridade do poder de compra (PPC) de 2011. Sua renda "per capita" era a sexta maior do mundo em 2010, no entanto o país é o mais desigual dos membros da Organização para a Cooperação e Desenvolvimento Econômico (OCDE), conforme calculado pelo Banco Mundial. Sua economia é alimentada pela abundância de recursos naturais, por uma infraestrutura bem desenvolvida e pela alta produtividade; e, apesar de ser considerado uma economia pós-industrial, o país continua a ser um dos maiores fabricantes do mundo. Os Estados Unidos respondem por 39% dos gastos militares do planeta e são um forte líder econômico, político e cultural.
Em 1510, o cartógrafo alemão Martin Waldseemüller elaborou um planisfério, onde denominou as terras do hemisfério ocidental de "América", em honra ao cartógrafo italiano Américo Vespúcio. As antigas colônias britânicas usaram pela primeira vez o nome do país moderno na Declaração de Independência — "unânime declaração de independência dos Estados Unidos da América", adotada pelos "representantes dos Estados Unidos da América", em 4 de julho de 1776. Seu nome atual foi formalmente adotado em 15 de novembro de 1777, quando o Segundo Congresso Continental aprovou os Artigos da Confederação, que estipulavam "O nome desta confederação será "Estados Unidos da América"". A forma "Estados Unidos" também é padronizada; outra forma comum é EUA. "Colúmbia", derivado do nome de Cristóvão Colombo, em tempos um nome popular para os Estados Unidos, ainda permanece no nome distrito de Colúmbia. Ocasionalmente o país é referido de forma incorreta como "Estados Unidos da América do Norte". Na escrita, também é comum o uso das abreviaturas EUA, US ou USA.
As formas padrão para se referir a um cidadão dos Estados Unidos são "americano" (mais usual), "estadunidense" (ou "estado-unidense") ou "norte-americano". Também é utilizado o adjetivo "ianque" (do inglês "yankee"). Originalmente e em sentido estrito, "yankee" é um habitantes da região de Nova Inglaterra, mas o uso generalizou-se, passando a designar todos os nativos dos estados do Norte; pode ainda designar especificamente os soldados nortistas durante a Guerra da Secessão ou, mais genericamente, qualquer nativo dos Estados Unidos.
Acredita-se que os povos indígenas dos Estados Unidos continentais, incluindo os nativos do Alasca, emigraram da Ásia. Eles começaram a chegar há 12 ou 40 milênios, senão antes. Alguns, como a cultura mississippiana pré-colombiana, desenvolveram agricultura avançada, arquitetura grandiosa e sociedades estaduais. Mais tarde os europeus começaram a colonização das Américas, muitos milhões de indígenas americanos morreram de epidemias de doenças importadas, como a varíola.
Em 1492, o explorador Cristóvão Colombo sob contrato com a coroa espanhola chegou a várias ilhas do Caribe, fazendo o primeiro contato com os povos indígenas. Em 2 de abril de 1513, o conquistador espanhol Juan Ponce de León desembarcou no local em que ele chamou de "La Florida" — a primeira visita europeia documentada no que viria a ser os Estados Unidos Continentais. Às colônias espanholas na Flórida seguiram-se outras no que é hoje o sudoeste dos Estados Unidos, que atraíram milhares de colonos através do México. Os comerciantes de peles franceses estabeleceram postos da Nova França em torno dos Grandes Lagos; a França acabou por reivindicar a maior parte do interior da América do Norte até o Golfo do México. O primeiro assentamento inglês bem sucedido foi a Colônia da Virgínia em Jamestown, em 1607, e a Colônia de Plymouth, dos chamados "Peregrinos" (em inglês: "Pilgrim Fathers" [pais peregrinos] ou simplesmente "Pilgrims"), em 1620. O fretamento de 1628 da Colônia da Baía de Massachusetts resultou em uma onda de migração; por volta de 1634, a Nova Inglaterra tinha sido povoada por cerca de puritanos. Entre o final dos anos 1610 e a Revolução Americana, cerca de prisioneiros foram enviados para as colônias americanas da Grã-Bretanha. A partir de 1614, os holandeses se estabeleceram ao longo do rio Hudson, nomeadamente na colônia de Nova Amsterdã na ilha de Manhattan.
Em 1674, os holandeses cederam seu território norte-americano à Inglaterra; a província da Nova Holanda foi renomeada para Nova Iorque. Muitos dos novos imigrantes, especialmente do Sul (cerca de dois terços de todos os imigrantes da Virgínia) foram contratados como trabalhadores temporários entre 1630 e 1680. A partir do final do , os escravos africanos foram se tornando a principal fonte de trabalho forçado. Com a divisão das Carolinas em 1729 e a colonização da Geórgia em 1732, foram estabelecidas as treze colônias britânicas que se tornariam os Estados Unidos. Todas contavam com um governo local eleito, estimulando o apoio ao republicanismo. Todas as colônias legalizaram o comércio de escravos africanos. Com taxas de natalidade altas, taxas de mortalidade baixas e imigração constante, a população colonial cresceu rapidamente. O movimento cristão revivalista das décadas de 1730 e 1740, conhecido como o Grande Despertar, incentivou o interesse na religião e na liberdade religiosa. Durante a Guerra Franco-Indígena, as forças britânicas tomaram o Canadá dos franceses, mas a população francófona permaneceu isolada política e geograficamente das colônias do sul. À exceção dos nativos americanos (popularmente conhecidos como "índios americanos"), que estavam sendo deslocados, as treze colônias tinham uma população de 2,6 milhões de habitantes em 1770, cerca de um terço da Grã-Bretanha; cerca de um em cada cinco norte-americanos eram escravos negros. Embora sujeitos aos impostos britânicos, os colonos americanos não tinham representação no Parlamento da Grã-Bretanha.
As tensões entre colonos americanos e os britânicos durante o período revolucionário dos anos 1770 e início dos anos 1780 levaram à Guerra Revolucionária Americana, travada de 1775 até 1781. Em 14 de junho de 1775, o Congresso Continental, em convocação na Filadélfia, criou um Exército Continental sob o comando de George Washington. Proclamando que "todos os homens são criados iguais e dotados de certos direitos inalienáveis", em 4 de julho de 1776 o Congresso aprovou a Declaração de Independência, redigida em grande parte por Thomas Jefferson. Essa data é hoje comemorada como o Dia da Independência dos Estados Unidos. Em 1777, os Artigos da Confederação estabeleceram um fraco governo confederado que operou até 1789.
Após a derrota britânica por forças americanas apoiadas pelos franceses, na Batalha de Yorktown, a Grã-Bretanha reconheceu a independência dos Estados Unidos e a soberania dos estados sobre o território americano a oeste do rio Mississippi. Uma convenção constitucional foi organizada em 1787 por aqueles que desejavam estabelecer um governo nacional forte, com poderes de tributação. A Constituição dos Estados Unidos foi ratificada em 1788. Em 1789 tomaram posse o primeiro Senado e o primeiro presidente (George Washington) da Nova República. Em 1791 foi adotada a "Bill of Rights" (Declaração dos Direitos dos Cidadãos), que proíbe restrições federais das liberdades pessoais e garante uma série de proteções legais.
As atitudes em relação à escravidão foram sendo alteradas; uma cláusula na Constituição protegia o comércio de escravos africanos apenas até 1808. Os estados do Norte aboliram a escravidão entre 1780 e 1804, deixando os estados escravistas do Sul como defensores dessa "instituição peculiar". O Segundo Grande Despertar, iniciado por volta de 1800, fez do evangelicalismo uma força por detrás de vários movimentos de reforma social, entre as quais o abolicionismo.
A ânsia americana de expansão para o oeste levou a uma longa série de Guerras Indígenas e ao genocídio dos indígenas. A compra da Louisiana, o território francês a sul, sob a presidência de Thomas Jefferson em 1803, quase duplicou o tamanho da nação. A Guerra de 1812, travada contra a Grã-Bretanha acabou num empate, reforçando o nacionalismo americano. Uma série de incursões militares americanas na Flórida levaram a Espanha a ceder esse e outros territórios na Costa do Golfo do México em 1819. A Trilha das Lágrimas em 1830 exemplificou a política de remoção dos índios, que retirava os povos indígenas de suas terras nativas. Os Estados Unidos anexaram a República do Texas em 1845. O conceito de "Destino Manifesto" foi popularizado durante essa época. O Tratado de Oregon, assinado com a Grã-Bretanha em 1846, levou ao controle norte-americano do atual Noroeste dos Estados Unidos. A vitória americana na Guerra Mexicano-Americana resultou na cessão da Califórnia e de grande parte do atual Sudoeste dos Estados Unidos em 1848. A corrida do ouro na Califórnia de 1848-1849 estimulou a migração ocidental. As ferrovias construídas, no entanto, tornaram a deslocalização mais fácil para os colonos e provocaram o aumento dos conflitos com os nativos americanos. Depois de meio século, até 40 milhões de bisões americanos foram abatidos para peles e carne e para facilitar a disseminação do transporte ferroviário. A perda do bisão, um recurso fundamental para os Índios das Planícies, constituiu rude golpe para a subsistência de muitas culturas nativas.
As tensões entre os estados ditos livres e os estados escravistas tiveram origem sobretudo em discussões sobre a relação entre os governos estadual e federal e em conflitos violentos acerca da propagação da escravidão em novos estados. Abraham Lincoln, candidato do Partido Republicano, em grande parte abolicionista, foi eleito presidente em 1860. Antes da sua tomada de posse, sete estados escravistas declararam sua secessão, o que o governo federal sempre considerou ilegal, e formaram os Estados Confederados da América.
Com o ataque confederado em Fort Sumter, a Guerra de Secessão começou, e mais quatro estados escravistas aderiram à Confederação. A Proclamação da Emancipação de Lincoln, em 1863, declarou livres os escravos da Confederação. Após a vitória da União em 1865, três emendas à Constituição americana garantiam a liberdade para quase quatro milhões de afro-americanos que tinham sido escravos, fizeram-nos cidadãos e lhes deram direito ao voto. A guerra e a sua resolução levaram a um aumento substancial do poder federal.
Após a guerra, o assassinato de Lincoln radicalizou as políticas republicanas da Reconstrução na reinserção e reconstrução dos estados do sul, assegurando os direitos dos escravos recém-libertos. A resolução da disputada eleição presidencial de 1876 pelo compromisso de 1877 terminou com a Era da Reconstrução; as Leis de Jim Crow iniciaram um período de perseguição aos afro-americanos.
No Norte, a urbanização e um afluxo de imigrantes sem precedentes da Europa meridional e oriental apressou a industrialização do país. A onda de imigração, que durou até 1929, proveu trabalho e transformou a cultura americana. O desenvolvimento da infraestrutura nacional estimulou o crescimento econômico.
A compra do Alasca do Império Russo em 1867 completou a expansão continental do país. O massacre de Wounded Knee, em 1890, foi o último grande conflito armado das Guerras Indígenas. Em 1893, a monarquia indígena do Reino do Havaí, no Pacífico, foi derrubada em um golpe de Estado liderado por residentes norte-americanos; os Estados Unidos anexaram o arquipélago em 1898. A vitória no mesmo ano da Guerra Hispano-Americana demonstrou que os Estados Unidos eram uma grande potência mundial e levou à anexação de Porto Rico, Guam e as Filipinas. As Filipinas conquistaram a independência meio século depois, Porto Rico e Guam permanecem como territórios americanos.
Durante os primeiros anos da Primeira Guerra Mundial, que eclodiu em 1914, os Estados Unidos mantiveram-se neutros. Apesar da maioria dos americanos simpatizarem com os britânicos e com os franceses, muitos eram contra uma intervenção. Em 1917, os Estados Unidos se juntaram aos Aliados, ajudando a virar a maré contra as Potências Centrais. Após a guerra, o Senado não ratificou o Tratado de Versalhes, que estabelecia a Liga das Nações. O país seguiu uma política de unilateralismo, beirando o isolacionismo.
Em 1920, o movimento pelos direitos das mulheres conseguiu a aprovação de uma emenda constitucional que concedia o sufrágio feminino. A prosperidade dos "Roaring Twenties" ("anos 20 florescentes, alegres, ruidosos ou vívidos") terminou com a quebra da Bolsa de Valores de Nova Iorque em 1929, que desencadeou a Grande Depressão. Após sua eleição como presidente em 1932, Franklin Delano Roosevelt respondeu à crise social e econômica com o "New Deal" ("novo acordo"), uma série de políticas de crescente intervenção governamental na economia. O "Dust Bowl" de meados da década de 1930 empobreceu muitas comunidades agrícolas e estimulou uma nova onda de imigração ocidental.
Os Estados Unidos, neutros durante as fases iniciais da Segunda Guerra Mundial, iniciada com a invasão da Polônia pela Alemanha Nazista em setembro de 1939, começaram a fornecer material para os Aliados em março de 1941 através do programa "Lend-Lease" ("Lend-Lease Act"; "Lei de empréstimo e arrendamento"). Em 7 de dezembro de 1941, o Império do Japão lançou um ataque surpresa a Pearl Harbor, o que levou os Estados Unidos a se juntar aos Aliados contra as potências do Eixo e ao internamento compulsivo de milhares de americanos de origem japonesa. A participação na guerra estimulou o investimento de capital e a capacidade industrial do país. Entre os principais combatentes, os Estados Unidos foram o único país a se tornar muito mais rico, ao contrário dos restantes aliados, que empobreceram por causa da guerra.
As conferências dos aliados em Bretton Woods e Yalta delinearam um novo sistema de organizações internacionais que colocou os Estados Unidos e a União Soviética no centro da política geoestratégica mundial. Como a vitória foi conquistada na Europa, uma conferência internacional realizada em 1945 em São Francisco produziu a Carta das Nações Unidas, que se tornou ativa depois da guerra. Tendo desenvolvido as primeiras armas nucleares, os Estados Unidos, usaram-as sobre as cidades japonesas de Hiroshima e Nagasaki, em agosto de 1945. O Japão se rendeu em 2 de setembro do mesmo ano, marcando o fim da guerra.
Os Estados Unidos e a União Soviética disputaram a supremacia mundial após a Segunda Guerra Mundial, durante o período chamado de Guerra Fria, cujos principais atores a nível militar na Europa foram Organização do Tratado do Atlântico Norte (OTAN) e o Pacto de Varsóvia. Os Estados Unidos promoviam a democracia liberal e o capitalismo, enquanto a União Soviética promovia o comunismo e uma economia planificada. Ambos apoiavam ditaduras e estavam envolvidos em guerras por procuração. As tropas americanas combateram as forças comunistas chinesas na Guerra da Coreia de 1950-53. O Comitê de Atividades Antiamericanas seguiu uma série de investigações sobre suspeitas de subversões de esquerda, enquanto o senador Joseph McCarthy tornou-se a figura emblemática do sentimento anticomunista.
O lançamento soviético de 1961 do primeiro voo tripulado fez com que o presidente John F. Kennedy lançasse o repto dos Estados Unidos serem o primeiro país a aterrissar um homem na lua, o que foi realizado em 1969. Kennedy também enfrentou uma tensa crise motivado pela presença de forças soviéticas em Cuba que por pouco não provocou um confronto nuclear. Entretanto, os Estados Unidos experimentaram uma expansão econômica sustentada. Ao mesmo tempo, cresceu o movimento dos direitos civis, simbolizado e liderado por afro-americanos, como Rosa Parks e Martin Luther King Jr, usando a não violência para enfrentar a segregação e a discriminação. Após o assassinato de Kennedy em 1963, a Lei de Direitos Civis de 1964 e a Lei dos Direitos ao Voto de 1965 foram aprovadas pelo presidente Lyndon B. Johnson. Johnson e seu sucessor, Richard Nixon, expandiram uma guerra por procuração no sudeste da Ásia para a mal sucedida Guerra do Vietnã. Um amplo movimento de contracultura cresceu, alimentado pela oposição à guerra, o nacionalismo negro e a revolução sexual. Betty Friedan, Gloria Steinem e outros levaram uma nova onda de feminismo que buscava a igualdade política, social e econômica das mulheres.
Como consequência do escândalo de Watergate, em 1974 Nixon se tornou o primeiro presidente americano a renunciar, para evitar sofrer um "impeachment" (impugnação do mandato) sob as acusações de obstrução da justiça e abuso de poder, sendo sucedido pelo vice-presidente Gerald Ford. A administração de Jimmy Carter da década de 1970 foi marcada pela estagflação e a crise dos reféns do Irã. A eleição de Ronald Reagan como presidente em 1980 anunciou uma virada à direita na política norte-americana, refletida em grandes mudanças na tributação e nas prioridades dos gastos. Seu segundo mandato foi marcado pelo escândalo Irã-Contras e pelo significativo progresso diplomático com a União Soviética. O posterior colapso soviético pôs fim à Guerra Fria.
Sob a presidência de George H. W. Bush, os Estados Unidos assumiram um papel de liderança na ONU sancionando a Guerra do Golfo. A maior expansão econômica da história moderna americana ocorreu de março de 1991 a março de 2001, abrangendo a administração de Bill Clinton e a "Bolha da Internet". Uma ação judicial civil e um escândalo sexual levaram ao "impeachment" de Clinton em 1998, mas ele permaneceu no cargo.
A eleição presidencial de 2000, uma das mais acirradas e controversas da história dos Estados Unidos, que chegou a envolver suspeitas de fraude e outras dúvidas na contagem de votos, foi resolvida por uma decisão da Suprema Corte dos Estados Unidos, que declarou George W. Bush, filho de George H. W. Bush, presidente. Na manhã de 11 de setembro de 2001, terroristas da organização fundamentalista islâmica al-Qaeda atacaram o complexo do World Trade Center, em Nova Iorque, e o prédio do Pentágono, nos arredores de Washington, D.C., causando a morte de cerca de três mil pessoas. Em resposta aos atentados, o governo Bush lançou a chamada Guerra ao Terror e, no final de 2001, forças norte-americanas lideraram uma invasão ao Afeganistão, removendo o governo Taliban e acabando com campos de treinamento da al-Qaeda. Insurgentes do Taliban, no entanto, continuam (2011) a travar uma guerra de guerrilha no país. Em 2002, a administração Bush começou a pressionar uma mudança de regime no Iraque por motivos controversos. Sem o apoio da OTAN ou da ONU para uma intervenção militar, o governo Bush organizou e liderou uma coalizão de forças militares para invadir preventivamente o Iraque em 2003, removendo o ditador Saddam Hussein do poder. Em 2005, o furacão Katrina causou profundos danos ao longo da Costa do Golfo, devastando a cidade de Nova Orleans, na Louisiana.
Em 2008, em meio a uma recessão econômica global, o primeiro presidente afro-americano, Barack Obama, foi eleito. Dois anos depois, grandes reformas nos sistemas de saúde e financeiro do país foram decretadas. Em 2011, um ataque de SEALs da marinha norte-americana matou o líder da rede al-Qaeda, Osama bin Laden, na cidade de Abbottabad, no Paquistão. A Guerra do Iraque acabou oficialmente com a retirada das tropas norte-americanas restantes do país em dezembro de 2011. No 11º aniversário dos ataques de 11 de setembro, e menos de um ano após os Estados Unidos colaborarem com a queda do ditador líbio Muammar Gaddafi, duas instalações norte-americanas foram atacadas na Líbia, o que resultou na primeira morte de um embaixador estadunidense desde 1979. Em outubro de 2012, o furacão Sandy causou vasta destruição no litoral das regiões Nordeste e do Médio Atlântico dos Estados Unidos. Em abril de 2013, um ataque terrorista aconteceu durante a Maratona de Boston; foi o primeiro atentado terrorista reconhecido no país desde o 11 de setembro de 2001.
A área dos Estados Unidos contíguos é de aproximadamente sendo que são terra emersa. O Alasca, separado dos Estados Unidos contíguos pelo Canadá, é o maior estado com . O Havaí, um arquipélago no Pacífico central, a sudoeste da América do Norte, tem cerca de A seguir à Rússia e ao Canadá, os Estados Unidos são a quarta maior nação do mundo em área total (terra e água), posição abaixo da China. A classificação varia conforme a estimativa da área total dos Estados Unidos utilize as águas territoriais marítimas, porém, pelo padrão de agrimensura, que considera apenas terra e águas internas a posição é a quarta. Assim, segundo o "CIA World Factbook", que contabiliza as águas costeiras e territoriais, segundo Divisão de Estatísticas das Nações Unidas, que considera as águas costeiras e territoriais dos grandes lagos. e segundo a Encyclopædia Britannica, que considera as águas territoriais dos grandes lagos. Incluindo apenas a área terrestre, os Estados Unidos são o terceiro maior país do mundo em superfície, atrás da Rússia e da China e à frente do Canadá.
Os Estados Unidos são considerados um "país megadiverso": cerca de espécies de plantas vasculares ocorrem nos Estados Unidos Continentais e no Alasca, e mais de espécies de plantas são encontradas no Havaí, algumas das quais ocorrem no continente. Os Estados Unidos são o lar de mais de 400 espécies de mamíferos, 750 de aves e 500 de répteis e anfíbios. Cerca de espécies de insetos têm sido registradas.
O território nacional conta com múltiplas formas de acidentes geográficos e é comum dividir-se a parte dos Estados Unidos na América do Norte excluindo o Alasca em três grandes regiões orográficas: a ocidental, a central e a oriental. À medida que se avança para o interior, a planícies costeiras do litoral Atlântico dão lugar a bosques caducifólios e à meseta de Piedmont. Os Apalaches separam a costa oriental dos Grandes Lagos das pradarias do centro-oeste. As montanhas de Serra Nevada e a Cordilheira das Cascatas ("Cascade Range") se encontram próximas à costa do Pacífico. O Monte McKinley, no Alasca, com metros de altitude, é o ponto mais alto do país e de todo o continente. Os vulcões ativos são comuns ao longo do Alasca e nas Ilhas Aleutas e no estado do Havaí só existem ilhas vulcânicas. O supervulcão localizado no Parque Nacional de Yellowstone, nas Montanhas Rochosas, é a maior vulcão do continente.
O principal sistema hidrográfico do país, formado pelos rios Mississipi e Missouri e o terceiro maior sistema fluvial do mundo, percorre o centro dos Estados Unidos de norte a sul. A pradaria plana e fértil das Grandes Planícies se estende até ao oeste, até ser interrompida por uma região de terras altas no sudoeste. As Montanhas Rochosas, na borda ocidental das Grandes Planícies, atravessam a nação do norte até o sul, chegando a altitudes superiores a metros. Ainda na região oeste encontram-se a Grande Bacia do Nevada ("Great Basin") e desertos, como o de Mojave, Sonora e Chihuahua.
Sua grande extensão e variedade geográfica, inclui a maioria dos tipos de clima. A leste do meridiano 100 oeste, o clima varia de continental úmido no norte, a subtropical úmido no sul. A ponta sul da Flórida é tropical, assim como o Havaí. As Grandes Planícies a oeste do meridiano 100 são semiáridas. Grande parte das montanhas ocidentais são alpinas. O clima é árido na Grande Bacia, desértico no sudoeste, mediterrânico na costa da Califórnia e oceânico nas costas do Oregon e de Washington e sul do Alasca. A maior parte do Alasca é subártico ou polar. Climas extremos não são incomuns; os países do Golfo do México são propensos a furacões e a maioria dos tornados do mundo ocorrem no interior do país, principalmente na "Tornado Alley" ("Alameda dos Tornados"), no Centro-Oeste.
A "Endangered Species Act" de 1973 protege espécies ameaçadas e seus "habitats", que são monitorados pelo "United States Fish and Wildlife Service". Há 58 parques nacionais e centenas de outros parques, florestas e áreas naturais geridas pelo governo federal, sendo que a porcentagem de área florestal é de 33,1% (2005). No total, o governo detém 28,8% da área terrestre do país. A maior parte desta área está protegida, apesar de algumas serem alugadas para perfuração de poços de petróleo e gás natural, mineração, exploração madeireira ou pecuária; 2,4% é usado para fins militares.
A população dos Estados Unidos foi estimada pelo "United States Census Bureau" em novembro de 2010 em habitantes, incluindo 11,2 milhões de imigrantes ilegais. Os Estados Unidos são a terceira nação mais populosa do mundo, a seguir à China e a Índia, e são o único país industrializado em que há perspetivas de aumento em grande parte da população. Com uma taxa de natalidade de 13,82 por mil, 30% abaixo da média mundial, a sua taxa de crescimento populacional é de 0,98%, significativamente superior às da Europa Ocidental, Japão e Coreia do Sul. No ano fiscal de 2009, foi concedida residência legal a 1,1 milhões de imigrantes. O México foi a principal fonte de novos residentes por mais de duas décadas; desde 1998, China, Índia e as Filipinas foram os quatro principais países de origem de imigrantes a cada ano.
Os Estados Unidos têm uma população muito diversificada: trinta e um grupos étnicos têm mais de um milhão de membros. Os estadunidenses brancos são o maior grupo racial; descendentes de alemães, irlandeses e ingleses constituem três dos quatro principais grupos étnicos do país. Os afro-americanos são a maior minoria racial da nação e o terceiro maior grupo étnico.
Os asiático-americanos são a segunda maior minoria racial do país; os dois maiores grupos étnicos asiático-americanos são chineses americanos e filipinos americanos. Em 2008, a população americana incluía um número estimado de 4,9 milhões de pessoas com alguma ascendência de nativos americanos ou nativos do Alasca (3,1 milhões exclusivamente de tal ascendência) e 1,1 milhões com alguma ascendência de nativos do Havaí ou das ilhas do Pacífico (0,6 milhões exclusivamente). De acordo com o censo de 2010, os hispânicos já são mais de 50 milhões nos Estados Unidos.
O crescimento populacional dos hispânicos e latino-americanos é uma grande tendência demográfica. Os 46,9 milhões de americanos de ascendência hispânica são identificados como uma etnia "distinta" pelo "Census Bureau"; 64% dos hispano-americanos são de origem mexicana. Entre 2000 e 2008, a população hispânica do país aumentou 32%, enquanto a população não hispânica cresceu apenas 4,3%. Grande parte deste crescimento populacional vem da imigração. Em 2007, 12,6% da população era era constituída por indivíduos nascidos em outros países, 54% deles na América Latina. A fertilidade é também um fator importante; o número médio de filho por mulher latino-americana (taxa de fecundidade é de três, de 2,2 para as mulheres não hispânicas negras e 1,8 para as mulheres não hispânicas brancas (abaixo da taxa de substituição populacional, que é de 2,1). Minorias (conforme definido pelo "Census Bureau", ao lado de todos os não hispânicos, não multirraciais brancos) constituem 34% da população. Estima-se que os não brancos constituirão a maioria da população em 2042.
Cerca de 82% dos americanos vivem em áreas urbanas; cerca de metade são residentes de cidades com populações superiores a . Em 2008, 273 cidades tinham populações superiores a habitantes, nove cidades tinham mais de um milhão de habitantes e quatro cidades globais tinham mais de 2 milhões de habitantes (Nova Iorque, Los Angeles, Chicago e Houston).
O inglês é a língua nacional "de facto". Embora não haja nenhuma língua oficial em nível federal, algumas leis, como os requisitos para naturalização, padronizam o inglês. Em 2006, cerca de 224 milhões de pessoas, ou 80% da população com idades entre cinco anos ou mais, falava apenas inglês em casa. O espanhol, falado em casa por 12% da população, é o segundo idioma mais comum e a segunda língua estrangeira mais ensinada. Alguns americanos defendem o inglês como a língua oficial do país, como é em, pelo menos, vinte e oito estados do país. Tanto o havaiano quanto o inglês são as línguas oficiais no Havaí por lei estadual.
Enquanto não tem uma língua oficial, o Novo México tem leis que preveem a utilização dos idiomas inglês e espanhol, a Louisiana tem leis para o inglês e o francês. Outros estados, como a Califórnia, obrigam a publicação de versões em espanhol de alguns documentos do governo, incluindo de tribunais. Vários territórios insulares concedem o reconhecimento oficial para suas línguas nativas, juntamente com o inglês: samoano e chamorro são reconhecidas pela Samoa Americana e Guam, respectivamente; caroliniano e o chamorro são reconhecidos pelas Ilhas Marianas do Norte, o espanhol é uma língua oficial de Porto Rico.
Os Estados Unidos são oficialmente uma nação secular; a Primeira Emenda da Constituição do país garante o livre exercício da religião e proíbe a criação de um governo religioso.
Em um estudo de 2002, 59% dos americanos disseram que a religião teve um papel "muito importante em suas vidas", um número muito maior do que qualquer outra nação desenvolvida. O nível de religiosidade do povo varia bastante regionalmente: segundo pesquisa de 2009, 63% dos habitantes do Mississippi frequentavam a igreja semanalmente, ao passo que em Vermont esse número cai para 23%.
O perfil religioso dos Estados Unidos vem mudando consideravelmente nos últimos anos. De acordo com uma pesquisa de 2014, 70,6% dos adultos se identificaram como cristãos, sendo que em 2007 esse número era de 78,4% e em 1990, de 86,4%. Na década de 2010, pela primeira vez na História, os evangélicos deixaram de ser a maioria da população norte-americana: em 2007, os protestantes representavam 51,3%, porém em 2014 reduziram-se a 46,5%. O grupo que mais cresce nos Estados Unidos são as pessoas sem religião (22,8%), que ultrapassaram os católicos romanos (20,8%) no início da década. Em 2007, o estudo classifica os protestantes brancos, 26,3% da população, como o maior grupo religioso do país; outro estudo estima protestantes de todas as raças em 30-35%.
O total de religiões não cristãs em 2007 foi de 4,7%, acima dos 3,3% em 1990. Os maiores credos não cristãos foram o judaísmo (1,7%), budismo (0,7%), islamismo (0,6%), hinduísmo (0,4%) e o Unitário-Universalismo (0,3%). 8,2% da população em 1990, contra 16,1% em 2007 e 22,8% em 2014, descreveu-se como agnóstico, ateu, ou simplesmente sem-religião.
Os Estados Unidos são a federação mais antiga do mundo. O país é uma república constitucional e uma democracia representativa, "em que a regra da maioria é temperada por direitos das minorias protegidos por lei". O governo é regulado por um sistema de separação de poderes definido pela Constituição, que serve como documento legal supremo do país. No sistema federalista estado-unidense, os cidadãos são geralmente sujeitos a três níveis de governo: federal, estadual e local; funções de governo local são geralmente divididas entre os condados e os governos municipais. Em quase todos os casos, funcionários do executivo e do legislativo são eleitos pelo voto da maioria dos cidadãos do distrito. Não há representação proporcional no nível federal e isso é muito raro em níveis inferiores.
O governo federal é composto de três ramos:
A Câmara dos Representantes tem 435 membros votantes, cada um representando um distrito do Congresso para um mandato de dois anos. Cadeiras na Câmara são distribuídas entre os estados pela população a cada dez anos. De acordo com o censo de 2000, sete estados têm um mínimo de um representante, enquanto a Califórnia, o estado mais populoso, tem cinquenta e três. O Senado tem 100 membros com cada estado tendo dois senadores, eleitos para mandatos de seis anos, um terço das cadeiras do Senado estão acima para a eleição a cada ano.
O presidente não é eleito pelo voto direto, mas por um sistema de colégio eleitoral indireto em que os votos são distribuídos de forma determinada por estado, para um mandato de quatro anos, podendo ser reeleito uma vez, consecutiva ou não. Cada estado recebe uma determinada quantidade de votos de acordo com o número de congressistas dentro do poder legislativo: senadores (dois por cada estado) e representantes (que variam de acordo com a população de cada estado); dando um total de 538 membros. O sistema bipartidarista permite que um dos candidatos à presidência, seja do Partido Republicano ou do Democrata, precise de apenas duzentos e setenta votos para assegurar a vitória. A Suprema Corte, liderada pelo Chefe de Justiça dos Estados Unidos, tem nove membros.
Os governos estaduais estão estruturados de forma mais ou menos semelhante. O estado de Nebraska, excepcionalmente, tem uma legislatura unicameral. O governador (chefe executivo) de cada estado é eleito por sufrágio direto. Alguns juízes estaduais e agentes do gabinete são nomeados pelos governadores dos respectivos estados, enquanto outros são eleitos pelo voto popular.
Todas as leis e procedimentos governamentais são passíveis de recurso judicial e a que foi julgada em desacordo com a Constituição é anulada. O texto original da Constituição estabelece a estrutura e as responsabilidades do governo federal e sua relação com os estados. O Artigo Primeiro protege o direito ao "grandes decreto" do "habeas corpus" e o Artigo Terceiro garante o direito a um julgamento com júri em todos os casos criminais. Emendas à Constituição exigem a aprovação de três quartos dos estados. A Constituição foi alterada vinte e sete vezes; as dez primeiras emendas, que constituem a Carta dos Direitos, e a Décima Quarta Emenda formam a base central dos direitos individuais dos americanos.
O presidente detém o título de comandante-em-chefe das forças armadas do país e nomeia seus dirigentes, o secretário de defesa e o Chefe do Estado-Maior Conjunto. O Departamento de Defesa dos Estados Unidos administra as forças armadas, incluindo o Exército, Marinha, Corpo de Fuzileiros Navais e da Força Aérea. A Guarda Costeira é executada pelo Departamento de Segurança Interna em tempos de paz e pelo Departamento da Marinha em tempos de guerra. Em 2008, as forças armadas tinham 1,4 milhões de pessoas na ativa. As Reservas da Guarda Nacional elevam o número total de tropas para 2,3 milhões. O Departamento de Defesa também empregou cerca de 700.000 civis, não incluindo empreiteiros.
O serviço militar é voluntário, embora a conscrição possa ocorrer em tempos de guerra através do chamado Sistema de Serviço Seletivo. As forças estado-unidenses podem ser rapidamente implantadas pela grande frota de aviões de transporte da Força Aérea, onze aviões ativos da Marinha e "Marine Expeditionary Unit" no mar com frotas da Marinha no Atlântico e no Pacífico. O país mantém 865 bases e instalações militares ao redor do mundo, com pessoal destacado para mais de 150 países. A extensão da presença militar global tem levado alguns estudiosos a descrever os Estados Unidos como a manutenção de um "império de bases".
O total de gastos militares dos Estados Unidos em 2008 foi de mais de 600 bilhões de dólares, superior a 41% da despesa militar mundial e maior do que todos os próximos quatorze maiores gastos militares nacionais somados. O gasto per capita de 1.967 dólares foi cerca de nove vezes superior à média mundial; com 4% do PIB, a taxa foi a segunda mais alta entre os quinze maiores gastadores militares, depois da Arábia Saudita. A base proposta pelo Departamento de Defesa para o orçamento de 2010, 533,8 bilhões de dólares, é um aumento de 4% em relação a 2009 e 80% maior que em 2001, um adicional de 130 bilhões de dólares é proposto para as campanhas militares no Iraque e no Afeganistão. Em setembro de 2009, havia cerca de 130 mil soldados americanos enviados ao Iraque e 62 mil mobilizados para o Afeganistão. Até 9 de outubro de 2009, os Estados Unidos haviam sofrido com militares mortos durante a Guerra do Iraque e 869 durante a Guerra no Afeganistão. Entre os anos de 1890 e 2012, o país invadiu ou bombardeou outras 149 nações ao redor do planeta.
Os Estados Unidos exercem uma forte influência econômica, política e militar em todo o mundo. O país é um membro permanente do Conselho de Segurança das Nações Unidas e Nova Iorque hospeda a sede das Nações Unidas. Quase todos os países têm embaixadas em Washington D.C. e muitos consulados em todo o país. Da mesma forma, quase todas as nações acolhem missões diplomáticas americanas. No mundo, apenas Butão, Coreia do Norte e Irã não têm relações diplomáticas com os Estados Unidos.
Os Estados Unidos mantêm laços fortes com o Reino Unido, Canadá, Austrália, Nova Zelândia, Japão, Coreia do Sul e Israel. Trabalha em estreita colaboração com outros membros da Organização do Tratado do Atlântico Norte (OTAN) sobre questões militares e de segurança e com seus vizinhos por meio da Organização dos Estados Americanos (OEA) e tem acordos de livre comércio trilateral, como o Tratado Norte-Americano de Livre Comércio com o Canadá e o México. Em 2008, os Estados Unidos gastaram 25,4 bilhões de dólares líquidos em assistência oficial ao desenvolvimento em grande parte do mundo. Em percentagem do produto nacional bruto (PNB), no entanto, a contribuição americana de 0,18% ficou em último lugar entre os vinte e dois Estados doadores. Em contraste, as doações particulares ao exterior dos americanas são relativamente generosas, particularmente com Israel.
A aplicação da lei nos Estados Unidos é sobretudo da responsabilidade da polícia local e dos departamentos de xerifes, com polícias estaduais que prestam serviços mais amplos. As agências federais, como o Escritório Federal de Investigação (FBI) e os "U.S. Marshals Service", têm funções especializadas. No nível federal e em quase todos os estados, a jurisprudência opera em um sistema de "common law". Tribunais estaduais julgam a maioria dos crimes; tribunais federais julgam certos crimes designados, bem como apelos de alguns sistemas estaduais.
Entre os países desenvolvidos, os Estados Unidos têm níveis acima da média de crimes violentos e níveis particularmente altos de violência armada e de homicídio. Em 2007, havia 5,6 homicídios por 100 mil pessoas, três vezes a taxa do vizinho Canadá. A taxa de homicídios do país, que diminuiu 42% entre 1991 e 1999, permaneceu aproximadamente constante desde então. O direito de civis possuírem armas é objeto de um controverso debate político.
Os Estados Unidos têm a maior taxa registrada de encarceramento e a maior população carcerária total do mundo. No início de 2008, mais de 2,3 milhões de pessoas foram presas, mais de um em cada 100 adultos. A taxa é de cerca de sete vezes o valor de 1980. As prisões de afro-americanos são em cerca de seis vezes maior que a taxa de prisão de homens brancos e três vezes a taxa de homens latinos. Em 2015, o país concentrava 5% da população mundial, mas 25% da população carcerária do planeta. E 60% dos presidiários eram de origem hispânica e africana.
Em 2006, a taxa de encarceramento americano foi mais de três vezes o valor da taxa da Polônia, país da Organização para a Cooperação e Desenvolvimento Econômico (OCDE) com a segunda taxa mais alta. A elevada taxa de encarceramento do país deve-se, em grande parte, à condenação e às políticas de drogas.
Embora tenha sido abolida na maioria das nações ocidentais, a pena capital é sancionada nos Estados Unidos para certos crimes federais e militares, e em trinta e seis estados. Desde 1976, quando a Suprema Corte dos Estados Unidos restabeleceu a pena de morte depois de uma moratória de quatro anos, houve mais mais de mil execuções. Em 2006, o país teve o sexto maior número de execuções no mundo, na sequência de China, Irã, Paquistão, Iraque e Sudão. Em 2007, Nova Jérsei se tornou o primeiro estado a abolir legislativamente a pena de morte desde a decisão de 1976 da Suprema Corte, seguida do Novo México em 2009.
Os Estados Unidos são uma união federal de cinquenta estados. Os originais treze estados foram os sucessores das treze colônias que se rebelaram contra o domínio britânico. No início da história do país, três novos estados foram organizados em território separados das reivindicações dos estados existentes: Kentucky da Virgínia; Tennessee da Carolina do Norte e Maine de Massachusetts. A maioria dos outros estados foi esculpida a partir de territórios obtidos através de guerras ou por aquisições do governo americano. Um conjunto de exceções compreende Vermont, Texas e Havaí: cada um era uma república independente antes de ingressar na união. Durante a Guerra Civil Americana, a Virgínia Ocidental se separou da Virgínia. O Havaí, o mais recente estado do país, foi anexado em 1898 e foi elevado à categoria de estado em 21 de agosto de 1959. Os estados não têm o direito de se separar da união.
Os estados compõem a maior parte da massa terrestre americana, as duas outras áreas consideradas partes integrantes do país são o Distrito de Colúmbia, o distrito federal, onde a capital, Washington, está localizada, e o Atol Palmyra, um território integrado, mas desabitado no Oceano Pacífico. Os Estados Unidos também possuem cinco grandes territórios ultramarinos: Porto Rico e Ilhas Virgens Americanas, no Caribe, e Samoa Americana, Guam e as Ilhas Marianas do Norte, no Pacífico. As pessoas nascidas nos territórios (exceto na Samoa Americana) possuem cidadania americana. Cidadãos americanos residentes nos territórios têm muitos dos mesmos direitos e responsabilidades dos cidadãos residentes nos estados, no entanto, eles geralmente são isentos do imposto de renda federal, não podem votar para presidente e têm apenas uma representação sem direito a voto no Congresso.
Os Estados Unidos têm uma economia mista capitalista, que é abastecida por recursos naturais abundantes, uma infraestrutura bem desenvolvida e pela alta produtividade. De acordo com o Fundo Monetário Internacional, o PIB dos Estados Unidos de 14,4 trilhões de dólares representa 24% do produto interno bruto mundial no mercado de câmbio e quase 21% do produto interno bruto mundial em paridade do poder de compra (PPC). O maior PIB nacional do mundo era cerca de 5% menor do que o PIB combinado da União Europeia em PPC, em 2008. O país ocupa a décima sétima posição no mundo em termos de PIB nominal per capita e a sexta posição em PIB per capita PPC.
Os Estados Unidos são o maior importador e terceiro maior exportador de bens, embora as exportações per capita sejam relativamente baixas. Em 2008, o déficit comercial total do país foi de 696 bilhões de dólares. Canadá, China, México, Japão e Alemanha são os seus principais parceiros comerciais. A China é o maior detentor da dívida externa pública dos EUA. Depois de uma expansão que durou pouco mais de seis anos, a economia americana entrou em recessão desde dezembro de 2007, recuperando-se em 2010. Os Estados Unidos ocupam o segundo lugar no "Global Competitiveness Report".
Em 2009, estimou-se que o setor privado constituía 55,3% da economia do país; a atividade do governo federal, 24,1%; e as atividades dos estados e de administrações locais (incluindo as transferências federais), os restantes 20,6%. A economia é pós-industrial, com o setor de serviços contribuindo com 67,8% do PIB, embora os Estados Unidos continuem a ser uma potência industrial.
Os Estados Unidos são o terceiro maior produtor de petróleo do mundo, bem como o seu maior importador. É o maior produtor do mundo de energia elétrica e nuclear, assim como de gás natural liquefeito, enxofre, fosfatos e sal. Enquanto a agricultura representa menos de 1% do PIB, os Estados Unidos são o maior produtor mundial de milho e soja. A Bolsa de Valores de Nova Iorque é a maior do mundo em volume de dólares. Coca-Cola e McDonald's são as duas marcas do país mais reconhecidas no mundo.
No terceiro bimestre de 2009, a força de trabalho do país era composta por 154,4 milhões de pessoas. Desses trabalhadores, 81% tinham emprego no setor de serviços. Com 22,4 milhões de pessoas, o governo é o principal campo de trabalho. Cerca de 12% dos trabalhadores são sindicalizados, contra 30% na Europa Ocidental. O Banco Mundial classifica os Estados Unidos em primeiro lugar na facilidade de contratação e demissão trabalhadores. Entre 1973 e 2003, um ano de trabalho para o norte-americano médio cresceu 199 horas.
Em parte como resultado disto, os Estados Unidos mantém a maior produtividade do trabalho no mundo. Em 2008, ele também levou a produtividade por hora do mundo, ultrapassando a Noruega, França, Bélgica e Luxemburgo, que havia superado os Estados Unidos durante a maior parte da década anterior. Em relação à Europa, a propriedade e as taxas de imposto de renda americanas são geralmente mais elevadas, enquanto trabalho e, particularmente, as taxas de imposto sobre o consumo são menores.
Os Estados Unidos têm sido um líder em pesquisa científica e em inovação tecnológica desde o . Em 1876, Alexander Graham Bell registou a primeira patente americana para o telefone. O laboratório de Thomas Edison desenvolveu o primeiro fonógrafo, a primeira lâmpada incandescente, a primeira câmera de vídeo viável. Nikola Tesla foi o pioneiro da corrente alternada, do motor AC e do rádio. No início do , as empresas de automóveis de Ransom E. Olds e Henry Ford promoveram a linha de montagem. Os irmãos Wright, em 1903, fizeram o primeiro objeto sustentado e controlado mais pesado que o ar voar.
A ascensão do nazismo na década de 1930 levou muitos cientistas europeus, incluindo Albert Einstein e Enrico Fermi, a imigrar para os Estados Unidos. Durante a Segunda Guerra Mundial, o Projeto Manhattan desenvolveu armas nucleares, dando início à Era Atômica. A Corrida Espacial produziu rápidos avanços no desenvolvimento de foguetes, da ciência dos materiais e de computadores. Os Estados Unidos também tiveram grande contribuição no desenvolvimento da ARPANET e de sua sucessora, a Internet. Hoje, a maior parte do financiamento para pesquisa e desenvolvimento, 64%, vem do setor privado. Os Estados Unidos lideram no mundo em trabalhos de pesquisa científica e fator de impacto. Os americanos possuem níveis de consumo tecnologicamente avançados, e quase metade dos lares têm acesso à banda larga. O país é o principal desenvolvedor e produtor de alimentos geneticamente modificados. Mais da metade das terras cultivadas com culturas transgênicas do mundo está nos Estados Unidos.
A educação pública americana é operada por governos estaduais e municipais, sendo regulada pelos Departamento de Educação dos Estados Unidos através de restrições sobre as subvenções federais. Crianças são obrigadas na maioria dos estados a frequentar a escola desde os seis ou sete anos (em geral, pré-escola ou primeira série) até os dezoito (geralmente até o décimo segundo grau, ao final do ensino médio); alguns estados permitem que os estudantes deixem a escola aos dezesseis ou dezessete anos. Cerca de 12% das crianças estão matriculadas em escolas paroquiais ou escolas privadas não sectárias. Pouco mais de 2% das crianças fazem ensino doméstico.
Os Estados Unidos têm muitas instituições públicas e privadas de ensino superior competitivas, bem como faculdades de comunidades locais com políticas abertas de admissão. Dos americanos com 25 anos ou mais, 84,6% concluíram o ensino superior, 52,6% frequentavam alguma faculdade, 27,2% recebiam um diploma de bacharel e 9,6% frequentavam uma pós-graduação. A taxa de alfabetização é de cerca de 99% da população. A Organização das Nações Unidas atribui aos Estados Unidos um índice de educação de 0,97, classificando-o na 12ª posição no mundo.
De acordo com a Unesco, os Estados Unidos são o segundo país com o maior número de instituições de educação superior no mundo, com um total de , com um ponto médio de quinze por cada estado. O país conta com o maior número de estudantes universitários do mundo, ascendendo a , correspondente a 4.5% da população total. Lá encontram-se algumas das universidades mais prestigiosas e de maior fama no mundo. Harvard, Berkeley, Stanford e o Instituto de Tecnologia de Massachusetts são consideradas como as melhores universidades por muitas de suas publicações.
Sendo um país desenvolvido, os Estados Unidos contam com uma avançada infraestrutura de transportes: quilômetros de autoestradas, quilômetros de vias férreas e quilômetros de vias fluviais. A maior parte dos seus habitantes utiliza o automóvel como o principal meio de transporte. Em 2003, havia 759 automóveis para cada 1.000 americanos, em comparação com os 472 automóveis para cada 1.000 habitantes da União Europeia no ano seguinte. Cerca de 40% dos veículos pessoais são vans, utilitários esportivos ou caminhões leves. O americano adulto médio (contabilização de todos os que dirigem e não dirigem) gasta 55 minutos dirigindo por dia, viajando 47 km.
A indústria da aviação civil é totalmente privada, enquanto a maioria dos grandes aeroportos são de propriedade pública. As quatro maiores companhias aéreas do mundo em passageiros transportados são americanos; "Southwest Airlines" é a número um. Dos trinta aeroportos mais movimentados por passageiros do mundo, dezesseis estão nos Estados Unidos, sendo o mais movimentado deles o Aeroporto Internacional de Atlanta Hartsfield-Jackson, o maior do mundo. Enquanto o transporte ferroviário de mercadorias é extenso, relativamente poucas pessoas usam transporte ferroviário em viagens, dentro ou entre as cidades. O transporte de massa contabiliza 9% do total de viagens de trabalho dos Estados Unidos, comparado aos 38,8% na Europa. O uso de bicicletas é mínimo, bem abaixo dos níveis europeus.
O consumo energético total do país é de 3,873 bilhões lWh anuais, equivalente a um consumo per capita de 7,8 toneladas de petróleo ao ano. Em 2005, 40% da energia provinha do petróleo, 23% do carvão e 22% de gás natural; o resto provinha de centrais nucleares e de fontes de energia renovável. Os Estados Unidos são o maior consumidor de petróleo e gás natural: anualmente são utilizados 19,15 milhões de barris de petróleo/dia e 683,3 mil milhões de metros cúbicos/dia de gás natural (2010). Por outro lado, no país são encontradas 27% das reservas mundiais de carvão. Durante décadas, a energia nuclear teve um papel julgado na produção de energia, em comparação à maioria dos países desenvolvidos, devido em parte à reação após o acidente de Three Mile Island. Em 2007, o governo recebeu múltiplas petições para a construção de novas centrais nucleares, o que poderia significar uma diminuição considerável no consumo de combustíveis fósseis e mudanças na política energética.
A expectativa de vida dos Estados Unidos é de 77,8 anos ao nascer, um ano menor do que o valor global da Europa Ocidental, e de três a quatro anos menor do que as taxas da Noruega, Suíça e Canadá. Ao longo das últimas duas décadas, a classificação do país em expectativa de vida caiu de 11ª posição para a 42ª no mundo. A taxa de mortalidade infantil é de 6,37 por mil, colocando o país também na 42ª posição entre 221 países, atrás de toda a Europa Ocidental. Aproximadamente um terço da população adulta do país é obesa e um terço adicional tem excesso de peso; a taxa de obesidade, a mais alta do mundo industrializado, mais do que duplicou no último quarto de século. A obesidade relacionada com o diabetes tipo 2 é considerada uma epidemia pelos profissionais de saúde.
A taxa de gravidez na adolescência no país é de 53 por 1.000 mulheres, seis vezes superior à da França e quatro vezes superior à da Alemanha. A legalização do aborto é altamente controversa. Muitos estados proíbem o financiamento público do processo e restringem o aborto, exigem a notificação parental para os menores de idade e o mandato de um período de espera. Apesar de a taxa de aborto estar caindo, a taxa de aborto de 241 por 1.000 nascidos vivos e taxa de abortamento de 15 por mil mulheres com idade entre 15-44 anos permanecem superiores aos da maioria das nações ocidentais.
O sistema de saúde americano gasta muito mais que qualquer sistema de saúde de outra nação, seja em gastos "per capita" ou em percentagem do PIB. A Organização Mundial de Saúde classificou o sistema de saúde americano, em 2000, como o primeiro em capacidade de resposta, mas o 37º em desempenho global. Os Estados Unidos são um líder em inovação médica. Em 2004, o setor não industrial gastou três vezes mais "per capita" do que a Europa em pesquisa biomédica.
Os Estados Unidos são sede dos melhores hospitais do mundo. Grande parte das instalações médicas são de propriedade privada que contam com alguns subsídios do governo local. Apesar de serem associações sem fins lucrativos, muitos dos hospitais mais importantes estão afiliados a grandes corporações ou faculdades de medicina, que têm feito o possível para albergarem 70% de todos os pacientes médicos do país. O Hospital Johns Hopkins, a Mayo Clinic e o Massachusetts General Hospital se encontram entre os melhores hospitais do país e do mundo.
No entanto, ao contrário de todos os outros países desenvolvidos, os Estados Unidos são o único país do mundo ocidental que não tem um sistema de saúde pública universal e estima-se que cerca de 125 cidadãos norte-americanos morram todos os dias por não poderem pagar um plano de saúde, além de seus indicadores de saúde serem considerados os piores entre os países mais industrializados. Em 2004, os seguros privados de saúde pagaram por 36% dos gastos pessoais de saúde, os pagamentos privados corriqueiros por 15%, e os pagamentos federais, estaduais e de governos locais por 44%. Em 2005, 46,6 milhões de americanos, ou 15,9% da população, eram não segurados, 5,4 milhões a mais que em 2001. A principal causa deste aumento é a queda no número de americanos com seguro de saúde patrocinado por empregadores. A questão de americanos não segurados é uma importante questão política. Um estudo de 2009 estimou que a falta de seguro está associada com cerca de 45.000 mortes por ano. Em 2006, Massachusetts se tornou o primeiro estado do país a ter um mandato de seguro de saúde universal. Uma legislação federal aprovada no início de 2010 (o chamado "Patient Protection and Affordable Care Act"), que entrou em vigor em 2014, determinou a criação de um sistema de seguro de saúde quase universal no país.
Os Estados Unidos são uma nação multicultural, lar de uma grande variedade de grupos étnicos, tradições e valores. Além das já pequenas populações nativas americanas e nativas do Havaí, quase todos os americanos ou os seus antepassados emigraram nos últimos cinco séculos. A cultura em comum pela maioria dos americanos é a cultura ocidental em grande parte derivada das tradições de imigrantes europeus, com influências de muitas outras fontes, tais como as tradições trazidas pelos escravos da África. A imigração mais recente da Ásia e especialmente da América Latina adicionou uma mistura cultural que tem sido descrita tanto como homogeneizada quanto heterogênea, já que os imigrantes e seus descendentes mantêm especificidades culturais.
De acordo com a análise de dimensões culturais de Geert Hofstede, os Estados Unidos têm maior pontuação de individualismo do que qualquer país estudado. Apesar da cultura dominante de que os Estados Unidos sejam uma sociedade sem classes, estudiosos identificam diferenças significativas entre as classes sociais do país, que afetam a socialização, linguagem e valores. A classe média e profissional americana iniciou muitas tendências sociais contemporâneas como o feminismo moderno, o ambientalismo e o multiculturalismo. A autoimagem dos americanos, dos pontos de vista social e de expectativas culturais, é relacionada com as suas profissões em um grau de proximidade incomum. Embora os americanos tendam a valorizar muito a realização sócio-econômica, ser parte da classe média ou normal é geralmente visto como um atributo positivo. Embora o sonho americano, ou a percepção de que os americanos gozam de uma elevada mobilidade social, desempenhe um papel fundamental na atração de imigrantes, alguns analistas acreditam que os Estados Unidos têm menos mobilidade social que a Europa Ocidental e o Canadá.
As mulheres na sua maioria trabalham fora de casa e recebem a maioria dos diplomas de bacharel. Em 2007, 58% dos americanos com dezoito anos ou mais eram casados, 6% eram viúvos, 10% eram divorciados e 25% nunca haviam sido casados. O casamento entre pessoas do mesmo sexo é permitido em todos os estados desde 26 de junho de 2015, quando, ao final do caso "Obergefell v. Hodges", decidiu-se que era inconstitucional a proibição da união homoafetiva.
Desde finais do , o beisebol é considerado como o esporte nacional, enquanto o futebol americano, o hóquei no gelo e o basquete são outros três grandes esportes de equipe profissionais. As ligas universitárias também atraem grandes audiências. O futebol americano é o esporte mais popular no país. O boxe e a corrida de cavalo foram uma vez os esportes individuais mais vistos, mas foram substituídos pelo golfe e o automobilismo. O futebol vem crescendo de popularidade desde a criação da MLS.
A maioria dos esportes mais importantes do país evoluíram de práticas europeias, como o basquete, o voleibol, a animação e o snowboarding são esportes criados dentro do território nacional. O lacrosse e o surfe surgiram de povos ameríndios e nativos do Havaí. O Comitê Olímpico dos Estados Unidos organizou, em 1904, os Jogos Olímpicos de Verão, em St. Louis, Missouri; os Jogos de Los Angeles em 1932 e 1984 e mais recentemente os Jogos de Atlanta em 1996. Em 2004, os Estados Unidos conseguiram um total de 103 medalhas, das quais 35 eram de ouro. O país conquistou, ao total, 2 301 medalhas em Jogos Olímpicos de Verão, onde é o país que mais venceu, e 216 nos Jogos Olímpicos de Inverno, onde é o segundo país no ranking total, atrás apenas da Noruega.
As principais artes culinárias americanas são semelhantes às de outros países ocidentais. O trigo é o principal cereal. A cozinha tradicional americana utiliza ingredientes como peru, veado, carne de cervo de rabo branco, batata, batata doce, milho, abóbora e xarope de bordo, alimentos utilizados pelos povos nativos americanos e pelos colonizadores europeus. Carne de porco lentamente cozida e churrasco de carne, "crabcakes", batata frita e "cookies" de chocolate são pratos distintamente americanos. A "soul food", desenvolvida por escravos africanos, é popular em todo o Sul e entre muitos afro-americanos em todo o país. O sincretismo, como o presente nas culinárias crioula da Louisiana, Cajun e Tex-Mex, é regionalmente importante.
Pratos característicos como a torta de maçã, frango frito, pizza, hambúrgueres e cachorros-quentes decorrem das receitas de diversos imigrantes. Batatas fritas, pratos mexicanos como tacos e burritos e pratos de massas livremente adotados a partir de fontes italianas são amplamente consumidos. Americanos geralmente preferem café a chá. O "marketing" feito por indústrias do país é largamente responsável pela onipresença de suco de laranja e leite no café da manhã. Durante os anos 1980 e 1990, a ingestão calórica dos americanos aumentou 24%; as frequentes refeições de "fast-food" estão associadas com o que as autoridades de saúde chamam a "epidemia de obesidade" nos Estados Unidos. Refrigerantes adoçados são amplamente populares; bebidas adoçadas são responsáveis por 9% da ingestão calórica do americano médio.
A primeira exposição comercial de filme do mundo foi feita em Nova Iorque em 1894, usando o cinetoscópio de Thomas Edison. No ano seguinte foi feita a primeira exibição comercial de um filme projetado, também em Nova York, e os Estados Unidos estavam na vanguarda do desenvolvimento do cinema sonoro nas décadas seguintes. Desde o início do , a indústria cinematográfica americana tem sido largamente sediada nos arredores de Hollywood, na Califórnia. O diretor D. W. Griffith foi central para o desenvolvimento da gramática cinematográfica, e o filme "Cidadão Kane" (1941) de Orson Welles é frequentemente citado como o melhor filme de todos os tempos. Atores cinematográficos americanos como John Wayne e Marilyn Monroe se tornaram figuras icónicas, enquanto o produtor/empresário Walt Disney foi um líder em filmes animados e de "merchandising". Os grandes estúdios cinematográficos de Hollywood têm produzido os filmes de maior sucesso comercial da história, como "Star Wars" (1977) e "Titanic" (1997), e os produtos de Hollywood hoje dominam a indústria cinematográfica mundial.
Os americanos são os maiores espectadores de televisão do mundo, e o tempo médio de visualização continua a aumentar, chegando a cinco horas por dia em 2006. As quatro grandes redes de televisão do país são todas entidades comerciais. Americanos ouvem programas de rádio, também largamente comercializado, em média, pouco mais de duas horas e meia por dia. Além de portais e motores de busca, os sites mais populares no país são o Facebook, YouTube, Wikipédia, Blogger, eBay, Google e Craigslist.
Os estilos rítmicos e vocais da música negra americano influenciaram profundamente a música americana em geral, distinguindo-a das tradições europeias. Elementos da música folclórica, como o "blues" e o que é agora conhecido como "old-time music", foram aprovadas e transformadas em gêneros populares com público global. O "jazz" foi desenvolvido por artistas inovadores, tais como Louis Armstrong e Duke Ellington no início do . A música country foi desenvolvida na década de 1920, e o "rhythm and blues" na década de 1940. Elvis Presley e Chuck Berry foram um dos pioneiros do "rock and roll" em meados dos anos 1950. Em 1960, Bob Dylan surgiu a partir do "american folk music revival" para se tornar um dos compositores mais célebres do país e James Brown liderou o desenvolvimento do "funk". Mais recentes criações musicais americanas incluem o "rap" e a "house music". Astros "pop" americanos como Elvis Presley, Michael Jackson e Madonna tornaram-se celebridades globais.
No e início do , a arte e a literatura americana tinham a maioria das suas influências da Europa. Escritores como Nathaniel Hawthorne, Edgar Allan Poe e Henry David Thoreau estabeleceram uma voz literária americana distinta em meados do . Mark Twain e o poeta Walt Whitman foram figuras importantes na segunda metade do século; Emily Dickinson, praticamente desconhecida durante sua vida, é agora reconhecida como uma poetisa americana fundamental. Algumas obras são consideradas sínteses dos aspectos fundamentais da experiência nacionais e caráter, como "Moby Dick" (1851) de Herman Melville, "As Aventuras de Huckleberry Finn" (1885) de Mark Twain e "The Great Gatsby" (1925) de F. Scott Fitzgerald, obra apelidada de "Great American Novel".
Doze cidadãos americanos ganharam o Prêmio Nobel de Literatura, os mais recentes deles Toni Morrison, em 1993, e Bob Dylan, em 2016. Ernest Hemingway, Prêmio Nobel de 1954, é muitas vezes apontado como um dos escritores mais influentes do . Gêneros literários populares, como a ficção ocidental e a "Hard Boiled" foram desenvolvidas nos Estados Unidos. Os escritores da Geração Beat abriram novas abordagens literárias, assim como os autores pós-modernos, tais como John Barth, Thomas Pynchon e Don DeLillo.
Os transcendentalistas, liderados por Thoreau e Ralph Waldo Emerson, estabeleceram o primeiro grande movimento filosófico americano. Após a Guerra Civil, Charles Sanders Peirce e William James e John Dewey foram os líderes no desenvolvimento do pragmatismo. No , o trabalho de W. V. O. Quine e Richard Rorty, construído em cima de Noam Chomsky, trouxe a filosofia analítica à frente dos acadêmicos americanos. John Rawls e Robert Nozick levaram o renascimento da filosofia política.
Nas artes visuais, a Escola do Rio Hudson foi um movimento de meados do , na tradição do naturalismo europeu. O "Armory Show" de 1913, em Nova York, uma exposição de arte moderna europeia, chocou o público e transformou a cena artística americana. Georgia O'Keeffe, Marsden Hartley e outras experiências com novos estilos, exibindo uma sensibilidade muito individualista. Importantes movimentos artísticos como o expressionismo abstrato de Jackson Pollock e Willem de Kooning e da arte pop de Andy Warhol e Roy Lichtenstein foram desenvolvidos em grande parte nos Estados Unidos. A maré do modernismo e pós-modernismo trouxe fama para arquitetos estado-unidenses, como Frank Lloyd Wright, Philip Johnson e Frank Gehry.
Um dos primeiros promotores principais do teatro americano foi o empresário P. T. Barnum, que começou um complexo de entretenimento em Manhattan em 1841. A equipe de Harrigan e Hart produziu uma série de comédias musicais populares em Nova York no final dos anos 1870. No , a forma moderna de musicais surgiu na Broadway, as canções de compositores de teatro musical, como Irving Berlin, Cole Porter e Stephen Sondheim, tornaram-se padrões pop. O dramaturgo Eugene O'Neill ganhou o Prêmio Nobel de literatura em 1936. Outros dramaturgos americanos aclamados incluem vários vencedores do Prêmio Pulitzer como Tennessee Williams, Edward Albee e August Wilson.
Apesar de largamente ignorado na época, o trabalho de Charles Ives na década de 1910 estabeleceu-o como o primeiro grande compositor americano na tradição clássica; outros experimentalistas, tais como Henry Cowell e John Cage, criaram uma abordagem americana de composição clássica. Aaron Copland e George Gershwin desenvolveram uma síntese única de música popular e clássica. As coreógrafas Isadora Duncan e Martha Graham ajudaram a criar a dança moderna, enquanto George Balanchine e Jerome Robbins eram líderes no balé do . Os americanos têm sido importantes no meio artístico da fotografia moderna, com grandes fotógrafos, incluindo Alfred Stieglitz, Edward Steichen e Ansel Adams. As tirinhas de jornais e os "comics" são inovações americanas. Superman, o super-herói dos quadrinhos por excelência, tornou-se um ícone americano.

</doc>
<doc id="791" url="https://pt.wikipedia.org/wiki?curid=791" title="Exposição Mundial de 1998">
Exposição Mundial de 1998

A EXPO'98, Exposição Mundial de 1998, ou, oficialmente, Exposição Internacional de Lisboa de 1998, cujo tema foi "Os oceanos: um património para o futuro", realizou-se em Lisboa, Portugal de 22 de maio a 30 de setembro de 1998. Teve o propósito de comemorar os 500 anos dos Descobrimentos Portugueses.
A zona escolhida para albergar o recinto foi o limite oriental da cidade junto ao rio Tejo. Foram construídos diversos pavilhões, alguns dos quais ainda permanecem ao serviço dos habitantes e visitantes, integrados no agora designado "Parque das Nações", destacando-se o Oceanário (o maior aquário do Mundo com a reprodução de 5 oceanos distintos e numerosas espécies de mamíferos e peixes, do arquiteto Peter Chermayeff) um pavilhão de múltiplas utilizações (Pavilhão Atlântico, arquiteto Regino Cruz) e um complexo de transportes com metropolitano e ligações ferroviárias (Estação do Oriente, do arquiteto Santiago Calatrava).
A EXPO'98 atraiu cerca de 11 milhões de visitantes, apesar de previsões iniciais apontarem para cerca de 15 milhões, o que veio a justificar algumas opções de gestão de carácter duvidoso, e, acima de tudo, ruinosas para a empresa e seus acionistas. Parte do seu sucesso ficou a dever-se à vitalidade cultural que demonstrou - por exemplo, os seus cerca de 5000 eventos musicais constituíram um dos maiores festivais musicais da história da humanidade. Arquitetonicamente, a Expo revolucionou esta parte da cidade e influenciou os hábitos de conservação urbana dos portugueses - pode dizer-se que o Parque das Nações é um exemplo de conservação bem-sucedida dum espaço urbano.
A utilização pioneira de ferramentas de design para grandes projetos de arquitetura, engenharia e construção transformou a EXPO'98 num caso de estudo internacional na área do desenho assistido por computador (CAD). O exemplo pegou e outras obras seguiram também a mesma metodologia desta experiência transformada já em «case study».
O pioneirismo da EXPO foi, aliás, ressaltado por um trabalho de reportagem intitulado 'A Tale of Two Cities' publicado na edição de Junho de 1999, da Computer Graphics World (volume 22, nº6), a revista de referência internacional do sector.
«Os clássicos estiradores foram substituídos por estações de trabalho. Estávamos em 1993, o que provocou uma verdadeira revolução no modo de trabalhar típico deste sector e representou uma situação ímpar na história de grandes projetos no nosso país». O homem no centro desta operação foi José da Conceição Silva, um especialista de Informática da área de CAD/AEC, do Laboratório Nacional de Engenharia Civil (LNEC), de Lisboa, requisitado para a Parque Expo para responsável pelo Departamento de CAD, SIG, Web e Multimédia.
A ideia de organizar uma Exposição Internacional em Portugal surgiu em 1989 da parte de António Mega Ferreira e Vasco Graça Moura. Ambos estavam à frente da comissão para as comemorações dos 500 anos dos Descobrimentos portugueses liderada Por Francisco Faria Paulino, director do Pavilhão de Portugal na Exposição de Sevilha, tendo também desempenhado as funções de Secretário-Executivo e Comissário-Geral Adjunto da Comissão Nacional para as Comemorações dos Descobrimentos Portugueses entre 1988 e 1996. Assumiu funções de diretor do Pavilhão de Portugal na Exposição Universal de Sevilha e de Comissário-Geral Adjunto do Pavilhão de Portugal na Exposição Internacional de Génova em 1992. Em 2008, foi também Comissário Executivo das Comemorações dos 500 anos da Cidade do Funchal.
Uma vez obtido o apoio do Governo, Mega Ferreira apresentou o projecto ao Bureau International d'Expositions. A candidatura de Lisboa ganhou à de Toronto. Criou-se uma empresa, Parque Expo, com vista a criar um evento auto-sustentável que obtivesse receitas de bilhetes vendidos e pela venda de terrenos adjacentes à exposição.
O primeiro comissário da EXPO'98 foi António Cardoso e Cunha. Foi substituído em 1997 por José de Melo Torres Campos, já sob o governo do Partido Socialista.
Decidiu-se construir a exposição na zona oriental de Lisboa, que vira através dos anos uma degradação crescente. A antiga Doca dos Olivais fora nos anos 40 um contacto privilegiado com o rio onde atracavam hidroaviões, tendo sido denominada de Aeroporto de Cabo Ruivo. Quando os aviões a jacto de longo curso tornaram os hidroaviões obsoletos, a zona passou a ser um terreno industrial que conheceu uma degradação constante ao longo das décadas seguintes. A zona de 50 hectares onde hoje está o recinto era, no fim dos anos oitenta, um campo de contentores, matadouros e indústrias poluentes. Toda a exposição foi construída do zero. A torre da refinaria da Petrogal, única estrutura conservada, ficou como lembrança do espaço antes da intervenção. Houve um grande cuidado para que quase todos os equipamentos do recinto tivessem utilização posterior, evitando assim o seu abandono e a degradação, como aconteceu em Sevilha em 1992.
Em paralelo, lançaram-se grandes obras públicas. Entre as maiores estão a Ponte Vasco da Gama (a maior da Europa à data), uma nova linha de metro com sete estações e um interface rodo-ferroviário, a Gare do Oriente.
Foram emitidos bilhetes de um dia (5.000$00–25 euros), três dias (12.500$00–62,35 euros), e bilhetes diários apenas para a parte da noite (2500$00–12,50 euros). Existia também um passe livre com acesso ilimitado à exposição durante três meses (50.000$00–250 euros).
A Swatch lançou alguns meses antes da exposição o modelo Adamastor, que continha um chip carregado com um bilhete de um dia. Para entrar, bastava encostar o relógio ao sensor presente em todos os molinetes de entrada.
O tema musical da exposição foi composto em 1996 por Nuno Rebelo. A peça, de seu nome "Pangea" (o nome do super-continente pré-histórico de onde derivaram os actuais), misturava sobre guitarras portuguesas e uma base sinfónica de cariz épico muitas e díspares sonoridades, reminiscentes dos quatro cantos do mundo.
O logótipo da EXPO'98, representando o mar e o sol, foi concebido por Augusto Tavares Dias, diretor criativo de publicidade.
A mascote foi concebida pelo pintor António Modesto e pelo escultor Artur Moreira. Foi selecionada entre 309 propostas e batizada de Gil (em homenagem a Gil Eanes) por José Luís Coelho, um estudante do ciclo, num concurso que envolveu escolas de todo o país.
Durante a EXPO'98 houve dois tipos de pavilhões; os temáticos da responsabilidade da Parque EXPO (Departamento de Conteúdos), e os pavilhões das Regiões Autónomas, entidades convidadas e patrocinadores.
Pavilhões temáticos:
Outros pavilhões:
África do Sul; Angola; Argélia; Benim; Botsuana; Cabo Verde; Comores; Congo; Costa do Marfim; Djibuti; Egito; Eritreia; Guiné-Bissau; Lesoto; Madagáscar; Malawi; Mali; Marrocos; Maurícia; Mauritânia; Moçambique; Namíbia; Nigéria; Quénia; República Democrática do Congo; São Tomé e Príncipe; Senegal; Seychelles; Suazilândia; Sudão; Tanzânia; Tunísia; Uganda; Zâmbia; Zimbabwe.
Antígua e Barbuda; Argentina; Bahamas; Barbados; Belize; Bolívia; Brasil; Canadá; Chile; Colômbia; Cuba; Dominica; El Salvador; Equador; Estados Unidos; Granada; Guatemala; Guiana; Honduras; Jamaica; México; Nicarágua; Panamá; Paraguai; Peru; República Dominicana; Santa Lúcia; São Vicente e Granadinas; São Cristóvão e Névis; Suriname; Trinidad e Tobago; Uruguai; Venezuela.
Arábia Saudita; Arménia; Bangladesh; Cazaquistão; China; Chipre; Coreia do Sul; Emirados Árabes Unidos; Filipinas; Iémen; Índia; Irão; Israel; Japão; Jordânia; Kuwait; Líbano; Mongólia; Nepal; Palestina; Paquistão;Quirguistão; Sri Lanka; Turquia; Vietname.
Albânia; Alemanha; Andorra; Áustria; Bélgica; Bielorrússia; Bósnia e Herzegovina; Bulgária; Croácia; Dinamarca; Eslováquia; Eslovénia; Espanha; Estónia; Finlândia; França; Grécia; Holanda; Hungria; Islândia; Itália; Jugoslávia; Letónia; Lituânia; Luxemburgo; Macedónia; Mónaco; Noruega; Ordem de Malta; Polónia; Portugal; Reino Unido; Roménia; Rússia; Santa Sé; São Marino; Suécia; Suíça; Ucrânia.
Estados Federados da Micronésia; Ilhas Cook; Ilhas Salomão; Kiribati; Papua-Nova Guiné; Samoa Ocidental; Tonga; Tuvalu.
A exposição fechou as portas já ao nascer do dia 1 de Outubro de 1998. A última noite viu a maior enchente da sua história, tendo entrado no recinto depois das 20 horas cerca de 215 mil pessoas. A certo ponto da noite, e por razões de segurança, tiveram de ser destrancados os molinetes de acesso, o que faz com que nunca tenha havido um número certo para a quantidade de gente que se concentrou para ver o fogo-de-artifício de encerramento, o maior alguma vez realizado em Portugal.
De 1 a 15 de Outubro de 1998, o recinto esteve fechado ao público. Reabriu, já como Parque das Nações, recebendo nesse primeiro fim-de-semana mais de 100 mil visitantes. O Oceanário, o Pavilhão do Futuro, do Conhecimento dos Mares, permaneceram com as exposições que exibiram durante a EXPO'98 até ao dia 31 de Dezembro de 1998. 
Em Fevereiro de 1999 já era possível encontrar algumas alterações no Parque das Nações, tais como:
Muitas zonas do Parque das Nações foram sendo gradualmente vendidas para habitação e escritórios. No fim do processo de venda de terrenos, as receitas tinham superado o custo da exposição em oito vezes.
A zona oriental de Lisboa é hoje o bairro mais moderno da cidade, concentrando áreas comerciais, culturais e de lazer com uma vista privilegiada do rio Tejo. A zona atraiu uma série de instituições e empresas de grande nome, que aí basearam as suas sedes ou representações (Vodafone, Microsoft, Sonaecom SGPS, Sony etc.). Cerca de 28 mil pessoas habitam nas suas áreas residenciais Norte e Sul, integrando a freguesia do Parque das Nações.

</doc>
<doc id="792" url="https://pt.wikipedia.org/wiki?curid=792" title="Euro">
Euro

Euro (símbolo: €; código: EUR) é a moeda oficial da zona Euro, a qual é constituída por 19 dos 28 estados-membro da União Europeia: Alemanha, Áustria, Bélgica, Chipre, Eslováquia, Eslovénia, Espanha, Estónia, Finlândia, França, Grécia, Irlanda, Itália, Letónia, Lituânia, Luxemburgo, Malta, Países Baixos e Portugal. A moeda é também usada de forma oficial pelas instituições da União Europeia e por quatro outros países europeus e, de forma unilateral, por outros dois. Em 2013, a moeda era usada diariamente por cerca de 334 milhões de europeus. A moeda é também usada oficialmente em diversos territórios ultramarinos da UE.
A moeda é ainda usada por mais 210 milhões de pessoas em todo o mundo, das quais 182 milhões em África, que usam moedas de câmbio fixo em relação ao euro. O euro é a segunda maior moeda de reserva e a segunda moeda mais transaccionada no mundo a seguir ao dólar dos Estados Unidos. Com mais de 995 mi milhões de euros em circulação em 2014, o euro tem o maior valor combinado de notas e moedas em circulação no mundo, tendo ultrapassado o dólar norte-americano. Com base em estimativas do Fundo Monetário Internacional do PIB e da paridade do poder de compra, a zona euro é a segunda maior economia do mundo.
O nome "euro" foi oficialmente adotado em 16 de dezembro de 1995. O euro foi introduzido nos mercados financeiros mundiais enquanto unidade de conta a 1 de janeiro de 1999, em substituição da antiga Unidade Monetária Europeia (ECU), a um câmbio de 1:1 (1,1743 USD). As moedas e notas físicas de euro entraram em circulação a 1 de janeiro de 2002, tornando-a a moeda de uso corrente entre os membros originais. Embora nos primeiros dois anos a cotação do euro tenha descido para 0,8252 USD (26 de outubro de 2000), a partir do fim de 2002 começou a ser transacionada a valores superiores ao dólar, atingindo um máximo de 1,6038 USD em 18 de julho de 2008. A partir do fim de 2009, a crise da dívida pública da Zona Euro levou à criação do Fundo Europeu de Estabilização Financeira e à adoção de várias reformas de estabilização monetária.
A ideia do estabelecimento da moeda única na CEE nasceu já na década de 70. Teve como principais defensores os Economistas Fred Arditti, Neil Dowling, Wim Duisenberg, Robert Mundell, Tommaso Padoa-Schioppa e Robert Tollison. No entanto, só pelo Tratado de Maastricht, de 1992 esta ideia passou da teoria para o Direito. Este tratado foi celebrado pelos doze países que à data faziam parte da Comunidade Económica Europeia. O Reino Unido e a Dinamarca optaram neste tratado por ficar de fora da moeda única. Na teoria os países que aderissem posteriormente à União teriam que aderir à moeda única. A Suécia aderiu à União em 1995 mas negociou entrar numa fase posterior. Os critérios para adesão à nova moeda única foram estabelecidos pelo Pacto de Estabilidade e Crescimento de 1997.
O primeiro nome para o sistema de conversão entre as moedas que se uniriam foi o ECU (European Currency Unit em Inglês). O nome de Euro é atribuído ao Belga German Pirloit que assim o sugeriu a Jacques Santer em 1995. O valor da nova moeda foi ancorado ao do ECU por resolução do Conselho da União Europeia de 31 de dezembro de 1998. Esta entrou em vigor a 1 de janeiro de 1999 em forma não material (transferências, cheques, etc.) e a 1 de janeiro de 2002 em notas e moedas.
A Zona Euro é composta pelos seguintes países da União Europeia, que adotaram a moeda comum: Alemanha, Áustria, Bélgica, Chipre, Eslováquia, Eslovénia, Espanha, Estónia, Finlândia, França, Grécia, Irlanda, Itália, Letónia, Lituânia, Luxemburgo, Malta, Países Baixos e Portugal, prevendo-se que com a expansão da União Europeia alguns dos aderentes mais recentes possam nos próximos anos partilhar também o euro como moeda oficial.
O governo dinamarquês anunciou no seu programa de 22 de novembro de 2007 a sua intenção de organizar um referendo sobre a entrada do país na Zona Euro
Alguns países pequenos que não praticam políticas de moeda própria usam também o euro: Andorra, Mónaco, São Marino e Vaticano. Montenegro também utiliza o euro como sua moeda oficial. Também no Kosovo, o euro passou a circular mesmo antes da sua declaração de independência.
Outros países tinham a sua moeda fixada a uma antiga moeda europeia. Este era o caso do escudo cabo-verdiano, que estava ligado ao escudo português, e do franco CFA, que era indexado ao franco francês, em circulação em diversos países africanos, e o Franco CFP, dos territórios franceses no Pacífico.
O banco que controla as emissões do euro e executa a política cambial da União Europeia é o Banco Central Europeu, com sede em Frankfurt am Main, na Alemanha.
Acumulação internacional de moedas de reserva
Com a implementação da nova moeda no quotidiano, decidiu-se que as regras para a formação do plural da palavra (p.ex. "euro", "euros", "euri", "eurok"), o género, o uso da vírgula ou ponto para separação das casas decimais, e da posição do símbolo da unidade monetária manter-se-iam segundo as convenções nacionais de cada país.
Convenções para Portugal e para a língua portuguesa (e para a generalidade das línguas que não o inglês):
Em finais de 2011, foi enunciado em vários parlamentos europeus, mais notavelmente no Parlamento da França e no próprio Parlamento Europeu, a possibilidade de extinção do euro como moeda. Foi referido por François Fillon, primeiro-ministro francês, que o fim da moeda única seria catastrófico para o continente europeu, ao desvalorizar em 25% as economias mais fortes e em 50% as mais frágeis. Várias empresas, como a Autoeuropa, que tem um peso importante na economia portuguesa, avaliam já o cenário próximo de fim do Euro. Embora seja garantido por vários governantes um contínuo esforço de manutenção da moeda, as pressões de "rating" por parte dos mercados financeiros, têm credibilizado a possibilidade de tal acontecer.
Para adoptar o euro os Estados-membros terão de verificar os critérios de convergência, que impõem limites ao valor percentual do défice público e da taxa de inflação, entre outras condições.

</doc>
<doc id="796" url="https://pt.wikipedia.org/wiki?curid=796" title="Engenharia do ambiente">
Engenharia do ambiente

A engenharia ambiental ou engenharia do ambiente é o ramo da engenharia que atua nas áreas da avaliação ambiental, gestão ambiental, abastecimento e tratamento de água, drenagem e tratamento de águas pluviais e residuais, gestão de resíduos, gestão de ecossistemas, gestão de recursos hídricos, clima e qualidade do ar, acústica e vibrações, plano e ordenamento do território, energia, saúde ambiental e segurança e saúde no trabalho e gestão de solos e subsolos.
A engenharia do ambiente estuda os problemas ambientais de forma integrada nas suas dimensões ecológica, social, econômica e tecnológica, com vista a promover o desenvolvimento sustentável. O engenheiro ambiental deverá saber reconhecer, interpretar e diagnosticar impactos ambientais negativos e positivos, avaliar o nível de danos ocorridos no meio ambiente e propor soluções integradas de acordo com o direito do ambiente vigente. 
O Engenheiro Ambiental tem por função resolver problemas concretos de prevenção e remediação (atividade corretiva) diante das ações antrópicas mediante aplicações da tecnologia disponível, pontual e localmente apropriada. De modo geral, tanto no âmbito público como privado, sua atuação deve atender às preocupações ambientais mais amplas, consideradas em tratados internacionais como exigências relativas ao clima da Terra, entre outros.
São exemplos as determinações das Cartas de Estocolmo (1972), do Rio de Janeiro (ECO-92), a Convenção de Viena (1985), o Protocolo de Montreal (1987), relativo à camada de Ozônio, o Protocolo de Quioto (1997), o Protocolo de Annapolis e a Conferência promovida pela ONU em Bali (2007) quanto às mudanças climáticas.
De modo geral, sua atuação tem em vista condições de contorno ambientais próprias do entorno circundante. Deve também preocupar-se com o efeito abrangente por sobre a extensão territorial afetada - exemplificada pela bacia hidrográfica quanto às águas e, o potencial da emissão atmosférica potencialmente carregada pelos ventos para local distante. Evidentemente também prevenir sobre possibilidade de outros vetores capazes de provocar alterações de natureza diversa.
De outra parte, o planejamento e a antevisão dos impactos ambientais expandem a responsabilidade da análise prospectiva (atividade preventiva) por sobre o "vir a ser" das coisas. E torna-se agente do próprio desenvolvimento econômico em termos da ética vinculada ao progresso e bem estar da coletividade. Por este motivo, o seu mercado de trabalho é bastante heterogêneo e distribuí-se por: administração central, seus serviços descentralizados a nível regional, administração local, empresas industriais, empresas de consultoria, empresas de serviços, ONGs, instituições de investigação e ensino superior.
Uma das aptidões que devem ser desenvolvidas pelo engenheiro ambiental é a avaliação da duração, magnitude e reversibilidade das alterações causadas pela atividade humana no meio ambiente, independentemente de sua natureza adversa ou benéfica.
Algumas das áreas de atuação do engenheiro ambiental são¹:

</doc>
<doc id="802" url="https://pt.wikipedia.org/wiki?curid=802" title="Estados físicos da matéria">
Estados físicos da matéria

Fases ou estados da matéria são conjuntos de configurações que objetos macroscópicos podem apresentar. O estado físico tem relação com a velocidade do movimento das partículas de uma determinada substância. Canonicamente e segundo o meio em que foram estudados, são quatro os estados ou fases considerados:
Outros tipos de fases da matéria, como o condensado de bose-einstein ou o plasma são estudados em níveis mais avançados de física. As características de estado físico são diferentes em cada substância e dependem da temperatura e pressão em que ela se encontra.
Há muitas discussões sobre quantos estados da matéria existem, porém as versões mais populares atualmente são de que a matéria somente tem três estados: sólido, líquido e gasoso. Mas há também outros que, ou são intermediários ou pouco conhecidos. Por exemplo: os vapores, que nada mais são uma passagem do estado líquido para o gasoso na mesma fase em que o gás, porém quando está em estado gasoso, não há mais possibilidade de voltar diretamente ao estado líquido; já quando em forma de vapor, pode ir ao estado líquido, desde que exista as trocas de energia necessárias para tal fato. Por isto que diz comumente "vapor d´água".
Se colocarmos os estados físicos da matéria em ordem crescente, conforme a quantidade de energia que cada um possui, teremos:
Condensado de Bose-Einstein → Sólido → Líquido → Gasoso → Plasma
O Plasma é o estado em que a maioria da matéria se encontra no universo. Sabe-se que qualquer substância pode existir em três estados: sólido, líquido e gasoso, cujo exemplo clássico é a água que pode ser gelo, água em estado líquido e vapor de água. Todavia há pouquíssimas substâncias que se encontram nestes estados, que se consideram indiscutíveis a difundidos, mesmo tomando o Universo no seu conjunto. É pouco provável que superem o que em química se considera como restos infinitamente pequenos. Toda a substância restante do universo subsiste no estado denominado plasma.
No estado sólido considera-se que a matéria do corpo mantém a forma macroscópica e as posições relativas das suas partículas, as moléculas se encontram próximas umas das outras com forte atração entre elas, nestas condições, possui forma e volume próprio, independentemente do corpo onde se encontra e ainda o movimento é praticamente nada. É particularmente estudado nas áreas da estática e da dinâmica.
No estado líquido, o corpo mantém a sua quantidade de matéria e aproximadamente o seu volume. A forma e posição relativa das suas partículas é variável se adaptando conforme o corpo. As moléculas estão relativamente próximas, e a força de atração é mediana, assim como os movimentos. É particularmente estudado nas áreas da hidrostática e da hidrodinâmica.
No estado gasoso, o corpo mantém apenas a quantidade de matéria, podendo variar amplamente a forma e o volume, as partículas possuem força de atração nula e movimentos bruscos (agitação térmica). É particularmente estudado nas áreas da aerostática e da aerodinâmica.
O condensado de bose-einstein possui características, de ambos, estado sólido e estado líquido, como supercondutividade e super-fluidez, porém, é encontrado em temperaturas extremamente baixas (próximas ao zero absoluto), o que faz com que suas moléculas entrem em colapso. É particularmente estudado na área da mecânica quântica.
O condensado fermiônico é uma coleção de milhares de partículas ultrafrias ocupando um único estado quântico, ou seja, todos os átomos se comportam como um único e gigantesco átomo.
O Superfluido de Polaritons é um superfluido que é capaz de levar energia de um lugar para outro utilizando-se de um feixe de luz, também pode gerar raios laser potentes com baixo consumo e fazer transporte de bits em meio sólido.
Existem outros possíveis estados da matéria; alguns destes só existem sob condições extremas, como no interior de estrelas mortas, ou no começo do universo depois do Big Bang:
Perto do zero absoluto, alguns líquidos formam um segundo estado líquido descrito como superfluido porque tem viscosidade zero ou fluidez infinita. Isso foi descoberto em 1937 para o hélio, que constitui um superfluido abaixo da temperatura lambda de 2,17 K. Neste estado, ele vai tentar "subir" para fora do recipiente. Também tem condutividade térmica infinita, de modo que nenhum gradiente de temperatura pode se formar em um superfluido.
Essas propriedades são explicadas pela teoria de que o isótopo comum hélio-4 faz um condensado de Bose-Einstein (ver próxima seção), no estado superfluido. Mais recentemente, superfluidos de condensado fermiônico tem sido formados a temperaturas ainda mais baixas pelo raro isótopo hélio 3 e lítio-6.
Em 1924, Albert Einstein e Satyendra Nath Bose previram o "condensado de Bose-Einstein", por vezes referido como o quinto estado da matéria.
Na fase gasosa, o condensado de Bose-Einstein manteve uma previsão teórica não verificada durante muitos anos. Em 1995, os grupos de pesquisa de Eric Cornell e Carl Wieman, de JILA na Universidade do Colorado em Boulder, produziram pela primeira vez esse condensado experimentalmente. Um condensado Bose-Einstein é "mais frio" do que um sólido. Pode ocorrer quando os átomos têm níveis quânticos muito semelhantes (ou o mesmo), em temperaturas muito perto do zero absoluto (-273,15 °C).
Como a cada uma destas fases de uma substância corresponde determinado tipo de estrutura corpuscular, há vários tipos de mudanças de estruturas dos corpos quando muda a fase, ou de estado de aglomeração, da substância que são feitos. A mudança de fases ocorre conforme o diagrama de fases da substância. Mudando a pressão ou a temperatura do ambiente onde um objeto se encontra, esse objeto pode sofrer mudança de fase.

</doc>
<doc id="803" url="https://pt.wikipedia.org/wiki?curid=803" title="Engenharia de software">
Engenharia de software

Engenharia de Software é uma área da computação voltada à especificação, desenvolvimento, manutenção e criação de sistemas de "software", com aplicação de tecnologias e práticas de gerência de projetos e outras disciplinas, visando organização, produtividade e qualidade. Atualmente, essas tecnologias e práticas englobam linguagens de programação, banco de dados, ferramentas, plataformas, bibliotecas, padrões, processos e a questão da qualidade de software.
Os fundamentos científicos para a engenharia de software envolvem o uso de modelos abstratos e precisos que permitem ao engenheiro especificar, projetar, implementar e manter sistemas de software, avaliando e garantindo suas qualidades. Além disso, a engenharia de software deve oferecer mecanismos para se planejar e gerenciar o processo de desenvolvimento de um sistema computacional.
Friedrich Ludwig Bauer foi o primeiro dizendo: "Engenharia de "Software" é a criação e a utilização de sólidos princípios de engenharia a fim de obter software de maneira econômica, que seja confiável e que trabalhe em máquinas reais". Margaret Hamilton é creditada por ter criado o termo "engenharia de software".. O próprio significado de engenharia já traz os conceitos de criação, construção, análise, desenvolvimento e manutenção.
A Engenharia de "Software" se concentra nos aspectos práticos da produção de um sistema de "software", enquanto a ciência da computação estuda os fundamentos teóricos dos aspectos computacionais.
O termo foi criado na década de 1960 e utilizado oficialmente em 1968 na "NATO Science Committee". Sua criação surgiu numa tentativa de contornar a crise do software e dar um tratamento de engenharia (mais sistemático e controlado) ao desenvolvimento de sistemas de "software" complexos. Um sistema de "software" complexo se caracteriza por um conjunto de componentes abstratos de "software" (estruturas de dados e algoritmos) encapsulados na forma de procedimentos, funções, módulos, objetos ou agentes e interconectados entre si, compondo a arquitetura do software, que deverão ser executados em sistemas computacionais.
Os fundamentos científicos envolvem o uso de modelos abstratos e precisos que permitem ao engenheiro especificar, projetar, implementar e manter sistemas de "software", avaliando e garantindo suas qualidades. Além disto, deve oferecer mecanismos para se planejar e gerenciar o processo de desenvolvimento. Empresas desenvolvedoras de "software" passaram a empregar esses conceitos sobretudo para orientar suas áreas de desenvolvimento, muitas delas organizadas sob a forma de Fábrica de Software.
A engenharia de sistemas é uma área mais ampla por tratar de todos os aspectos de sistemas baseados em computadores, incluindo "hardware" e engenharia de processos além do "software".
A Universidade Federal de Goiás foi a primeira instituição no país a criar o curso de graduação em Engenharia de Software, tendo em constante evolução de sua grade curricular.
Segundo o SWEBOK (Corpo de Conhecimento da Engenharia de Software), versão 2004, as áreas de conhecimento da Engenharia de Software são:
Conforme Pressman, a Engenharia de Software (ES) é uma tecnologia em camadas. E a base de todas essas camadas é o foco na qualidade do software desenvolvido. Portanto, inclusive do ponto de vista didático, é interessante estudarmos a ES em suas camadas de Processo, Métodos e Ferramentas.
Processo de "software", ou processo de engenharia de software, é uma seqüência coerente de práticas que objetiva o desenvolvimento ou evolução de sistemas de "software". Estas práticas englobam as atividades de especificação, projeto, implementação, testes e caracterizam-se pela interação de ferramentas, pessoas e métodos.
SEE e PSEE são os ambientes voltados ao desenvolvimento e manutenção de processos. O projeto ExPSEE é uma continuação dos estudos de processos, principalmente do ambiente PSEE.
Devido ao uso da palavra projeto em muitos contextos, por questões de clareza, há vezes em que se prefira usar o original em inglês design.
Um modelo de processo de desenvolvimento de software, ou simplesmente modelo de processo, pode ser visto como uma representação, ou abstração dos objetos e atividades envolvidas no processo de software. Além disso, oferece uma forma mais abrangente e fácil de representar o gerenciamento de processo de software e consequentemente o progresso do projeto.
Exemplos de alguns modelos de processo de software;
Os modelos de maturidade são um metamodelo de processo. Eles surgiram para avaliar a qualidade dos processos de "software" aplicados em uma organização (empresa ou instituição). O mais conhecido é o "Capability Maturity Model Integration" (CMMi), do Software Engineering Institute - SEI.
O CMMI pode ser organizado através de duas formas: Contínua e estagiada.
Pelo modelo estagiado, mais tradicional e mantendo compatibilidade com o CMM, uma organização pode ter sua maturidade medida em 5 níveis:
O (MPS.BR), ou Melhoria de Processos do Software Brasileiro, é simultaneamente um movimento para a melhoria e um modelo de qualidade de processo voltada para a realidade do mercado de pequenas e médias empresas de desenvolvimento de software no Brasil. O MPS.BR contempla 7 níveis de maturidade, de A a G, sendo a primeira o mais maduro. Até agosto/2012, no Brasil, há somente 2 empresas neste nível.
O termo metodologia é bastante controverso nas ciências em geral e na Engenharia de Software em particular. Muitos autores parecem tratar metodologia e método como sinônimos, porém seria mais adequado dizer que uma metodologia envolve princípios filosóficos que guiam uma gama de métodos que utilizam ferramentas e práticas diferenciadas para realizar algo.
Assim teríamos, por exemplo, a Metodologia Estruturada, na qual existem vários métodos, como Análise Estruturada e Projeto Estruturado (muitas vezes denominados SA/SD, e Análise Essencial).
Dessa forma, tanto a Análise Estruturada quanto a Análise Essencial utilizam a ferramenta Diagrama de Fluxos de Dados para modelar o funcionamento do sistema.
Segue abaixo as principais Metodologias e Métodos correspondentes no desenvolvimento de software:
A abstração do sistema de "software" através de modelos que o descrevem é um poderoso instrumento para o entendimento e comunicação do produto final que será desenvolvido.
A maior dificuldade nesta atividade está no equilíbrio ("tradeoff") entre simplicidade (favorecendo a comunicação) e a complexidade (favorecendo a precisão) do modelo.
Para a modelagem podemos citar 3 métodos:
A engenharia de software aborda uma série de práticas e tecnologias, principalmente estudadas pela ciência da computação, enfocando seu impacto na produtividade e qualidade de "software".
Destacam-se o estudo de linguagem de programação, banco de dados e paradigmas de programação, como:
Outro ponto importante é o uso de ferramentas CASE (do inglês "Computer-Aided Software Engineering"). Essa classificação abrange toda ferramenta baseada em computadores que auxiliam atividades de engenharia de "software", desde a análise de requisitos e modelagem até programação e testes.
Os ambientes de desenvolvimento integrado (IDEs) têm maior destaque e suportam, entre outras coisas:
A gerência de projetos se preocupa em entregar o sistema de "software" no prazo e de acordo com os requisitos estabelecidos, levando em conta sempre as limitações de orçamento e tempo.
A gerência de projetos de software se caracteriza por tratar sobre um produto intangível, muito flexível e com processo de desenvolvimento com baixa padronização.
O planejamento de um projeto de desenvolvimento de "software" inclui:
Essas atividades sofrem com dificuldades típicas de desenvolvimento de "software". A produtividade não é linear em relação ao tamanho da equipe e o aumento de produtividade não é imediato devido aos custos de aprendizado de novos membros. A diminuição de qualidade para acelerar o desenvolvimento constantemente prejudica futuramente a produtividade.
A estimativa de dificuldades e custos de desenvolvimentos são muito difíceis, além do surgimento de problemas técnicos. Esses fatores requerem uma análise de riscos cuidadosa.
Além da própria identificação dos riscos, há que ter em conta a sua gestão. Seja evitando, seja resolvendo, os riscos necessitam ser identificados (estimando o seu impacto) e devem ser criados planos para resolução de problemas.
As atividades de análise concentram-se na identificação, especificação e descrição dos requisitos do sistema de "software". Em resumo, requisito é uma necessidade que o "software" deve cumprir.
Há várias interpretações e classificações sobre requisitos, entre elas:
É comum que o cliente não saiba o que ele realmente deseja, que haja problemas na comunicação e ainda que haja mudança constante de requisitos. Todos esses fatores são recrudescidos pela intangibilidade sobre características de sistemas de "software", principalmente sobre o custo de cada requisito.
A Engenharia de requisitos é um processo que envolve todas as atividades exigidas para criar e manter o documento de requisitos de sistema (SOMMERVILLE). Segundo RUMBAUGH, alguns analistas consideram a engenharia de Requisitos como um processo de aplicação de um método estrutura como a análise orientada a objetos. No entanto, a Engenharia de requisitos possui muito mais aspectos do que os que estão abordados por esses métodos.
Abaixo um pequeno Processo de Engenharia de Requisitos (SOMMERVILLE).
Estudo da viabilidade → "Relatório de Viabilidade"
Obtenção e Análise de Requisitos → "Modelos de Sistema"
Especificação de Requisitos → "Requisitos de Usuário e de Sistema"
Validação de Requisitos → "Documento de Requisitos"
O primeiro processo a ser realizado num Sistema novo é o Estudo de Viabilidade. Os resultados deste processo devem ser um relatório com as recomendações da viabilidade técnica ou não da continuidade no desenvolvimento do Sistema proposto. Basicamente um estudo de viabilidade, embora seja normalmente rápido, deverá abordar fundamentalmente as seguintes questões:
Existem cinco tipo de gestões: pessoal, produto, processo, projeto e material.
A Engenharia de Software (ES) surgiu em meados dos anos 1970 numa tentativa de contornar a crise do software e dar um tratamento de engenharia (mais sistemático e controlado) ao desenvolvimento de sistemas de software complexos. Um sistema de software complexo se caracteriza por um conjunto de componentes abstratos de software (estruturas de dados e algoritmos) encapsulados na forma de procedimentos, funções, módulos, objetos ou agentes interconectados entre si, compondo a arquitetura do software, que deverão ser executados em sistemas computacionais.
Atualmente existe um destaque todo especial para a Engenharia de Software na Web. Também utilizado por Presmann a sigla WebE, é o processo usado para criar WebApps (aplicações baseadas na Web) de alta qualidade. Embora os princípios básicos da WebE sejam muito próximos da Engenharia de Software clássica, existem peculiaridades específicas e próprias.
Com o advento do B2B (e-business) e do B2C (e-commerce), e ainda mais com aplicações para a Web 2.0, maior importância ficou sendo esse tipo de engenharia. Normalmente adotam no desenvolvimento a arquitetura MVC (Model-View-Controller).
Outra área de tendência em Engenharia de Software trata da aplicação de técnicas otimização matemática para a resolução de diversos problemas da área. A área, denominada Search-based software engineering, ou Otimização em engenharia de software em Português, apresenta vários resultados interessantes. Para mais detalhes em Português, ver texto com aplicações da otimização em engenharia de software.
O Brasil atualmente conta com diversos cursos de nível superior em Engenharia de Software nas seguintes instituições reconhecidas pelo MEC: UnB, UFRN, Universidade do Estado de Santa Catarina, Universidade Federal do Ceará, Universidade Federal de Goiás, Universidade de Rio Verde, Unipampa, UniCesumar, UTFPR e PUCRS
Eventos acadêmicos também mostram tópicos interessantes sobre futuras tendências de engenharia de software. O Brasil em 2013 sedia grandes eventos de engenharia como a Conferência Internacional de Engenharia de Requisitos e a Escola Latino Americana de Engenharia de Software.

</doc>
<doc id="805" url="https://pt.wikipedia.org/wiki?curid=805" title="Engenharia civil">
Engenharia civil

A engenharia civil é o ramo da engenharia que engloba a concepção, o projeto, construção e manutenção de todos os tipos de infraestrutura necessários ao bem estar e ao desenvolvimento da sociedade, além da preservação do ambiente natural. Desta forma, esta área dedica-se à criação de edifícios, pontes, túneis, usinas geradoras de energia, indústrias e inúmeros outros tipos de estrutura.
Desde o início da história, os humanos passaram a construir seus próprios abrigos utilizando os elementos naturais ao seu redor. Posteriormente, as estruturas adquiriram características cada vez mais complexas, reflexo do desenvolvimento das técnicas. Passou-se então, a utilizar conhecimentos científicos nesta área, de forma que as dimensões, a resistência e outros atributos de uma determinada obra podiam ser estimados. Novos materiais passaram a ser utilizados, sobretudo ferro e cimento, que possibilitaram o surgimento das grandes estruturas que hoje compõem o cenário do mundo moderno.
Desta forma, a formação de um engenheiro civil é fortemente ligada às ciências exatas. Contudo, um bom profissional deve conter muitos outros atributos, principalmente habilidades em comunicação e de análise racional dos fatos, além de seguir um código de ética, visto que suas obras influenciam significativamente em todos os segmentos da sociedade. Dada a vasta abrangência, a engenharia civil divide-se em vários campos específicos, desde geotecnia, mapeamento, até transportes, construção e estrutural, dentre muitas outras.
A designação "engenharia civil" foi inicialmente utilizada por oposição à de "engenharia militar". Designava assim, toda a engenharia não militar. Com o passar do tempo e na maioria dos países, o termo passou a ser utilizado num âmbito mais restrito, referindo-se apenas ao ramo da construção, com os outros ramos da engenharia a receberem designações distintas (ex., industrial, agrícola, posteriormente outras). Contudo, em alguns países como a Bélgica, a Dinamarca, a França, a Noruega e a Suécia, os engenheiros não militares são ainda genericamente referidos como "engenheiros civis", independentemente da sua especialidade ser a construção ou outra (mecânica, química, eletricidade, etc.).
Desde o início da existência humana, conhecimentos e habilidades de engenharia tem sido necessários para evolução do padrão de vida. A partir do momento em que tribos deixaram de ser nômades, surgiram assentamentos que necessitavam de estrutura necessária para abrigo e proteção que, ao longo do tempo, cresceram em complexidade. Ao decorrer dos séculos, a grande demanda por estruturas cada vez maiores e mais eficientes impulsionava o surgimento de novas técnicas e a formação de profissionais habilitados para assumir tal responsabilidade. Entretanto, a profissão de engenheiro civil só foi reconhecida oficialmente a partir da Revolução Industrial.
São diversas as obras remanescentes que atestam o desenvolvimento da engenharia civil ao longo de milênios. Os registros escritos destas construções, contudo, se perderam no tempo. Grandes obras de engenharia surgiram há mais de cinco mil anos na Mesopotâmia, embora haja poucos edifícios remanescentes. Os sumérios que habitavam a região construíram muros e templos e criaram canais para irrigação. Ainda na mesma região surgiu a pavimentação, feita com pedras achatadas colocadas nos trajetos mais movimentados das cidades. Ainda na Mesopotâmia há registro da primeira ponte feita de pedra, que se estendia sobre o rio Eufrates. Até então, as pontes eram feitas somente com madeira.
Os pérsios, ao longo do tempo e de seus vastos domínios, foram responsáveis por criar novas e eficientes técnicas de irrigação, além de inovarem nas técnicas construtivas de pontes, especialmente para fins militares. No Antigo Egito, dentre as mais notáveis obras de engenharia destacam-se as Pirâmides de Gizé, feitas há mais de quatro mil anos, e a cidade de Alexandria (durante a era de Alexandre, o Grande), na qual foi concebido um grande farol, não mais existente. Contudo, na Grécia Antiga, houve, pela primeira vez, a conexão entre a engenharia e a ciência pura, sendo um dos primeiros trabalhos considerando aplicações práticas de princípios físicos e matemáticos atribuído à Arquimedes, que criou um sistema capaz de transportar água para diferentes elevações.
Durante a expansão do Império Romano, houve o surgimento de novas técnicas construtivas, especialmente a partir da grande oferta de matérias-primas e trabalho escravo. Embora não tenha grande ligação com a ciência, a engenharia praticada pelos romanos estava fortemente ligada ao pragmatismo. As grandes estruturas eram voltadas sobretudo para bens públicos, como aquedutos, portos, mercados, pontes, barragens e estradas. Vitrúvio foi o autor de um dos manuscritos mais antigos sobre engenharia, no qual descreve as técnicas e habilidades que um profissional deve dominar, como conhecimentos científicos, filosóficos e éticos, dentre outros. Os romanos também foram os primeiros a utilizar concreto em suas obras, quando descobriu-se que uma mistura formada principalmente por cinzas vulcânicas solidificava-se e dava origem a um material tão duro quanto as rochas.
Na Índia a maior parte das construções eram feitas com madeira. Contudo, a partir do surgimento do budismo, novos e grandes templos e monastérios foram construídos no topo e nas bordas das montanhas, o que exigiu novas técnicas que faziam o uso de pedras e rochas. De forma similar, o hinduísmo motivou o surgimento de grandes templos construídos com pedras. As técnicas de engenharia na China, por outro lado, desenvolveram-se de forma quase independente àquelas do mundo ocidental. Os chineses utilizavam-se da grande variedade de matérias primas existentes em seu território para construção das fundações de pedra e casas de tijolos e telhados de argila. Destaca-se, ainda o surgimento de pontes suspensas antes feitas com fibras de bambu e posteriormente com correntes de ferro, além dos pagodes, templos em forma de torres. Contudo, a mais notável obra ainda remanescente é a Muralha da China, que se estende por milhares de quilômetros e cuja construção iniciou-se em 220 a.C.
No continente africano ao sul do deserto do Saara, as obras com estilos mais simples utilizavam-se dos materiais existentes e dependiam da cultura das milhares de etnias diferentes do continente. Destaca-se, contudo, um local de cunho religioso, o Grande Zimbabwe, cuja origem remonta ao século XI. Na América, por fim, as grandes civilizações inovaram em técnicas que os permitiram criar grandes templos, especialmente de cunho religioso. Durante a civilização Maia, muitas grandes obras foram realizadas, das quais destaca-se a cidade de Teotihuacan. Os Incas, séculos depois, estenderam seus domínios na cordilheira dos Andes e criaram elementos de infraestrutura como pontes, estradas e complexos urbanos, centralizados na então capital, Cusco. Dentre os principais feitos dos Astecas, contemporâneos dos Incas, destaca-se a cidade de Tenochtitlán, capital do império dotada de complexos componentes urbanos, localizada numa região pantanosa no centro de um lago.
O Império Romano, devido à sua grande extensão e falta de governo central, não conseguiu se manter unido e chegou ao fim no ano de 476. Muitas das obras de infraestrutura, inclusive estradas, aquedutos e portos então existentes, foram demolidas para construção de fortificações. Durante todo o período medieval, quase não houve avanços científicos, o que afetou também o desenvolvimento de técnicas de engenharia, que passaram a se restringir a conceitos práticos pouco estruturados. Os árabes, sobretudo durante o período da expansão islâmica, incorporaram técnicas romanas sobretudo utilizadas em fortificações, embora já possuíssem conhecimentos na construção de grandes mesquitas.
Não havia método científico nas construções, pelo que eram baseadas no sistema de tentativa e erro, sendo numerosos os exemplos de colapso de estruturas. Neste período nota-se, ainda, a criação de grandes fortificações em castelos, para prevenir invasões. Houve um avanço na utilização de rodas de água para transportar água e mover moinhos. Ocorreram também avanços na construção de canais navegáveis.
A partir da Renascença, o profissional engenheiro passou a ganhar importância e reconhecimento, ao contrário do período medieval em que projetos eram criados por artesãos. Um dos pioneiros do período foi Filippo Brunelleschi, que projetou o domo da catedral de Santa Maria del Fiore em Florença. Ainda com o surgimento da impressão de livros, começaram a surgir os primeiros manuais com técnicas de projeto e construção.
Posteriormente, a Revolução Industrial começava a mudar radicalmente o perfil da Inglaterra, o que posteriormente viria a acontecer no restante da Europa. A população começou a migrar da zona rural para as cidades para trabalharem nas indústrias. As obras estruturais necessárias para o desenvolvimento industrial era geralmente conduzida por engenheiros militares. No entanto, em 1768, o inglês John Smeaton se autodenominou 'engenheiro civil' para diferenciar-se dos profissionais militares, criando assim uma nova e distinta profissão. Poucos anos depois criou a Sociedade dos Engenheiros Civis, com a finalidade de reunir profissionais para conceber e executar grandes projetos.
A Revolução Industrial trouxe consigo novas técnicas e materiais pertinentes à engenharia. A Ponte de Ferro, no Reino Unido, foi a primeira ponte de arco construída somente com ferro fundido, o que é considerado um marco na história. Conforme ocorria o crescimento econômico, era cada vez maior a necessidade de se acelerar os transportes. Por isso, houve grande ampliação do sistema de canais e posteriormente surgiu a primeira ferrovia. A utilização do ferro como elemento estrutural causou grandes mudanças, especialmente por conta de sua resistência, capacidade de pré-fabricação e facilidade de montagem. Os engenheiros civis, a partir de então, puderam inovar no formato dos prédios, além de agilizar sua construção. Houve ainda inovação no que se refere à construção de túneis, a partir do primeiro construído sob o rio Tâmisa em Londres para a criação do sistema metroviário londrino.
A partir do século XX, a engenharia como um todo passou a se desenvolver e se especializar sobretudo por conta dos avanços científicos e fundamentações teóricas do comportamento dos materiais. A partir de então surgiram grandes estruturas antes inimagináveis, como o Viaduto de Millau, na França, a mais alta ponte para veículos do mundo, e o Burj Khalifa, o mais alto edifício do mundo, com mais de oitocentos metros de altura. A Sociedade Americana de Engenheiros Civis compilou uma lista com as sete maravilhas do mundo moderno, das quais destacam-se o Eurotúnel, sob o estreito de Dover entre o Reino Unido e a França, o canal do Panamá, que liga o oceano Pacífico ao Atlântico e a Usina Hidrelétrica de Itaipu entre o Brasil e o Paraguai.
A demanda de profissionais especializados logo demandou o surgimento de centros de ensino voltados para a engenharia. O primeiro deles foi a École Polytechnique em Paris, criada no ano de 1794. Várias décadas depois academias surgiram pela Europa e Estados Unidos, onde, em 1835, formaram-se os primeiros engenheiros civis pela Instituto Politécnico Rensselaer.
É necessária para a formação de um engenheiro civil uma forte base na área de ciências exatas, especialmente matemática e física, além da análise de dados, concepção, planejamento e execução de sistemas, identificação e solução de problemas e uso prático de técnicas e habilidades. Desta forma, o curso geralmente apresenta uma combinação de várias especialidades científicas, como mecânica, hidráulica, geotécnica, ciências dos materiais e análises estatísticas. Estes conhecimentos passam a ser aplicados para o desenvolvimento de projetos, especialmente com o uso de ferramentas de desenho assistido por computador (CAD). O período de formação em engenharia civil leva entre três anos para o grau de licenciatura ou cinco anos para o grau de mestrado. São grandes ainda as opções de especialização, dada a vasta gama de temas que um curso de engenharia civil abrange. Deve haver ainda uma preocupação durante a formação no que se refere a conceitos de legislação, economia e ética, uma vez que as atividades de um engenheiro civil afetam grande parte dos segmentos da sociedade.
Um engenheiro civil é um profissional capacitado para conceber, projetar e construir os mais diversos componentes da infraestrutura necessários para o bem-estar e desenvolvimento da sociedade. O local de trabalho de um engenheiro varia conforme a especialidade escolhida, embora a maioria trabalhe em firmas de consultoria, que criam projetos e soluções para construção de determinada estrutura. Existem ainda muitas possibilidades no setor público, desde o âmbito municipal até federal, além da possibilidade de atuar em carreira militar ou no setor industrial. Tipicamente o engenheiro precisa visitar os locais de obra e trabalhar com diferentes equipes técnicas especializadas. A Associação Americana de Engenheiros Civis define engenharia civil como sendo:
Em geral, um engenheiro civil deve ser um profissional devidamente preparado com base em aspectos teóricos que lhe conferem uma habilidade de análise racional das situações. Desta forma, é necessária uma sólida formação em ciências exatas, especialmente matemática e física. Além disso, o profissional deve seguir um código de ética, dada a importância de sua função na sociedade, que inclui realizar seu trabalho de forma responsável, buscando sempre contribuir ao máximo para o bem estar da sociedade. Um atributo indispensável de um engenheiro civil é a sua capacidade de comunicação e liderança, visto que frequentemente é necessária a coordenação entre diversos tipos de profissionais para uma determinada finalidade.
Existem na maioria dos países associações de engenheiros civis que buscam a troca de conhecimento e a divulgação e aperfeiçoamento de técnicas. As pioneiras e atualmente mais importantes são o Instituto Britânico de Engenheiros Civis e a Sociedade Americana de Engenheiros Civis. Para exercer a profissão, o engenheiro civil precisa obter certificação e licença formal, tipicamente fornecida por estas associações. No Brasil, a certificação é fornecida pelo Conselho Federal de Engenharia e Agronomia, através de seus conselhos regionais. Em Portugal, a validação do diploma é feita pela Agência de Avaliação e Acreditação do Ensino Superior.
As tendências atribuídas para a engenharia civil estão diretamente relacionadas às transformações naturais, sociais e econômicas que o mundo tem experimentado nas últimas décadas. Com a migração da população para as cidades será necessário a utilização racional dos recursos naturais, utilizando meios sustentáveis de desenvolvimento. Será necessário o aumento, melhoria e manutenção da infraestrutura urbana, além da maior preocupação no fornecimento de água, energia aliados à correta disposição dos resíduos gerados. Desta forma, o engenheiro tem papel fundamental na determinação dos rumos do desenvolvimento, tendo em vista os benefícios à sociedade e a proteção do ambiente.
A engenharia civil, por sua própria natureza, é uma área na qual erros causam grandes consequências. Desta forma, o profissional deve desenvolver com o máximo de atenção para evitar erros atribuídos a omissões, falta de planejamento, erros durante o processo de construção e relacionados à qualidade dos componentes. Há a necessidade de avaliação cuidadosa do ambiente na qual determinada estrutura será instalada, a fim de garantir sua durabilidade a longo prazo. Um engenheiro precisa, ainda, ser capaz de aprender com erros anteriores relatados em outras obras, de forma que haja minimização dos riscos. Dentre os exemplos notáveis de falhas estão o desabamento do teto do terminal 2 do Aeroporto de Paris-Charles de Gaulle em 2004 e a Ponte Tacoma Narrows que, em 1940, entrou em colapso por ação do vento.
Um engenheiro civil tipicamente interage com a interface dos projetos e seu ambiente de implantação. Em geral é capaz de aplicar os princípios básicos de construção, estruturais, geotécnicos, hidráulicos e de transporte para a construção de edifícios residenciais, industriais ou outras obras públicas de diferentes tipos e finalidades. Contudo, há a necessidade de se interagir em diversas ocasiões com profissionais especializados em uma determinada área, dada a abrangência desta profissão.
Dentre as áreas de atuação de um engenheiro civil, está a de Recursos Energéticos. Esse profissional pode se relacionar com fontes de energia relacionadas com Engenharia ambiental, como as tradicionais, alternativas e renováveis, com sistemas e métodos de conversão e conservação de energia, com impactos energéticos ambientais e com a eficientização ambiental de sistemas energéticos vinculados ao campo de atuação da engenharia ambiental.
Como é característica da área de engenharia civil, há diversas funções que podem ser desempenhadas por esse engenheiro que envolve recursos energéticos. O mercado de trabalho é constituído por Empresas Públicas, Privadas ou de Economia Mista, Órgãos Governamentais nas três esferas de governo, além de organizações sociais de interesse público e Organizações não Governamentais.
As atividades desenvolvidas são várias, dentre elas o diagnóstico do melhor tipo e melhores condições de uso de energia, planejar e coordenar o processo de implantação de usinas e analisar os impactos (sociais, econômicos e ambientais) no local de instalação, desenvolver tecnologia para a geração, uso e transformação de energia e a otimização do consumo de energia nas indústrias, com o objetivo de reduzir gastos.
Os locais de atuação podem ser em escritórios ou em campo, fixo ou variável, dependendo da atividade desenvolvida pelo profissional. Por exemplo, para analisar impactos de instalação de usinas, o trabalho envolve pesquisa em campo e em escritório.
Este ramo lida com a execução e gerenciamento de obras, levando em conta custos, eficiência e segurança. Dentre as atividades desenvolvidas, destacam-se a criação de fundações, concretagem, acabamento, construção de pontes e túneis, dentre muitos outros exemplos. O profissional especializado nesta área deve possuir domínio sobre as técnicas e equipamentos modernos disponíveis. Dentre as funções de gerenciamento busca-se a economia e a utilização racional dos recursos disponíveis com o objetivo principal de aumentar a eficiência. O profissional é responsável ainda pela utilização dos materiais de qualidade que visem a segurança e a durabilidade da obra a longo prazo, além de organizar toda a logística necessária para o transporte e a utilização dos materiais, funcionários e equipamentos. Este segmento lida ainda com os aspectos legais de uma obra, como a criação e revisão de contratos e concordância com a legislação vigente.
Esta subdisciplina tem como fundamento o estudo das infraestruturas relacionadas direta ou indiretamente com sistemas de transportes e seu possível desenvolvimento e manutenção. O princípio básico desta área é o transporte de pessoas e mercadorias de forma rápida, econômica e segura. Desta forma, esta especialidade lida com o planejamento e manutenção de rodovias, ferrovias, sistema hidroviários e aeroviário e sua interação, de forma a criar uma rede eficiente. Desta forma, o engenheiro de transporte pode atuar desde a concepção de uma via de trasporte e sua construção até o planejamento e gerenciamento do tráfego.
Focada no projeto de estruturas em edificações, a engenharia estrutural busca a concepção de elementos seguros e econômicos para fornecer rigidez e resistência a um edifício. Portanto, são necessários o uso de princípios físicos, conhecimento das características dos materiais e ferramentas computacionais para realizar o dimensionamento correto de vigas, colunas e outros elementos, inclusive a fundação. O engenheiro estrutural pode escolher dentre os diversos materiais disponíveis no mercado, de acordo com a necessidade de cada projeto. Pode atuar nos mais diversos segmentos de obras, desde prédios, pontes e túneis até plataformas de petróleo e gás em alto mar.
O campo dos recursos hídricos incluem uma série de métodos e conhecimentos relacionados a processos hidrológicos e hidráulicos utilizados como base para o planejamento e dimensionamento de estruturas para realizar o fornecimento de água, prevenção de enchentes, criação de redes de irrigação e geração de energia, dentre muitas outras aplicações. Em geral, este ramo engloba todos os campos do conhecimento que, de alguma forma, relacionam-se com a água, desde o subsolo, rios, lagos e oceanos até o gerenciamento de água da chuva. Além de sistemas de distribuição de água, um engenheiro hidráulico atua na construção de canais, usinas hidroelétricas, sistemas de proteção costeiros, dentre inúmeros outros exemplos. Um engenheiro hídrico também deve preocupar-se com os impactos ambientais de suas obras, especialmente sobre a vida aquática, além de aspectos dos arredores como estética e utilização pública.
A engenharia geotécnica é o ramo que se preocupa com os componentes que se encontram na superfície terrestre, como o solo e as rochas, e sua principal aplicação refere-se ao comportamento e a capacidade destas estruturas ao receberem sobre si a fundação das demais obras de infraestrutura, especialmente suas fundações. Dentre os atributos analisados na mecânica dos solos e das rochas, incluem sua origem, distribuição granulométrica, capacidade de drenagem, resistência à compressão e capacidade de cargas, dentre outros.
A análise destas variáveis é necessária para que se obtenha segurança e firmeza duradouras, uma vez que todo o peso de uma determinada estrutura é transferido para o solo, e este deve ser capaz de suportar tal estrutura. Um dos exemplos mais notáveis de erros relacionados ao mal planejamento geotécnico é a Torre de Pisa, inclinada porque o solo sob sua base não suportou o peso e afundou, de forma que a torre perdesse seu alinhamento. Reforços na estrutura são responsáveis por mantê-la ainda de pé.
Lida com a interação entre os elementos abióticos e a biosfera, especialmente no que se refere à proteção ambiental, manejo de recursos e minimização dos impactos ambientais. Destaca-se nesta área de atuação a distribuição de água e criação de infraestruturas para o saneamento básico. Com a crescente urbanização, tornou-se cada vez maior a demanda de componentes hidrossanitários e, consequentemente, manutenção da saúde pública. Os resíduos gerados também precisam ser tratados para que não haja poluição dos rios ou de qualquer outro local de despejo. Muitos locais, contudo, ainda enfrentam problemas severos com a poluição, especialmente provocada por detritos industriais, além do despejo incorreto de lixo, dentre outros. Desta forma, a engenharia ambiental procura entender todos os impactos provocados no ambiente e suas consequências, inclusive, para a população, além de propor possíveis soluções para que as atividades humanas causem o menor prejuízo possível para os ecossistemas.
Para que haja a criação de uma nova infraestrutura é imprescindível que haja um levantamento detalhado da área a ser ocupada, o que é feito por meio de mapeamentos conforme o futuro da construção. O profissional especializado é responsável pela coleta de dados em campo e confecção de mapas que servirão de base para o planejamento. Desta forma, são efetuadas medidas em determinados pontos, cujos dados são reunidos de forma a criar um modelo do terreno. Estes dados podem ser coletados com uma vasta gama de equipamentos existentes, desde instrumentos rústicos como teodolitos e fitas métricas para a determinação de ângulos e distâncias, até estações totais e o Sistema de Posicionamento Global (GPS), cada um de acordo com as circunstâncias. Existe ainda a possibilidade de atuação em áreas como planejamento urbano, gerenciamento de situações de desastre e manejo ambiental, utilizando técnicas modernas como os sistemas de informações geográficas, sensoriamento remoto e fotografias aéreas, dentre outras.

</doc>
<doc id="806" url="https://pt.wikipedia.org/wiki?curid=806" title="Edgar Allan Poe">
Edgar Allan Poe

Edgar Allan Poe (nascido Edgar Poe; Boston, Massachusetts, Estados Unidos, 19 de Janeiro de 1809 — Baltimore, Maryland, Estados Unidos, 7 de Outubro de 1849) foi um autor, poeta, editor e crítico literário estadunidense, integrante do movimento romântico estadunidense. Conhecido por suas histórias que envolvem o mistério e o macabro, Poe foi um dos primeiros escritores americanos de contos e é geralmente considerado o inventor do gênero ficção policial, também recebendo crédito por sua contribuição ao emergente gênero de ficção científica. Ele foi o primeiro escritor americano conhecido por tentar ganhar a vida através da escrita por si só, resultando em uma vida e carreira financeiramente difíceis.
Ele nasceu como Edgar Poe, em Boston, Massachusetts; quando jovem, ficou órfão de mãe, que morreu pouco depois de seu pai abandonar a família. Poe foi acolhido por Francis Allan e o seu marido John Allan, de Richmond, Virginia, mas nunca foi formalmente adotado. Ele frequentou a Universidade da Virgínia por um semestre, passando a maior parte do tempo entre bebidas e mulheres. Nesse período, teve uma séria discussão com seu pai adotivo e fugiu de casa para se alistar nas forças armadas, onde serviu durante dois anos antes de ser dispensado. Depois de falhar como cadete em West Point, deixou a sua família adotiva. Sua carreira começou humildemente com a publicação de uma coleção anônima de poemas, Tamerlane and Other Poems (1827).
Poe mudou seu foco para a prosa e passou os próximos anos trabalhando para revistas e jornais, tornando-se conhecido por seu próprio estilo de crítica literária. Seu trabalho o obrigou a se mudar para diversas cidades, incluindo Baltimore, Filadélfia e Nova Iorque. Em Baltimore, casou-se com Virginia Clemm, sua prima de 13 anos de idade. Em 1845, Poe publicou seu poema The Raven, foi um sucesso instantâneo. Sua esposa morreu de tuberculose dois anos após a publicação. Ele começou a planejar a criação de seu próprio jornal, "The Penn" (posteriormente renomeado para "The Stylus"), porém, em 7 de outubro de 1849, aos 40 anos, morreu antes que pudesse ser produzido. A causa de sua morte é desconhecida e foi por diversas vezes atribuída ao álcool, congestão cerebral, cólera, drogas, doenças cardiovasculares, raiva, suicídio, tuberculose entre outros agentes.
Poe e suas obras influenciaram a literatura nos Estados Unidos e ao redor do mundo, bem como em campos especializados, tais como a cosmologia e a criptografia. Poe e seu trabalho aparecem ao longo da cultura popular na literatura, música, filmes e televisão. Várias de suas casas são dedicadas como museus atualmente.
Edgar Allan Poe nasceu no seio de uma família escocesa-irlandesa, em 19 de janeiro de 1809, na cidade de Boston, no estado de Massachusetts, na região americana da Nova Inglaterra, no nordeste do país. Segundo filho dos atores David Poe Jr. (1784-1811), americano, e Elizabeth Arnold Hopkins Poe (1787-1811), inglesa, ele teve ainda um irmão mais velho, William Henry, nascido em 1808, e uma irmã caçula, Rosalie, nascida em 1811. Seu pai abandonou-os quando Edgar tinha cerca de um ano e meio de vida, em 1810, deixando ele, o irmão Henry e Elizabeth, esta grávida novamente, desamparados. Ela morreu poucas semanas depois de dar à luz Rosalie, já em 1811, devido tanto a complicações no parto quanto à tuberculose, deixando os três filhos órfãos.
Depois da morte da mãe, o irmão mais velho de Edgar, Henry, foi mandado para casa de parentes no interior do país, enquanto sua irmã, Rosalie, foi enviada formalmente para a adoção. Já Edgar foi acolhido, embora não formalmente adotado, pelo empresário John Allan e sua esposa, Francis Allan, que residiam na época na cidade de Richmond, no estado da Virgínia, no sudeste do país. O casal nunca o adotou legalmente, embora John tenha lhe dado o seu sobrenome, fazendo com que Edgar se chamasse, a partir de então, Edgar Allan Poe. No entanto, John Allan e Edgar nunca conseguiram desenvolver uma boa relação, sendo que algumas fontes afirmam que Allan só acolheu o menino para criá-lo por insistência de sua esposa, Francis. De fato, Edgar se mostrou desde pequeno mais apegado à mãe adotiva do que ao pai, que permanecia sempre distante, o que fomentou, direta e indiretamente, a difícil relação estabelecida entre os dois a partir da adolescência e fase adulta do escritor, permeada por constantes brigas e discussões que ambos teriam ao longo da vida deste último.
Com os pais adotivos de boa situação financeira, Edgar recebeu uma educação formal de qualidade em sua infância. Em 1815, aos seis anos de idade, se mudou com eles para a Inglaterra, onde seu pai adotivo esperava expandir seus negócios. Lá, eles se estabeleceram por alguns anos no coração da capital, Londres. Na capital britânica, depois de frequentar a escola de Misses Duborg School, e a Manor School, Poe regressou com a família Allan a Richmond em 1820, aos onze anos, tendo sido então matriculado em um colégio interno localizado nos arredores de Charlottesville, Virgínia. Mais tarde, já adolescente, em 1826, foi admitido na Universidade da Virgínia, também em Charlottesville. Desta viria a ser expulso depois de cerca de um ano de frequência, graças ao seu estilo aventureiro e boêmio.
Na sequência de desentendimentos com o seu pai adotivo, relacionados com as dívidas de jogo, Poe alistou-se nas forças armadas, sob o nome Edgar A. Perry, no ano de 1827. Nesse mesmo período, Poe publicou o seu primeiro livro, "Tamerlane and Other Poems". Depois de dois anos de serviço militar, acabaria por ser dispensado. Em 1829, a sua mãe adotiva, Francis, faleceu, ele publicou o seu segundo livro, "Al Aaraf", reconciliando-se com o seu pai adotivo, John Allan, que o auxiliou a entrar na Academia Militar de West Point. Em virtude da sua, supostamente propositada, desobediência a ordens, ele acabou por ser expulso desta academia, em 1831, fato pelo qual o seu pai adotivo o repudiou até a sua morte, em 1834.
Antes de entrar em "West Point", Poe mudou-se para Baltimore, no estado de Maryland, onde estabeleceu-se na casa da sua tia viúva, Maria Clemm, e da sua filha, Virgínia Clemm, sua prima em primeiro grau. Durante esta época, Poe usou a escrita de ficção como meio de subsistência e, no final de 1835, tornou-se editor do jornal "Southern Literary Messenger" em Richmond, tendo trabalhado nesta posição até 1837. Neste intervalo de tempo, Poe acabaria por casar-se, em segredo, com a sua prima Virgínia, de treze anos, em 1836.
Em 1837, Poe mudou-se para Nova Iorque, onde passaria quinze meses aparentemente improdutivos, antes de se mudar em definitivo para a Filadélfia, na Pensilvânia, pouco depois de publicar "The Narrative of Arthur Gordon Pym". No verão de 1839, tornou-se editor assistente da "Burton's Gentleman's Magazine", onde publicou um grande número de artigos, histórias e críticas literárias e teatrais. Nesse mesmo ano, foi publicada, em dois volumes, a sua coleção "Tales of the Grotesque and Arabesque" (traduzido para o francês por Baudelaire como "Histoires Extraordinaires" e para o português como "Histórias Extraordinárias"), que, apesar do insucesso financeiro, é apontada como um marco da literatura norte-americana.
Durante este período, sua esposa Virgínia Clemm-Poe, começou a sofrer de tuberculose, que a tornaria inválida e acabaria por levá-la à morte. A doença da mulher acabou por levar Poe ao consumo excessivo de álcool e, algum tempo depois, este deixou a "Burton's Gentleman's Magazine" para procurar um novo emprego. Regressou a Nova Iorque, onde trabalhou brevemente no periódico "Evening Mirror", antes de se tornar editor do mais renomado "Broadway Journal". Foi no "Evening Mirror", porém, que, no início de 1845, foi publicado o seu popular poema "The Raven" (em português "O Corvo").
Em 1846, o "Broadway Journal" faliu, e Poe mudou-se para uma casa no Bronx, hoje conhecida como "Poe Cottage" e aberta ao público, onde Virgínia morreu no ano seguinte. Biógrafos e críticos costumam sugerir que o tema de "morte de mulheres bonitas" que aparece frequentemente em suas obras decorre da perda de mulheres ao longo de sua vida, incluindo sua esposa.
Cada vez mais instável, após a morte da mulher, Poe tentou cortejar a poeta Sarah Helen Whitman. No entanto, o seu noivado com ela acabaria por falhar, alegadamente em virtude do comportamento errático e alcoólico de Poe, mas bastante provavelmente também devido à intromissão da mãe de Sarah, que não via Edgar com bons olhos. Nesta época, segundo ele mesmo relatou, Poe tentou o suicídio por sobredosagem de láudano, e acabou por regressar a Richmond, onde retomou a relação com uma paixão de infância, Sarah Elmira Royster, então já viúva.
No dia 3 de Outubro de 1849, Poe foi encontrado nas ruas de Baltimore, com roupas que não eram as suas, em estado de delirium tremens, e levado para o Washington College Hospital, onde veio a morrer apenas quatro dias depois. Poe nunca conseguiu estabelecer um discurso suficientemente coerente, de modo a explicar como tinha chegado à situação na qual foi encontrado. As suas últimas palavras teriam sido, de acordo com determinadas fontes, "Lord, please, help my poor soul", em português, "Senhor, por favor, ajude minha pobre alma."
Nunca foram apuradas as causas precisas da morte de Poe, sendo bastante comum, apesar de não comprovada, a ideia de ter sido causada por embriaguez. Por outro lado, muitas outras teorias têm sido propostas ao longo dos anos, entre as quais estão presentes: diabetes, sífilis, raiva, e doenças cerebrais raras.
As obras mais conhecidas de Poe são góticas, um gênero que ele seguiu para satisfazer o gosto do público. Seus temas mais recorrentes lidam com questões da morte, incluindo sinais físicos dela, os efeitos da decomposição, interesses por pessoas enterradas vivas, a reanimação dos mortos e o luto. Muitas das suas obras são geralmente consideradas partes do gênero do romantismo sombrio, uma reação literária ao transcendentalismo, do qual Poe fortemente não gostava.
Além do horror, Poe também escreveu sátiras, contos de humor e hoaxes. Para efeito cômico, ele usou a ironia e a extravagância do ridículo, muitas vezes na tentativa de liberar o leitor da conformidade cultural. De fato, "Metzengerstein", a primeira história que Poe publicou, e sua primeira incursão em terror, foi originalmente concebida como uma paródia satirizando o gênero popular. Poe também reinventou a ficção científica, respondendo na sua escrita às tecnologias emergentes como balões de ar quente em "The Balloon-Hoax".
Poe escreveu muito de seu trabalho usando temas especificamente oferecidos para os gostos do mercado em massa. Para esse fim, sua ficção incluiu muitas vezes elementos da popular pseudociência, como frenologia e fisiognomia.
A escrita de Poe reflete suas teorias literárias, que ele apresentou em sua crítica e também em peças literárias como "The Poetic Principle".
Ele não gostava de didatismo e alegoria, pois acreditava que os significados na literatura deveriam ser uma subcorrente sob a superfície. Trabalhos com significados óbvios, ele escreveu, deixam de ser arte. Acreditava que o trabalho de qualidade deveria ser breve e concentrar-se em um efeito específico e único. Para isso, acreditava que o escritor deveria calcular cuidadosamente todos sentimentos e ideias.
Em "The Philosophy of Composition", uma peça na qual Poe descreve seu método de escrita em "The Raven", ele afirma ter seguido estritamente este método. Porém, foi questionado se ele realmente seguiu esse sistema.
T. S. Eliot disse: "É difícil para nós lermos esta peça sem pensar se Poe escreveu seu poema com tanto cálculo, ele poderia ter pego um pouco mais de dores sobre isto: o resultado dificilmente tem crédito ao método". O biógrafo Joseph Wood Krutch descreveu a peça como "um exercício um tanto engenhoso na arte de racionalização".
Durante sua vida, Poe era sobretudo conhecido como um crítico literário. James Russell Lowell, também crítico, dizia que ele era "o mais distinto, filosófico e destemido crítico de obras que tem escrito na América", sugerindo – retoricamente – que ele ocasionalmente usava ácido prússico ao invés de tinta. As críticas cáusticas de Poe fizeram com que ele ganhasse o apelido de "Homem Tomahawk". Seu alvo favorito era o poeta de Boston, aclamado em sua época, Henry Wadsworth Longfellow, que era frequentemente defendido por seus companheiros literários no que seria mais tarde chamada de "A Guerra de Longfellow". Poe acusava Longfellow de "a heresia da didática", escrevendo poesias enfadonhas, derivativas e tematicamente plagiadas.
Poe também era conhecido como um escritor de ficção e se tornou um dos primeiros escritores americanos do século XIX a se tornar mais popular na Europa do que nos Estados Unidos. Poe era respeitado especialmente na França, em parte devido as traduções sem demora de Charles Baudelaire, estas que vieram a se tornar as edições definitivas das obras de Poe pela Europa.
Os contos de detetive de Poe com o personagem C. Auguste Dupin acabariam por se tornar a base para as futuras historias de detetive da literatura. Segundo sir Arthur Conan Doyle: "Cada uma [das estórias de detetive de Poe] é uma raiz da qual toda uma literatura se desenvolveu... Onde estavam as estórias de detetives antes de Poe soprar o sopro da vida nelas?" A associação "Mystery Writers of America" nomeou seus prêmios para a excelência no gênero de "Edgars". Poe também influenciou o gênero de ficção científica, especialmente Jules Verne, que escreveu uma continuação para o romance de Poe "A Narrativa de Arthur Gordon Pym" chamada "An Antarctic Mystery", também conhecida como "The Sphinx of the Ice Fields". Segundo o autor de ficção científica H. G. Wells, ""Pym" conta o que uma mente muito inteligente poderia imaginar sobre o polo sul a um século atrás."
Assim como diversos artistas famosos, as obras de Poe geraram diversos imitadores. Uma interessante tendência entre os imitadores de Poe, no entanto, eram as alegações de clarividentes ou pessoas com poderes paranormais de estarem canalizando poemas do espírito de Poe. O mais notável destes casos foi o de Lizzie Doten, que em 1863 publicou "Poems from the Inner Life", no qual ela alega ter "recebido" novas obras pelo espírito do autor. Estas obras constituíam de retrabalhos de poemas famosos de Poe como The Bells mas que refletiam uma nova perspectiva, mais positiva.
No entanto, Poe também era alvo de criticismo. Isto era parcialmente devido à visão negativa que existia devido ao seu carácter pessoal e a influência que este tinha em sua reputação. William Butler Yeats ocasionalmente criticava Poe e uma vez chegou a chama-lo de "vulgar". Transcendentalista Ralph Waldo Emerson reagiu ao poema "O Corvo" dizendo que "não via nada de mais nele", referindo-se a Poe de modo zombeteiro como "the jingle man". Aldous Huxley escreveu que a composição literária de Poe "cai na vulgaridade" por ser "muito poética" – o equivalente a usar um anel de diamantes em cada dedo.
Acredita-se que apenas doze cópias do primeiro livro de Poe, "Tamerlane and Other Poems", ainda existem. Em dezembro de 2009, foi vendida uma cópia na sociedade de leilões Christie's, em Nova Iorque, por seiscentos e sessenta dois mil e 500 dólares, um preço record pago por uma obra da literatura americana.
"Eureka: Um poema em prosa", dissertação escrita em 1848, contém uma teoria cosmológica que previu a teoria do "Big Bang" oitenta anos antes do seu surgimento, assim como uma solução plausível para o paradoxo de Olbers. Poe ignorou o método científico em "Eureka" e ao invés disso escreveu utilizando apenas sua intuição. Por esta razão ele a considerou uma obra de arte ao invés de um trabalho científico, mas insistiu que ainda assim era verdadeiro e considerou ser a obra prima de sua carreira. Ainda assim "Eureka" está repleta de erros científicos. Em particular, as sugestões de Poe ignoram as leis de Newton relacionadas à densidade e rotação de planetas.
Poe tinha um grande interesse em criptografia. Ele notou pela primeira vez suas habilidades no periódico da Filadélfia "Alexander's Weekly (Express) Messenger" que estava convidando leitores a submeterem cifras, o qual ele procedeu a resolver. Em julho de 1841, Poe escreveu um artigo chamadao "Algumas palavras sobre Escrita Secreta" no periódico "Graham's Magazine". Se aproveitando do interesse público no tópico, ele escreveu "O Escaravelho de Ouro" incorporando cifras como parte essencial da estoria. O sucesso de Poe com criptografia não dependia muito em seu conhecimento profundo do campo (seu método era limitado a simples cifra de substituição), mas sim no conhecimento adquirido da cultura de jornais e periódicos. Sua afiada habilidade analítica, tão evidente em suas estorias de detetive, permitia que ele visse que o público em geral não possuía o conhecimento necessário para saber como um simples criptograma de substituição possa ser resolvido, e ele usava isso a seu favor. A comoção criada por suas façanhas criptográficas desempenhou um papel importante em popularizar criptogramas em jornais e revistas.
Poe teve uma influência na criptografia além de incrementar o interesse público durante sua vida. William Friedman, um dos principais criptologistas da América, foi profundamente influenciado por Poe. O interesse inicial de Friedman por criptografia veio após ler "O Escaravelho de Ouro" quando criança, interesse que mais tarde seria posto em uso para decifrar códigos da maquina PURPLE, pertencente ao Japão, durante a segunda guerra mundial.
Contos
Poesia
Outras obras

</doc>
<doc id="807" url="https://pt.wikipedia.org/wiki?curid=807" title="Ernst Weiss">
Ernst Weiss

Ernst Weiss ou Ernst Weiß (Weinberg perto de Brno, 28 de outubro de 1882 - Paris, 15 de junho de 1940), foi um médico e escritor judeu do Império Austríaco. 
Franz Kafka, amigo de Weiss, ajudou-o a publicar a sua primeira obra "Die Galeere" que tinha sido rejeitada por diversos editores.

</doc>
<doc id="808" url="https://pt.wikipedia.org/wiki?curid=808" title="Ernest Hemingway">
Ernest Hemingway

Ernest Miller Hemingway (Oak Park, 21 de Julho de 1899 — Ketchum, 2 de Julho de 1961) foi um escritor norte-americano. Trabalhou como correspondente de guerra em Madrid durante a Guerra Civil Espanhola (1936-1939). Esta experiência inspirou uma de suas maiores obras, "Por Quem os Sinos Dobram". Ao fim da Segunda Guerra Mundial (1939-1945), se instalou em Cuba. Em 1953, ganhou o Prémio Pulitzer de Ficção, e, em 1954, ganhou o prêmio Nobel de Literatura. Suicidou-se em Ketchum, em Idaho, em 1961.
Ainda muito jovem, quando a Grande Guerra (1914-1918) assombrava o mundo, decidiu ir à Europa pela primeira vez. Hemingway havia terminado o segundo grau em Oak Park e trabalhado como jornalista no jornal "The Kansas City Star". Tentou alistar-se no exército, mas foi preterido por ter um problema na visão. Decidido a ir à guerra, conseguiu uma vaga de motorista de ambulância na Cruz Vermelha. Na Itália, apaixonou-se pela enfermeira Agnes Von Kurowsky, que viria a ser sua inspiração para a criação da heroína de Adeus às Armas (1929) – a inglesa Catherine Barkley. Atingido por uma bomba, retornou para Oak Park, que, no entanto, depois do que havia visto na Itália, tornara-se monótona demais para ele. 
Voltou então à Europa (Paris) em 1921, recém-casado com Elizabeth Hadley Richardson, seu primeiro casamento, com quem teve um filho. Na ocasião, trabalhava para a revista canadense "Toronto Star Weekly" e, em início de carreira, se aproximou de outros principiantes: Ezra Pound (1885 – 1972), Scott Fitzgerald (1896 – 1940) e Gertrude Stein (1874 – 1940). Hemingway era parte da comunidade de escritores expatriados em Paris conhecida como "geração perdida", nome inventado e popularizado por Gertrude Stein. 
A vida e a obra de Hemingway têm intensa relação com a Espanha, país onde viveu por quatro anos. Uma breve mas marcante passagem para o escritor americano, que estabeleceu uma relação emotiva e ideológica com os espanhóis. Em Pamplona, em meados do , fascinou-se pela tauromaquia, chegando a tourear como amador, experiência que abordaria no seu livro O Sol Também Se Levanta (1926).
O seu segundo casamento (1927) foi com a jornalista de moda Pauline Pfeiffer, com quem viria a ter dois filhos. Em 1928, o casal decidiu morar em Key West, na Flórida. Em Key West, no entanto, o escritor sentiu falta da vida de jornalista e correspondente internacional. Ao mesmo tempo, o casamento com Pauline se tornou instável. Nessa época, conheceu Joe Russell, dono do "Sloppy Joe's Bar" e companheiro de farra. 
Já na década de 1930, resolveu partir com o amigo para uma pescaria. Dois dias em alto-mar que terminaram em Havana, capital cubana, para onde passou a voltar anualmente na época da pesca ao marlim (entre os meses de maio e julho). Na cidade, hospedava-se no Hotel Ambos Mundos, em plena "Habana Vieja", bairro mais antigo da cidade, que se tornou o lar do escritor e o cenário que comporia sua história e a da própria ilha pelos próximos 23 anos. Duas décadas de turbulências que teriam, como desfechos, a revolução socialista e o suicídio do escritor.
Em Cuba, o escritor se apaixonou por Jane Mason, que era casada com o diretor de operações da Pan American Airways. Hemingway e Jane se tornaram amantes. Em 1936, novamente se apaixonou: desta feita pela destemida jornalista Martha Gellhorn, motivo do segundo divórcio, confirmando o que predissera seu amigo, Scott Fitzgerald, quando eles se conheceram em Paris: "Você vai precisar de uma mulher a cada livro". Assim, Hemingway partiu para a Espanha, onde Martha já estava, e, em meio à guerra, os dois viveram um romance que resultou no seu terceiro casamento. Ao cobrir a Guerra Civil Espanhola como jornalista do "North American Newspaper Alliance", não hesitou em se aliar às forças republicanas contra o fascismo, o que viria a ser o tema do livro "Por Quem os Sinos Dobram" (1940), considerada sua obra-prima.
Quando a república espanhola caiu e a Europa vivia o prenúncio de um conflito generalizado, Hemingway retornou para Cuba com Martha. 
Em Cuba, durante a Segunda Guerra Mundial, Hemingway montou uma rede de informantes com a finalidade de fornecer, ao governo dos Estados Unidos, informações sobre os espanhóis simpatizantes do fascismo na ilha. Também passou a patrulhar o litoral a bordo de seu iate Pilar na busca de possíveis submarinos alemães. Porém a Agência Federal de Investigação estadunidense via com desconfiança a colaboração de Hemingway, por considerá-lo um simpatizante do comunismo.
Em 1946, o escritor casou-se pela quarta e última vez: desta vez com Mary Welsh, também jornalista mas tímida e disposta a viver ao lado de um Hemingway cada vez mais instável emocionalmente. Levando uma vida turbulenta, Hemingway casou-se quatro vezes, além de ter tido vários relacionamentos românticos. 
Em 1952, publicou "O Velho e o Mar", com o qual ganhou o Prémio Pulitzer de Ficção (1953). Foi laureado com o Nobel de Literatura de 1954. 
Ao longo da vida do escritor, o tema suicídio aparece em escritos, cartas e conversas com muita frequência. Seu pai suicidou-se em 1929 por problemas de saúde e financeiros. Sua mãe, Grace, dona de casa e professora de canto e ópera, o atormentava com a sua personalidade dominadora. Ela enviou-lhe, pelo correio, a pistola com a qual o seu pai havia se matado. O escritor, atônito, não sabia se ela queria que ele repetisse o ato do pai ou que guardasse a arma como lembrança. Aos 61 anos e enfrentando problemas de hipertensão, diabetes, depressão e perda de memória, Hemingway decidiu-se pela primeira alternativa: era, também, portador de hemocromatose, a qual está relacionada à depressão, hipertensão e diabete.
Todas as personagens deste escritor se defrontaram com o problema da "evidência trágica" do fim. Hemingway não pôde aceitá-la. A vida inteira jogou com a morte, até que, na manhã de 2 de julho de 1961, em Ketchum, em Idaho, tomou um fuzil de caça e disparou contra si mesmo. Encontra-se sepultado no Cemitério de Ketchum, em Ketchum, no Condado de Blaine, em Idaho, nos Estados Unidos.

</doc>
<doc id="809" url="https://pt.wikipedia.org/wiki?curid=809" title="Entre Douro e Vouga">
Entre Douro e Vouga

O Entre Douro e Vouga foi uma sub-região estatística portuguesa, já extinta, parte da Região Norte e da Área Metropolitana do Porto, integrados na nova NUTS III da Área Metropolitana do Porto. Todos os concelhos estão integrados no Distrito de Aveiro, na parte do seu extremo noroeste. Confina com o Grande Porto e o Tâmega, a leste com o Dão-Lafões e a sul e a oeste com o Baixo Vouga. Tem uma área de 859 km² e uma população de 274 859 habitantes (INE 2011).
Compreende 5 concelhos:
Existem algumas diferenças entre os municípios do Entre Douro e Vouga, sendo que a área mais dinâmica e industrial corresponde aos concelhos da faixa ocidental, i.e., o eixo urbano constituído por Santa Maria da Feira, Oliveira de Azeméis e São João da Madeira. Esta é, de facto, uma região com uma densidade populacional elevada convergindo progressivamente para uma integração urbana cada vez mais efectiva. Em contraponto aparecem os municípios de Vale de Cambra e Arouca, com povoamento mais disperso, menores densidades populacionais e uma dinâmica industrial menos evidente.
Existe uma grande interacção socio-económica entre todos os concelhos do Entre Douro e Vouga e também destes com todos os municípios do Grande Porto.
O Entre Douro e Vouga está, ao nível turístico, abrangido pelo região de Turismo do Porto e Norte de Portugal.
Lojas interativas de turismo:
- Arouca
- Oliveira de Azeméis
- Santa Maria da Feira
- São João da Madeira
Existem diversos clubes no Entre Douro e Vouga, sendo que 3 disputam atualmente a Liga de Honra:

</doc>
<doc id="810" url="https://pt.wikipedia.org/wiki?curid=810" title="EEPROM">
EEPROM

EEPROM (também escrita EPROM, e pronunciada "e-e-prom"), sigla do inglês de "Electrically-Erasable Programmable Read-Only Memory", é um tipo de memória não-volátil usada em computadores e outros dispositivos eletrônicos para armazenar pequenas quantidades de dados que precisam ser salvos quando a energia é removida, por exemplo, dados de configuração do dispositivo. Apesar de no nome se declarar Read-Only, esse foi classificado incorretamente, pois é tanto Read/Ler, quanto Write/Escrever, pelo fato de que códigos de erro no OBD-II poderem ser removidos independentemente, dentre outras características. Este se assemelha à denominação incorreta de ROM dos smartphones, conforme a Ciência da Computação. 
Ao contrário da maioria dos outros tipos de memória não-volátil, bytes individuais em uma EEPROM tradicional pode ser lidos, apagados e re-escrita de forma independente. 
Atualmente já existe uma memória não-volátil mais moderna, derivada da EEPROM, a memória flash. Quando grandes quantidades de dados estáticos devem ser armazenados (por exemplo, em unidades flash USB) a memória flash é mais econômica do que os dispositivos tradicionais de EEPROM. 
Enquanto uma EPROM é programada por um dispositivo eletrônico que dá voltagens maiores do que os usados normalmente em circuitos elétricos e pode ser apagada apenas por exposição a uma forte luz ultravioleta, a EEPROM pode ser programada e apagada dentro do próprio circuito, eletricamente, pela aplicação de sinais de programação especiais. Originalmente, EEPROMs foram limitados a operações de byte único que os fizeram mais lento, mas EEPROMs modernos permitem operações com múltiplos bytes. 
Embora uma EEPROM possa ser lida, um número praticamente ilimitado de vezes, ela possui uma vida útil limitada - isto é, o número de vezes que pode ser reprogramada (apagada e programada novamente) foi limitado a dezenas ou centenas de milhares de vezes, devido a contínua deterioração interna do "chip" durante o processo de exclusão que requer uma tensão elétrica mais elevada. Essa limitação foi estendido para um milhão de operações de gravação em EEPROM modernos. Entretanto essa vida útil da EEPROM, se torna uma importante consideração a ser feita, quando seu uso em um computador, por exemplo, tenha uma previsão de frequentes reprogramações. É por esta razão que EEPROMs foram utilizados para informações de configuração, ao invés de memória de acesso aleatório. 
Como cada novo dado gravado no "chip" requer o apagamento do anterior, considera-se apagamento e gravação como uma só operação, porém seria possível gravar o mesmo endereço de memória um bit de cada vez, fazendo então oito gravações com um só prévio apagamento. Entretanto a maioria das memórias EEPROM faz o apagamento do conteúdo do endereço automaticamente antes da gravação. 
Tecnologias mais novas como FRAM e MRAM estão aos poucos substituindo as EEPROMs em algumas aplicações.
Eli Harari na Hughes Aircraft, inventou a EEPROM em 1977 utilizando, o tunelamento de Fowler-Nordheim, esse processo utiliza de uma tensão elétrica, geralmente entre 10 a 13 volts, aplicados à porta flutuante, para mudar o valor da célula para "0", corrente essa que vem da coluna, ou bitline (linha de bits), entra na porta flutuante e é drenada para a fonte. E com uma tensão mais alta é possível fazer com que os elétrons nas células do chip de mémoria se tornem "1". A "Hughes" passou a produzir os primeiros dispositivos EEPROM. Em 1978, George Perlegos na Intel desenvolveu o Intel 2816, que foi construído anteriormente com a tecnologia EPROM, mas passou a utilizar uma camada de óxido de porta flutuante permitindo que o chip pudesse apagar seus próprios dados sem uma fonte de UV. Perlegos e outros desenvolvedores, deixaram a Intel para formar Seeq Technology, que utilizou novos dispositivos de carga para abastecer as altas voltagens necessárias para a programação de EEPROMs.
Existem diferentes tipos de interfaces elétricas para dispositivos EEPROM . Principais categorias de estes tipos de interface são:
Como o dispositivo é operado depende da sua interface elétrica.
Os tipos de interface seriais mais comuns são , I²C, , , e 1-Wire. Estas interfaces requerem entre um e quatro sinais de controle para o funcionamento, resultando em um dispositivo de memória de oito pinos (ou menos) de pacote.
A EEPROM serial (ou SEEPROM) opera tipicamente em três fases: Fase de Código de Operação("OP-Code"), Fase de Endereçamento e Fase de Dados. O OP-Code é geralmente os 8 primeiros bits de entrada no pino serial do dispositivo EEPROM (ou com a maioria dos dispositivos I²C , está implícito); seguido de 8 a 24 bits de endereçamento, dependendo da profundidade do dispositivo, em seguida, os dados a serem lidos ou escritos.
Cada dispositivo EEPROM normalmente não tem o seu próprio conjunto de OP-Codes de instruções para mapear diferentes funções. Algumas das operações comuns em dispositivos EEPROM SPI são:
Outras operações suportadas por alguns dispositivos EEPROM são:
Dispositivos EEPROM paralelos normalmente têm um barramento de dados de 8 bits e um barramento de endereços grande o suficiente para cobrir o restante da memória. A maioria dos dispositivos têm seletor de chips e pinos com escrita protegida. Alguns microcontroladores também têm integrado EEPROM paralelo.
Operação de uma EEPROM paralela é simples e rápido quando comparado a EEPROM serial, mas estes dispositivos são maiores devido à maior quantidade de pinos (28 pinos ou mais) e sua popularidade têm vindo a diminuir em relação a EEPROM serial ou Flash.
Memória EEPROM, também é usada para habilitar recursos em outros tipos de produtos que não são estritamente produtos de memória. Produtos como relógios em tempo real, potenciômetros digitais, sensores de temperatura digital, entre outros, podem ter pequenas quantidades de EEPROM contendo informação para a calibração desses dispositivos ou outros dados que precisam estar disponíveis em caso de perda de energia. Ela também foi usada em cartuchos de jogos de vídeo game para salvar o progresso do jogo e configurações, antes do uso de memórias flash externo e interno.
Existem duas limitações quanto ao armazenamento de dados, a resistência e a retenção de dados.
Durante regravações, a camada de óxido em transistores de porta flutuante gradualmente acumula elétrons presos. O campo elétrico dos elétrons presos acrescenta aos elétrons na porta flutuante, baixando a janela entre as tensões de zeros e uns. Depois de um número suficiente de ciclos de reescrita, a diferença torna-se demasiada pequena para ser reconhecível, a célula é presa no estado programado, e a falha de resistência ocorre. Os fabricantes normalmente especificam o número máximo de reescritas sendo 1 milhão ou mais.
Durante o armazenamento, os elétrons injetados na porta flutuante pode ser movimentado através do isolador, aumentando a temperatura e causando perda de carga, revertendo a célula ao estado apagado. Os fabricantes normalmente garante a retenção de dados de 10 anos ou mais.
A memória flash é uma variação moderna da EEPROM, mas existe na indústria uma convenção para reservar o termo EEPROM para as memórias de escrita bit a bit, não incluindo as memórias de escrita bloco a bloco, como as memórias flash. As EEPROM necessitam de maior área que as memórias flash, pois como são organizadas como matrizes de transistores de porta flutuante, cada célula geralmente necessita de um transistor de leitura e outro de escrita, ao passo que as células da memória flash só necessitam de um, justamente por utilizarem blocos. 
Tecnologias de memória não-volátil, mais recentes como FeRAM e MRAM estão substituindo lentamente as EEPROMs em algumas aplicações, mas todavia uma fração do mercado deverá manter o uso de EEPROM em um futuro próximo. 
A diferença entre EPROM e EEPROM está na maneira que as memórias são programadas e apagadas. EEPROM pode ser programada e apagada eletricamente usando emissão de elétrons de campo (mais comumente conhecida na indústria como "o tunelamento de Fowler-Nordheim"). 
As EPROMs não pode ser apagadas eletricamente, e são programados através de um mecanismo conhecido como aplicado na porta flutuante, e a exclusão é através de uma fonte de luz ultravioleta, embora na prática, muitas EPROM são encapsuladas em plástico que é opaco a luz UV, tornando-os "programável apenas uma vez ". Já a memória Flash é um estilo de programação híbrida e a exclusão,embora mais abrangente, se baseia na exclusão da EEPROM.

</doc>
<doc id="811" url="https://pt.wikipedia.org/wiki?curid=811" title="Eletromagnetismo">
Eletromagnetismo

No estudo da Física, o é o nome da teoria unificada desenvolvida por James Maxwell para explicar a relação entre a eletricidade e o magnetismo. Esta teoria baseia-se no conceito de "campo eletromagnético".
O campo magnético é resultado do movimento de cargas elétricas, ou seja, é resultado de corrente elétrica. O campo magnético pode resultar em uma força eletromagnética quando associada a ímãs.
A variação do fluxo magnético resulta em um campo elétrico (fenômeno conhecido por indução eletromagnética, mecanismo utilizado em geradores elétricos, motores e transformadores de tensão). Semelhantemente, a variação de um campo elétrico gera um campo magnético. Devido a essa interdependência entre campo elétrico e campo magnético, faz sentido falar em uma única entidade chamada campo eletromagnético.
Desde a Grécia Antiga, fenômenos magnéticos e elétricos são conhecidos. Mas foi somente no início do século XVII que se começaram a formular explicações científicas destes fenômenos. Durante estes dois séculos, XVII e XVIII, célebres cientistas como William Gilbert, Otto von Guericke, Stephen Gray, Benjamin Franklin e Alessandro Volta, entre outros, dedicaram-se a investigar estes dois fenômenos separadamente e chegaram a conclusões coerentes com seus experimentos. 
No início do século XIX, Hans Christian Ørsted obteve evidência empírica da relação entre os fenômenos magnéticos e elétricos. A partir daí, os trabalhos de físicos como André-Marie Ampère, William Sturgeon, Joseph Henry, Georg Simon Ohm, Michael Faraday foram unificados por James Clerk Maxwell em 1861 por meio de equações que descreviam ambos os fenômenos como um só: o fenômeno eletromagnético. Esta unificação foi uma das grandes descobertas da física no .
As chamadas equações de Maxwell demonstravam que os campos elétricos e magnéticos eram manifestações de um só campo eletromagnético. Além disso, descreviam a natureza ondulatória da luz, mostrando-a como uma onda eletromagnética. 
Com uma teoria única e consistente, que descrevia os dois fenômenos anteriormente julgados distintos, os físicos puderam realizar vários experimentos prodigiosos e inventos úteis, como a lâmpada elétrica (Thomas Alva Edison) ou o gerador de corrente alternada (Nikola Tesla). O êxito preditivo da teoria de Maxwell e a busca de uma interpretação coerente das suas implicações foi o que levou Albert Einstein a formular sua teoria da relatividade, que se apoiava em alguns resultados prévios de Hendrik Antoon Lorentz e Henri Poincaré.
Na primeira metade do século XX, com o advento da mecânica quântica, o eletromagnetismo teve sua formulação refinada, com o objetivo de adquirir coerência com a nova teoria. Isto se conseguiu na década de 1940, quando se completou a teoria quântica eletromagnética, mais conhecida como eletrodinâmica quântica.
A força que um campo eletromagnético exerce sobre cargas elétricas, chamada força eletromagnética, é uma das quatro forças fundamentais. As outras são: a força nuclear forte (que mantém o núcleo atômico coeso), a força nuclear fraca (que causa certas formas de decaimento radioativo), e a força gravitacional. Quaisquer outras forças provêm necessariamente dessas quatro forças fundamentais.
A força eletromagnética tem a ver com praticamente todos os fenômenos físicos que se encontram no cotidiano, com exceção da gravidade. Isso porque as interações entre os átomos são regidas pelo eletromagnetismo, já que são compostos por prótons e elétrons, ou seja, por cargas elétricas. Do mesmo modo as forças eletromagnéticas interferem nas relações intermoleculares, ou seja, entre nós e quaisquer outros objetos. Assim podem-se incluir fenômenos químicos e biológicos como consequência do eletromagnetismo.
Cabe ressaltar que, conforme a eletrodinâmica quântica, a força eletromagnética é resultado da interação de cargas elétricas com fótons.
O cientista William Gilbert propôs que a eletricidade e o magnetismo, apesar de ambos causarem efeitos de atração e repulsão, seriam efeitos distintos. Entretanto marinheiros percebiam que raios causavam perturbações nas agulhas das bússolas, mas a ligação entre os raios e a eletricidade ainda não estava traçada até os experimentos que Benjamin Franklin propôs em 1752. Um dos primeiros a descobrir e publicar as relações entre corrente elétrica e o magnetismo foi Romagnosi, que em 1802 afirmou que um fio conectado a uma pilha provocava um desvio na agulha de uma bússola que estivesse próxima. No entanto essa notícia não recebeu o crédito que lhe era devido até que, em 1820, Hans Christian Ørsted montou um experimento similar.
A teoria do eletromagnetismo foi desenvolvida por vários físicos durante o século XIX, culminando finalmente no trabalho de James Clerk Maxwell, o qual unificou as pesquisas anteriores em uma única teoria e descobriu a natureza eletromagnética da luz. No eletromagnetismo clássico, o campo eletromagnético obedece a uma série de equações conhecidas como equações de Maxwell, e a força eletromagnética pela Lei de Lorentz.
Uma das características do eletromagnetismo clássico é a dificuldade em associar com a mecânica clássica, compatível porém com a relatividade especial. Conforme as equações de Maxwell, a velocidade da luz é uma constante, depende apenas da permissividade elétrica e permeabilidade magnética do vácuo. Isso porém viola a invariância de Galileu, a qual já era há muito tempo base da mecânica clássica. Um caminho para reconciliar as duas teorias era assumir a existência de éter luminífero através do qual a luz propagaria. No entanto, os experimentos seguintes falharam em detectar a presença do éter. Em 1905, Albert Einstein resolveu o problema com a teoria da relatividade especial, a qual abandonava as antigas leis da cinemática para seguir as transformações de Lorentz as quais eram compatíveis com o eletromagnetismo clássico.
A teoria da relatividade mostrou também que adotando-se um referencial em movimento em relação a um campo magnético, tem-se então um campo elétrico gerado. Assim como também o contrário era válido, então de fato foi confirmado a relação entre eletricidade e magnetismo. Portanto o termo "eletromagnetismo" estava consolidado.

</doc>
<doc id="812" url="https://pt.wikipedia.org/wiki?curid=812" title="Encíclica">
Encíclica

Encíclica (do latim tardio "encyclĭcus,a,um", adaptado do grego εγκyκλιος, transl. "enkyklios": 'circular, que circula') ou, mais propriamente, carta encíclica (do latim "littĕrae encyclĭcae" ) é uma comunicação escrita papal , um documento pontifício, dirigido aos bispos de todo o mundo e, por meio deles, a todos os fiéis. O termo "epistola encyclica" parece ter sido introduzido pelo Papa Bento XIV (1740-1758). 
A encíclica é usada pelo Papa para exercer o seu magistério ordinário. 
Geralmente as encíclicas se dirigem aos Patriarcas, Arcebispos, Bispos, Presbíteros, "Filhos e Filhas da Igreja", os fiéis; todavia o círculo pode-se alargar para compreender todo o ""homem de boa vontade".
Trata de matéria doutrinária em variados campos: fé, costumes, culto, doutrina social, etc. 
A matéria nela contida não é formalmente objeto de fé. Mas, a ela, se deve o religioso obséquio do assentimento exterior e interior. Logo, uma "encíclica não define, e nem altera um dogma, mas atualiza a doutrina católica através de um ensinamento ou um tema da atualidade e é vista como a posição da Igreja Católica sobre um determinado tema. Normalmente, uma encíclica é designada pelas suas primeiras palavras a partir do texto em latim".
Exemplos de encíclicas:
O Papa Francisco escreveu, até o momento, as encíclicas Lumen Fidei e Laudato Si'.
Obs. Para que esses ensinamentos sejam válidos, é necessário que esses ensinamentos estejam em sintonia com outros ensinamentos que, foram dados pelos Papas anteriores ao longo dos séculos.

</doc>
<doc id="813" url="https://pt.wikipedia.org/wiki?curid=813" title="Esoterismo">
Esoterismo

Esoterismo é o nome genérico que evidencia um conjunto de tradições e interpretações filosóficas das doutrinas e religiões - ou mesmo das Fraternidades Iniciáticas - que buscam transmitir um rol acerca de determinados assuntos que diz respeito a natureza da vida que estão sutilmente ocultas. Um sentido popular do termo é da percepção de que transmitem um conhecimento enigmático ou incomum, sempre com vetor oculto. Segundo alguns, o esoterismo é o termo para as doutrinas cujos princípios e conhecimentos não podem ou não devem ser "vulgarizados", sendo comunicados a um restrito número de partidários adeptos. Tais escolhas de partidários acontecem da instituição (de caráter esotérico) para indivíduo ou do indivíduo - ao manifestar interesse - para a instituição esotérica, não havendo, à rigor, um âmbito de secreto, mas de ritos tradicionais e burocracias internas que acontecem tanto de forma discreta e privada quanto aberta, pois a filiação não está à margem de qualquer lei. No entanto, é possível entrar em contato com o esoterismo por conta própria, isto é, desvinculado de qualquer instituição. Encontra-se esse tipo de conhecimento em leituras; e costumeiramente as bibliotecas e livrarias oferecem esta especificidade e gênero deste acervo. 
No tempo presente, com a despreocupação da sociedade para com arregimentação de conceitos variados, o esoterismo, enquanto característica sobre assuntos das coisas ocultas, tem adquirido uma deturpação na conexão com o misticismo. Não são, naturalmente, sinônimos, uma vez que o esoterismo contém variadas correntes ocultistas, ciências ocultas e mesmo correntes místicas dentro de seu rol. Logo não são, à rigor, a mesma coisa; o misticismo desce do plano do esoterismo (que é um termo genérico), e tem a sua especificidade, onde se apresenta, costumeiramente, como práticas do ensinamento místico que conduz à experiência empírica para comprovações fenomenológicas pessoais do que fora estudado pelos seus adeptos. O considerado 'místico', como se reconhecem, tem um propósito à alcançar e não se limita aos estudos. Portanto, temos que esoterismo é o termo que afunila e comporta toda e qualquer ciência oculta.
Em suma, esoterismo evidencia a característica do conhecimento "das verdades e leis últimas que regem todo o universo", porém ligando ao mesmo tempo o natural com o que chamam de 'sobrenatural'. 
Há doutrinas, nomeadamente as espiritualistas, que são também chamadas esotéricas. Há também, com o fenômeno da globalização e o conhecimento mútuo entre as nações e suas culturas, a percepção da compatibilidade do esoterismo com as religiões mais famosas do Oriente; a saber, o Budismo, o Tao etc., uma vez que tem muitos pontos de afinidade conceitual e consonância na aplicabilidade.
Existem duas espécies de conhecimento: esotérico e exotérico. O termo "exotérico" (antônimo de "esotérico", apesar de ter a mesma pronúncia) se refere ao ensinamento que nas escolas da Antiguidade grega era transmitido ao público sem restrições, por se tratar de ensinamento dialético, provável e verossímil. O conhecimento exotérico ou conhecimento do mundo exterior é aquele que percebemos através dos sentidos físicos.
Helena Blavatsky, que é considerada a criadora da moderna Teosofia, dizia que o termo "esotérico" refere-se o que está "dentro", em oposição ao que está "fora" e que é designado como "exotérico". Aponta o significado verdadeiro da doutrina, sua essência, em oposição ao exotérico que é a "vestimenta" da doutrina, sua "decoração". Também segundo ela, todas as religiões e filosofias concordam em sua essência, diferindo apenas na "vestimenta", pois todas foram inspiradas no que ela chamou de "Religião-Verdade".

</doc>
<doc id="814" url="https://pt.wikipedia.org/wiki?curid=814" title="António Egas Moniz">
António Egas Moniz

António Caetano de Abreu Freire Egas Moniz (Estarreja, Avanca, Vilarinho do Bairro, — Lisboa, ) foi um médico, neurologista, investigador, professor, político e escritor português.
Responsável pela criação da leucotomia pré-frontal, foi galardoado, como resultado, com o Nobel de Fisiologia ou Medicina de 1949, partilhado com Walter Rudolf Hess.
Nascido António Caetano de Abreu Freire de Resende no seio de uma família aristocrata rural, filho único de Fernando de Pina de Resende de Abreu Freire (Idanha-a-Nova, Idanha-a-Nova, 15 de Abril de 1828 - Lourenço Marques, 29 de Março de 1890) e de sua mulher (Estarreja, Salreu, 22 de Junho de 1870) Maria do Rosário de Oliveira de Almeida e Sousa (Anadia, Vilarinho do Bairro, 19 de Junho de 1840 - Estarreja, Pardilhó, 19 de Novembro de 1896).
Seu tio paterno e padrinho, o padre Caetano de Pina Resende Abreu e Sá Freire, insistiria para que ao apelido (sobrenome) fosse adicionado Egas Moniz, em virtude de a família de Resende descender em linha directa de Egas Moniz, o mordomo de Dom Afonso Henriques.
Casou em 1902 com Elvira de Macedo Dias (Rio de Janeiro, Sacramento, 14 de Julho de 1884 - ?), filha de José Joaquim Dias e de sua mulher Matilde Flora de Macedo, sem geração.
Completou a instrução primária na Escola do Padre José Ramos, em Pardilhó, e o Curso Liceal noColégio de S. Fiel, dos Jesuítas, em Louriçal do Campo, concelho de Castelo Branco. Formou-se em Medicina na Universidade de Coimbra, onde começou por ser lente substituto, leccionando anatomia e fisiologia. Em 1911 foi transferido para a recém-criada Faculdade de Medicina da Universidade de Lisboa onde foi ocupar a cátedra de neurologia como professor catedrático. Reformou-se em fevereiro de 1944, fruto de uma depressão exacerbada, motivada pela existência de "quórums" antropométricos que questionavam a sua capacidade para leccionar, devido à dimensão desproporcional das suas orelhas.
Em 1950 é fundado, no Hospital Júlio de Matos, o Centro de Estudos Egas Moniz, do qual é presidente. O Centro de Estudos é, em 1957] transferido para o serviço de Neurologia do Hospital de Santa Maria onde existe ainda hoje compreendendo, entre outros, o Museu Egas Moniz (onde se encontra uma restituição do seu gabinete de trabalho com as peças originais, vários manuscritos, entre outros).
Egas Moniz contribuiu decisivamente para o desenvolvimento da medicina ao conseguir pela primeira vez dar visibilidade às artérias do cérebro. A Angiografia Cerebral, que descobriu após longas experiências com raios X, tornou possível localizar neoplasias, aneurismas, hemorragias e outras mal-formações no cérebro humano e abriu novos caminhos para a cirurgia cerebral.
As suas descobertas clínicas foram reconhecidas pelos grandes neurologistas da época, que admiravam a acuidade das suas análises e observações.
A 5 de Outubro de 1928 foi agraciado com a Grã-Cruz da Ordem de Benemerência e a 3 de Março de 1945 com a Grã-Cruz da Ordem Militar de Sant'Iago da Espada.
Egas Moniz teve também papel activo na vida política. Foi fundador do Partido Republicano Centrista, dissidência do Partido Evolucionista; apoiou o breve regime de Sidónio Pais, durante o qual exerceu as funções de Embaixador de Portugal em Madrid (1917) e Ministro dos Negócios Estrangeiros (1918); viu entretanto o seu partido fundir-se com o Partido Sidonista. Foi ainda um notável escritor e autor de uma notável obra literária, de onde se destacam as obras "A nossa casa" e "Confidências de um investigador científico". É também autor de um notável ensaio de crítica literária, "Júlio Dinis e a sua obra" (1924), onde demonstra que o escritor Júlio Dinis se inspirou em personagens reais oriundas de Ovar na criação das figuras principais dos seus romances "A Morgadinha dos Canaviais" e "Pupilas do Senhor Reitor". Egas Moniz também escreveu sobre pintura e reuniu uma notável colecção de pintura naturalista, actualmente aberta ao público na Casa-Museu Egas Moniz, em Estarreja, onde se destacam obras de Silva Porto, José Malhoa e Carlos Reis, além de peças de louça, prata e mobiliário de variada proveniência, testemunho o seu grande interesse e apurado gosto pelas artes plásticas e decorativas.
Como investigador, Egas Moniz, contando com a preciosa colaboração de Pedro Almeida Lima, gizou duas técnicas: a leucotomia pré-frontal e a angiografia cerebral. Deve-se ainda a este autor a descrição do trajeto da artéria carótida interna no interior do osso temporal, tomando o mesmo a designação de Sifão carotídeo ou Sifão de Egas Moniz.
António Egas Moniz foi proposto cinco vezes (1928, 1933, 1937, 1944 e 1949) ao Nobel de Fisiologia ou Medicina, sendo galardoado em 1949. A primeira delas acontece alguns meses depois de ter publicado o primeiro artigo sobre a encefalografia arterial e, subsequentemente, ter feito, no Hospital de Necker, em Paris, uma demonstração da técnica encefalográfica. Este imediatismo não era uma coisa absolutamente ridícula pois, na verdade, «a vontade de Alfred Nobel era precisamente a de galardoar trabalhos desenvolvidos no ano anterior ao da atribuição do Prémio».
A técnica desenvolvida por Egas Moniz, a operação ao cérebro denominada lobotomia, após forte controvérsia deixou de ser praticada na década de 1960. Familiares de pacientes que sofreram aquela intervenção cirúrgica exigiram que fosse anulada a atribuição do Prémio Nobel feita a Egas Moniz.

</doc>
<doc id="815" url="https://pt.wikipedia.org/wiki?curid=815" title="Embriologia">
Embriologia

A embriologia é a ciência que estuda a formação dos órgãos e sistemas de um animal, a partir de uma célula. Faz parte da biologia do desenvolvimento. O desenvolvimento embrionário dos animais inicia-se pela relação sexual, gerando o zigoto ou ovo, que passará por três fases sucessivamente: mórula, blástula e gástrula.
Os espermatozoides são formados nos testículos, sendo depois armazenados nos epidídimos, estruturas em formas de C que ficam à volta dos testículos, onde ocorre a maturação dos espermatozoides. Estes são levados pelos funículos espermáticos, e em seguida ao ducto deferente até a parte final da uretra, a fossa navicular de onde é expelido durante a ejaculação. É importante lembrar que a cada ejaculação o homem produz em média de 200 a 500 milhões de espermatozoides, sendo somente 15 por cento são perfeitos, com chances de chegar ao seu objetivo. E desses um só consegue penetrar no ovócito II. 
Já dentro do trato genital feminino, o espermatozoide, com seu flagelo, vai ao encontro do ovócito II, por atração química. Durante esse percurso é quando acontece a capacitação, onde o espermatozoide, juntamente com substâncias genitais femininas, das quais retira algumas propriedades, o que faz com que ele seja atraído pelo ovócito II e consiga fecundá-lo.
Chegando ao encontro do gameta feminino, esse espermatozoide, cuja célula tem grande número de lisossomas, libera algumas substâncias para digerir a camada de células (teca) e a zona pelúcida, que envolve o ovócito II. É importante lembrar que essa camada é um pouco espessa, e portanto o primeiro espermatozoide a chegar nunca entra no ovócito II, mas os outros aproveitam-se do caminho feito pelos primeiros.
Quando o espermatozoide atinge o ovócito II, há uma despolarização química desse ovócito II, o que a enrijece e impede que outros gametas adentrem o ovócito II, o que dura aproximadamente 15 segundos, fazendo desencadear o bloqueio lento. Esse bloqueio lento é o processo pelo qual ocorre a diferenciação sexual.
Dentro do ovócito II, existem algumas estruturas chamadas vesículas corticais, que "estouram" depois do bloqueio lento, liberando substâncias que tornam o ovócito II não mais atrativo ao espermatozoide.
Então depois de todo esse trajeto e algum tempo, o ovócito II e o espermatozoide, já fundidos, passam a se chamar ovo, uma única célula com 46 cromossomas, 23 do pai e 23 da mãe, que dará origem a um novo ser.
Portanto, a fecundação dá-se quando um espermatozoide fecunda um ovócito II e forma uma Célula-ovo que se divide por mitoses sucessivas em 2,4,8..16..32... células.
Atualmente há um interesse crescente em torno do desenvolvimento humano desde o período que precede o nascimento (chamado de desenvolvimento embrionário). Este é um processo contínuo que tem seu início quando um ovócito (óvulo) é fertilizado por um espermatozoide. Algumas fases se combinam e transformam o ovócito fertilizado (totipotente) em um organismo multicelular, são elas: a divisão, a migração e a morte celular junto à diferenciação, ao crescimento e ao rearranjo celular. Apesar da maioria das mudanças ocorrerem nos períodos embrionários e fetais, acontecem também muitas mudanças significativas e igualmente importantes no período posterior ao nascimento, na sequência das fases de infância, adolescência e início da fase adulta.
Com isso é fácil dizer que o desenvolvimento não termina ao nascimento, aliás se inicia com a fertilização, pois a partir de então ocorre mudanças que vão além do crescimento, como por exemplo o desenvolvimento dos dentes e das mamas. O cérebro triplica seu peso entre o nascimento e os 16 anos de idade, contudo o desenvolvimento estará completo por volta dos 25 anos, podendo variar de indivíduo para indivíduo.
Veremos a seguir as etapas do desenvolvimento do indivíduo, dividindo-o em dois períodos: pré-natal e pós-natal.
Ficheiro:
No quadro esquemático acima pode-se acompanhar as principais alterações ocorridas antes do nascimento. Vários estudos realizados sobre a cronologia pré-natal mostram que muitos dos avanços perceptíveis ocorrem entre a terceira e a oitava semana de gestação, ainda que se saiba que o embrião inicia todo seu desenvolvimento a partir da fertilização do ovócito. Para entender melhor este quadro esquemático, faz-se necessário conhecer as terminologias embriológicas a seguir:
É o processo de formação e desenvolvimento das células germinativas, os gametas, preparando-os para a fertilização. Durante a gametogênese, o número de cromossomos é reduzido para metade e a forma das células é alterada. A gametogênese masculina é chamada espermatogênese e a feminina Ovogênese.
Na espermatogênese, ainda no período fetal são formadas as espermatogônias, células diploides, que ficam nos tubos seminíferos. Ao atingir a puberdade, estas células irão começar a desenvolver-se, aumentando de número por meio de sucessivas mitoses. Após sofrerem mitoses e modificações, transformam-se em espermatócitos primários. Estas células sofrerão uma meiose reducional. Assim formam-se dois espermatócitos secundários, haploides, que sofrem uma 2° divisão meiótica que formará quatro espermatidíos haploides. Esses espermatidíos sofrerão a espermiogênese, um processo de maturação das espermatidíos até se transformarem em espermatozoides. Todo o processo da espermatogênese é sustentado pelas células de Sertoli, que revestem o túbulo seminífero, nutrindo os espermatidíos.
A ovogênese é mais complicada. Consiste, muito resumidamente, na transformação das ovogônias em ovócitos maduros. Antes de nascer, no período fetal, as ovogônias, células diploides, começam a proliferar-se por divisões mitóticas. Ainda no período fetal, as ovogônias desenvolvem-se e formam os ovócitos primários (ovócito I), que consistem em células esféricas cobertas pela zona pelúcida e por um folículo primordial, células do tecido conjuntivo achatadas. Na puberdade este folículo primordial cresce, e o ovócito primário também. As células foliculares sofrem modificações até formarem o Folículo Primário. Depois com a formação de mais camadas foliculares, forma-se o folículo secundário. E assim o desenvolvimento destas células fica parado na prófase da Meiose I (estágio de dictióteno), que seria até mais ou menos os 11 anos.
Após o nascimento , não se forma mais nenhum ovócito I. Ou seja, a mulher nasce com um número certo de células reprodutoras, enquanto o homem têm uma contínua produção de espermatócitos, pois o ciclo mitótico e meiótico é constante nos homens.
Assim os ovócitos I permanecem em repouso nos folículos ovarianos até a puberdade (em prófase, no dictióteno). O ovócito I aumenta de tamanho na maturação imediatamente antes da ovulação.
É nos túbulos seminíferos, que são produzidos os espermatozoides. Dentro deles encontra-se o epitélio germinativo, que são células que se diferenciam para formar o espermatozoide.

</doc>
<doc id="816" url="https://pt.wikipedia.org/wiki?curid=816" title="Wikipédia:Embaixada">
Wikipédia:Embaixada

O projeto Wikipédia é multilíngue. Está disponível em cerca de duas centenas de línguas, sendo elaboradas ativamente e muitas mais prontas para começar.
Esta Embaixada da Wikipédia foi estabelecida como um ponto de referência de recursos que ajudem a tratar questões interlinguísticas — políticas e modificações no software que afetam a todas as versões da Wikipédia e interligação entre Wikipédias em diferentes línguas.
Se estiver disposto a ajudar, estabeleça uma página equivalente na Wikipédia de sua língua, ligue-a com as outras embaixadas e inclua seu nome como um Embaixador da Wikipédia abaixo.
A lista de discussão "wikipedia-l" (Wikipédia em geral - todas as línguas) está aberta a todos os wikipedistas de todas as línguas e nacionalidades. A língua principal é o inglês, mas todas as línguas são bem-vindas — outra pessoa pode traduzir se necessário. Mensagens bilíngues são "muito" bem-vindas!
O trabalho de um Embaixador da Wikipédia é ficar de olho na página da Embaixada de sua língua. Na Wikipédia em português é a página . Também deve usar a lista de discussão "wikipt" (Wikipédia em português) e "wikipedia-l" (Wikipédia em geral - todas as línguas) para tratar de assuntos de interesse da comunidade que ele representa. Ele deve também trazer à atenção da comunidade multilíngue geral questões e ideias surgidas localmente que possam afetar ou beneficiar a todos.
A lista completa de embaixadores está em .

</doc>
<doc id="817" url="https://pt.wikipedia.org/wiki?curid=817" title="Exu (Pernambuco)">
Exu (Pernambuco)

Exu é um município brasileiro do estado de Pernambuco no Sertão Pernambucano. Administrativamente, o município é composto pelo distrito sede e pelos povoados de Tabocas, Timorante, Viração e Zé Gomes São Felix e União São Bento. Localizado na BR-122, altura da Serra do Araripe, é ultima cidade ("dado não oficial") na divisa entre os estados de Pernambuco e Ceará. Com seus 108 anos, vem crescendo gradativamente. Um de seus filhos mais importantes foi o músico Luis Gonzaga, conhecido como O Rei do Baião.
A região onde se situa o município era primitivamente habitada pelos índios Ançus, do tronco dos Cariris. A região foi ocupada por fazendas de gado no início do século XVIII, tendo à frente Leonel de Alencar Rego e posteriormente seu filho Joaquim Pereira de Alencar. Após a ocupação, missões jesuíticas viveram na região, onde construíram a capela de Bom Jesus dos Aflitos. Em 1734, foi criada a freguesia do Senhor Bom Jesus dos Aflitos de Exu. O município foi instalado em 7 de junho de 1885, passando a autônomo em 9 de julho de 1893, em face a lei n. 52, de 3 de agosto de 1892. O primeiro prefeito foi Manoel da Silva Parente. O município foi supresso em 1895 e restaurado 1907, com a denominação de Novo Exu. Pelo decreto-lei estadual n 235, de 9 de dezembro de 1938, o município de Novo Exu passou a denominar-se Exu.
Passou por uma grave crise no século XX devido a lutas políticas entre três famílias: Alencar, Sampaio e Saraiva, o que provocou o atraso da cidade em relação a outras da região, como Araripina, Ouricuri e Salgueiro. Procurou reconquistar o espaço novamente na Microrregião de Araripina com a cultura (sem sucesso), através de artistas como Luiz Gonzaga, oriundo de Exu.
A cidade está localizada no Polígono da Seca e abriga um museu em homenagem ao seu filho mais ilustre, Luiz Gonzaga.
Segundo o IBGE, há duas versões prováveis para o nome do município. A primeira é que seja uma corruptela de "Ançu", uma tribo índigena que habitava o entorno. Outra, é que o nome tenha vindo da abelha enxu (inxu), muito comum na região à época. Há que se notar que dificilmente as origens do nome sejam no orixá homônimo, haja vista que à altura da fundação da vila, criada por colonos, apenas indígenas habitavam o local.
Deve-se considerar que devido a influência dos cristãos novos (muito abundantes em Pernambuco naquela época) o nome da freguesia "Aflitos de Exu" pode aludir à aflição que os marranos sentiam por serem perseguidos pelo Tribunal do Santo Ofício que os perseguiu desde Espanha e Portugal até ao Brasil. Para fugir da Inquisição aqueles marranos buscaram se instalar cada vez mais no interior de Pernambuco. Ieshu (ou IEXU em português) é uma palavra hebraica (a língua dos marranos pernambucanos) e significa Jesus.
Localiza-se a uma latitude 07º30'43" sul e a uma longitude 39º43'27" oeste, estando a uma altitude de 523 metros. Sua população em 2007 era de 30.569 habitantes.
O clima é semiárido e quente, frio no inverno e quente no verão. O índice pluviométrico é 865 mm anuais de água.
O município de Exu está inserido na maior parte na unidade geoambiental dos Maciços e Serras Baixas, com altitudes entre 300 e 800 metros. Ao norte, uma porção está inserida na unidade geoambiental das Chapadas Altas.
O relevo de Exu apresenta terrenos planos e acidentados, influenciado pela Chapada do Araripe, com terras altas, planas e descendo a serra, encontram-se terras baixas e terras férteis e várias nascentes no sopé da serra.
A vegetação é predominantemente de Floresta Caducifólia e Caatinga Hipoxerófila. O município também apresenta vegetação do cerrado no sopé da chapada, com espécies como: aroeira, braúna, sabiá, ameixa, pequi, sucupira e angico, amburana branca e vermelha, cedro, angico, eucalipto e a barriguda, quase extinta.
As principais espécies animais da região são o preá, tatupeba, gambá, sagüi, urubu, coruja, gavião, raposa, além de diversos tipos de aves e répteis.
O município de Exu situa-se na bacia hidrográfica do rio Brígida. Seus principais tributários são os riachos da Brígida, da Carnaúba ou Carrancudo, da Queimada Grande, Tabuleiro, Cantarino, do Ouro, da Califórnia, da Maniçoba, de José Gomes, da Estrada, dos Paus Grandes, das Tabocas, do Mocambo, São Joaquim e do Tigre, todos de regime intermitente. Conta ainda com as lagoas da Caraíba, de Dentro, da Cascavel, do Caracol, Grande e das
Marrecas.

</doc>
<doc id="818" url="https://pt.wikipedia.org/wiki?curid=818" title="Entre Folhas">
Entre Folhas

Entre Folhas é um município brasileiro no interior do estado de Minas Gerais, Região Sudeste do país. Pertence à Mesorregião do Vale do Rio Doce, à Microrregião de Caratinga e ao colar metropolitano do Vale do Aço e sua população estimada em 2014 era de habitantes.
A exploração da área onde está situado o atual município foi iniciada em 1781. O nome recebido pela localidade, Entre Folhas, refere-se a um córrego coberto de folhas que corria em meio à mata. O local recebera a sede da Intendência do Império, tendo por muito tempo forte influência da política do coronelismo. Através do decreto estadual nº 16, de 6 de fevereiro de 1890, é criado o distrito, subordinado a Manhuaçu, mais tarde passando a pertencer a Caratinga.
Em 1900, houve a destituição da função de intendência, deixando de possuir influência regional. A Igreja da Matriz Nossa Senhora do Rosário ainda mantém o sino doado por Dom Pedro II, trazendo o selo da Casa de Bragança, no entanto quase todo o acervo histórico, que era mantido no templo, foi perdido em um incêndio acidental. O distrito chegou a ser extinto pela lei nº 336, de 27 de dezembro de 1948, sendo recriado pela lei estadual nº 1.039, de 12 de dezembro de 1953. A emancipação é decretada pela lei estadual nº 10.704, 27 de abril de 1992.
Localiza-se na vertente ocidental do Caparaó e tem como vizinhas as cidades de Vargem Alegre, recém-emancipada, Bom Jesus do Galho, Inhapim, Ubaporanga e Caratinga, estando a uma altitude de 495 metros. A principal atividade econômica desenvolvida no município é a agropecuária, sobretudo o cultivo do café e hortifrutigranjeiras que influenciam a demanda escolar, sendo que anualmente há um índice de evasão por alunos que se dedicam à colheita.
Entre Folhas é dotada de um Posto de Saúde Municipal que oferece a toda população um atendimento básico, tais como: Consulta, Exames laboratoriais mais simples, equipe de PSF(Programa Saúde da Família), Programas de vacinação, Fisioterapia, Saúde Bucal, Funasa, Programa de Saúde Mental, Assistência Social, CRAS, Conselho Tutelar.
Em Entre Folhas, durante sua história, já existiram vários colégios. O primeiro foi o "Externato", fundado pelo Padre Caetano e pelo Sr. José Cristiano Júnior, por volta de 1916.
Atualmente, Entre Folhas conta com 6 escolas municipais e 1 estadual.
A cidade de Entre Folhas de 1998 a 1999 foi sede do Seminário Propedêutico São José de Ubaporanga. Durante a fundação e os primeiros anos a instituição de formação inicial de seminaristas da Diocese de Caratinga teve sua sede na paróquia situada na cidade.

</doc>
<doc id="820" url="https://pt.wikipedia.org/wiki?curid=820" title="Embu das Artes">
Embu das Artes

Embu das Artes é um município da Microrregião de Itapecerica da Serra, na Zona Sudoeste da Região Metropolitana de São Paulo, no estado de São Paulo, no Brasil. Sua população estimada em 2009 era de habitantes. A sua área é de 70,1 km², o que resulta em uma densidade demográfica de . É considerado, oficialmente, uma estância turística.
Sua história curiosa lhe trouxe uma especialização contemporânea imprevista: ser uma cidade especialmente vocacionada para acolher artistas. Isto aporta dividendos turísticos à cidade.
"Embu" é um termo oriundo da língua tupi, significando "rio das cobras", a partir da junção dos termos "mboîa" (cobra) e " 'y " (rio).
Embu das Artes é um dos 29 municípios paulistas considerados estâncias turísticas pelo Estado de São Paulo, por cumprirem determinados pré-requisitos definidos por lei estadual. Tal "status" garante a esses municípios uma verba maior por parte do estado para a promoção do turismo regional. Também, o município adquire o direito de agregar junto a seu nome o título de estância turística, termo pelo qual passa a ser designado tanto pelo expediente municipal oficial quanto pelas referências estaduais.
Até o século XVI, a região era habitada pelos índios tupiniquins.
Em 1554, um grupo de jesuítas fundou o aldeamento de Bohi, depois M'Boy Mirin, a meio caminho do mar e do sertão paulista. Como todas as missões jesuíticas no interior do Brasil de então, esta tinha objetivos missionários e pretendia catequizar os índios locais, aproveitando-os também como força de trabalho para as fazendas que se foram criando na região.
Em 1607, as terras da aldeia passam para as mãos de Fernão Dias (tio do bandeirante Fernão Dias, o Caçador de Esmeraldas), mas, poucos anos mais tarde, em 1624, foram doadas à Companhia de Jesus. Em 1690, o Padre Belchior de Pontes iniciou a construção da Igreja do Rosário, transferindo, ao mesmo tempo, o núcleo da aldeia original. Já no século XVIII, entre 1730 e 1734, os jesuítas construíram a sua residência anexa à igreja, formando um conjunto arquitetônico contínuo de linhas retas e sóbrias. Mas, em 1760, por ordem da Coroa Portuguesa, os jesuítas foram expulsos do Brasil.
A região fazia parte do antigo município de Santo Amaro, e posteriormente do município de Itapecerica da Serra.
Embu foi elevada à categoria de município em 1959, quando se emancipou de Itapecerica da Serra.
A vocação artística da cidade começou a projetar-se em 1937, quando Cássio M'Boy, santeiro de Embu, ganhou o Primeiro Grande Prêmio na Exposição Internacional de Artes Técnicas em Paris. Já antes, no entanto, Cássio foi professor de vários artistas e recebia em sua casa expoentes do Movimento Modernista de 1922 e das artes em São Paulo, incluindo Anita Malfatti, Tarsila do Amaral, Oswald de Andrade, Menotti Del Picchia, Alfredo Volpi e Yoshiya Takaoka.
A Cássio M'Boy seguiu-se Sakai de Embu, que começou por ser discípulo de Cássio e veio a ser reconhecido internacionalmente como um dos grandes ceramistas-escultores brasileiros. Sakai forma um grupo de artistas plásticos, ao qual pertence Solano Trindade.
Este chegou a Embu em 1962 e trouxe consigo a cultura negra, congregando um grupo de artistas em seu redor e introduzindo a tradição dos orixás.
A tradição artística da cidade institucionaliza-se e ganha projecção dentro e fora do Brasil em 1964, com o Primeiro Salão das Artes. Paralelamente, a partir dos finais dos anos 1960, a cidade passou a polo de atracção para "hippie"s, que expunham os seus trabalhos de artesanato nos finais de semana, dando origem à Feira de Artes e Artesanato, que se realiza todos os fins de semana desde 1969 e que é um dos principais motores da projecção turística da cidade.
Em 23 de Outubro de 2009, o prefeito de Embu das Artes, Chico Brito, deu início ao processo para que Embu fosse, oficialmente, chamada de Embu das Artes. Em 25 de novembro, o prefeito e o vice deram início ao ato pró-plebiscito para a coleta de assinaturas.
Para que o município recebesse o sobrenome "das Artes", foi necessária a realização de um plebiscito em que ao menos um por cento dos eleitores deveriam participar. O plebiscito foi anexado a um projeto de lei que foi enviada pelos poderes executivo e legislativo embuense para sanção do prefeito. Em seguida, o documento foi protocolado no Tribunal Regional Eleitoral, que convocou uma eleição para mudança do nome.
Segundo o prefeito, a oficialização do município para Estância Turística de Embu das Artes foi para que a cidade tivesse sua identidade e que não fosse mais confundida com Embu-Guaçu.
As três primeiras assinaturas do abaixo-assinado foram de Chico Brito (prefeito de Embu das Artes), Annis Neme Bassith (um dos articuladores da emancipação do município) e Silvino Bornfim (presidente da câmara municipal), que declarou:
O abaixo-assinado passou por toda a cidade através da campanha Embu das Artes - Todo Mundo Quer, lançada pela prefeitura.
O plebiscito ocorreu em 1 de maio de 2011 e 66,48 por cento da população optou pela nova denominação.
Em 6 de setembro de 2011, o governador Geraldo Alckmin sancionou a Lei Estadual 14.537/11, que, oficialmente, passou a denominar o município como Embu das Artes.
Situado no oeste da Grande São Paulo, o município tem os seguintes limites: a sudoeste, oeste e norte, com Cotia; a noroeste, Taboão da Serra; a sul, com o Itapecerica da Serra e o bairro paulistano de Capão Redondo.
O sistema hidrográfico de Embu é dividida em áreas de três bacias principais, todas afluentes do Rio Tietê:
Estima-se que 59% do território encontra-se sob área de proteção aos mananciais, sendo o Rio Embu-Mirim (Trata-se de uma extensão do Rio M'Boi Mirim) um dos principais contribuintes da Represa Guarapiranga.
O clima é tipo "C", segundo a Classificação de Köppen, subtropical ou mesotérmico de latitudes médias e com grande quantidade de chuvas no verão. A região possui altitude média, juntamente com ilhas de vegetação de Mata Atlântica, que amenizam a temperatura. O índice pluviométrico é de aproximadamente milímetros por ano e a temperatura média anual gira em torno dos , e.
Segundo a SABESP (Companhia de Saneamento Básico do Estado de São Paulo), o município é abastecido por dois sistemas: o Guarapiranga e o Alto Cotia, este último contribui com o seu subsistema principal, utilizando águas do Rio Cotia, localizado a oeste de Embu.
O Embu é servido de redes rodoviárias. A malha prevê as ligações da cidade com a capital e demais municípios da sub-região. Composta por rodovias, vias arteriais urbanas e estradas (municipais/estaduais), tem a principal dentre essas vias a BR116 - Rodovia Régis Bittencourt, cruzando o território municipal de nordeste a sudoeste por uma extensão de 9,2 km.
Sua origem está ligada a uma imagem do santo São Lázaro esculpida em madeira pelo artista Cássio M'Boy nos anos 1920. A imagem atraiu grande número de devotos e, em 1934, foi construída uma capela para abrigá-la. Em 1969, a capela foi restaurada, aproximando-se das linhas da arquitetura jesuítica da igreja do Conjunto Nossa Senhora do Rosário.
Sua arquitetura apresenta características do estilo barroco paulista e um acervo rico em imagens de anjos, santos e personagens bíblicos, quase todos entalhados em madeira, modelados em terracota ou em armações em roca, produzidas entre os séculos XVII e XIX.
A principal obra do museu é o "Senhor Morto", esculpido em uma tora de madeira, bem como as iamgens de Nossa Senhora das Dores e da Santa Ceia, em roca, de autoria do Padre Macaré. As demais obras foram esculpidas pelos jesuítas e índios.
É formado pela igreja e pela antiga residência dos padres, conjugadas numa mesma edificação. Trata-se de uma das mais importantes construções jesuítas em São Paulo, caracterizadas pela simplicidade das linhas retas.
A igreja começou a ser construída por volta de 1700 pelo Padre Belchior de Pontes. A intenção era a de que ela tivesse capacidade para que os índios e vizinhos pudessem comodamente observar os preceitos a que estavam obrigados, como registrou o Padre Manuel da Fonseca no livro "A Vida do Venerável Padre Belchior de Pontes", diferentemente da antiga capela da fazenda de Catarina Camacho situada não muito longe dali.
No Centro Histórico, encontra-se grande quantidade de galerias de arte, móveis rústicos e lojas de artesanato. Uma grande variedade gastronômica de comida típica brasileira e culinária internacional.
O Centro Cultural Mestre Assis do Embu oferece ao público, gratuitamente, acesso à arte, cultura e ao conhecimento. Ocupa, hoje, o histórico prédio da prefeitura. Nele, o público tem à disposição três salas para exposições e o auditório Cássio M’Boy, com capacidade para 150 pessoas destinado a palestras, recitais, espetáculos musicais e teatrais.
Instalada em frente ao Centro, fica a tenda Embu das Artes ao Vivo, onde artistas do município montaram uma extensão de seus ateliês, possibilitando ao público acompanhar em tempo real todo o processo criativo de pintores, escultores, ceramistas e forjadores da cidade.
O Brasão de armas da cidade de Embu foi instituído em 19 de novembro de 1962, pela lei N°130. Abaixo estão as características explicada e justificada segundo as leis:

</doc>
<doc id="821" url="https://pt.wikipedia.org/wiki?curid=821" title="Eduard von Steinle">
Eduard von Steinle

Eduard Jakob von Steinle (Viena, 2 de Julho de 1810 - Frankfurt am Main, 19 de Setembro de 1886) foi um pintor austríaco.
Um dos últimos grandes pintores da escola romântica, foi influenciado por Kupelweiser, Overbeck e Cornelius. Tem obras de arte sacra, nomeadamente frescos em igrejas e capelas em vários pontos da Alemanha, e também retratos de líderes alemães.

</doc>
<doc id="822" url="https://pt.wikipedia.org/wiki?curid=822" title="Estrutura algébrica">
Estrutura algébrica

Em álgebra abstracta, uma estrutura algébrica consiste num conjunto associado a uma ou mais operações sobre o conjunto que satisfazem certos axiomas. Caso não existam ambiguidades, geralmente identifica-se o conjunto com a estrutura algébrica. Por exemplo, um grupo ("G",*) refere-se geralmente apenas como grupo "G".
Em algumas estruturas algébricas além do conjunto principal existe mais um conjunto, denominado conjunto de escalares. Neste caso a estrutura terá dois tipos de operações: operações internas, que operam os objetos principais entre si e operações externas, que representam ações dos escalares sobre elementos do conjunto principal. Por exemplo, um espaço vectorial tem dois conjuntos, um conjunto de vectores e outro de escalares. Assim, se v1 e v2 são dois vetores e k é um escalar v1 * v2 seria o produto (interno) de vetores e k * v1 seria o produto (externo) de um escalar por um vetor.
O conceito de estrutura algébrica pode ser considerado sinônimo de Álgebra e Álgebra universal.
É comum representar uma estrutura algébrica por uma "n-upla" do tipo "(G,F,+,-,f,<,1)". Nesta notação, são enumerados os conjuntos que fazem parte da estrutura, seguido de constantes, funções e relações.
Dependendo das operações e axiomas, as estruturas algébricas ganham os seus nomes específicos.
O que se segue é uma lista parcial de estruturas algébricas:
Nas estruturas seguintes, temos dois conjuntos, um deles (auxiliar), chamado de "conjunto de escalares" e outro, o conjunto principal. Além das operações internas sobre o conjunto principal, podemos ter operações conectando os dois conjuntos:
As proposições que se aplicam colectivamente a todas as estruturas algébricas são investigadas no ramo da matemática conhecido como álgebra universal.
As estruturas algébricas também podem ser definidas em conjuntos com estruturas não-algébricas adicionais, como os espaços topológicos. Por exemplo, um grupo topológico é um espaço topológico com uma estrutura de grupo tal que as operações de multiplicação e inversão são contínuas; um grupo topológico possui quer uma estrutura topológica, quer uma estrutura algébrica. Outros exemplos comuns são espaços vectoriais topológicos e grupos de Lie.
Cada estrutura algébrica tem a sua própria noção de homomorfismo, uma função que é compatível com a operação ou as operações dadas. Desta forma, cada estrutura algébrica define uma categoria. Por exemplo, a categoria dos grupos tem como objectos todos os grupos e como morfismos todos os homomorfismos desses grupos. Esta categoria, uma vez que é uma categoria concreta, pode ser vista como uma categoria de conjuntos com estrutura extra, no sentido teórico das categorias. Analogamente, a categoria dos grupos topológicos (com os homomorfismos contínuos de grupo como morfismos) é uma categoria de espaços topológicos com estrutura extra.
Além das estruturas algébricas, existem mais duas estruturas fundamentais na matemática. São elas:
A partir destas três estruturas podem ser definidas estruturas mistas, quando para um conjunto são considerados operações, relações e partes de forma combinada. Por exemplo, um grupo topológico é um espaço topológico com uma estrutura de grupo tal que as operações de multiplicação e inversão são contínuas; um grupo topológico possui quer uma estrutura topológica, quer uma estrutura algébrica. Outros exemplos comuns são espaços vectoriais topológicos e grupos de Lie.

</doc>
<doc id="825" url="https://pt.wikipedia.org/wiki?curid=825" title="Engenharia metalúrgica">
Engenharia metalúrgica

A Engenharia metalúrgica é um ramo da engenharia, mais precisamente da engenharia de materiais que é dedicado ao estudo dos materiais metálicos, englobando sua caracterização estrutural, propriedades mecânicas, produção e processamento.
O engenheiro metalurgista é o profissional que desenvolve, executa e coordena projetos de tratamento e de produção de metais, é responsável por todo processo de beneficiamento de minérios, por sua transformação em ligas metálicas com propriedades físicas, químicas e metalúrgicas adaptadas a usos diversos, e estuda a utilização desses metais na confecção de máquinas, estruturas ou peças. Na indústria, determina a composição química dos metais e seu modo de industrialização. O engenheiro metalúrgico é também responsável pelo desenvolvimento de novas ligas metálicas, com propriedades físicas, químicas e metalúrgicas adaptadas a usos diversos.
Os dois primeiros anos são de aulas básicas de cálculo, física e química, em dois turnos. Boa parte das disciplinas específicas, do 5º ao 10º semestre, ocorrem em laboratórios. Os estudantes se envolvem em pesquisas, projetos e trabalhos como a certificação de materiais e perícias. Professores e alunos estudam em dez áreas: metalurgia física, processamento mineral, siderurgia, estudos ambientais para metalurgia, fundição, processos eletroquímicos e corrosão, transformação mecânica, termodinâmica computacional e fundamentos de economia e administração.
O mercado está aquecido para o profissional na metalurgia e mineração, pois a demanda ainda é maior que a oferta de formados. Engenheiros metalúrgicos encontram boa chance de emprego em empresas dos setores mecânico, metalurgia de metais não ferrosos, automobilísticas, de mineração, de armamento, de base, áreas de extração mineral. Outro campo promissor está nas indústrias aeronáuticas e siderúrgicas. De acordo com o Departamento Nacional de Produção Mineral (DNPM), o Brasil é o nono maior produtor e o 13º exportador mundial do aço. Novos investimentos garantem perspectivas positivas de emprego na área para os próximos dez anos. Nas mineradoras, especialmente as dos setores de alumínio e cobre, o profissional trabalha na área de metalurgia primária, que inclui a laminação e a fundição dos produtos. Os empregadores concentram-se principalmente em Minas Gerais, Rio de Janeiro, São Paulo, Espírito Santo, Rio Grande do Sul, Paraná, Bahia, Pernambuco, Ceará, Pará e Maranhão. Os engenheiros metalúrgicos também são requisitados em setores públicos, empresas de projetos e de consultoria, indústrias de autopeças, além de bancos para fazer análise de projetos e centros de pesquisa. Outro campo em crescimento é o do ensino, já que a tendência é de aumento no número de cursos oferecidos no país.
O parque siderúrgico brasileiro compõe-se hoje de 27 usinas, administradas por oito grupos empresariais. São eles: Aperam South America, Gerdau, Companhia Siderúrgica Nacional (CSN), Usiminas, Siderúrgica Norte Brasil(SINOBRAS), Vallourec, Villares Metals S.A e Votorantim Siderurgia. A privatização trouxe ao setor uma concorrência expressiva de capitais. Assim, muitas empresas produtoras ampliaram o interesse na siderurgia. O parque produtor brasileiro é novo e passa por um processo de atualização tecnológica. O parque metal-mecânico do Brasil está aquecido com novas unidades.
A Petrobras é a empresa que mais contrata engenheiros metalúrgicos no país. Eles atuam em inspeção, pesquisa, dutos, refinarias e apoio nas plataformas. O profissional também trabalha em bioengenharia (uso de próteses para o corpo humano), controle ambiental e em processos de indústrias automobilísticas, mecânicas, instituições de ensino e pesquisa.
O piso salarial do engenheiro é oito salários mínimos, variando de estado e por função exercida.
FEAMIG,IFMG,UEMG,FASAR, UFRGS, UFOP, UFC, UFF, UFMG, UFRJ, USP, PUC-RJ, PUC-MG, IFES (antigo CEFET-ES), UENF, Mackenzie, Sociesc, UVV, UnilesteMG
Os laboratórios da faculdade funcionam como porta para o mercado. O aluno deve buscar oportunidades e caprichar no trabalho de conclusão.

</doc>
<doc id="826" url="https://pt.wikipedia.org/wiki?curid=826" title="Física">
Física

Física (do grego antigo: φύσις "physis" "natureza") é a ciência que estuda a natureza e seus fenômenos em seus aspectos mais gerais. Analisa suas relações e propriedades, além de descrever e explicar a maior parte de suas consequências. Busca a compreensão científica dos comportamentos naturais e gerais do mundo em nosso torno, desde as partículas elementares até o universo como um todo. Com o amparo do método científico e da lógica, e tendo a matemática como linguagem natural, esta ciência descreve a natureza através de modelos científicos. É considerada a ciência fundamental, sinônimo de ciência natural: as ciências naturais, como a química e a biologia, têm raízes na física. Sua presença no cotidiano é muito ampla, sendo praticamente impossível uma completíssima descrição dos fenômenos físicos em nossa volta. A aplicação da física para o benefício humano contribuiu de uma forma inestimável para o desenvolvimento de toda a tecnologia moderna, desde o automóvel até os computadores quânticos.
Historicamente, a afirmação da física como ciência moderna está intimamente ligada ao desenvolvimento da mecânica, que tem como pilares principais de estudo a energia mecânica e os momentos linear e angular, suas conservações e variações. Desde o fim da Idade Média havia a necessidade de se entender a mecânica, e os conhecimentos da época, sobretudo aristotélicos, já não eram mais suficientes. Galileu centrou seus estudos dos projéteis, dos pêndulos e nos movimentos dos planetas, e Isaac Newton elaborou mais tarde os princípios fundamentais da dinâmica ao publicar suas leis e a gravitação universal em seu livro "Principia", que se tornou a obra científica mais influente de todos os tempos. A termodinâmica, que estuda as causas e os efeitos de mudanças na temperatura, pressão e volume em escala macroscópica, teve sua origem na invenção das máquinas térmicas durante o século XVIII. Seus estudos levaram à generalização do conceito de energia. A ligação da eletricidade, que estuda cargas elétricas, com o magnetismo, que é os estudo das propriedades relacionadas aos ímãs, foi percebida apenas no início do século XIX por Hans Christian Ørsted. As descrições físicas e matemáticas da eletricidade e magnetismo foram unificadas por James Clerk Maxwell, e a partir de então estas duas áreas, juntamente com a óptica, passaram a ser tratadas como visões diferentes do mesmo fenômeno físico, o eletromagnetismo. No início do século XX, a incapacidade da descrição e explicação de certos fenômenos observados, como o efeito fotoelétrico, levantou a necessidade de abrir novos horizontes para a física. Albert Einstein publicou a teoria da relatividade geral em 1915, afirmando a constância da velocidade da luz e suas consequências até então imagináveis. A teoria da relatividade de Einstein leva a um dos princípios de conservação mais importantes da física, a relação entre massa e energia, expressa pela famosa equação E=mc². A relatividade geral também unifica os conceitos de espaço e tempo: a gravidade é apenas uma consequência da deformação do espaço-tempo causado pela presença de massa. Max Planck, ao estudar a radiação de corpo negro, foi forçado a concluir que a energia está dividida em "pacotes", conhecidos como quanta. Einstein demonstrou fisicamente as ideias de Planck, fixando as primeiras raízes da mecânica quântica. O desenvolvimento da teoria quântica de campos trouxe uma nova visão da mecânica das forças fundamentais. O surgimento da eletro e cromodinâmica quântica e a posterior unificação do eletromagnetismo com a força fraca a altas energias são a base do modelo padrão, a principal teoria de partículas subatômicas e capaz de descrever a maioria dos fenômenos da escala microscópica que afetam as principais áreas da física.
A física é uma ciência significativa e influente e suas evoluções são frequentemente traduzidas no desenvolvimento de novas tecnologias. O avanço nos conhecimentos em eletromagnetismo permitiu o desenvolvimento de tecnologias que certamente influenciam o cotidiano da sociedade moderna: o domínio da energia elétrica permitiu o desenvolvimento e construção dos aparelhos elétricos; o domínio sobre as radiações eletromagnéticas e o controle refinado das correntes elétricas permitiu o surgimento da eletrônica e o consequente desenvolvimento das telecomunicações globais e da informática, que são indissociáveis da definição de sociedade civilizada contemporânea. O desenvolvimento dos conhecimentos em termodinâmica permitiu que o transporte deixasse de ser dependente da força animal ou humana graças ao advento dos motores térmicos, que também impulsionou toda uma Revolução Industrial. Nada disso seria possível, entretanto, sem o desenvolvimento da mecânica, que tem suas raízes ligadas ao próprio desenvolvimento da física. Porém, como qualquer outra ciência, a física não é estática. Físicos ainda trabalham para conseguir resolver problemas de ordem teórica, como a catástrofe do vácuo, gravitação quântica, termodinâmica de buracos negros, dimensões suplementares, flecha do tempo, inflação cósmica e o mecanismo de Higgs, que prevê a existência do bóson de Higgs, a única partícula ainda não descoberta do modelo padrão que explicaria a massa das partículas subatômicas. Ainda existem fenômenos observados empiricamente e experimentalmente que ainda carecem de explicações científicas, como a possível existência da matéria escura, raios cósmicos com energias teoricamente muito altas e até mesmo observações cotidianas como a turbulência. Para tal, equipamentos sofisticadíssimos foram construídos, como o "Large Hadron Collider", o maior acelerador de partículas já construído do mundo, situado na Organização Europeia para a Investigação Nuclear (CERN).
As pessoas, desde a Antiguidade, estavam conscientes da regularidade da Natureza. Desde tempos remotos sabia-se que o ciclo lunar era de aproximadamente 28 dias, e que os objetos, na ausência de suporte, caíam. Inicialmente, tentaram explicar tais regularidades usando a metafísica e a mitologia; tais regularidades eram obras de deuses e deusas, que controlavam o mundo ao seu bel prazer. Entretanto, a física, conhecida desde a antiguidade até o século XVIII como filosofia natural, iniciou-se como uma tentativa de se obter explicações racionais para os fenômenos naturais, evitando-se sobremaneira as infiltrações religiosas ou mágicas.
Povos de diferentes partes da Terra começaram a desenvolver ciência, sempre em torno da filosofia natural, em épocas e com ênfases diferentes. Os Indianos já refletiam sobre questões físicas desde o terceiro milênio antes de Cristo. Entre o nono e o sexto século a.C. os filósofos indianos já defendiam o heliocentrismo e o atomismo. No quarto século a.C., os chineses já haviam enunciado o que é conhecido hoje como a Primeira lei de Newton. No primeiro século a.C. os povos maias já haviam elaborado a noção de zero, antes mesmo dos europeus.
As primeiras tentativas ocidentais de prover uma explicação racional para os fenômenos naturais vieram com os gregos. Tales de Mileto foi historicamente o primeiro filósofo ocidental a recusar explicações sobrenaturais, religiosas ou mitológicas para os fenômenos naturais, defendendo que todo evento físico tem uma causa natural. Pitágoras e seus seguidores acreditavam que o mundo, assim como o sistema numérico inteiro, era dividido em elementos finitos, concebendo, assim, as noções de atomismo. Demócrito de Abdera, Leucipo de Mileto e Epicuro, entre o quinto e o terceiro séculos a.C., impulsionaram a filosofia do atomismo, onde propuseram que toda matéria seria constituída de pequenos átomos indivisíveis. Aristarco de Samos foi um dos primeiros defensores do heliocentrismo, embora na Grécia Antiga prevalecesse o paradigma geocentrista. A experiência, assim como todo trabalho braçal, na Grécia Antiga, eram ignorados, pois as explicações sobre o mundo físico eram baseadas em um pequeno número de princípios filosóficos. Arquimedes, entretanto, prezava a experiência: os fundamentos da estática e da hidrostática têm suas origens em Arquimedes. Os princípios do conceito de empuxo foram primeiramente formulados por ele. Tal conceito ficou conhecido como o princípio de Arquimedes.
Aristóteles é considerado um dos principais filósofos naturais da Grécia Antiga. Para ele e seguindo a ideia de Empédocles, o Universo era formado de quatro elementos básicos: o ar, a terra, a água e o fogo, além de um quinto elemento, o éter, elemento perfeito, que preencheria o restante do Universo para além da órbita da Lua. Para Aristóteles, era inconcebível a noção de vácuo e infinito. Cada elemento teria lugar próprio dentro do Universo, sendo que a terra tenderia a permanecer no centro do Universo e o fogo tenderia a fugir dele. No seu livro, "física", Aristóteles diz que a causa do movimento é a força atuante; assim que cessa a força, cessa o movimento. A continuação do movimento após a perda de contato com o causador do movimento seria a "tendência" do ar em preencher o vazio que um projétil deixa em seu rastro. Este "preenchimento" resultaria em uma força que impulsionaria o projétil para frente, mas tal efeito não seria perpétuo, findando em algum instante.
Para explicar o movimento planetário, Eudoxo de Cnido, no quarto século a.C., elaborou as primeiras observações quantitativas para montar um modelo matemático dos movimentos planetários. Eudoxo desenvolveu um sistema de esferas concêntricas, sendo que cada esfera carrega um planeta. Este sistema foi se sofisticando ao longo dos séculos, com a crença dos gregos em um sistema geocêntrico. Todas as anomalias observadas, como a regressão aparente dos planetas e até mesmo a precessão do eixo da Terra, descoberta por Hiparco, foi explicada através do aumento da complexidade do sistema de esferas geocêntricas. Ptolomeu, no século II a.C. havia elaborado um sistema esférico dos planetas com mais de 80 esferas e epiciclos e seu trabalho, resumido em uma coleção de 13 livros que ficaram conhecidos como "Almagesto", foi utilizado amplamente pelos árabes e europeus até a alta Idade Média.
Com a queda do Império Romano, no século IV d.C., a maior parte da filosofia natural grega, assim como toda a educação em geral, perde importância. Esta época ficou conhecida como a "idade das trevas" para a evolução do conhecimento natural. Entretanto, o conhecimento natural dos gregos não foi totalmente perdido, migrou para o Oriente Médio e para o Egito. Os árabes, que já viviam naquela região, traduziram a literatura grega para o árabe. Assim, os árabes não só adquiriram o conhecimento grego, mas também o refinaram. Al-Khwarizmi é considerado o fundador da álgebra que hoje conhecemos. O astrolábio, presumidamente inventado por Ptolomeu, foi aperfeiçoado pelos persas.
No século XI, após a reconquista espanhola sobre os árabes, boa parte dos textos gregos que os árabes possuíam começou a ser traduzido para o latim. Assim, a Europa medieval voltou a apreciar a filosofia natural após longos séculos de escuridão. Uma vez traduzidos, todos os documentos foram estudados primeiramente por escolas estabelecidas juntamente a igrejas e catedrais. Tais escolas transformaram-se nas primeiras universidades medievais posteriormente. As universidades de Cambridge e Oxford foram fundadas no século XIII. Apesar de oferecerem ainda um ensino escolástico, tais universidades começaram a dar suporte para os primeiros desenvolvimentos científicos.
Guilherme de Ockham foi um dos mais importantes filósofos naturais da Idade Média. Rejeitou a explicação aristotélica do movimento e a teoria do "impetus", desenvolvida ainda na Grécia Antiga e retomada por Jean Buridan. Ockham afirmava que um objeto em movimento, após ter perdido contato com o seu lançador, já não é "portador" de qualquer força, segundo a teoria do "impetus", pois não se pode mais distinguir o objeto em movimento: o objeto em movimento pode ser o projétil, sob a perspectiva do lançador, ou o próprio lançador, sob o ponto de vista do projétil. A "Navalha de Ockham" diz que a explicação para qualquer fenômeno deve assumir apenas as premissas estritamente necessárias à explicação deste e eliminar todas as que não causariam qualquer diferença aparente nas predições da hipótese ou teoria.
O renascimento foi a época do redescobrimento do conhecimento na Europa. Vários acontecimentos revolucionaram a forma de pensar da sociedade europeia. Em 1543, Nicolau Copérnico publica "De revolutionibus orbium coelestium", apresentando um modelo matemático completo de um sistema heliocêntrico. Galileu Galilei é considerado o fundador da ciência moderna. Segundo Galileu, o cientista não tem o papel de explicar porque os fenômenos acontecem na Natureza, apenas pode descrevê-los. Em uma de suas obras, Galileu não afirmou que estava explicando a queda livre, apenas estava descrevendo-o. Galileu também foi o primeiro a conceber o conceito de inércia na Europa e foi o fundador da física como conhecemos hoje ao empregar a matemática na descrição de fenômenos naturais, que eram endossados pela experimentação. A sua contribuição para o desenvolvimento do telescópio contribuiu para a gradual consolidação do heliocentrismo, com a descoberta dos satélites galileanos.
Os métodos científicos de Galileu já eram uma derivação da nova forma de filosofia que vinha sendo desenvolvida por Francis Bacon e René Descartes, formulando as bases do método científico, que vinha sendo ensaiado desde a "era dourada" da filosofia natural Islâmica. Segundo Bacon, a ciência é experimental, qualitativa e indutiva. Rejeita assunções "a priori" e se houver uma quantidade suficiente de observações, estas seriam usadas para se induzir ou generalizar os princípios fundamentais envolvidos.
René Descartes propôs uma lógica diferente: em vez de se iniciar as observações com fatos "crus", Descartes acreditava que os princípios básicos que regem a Natureza podiam ser obtidos por uma combinação da pura razão com lógica matemática. Sua abordagem era analítica; os problemas deveriam ser "partidos" e rearranjados logicamente. Os fenômenos podem ser reduzidos e analisados aos seus componentes fundamentais. Se os componentes fundamentais fossem entendidos, o fenômeno também seria. A congruência entre os pensamentos de Bacon e de Descartes, mesmo que entrassem em conflito em certas discussões, dominou as investigações científicas nos três séculos seguintes.
A filosofia cartesiana, ou cartesianismo, rejeita toda e qualquer autoridade na obtenção do conhecimento. Os princípios básicos que regem a Natureza podiam ser obtidos por uma combinação da pura razão com lógica matemática. Em outras palavras, a busca pela verdade está baseada apenas na razão. Desse paradigma os dogmas religiosos, os preconceitos sociais, as censuras políticas e os aspectos fornecidos pelos sentidos são excluídos. A matemática passou a ser o modelo e a linguagem de todo conhecimento relacionado à ciência. Várias correntes de pensamento surgiram da filosofia cartesiana, como o racionalismo e o empirismo, e destas surgiriam o determinismo, o reducionismo e o mecanicismo.
Após Galileu, Isaac Newton foi um dos cientistas mais importantes para o desenvolvimento da mecânica clássica. Suas três leis serviram de base para toda a mecânica até o início do século XX. Sua mecânica tornou-se modelo para a construção de teorias científicas futuras. Em seu livro "Philosophiae Naturalis Principia Mathematica", considerado a publicação mais influente de toda a história, descreveu a universalidade de suas leis e concluiu a primeira grande unificação da História da física, já iniciada por Galileu, ao unir Céus e Terra sob as mesmas leis físicas, a gravitação universal.
A invenção da máquina a vapor, aprimorada por Thomas Newcomen e James Watt, levou a um grande interesse científico no estudo do calor. O francês Sadi Carnot, já no século XIX, formulou as bases para o entendimento de máquinas térmicas. Joseph Black começou a quantificar o calor através da medida da capacidade térmica das substâncias. James Prescott Joule estabeleceu uma equivalência numérica entre trabalho e calor e mostrou que o calor produzido por uma corrente elétrica I em um condutor de resistência R era dado por I²R, conhecido atualmente como Lei de Joule. Os trabalhos de Joule estabeleceram o princípio da conservação da energia, que se tornou a base para a primeira lei da termodinâmica, formulada por Rudolf Clausius e William Thomson (Lord Kelvin). Clausius também formulou o conceito de entropia, que é a base para a segunda lei da termodinâmica. Assim como a mecânica Newtoniana se apoia em três leis fundamentais, as quatro leis da termodinâmica apoiam todo o conhecimento nesta área.
As forças magnética e elétrica já eram conhecidas desde a antiguidade. Entretanto, o estudo científico da eletricidade e do magnetismo foi iniciado no século XVII por William Gilbert, em seu livro "De Magnete". Otto von Guericke produziu o primeiro gerador eletrostático. Pieter van Musschenbroek construiu a primeira garrafa de Leiden, que acumula cargas elétricas. Alessandro Volta construiu a primeira pilha voltaica, que podia fornecer uma corrente elétrica contínua.
Benjamin Franklin foi um dos primeiros a propor que os relâmpagos eram uma forma de eletricidade. Também propôs que as cargas elétricas eram divididas em dois tipos, negativa e positiva, com cargas elétricas idênticas se repelindo e cargas contrárias se atraindo. Hans Christian Ørsted argumentou que a corrente elétrica gera magnetismo em torno do fio condutor. André-Marie Ampère forneceu os primeiros apoios matemáticos para o magnetismo em função da corrente elétrica. Michael Faraday postulou que o inverso também era válido, sendo que a variação do campo magnético induz a geração de corrente elétrica. Faraday elaborou um modelo qualitativo de como as forças elétrica e magnética agem. Também elaborou os conceitos de campos magnético e elétrico. James Clerk Maxwell unificou as teorias elétricas e magnéticas de Ampère, Faraday e de Gauss, resultando no nascimento da teoria eletromagnética, resumindo matematicamente o trabalho experimental de seus antecessores em quatro equações, conhecidas como as Equações de Maxwell. Maxwell propôs a existência de ondas eletromagnéticas, e sugeriu que a própria luz seria um exemplo de onda eletromagnética. A existência de tais ondas foi comprovada por Heinrich Hertz, em 1888, e a constatação da luz como onda eletromagnética completou outra grande unificação da física, fundindo a eletricidade, o magnetismo e a óptica dentro da teoria eletromagnética.
No final do século XIX, as teorias clássicas da física estavam firmemente estabelecidas. Restavam aos físicos realizar medidas mais precisas para as constantes universais e aplicar o conhecimento obtido em tecnologias vindouras. Os "fenômenos rebeldes" consistiam um problema, embora fosse "uma questão de tempo" adequá-las às teorias vigentes. Entretanto, tais "fenômenos rebeldes" se tornaram um imenso desafio para física no final do Século XIX e no início do Século XX.
Entre os "fenômenos rebeldes", destacavam-se a radiação de corpo negro, o efeito fotoelétrico e o espectro de raias dos elementos. Max Planck, em 1900, em uma tentativa de dar suporte matemático à radiação de corpo negro, propôs a tese de que havia uma limitação energética na vibração dos osciladores causadores da radiação; um oscilador não poderia vibrar com qualquer energia, mas apenas com algumas energias "demarcadas", ou seja, discretas, sendo que seus valores seriam múltiplos de números naturais. As regiões discretas de energia ficaram conhecidas como "quanta" de energia. A energia desses "quanta" seria dada pelo produto de um número natural pela frequência e por uma constante universal, que ficou conhecida como a constante de Planck.
Em 1905, Albert Einstein publica cinco artigos no periódico alemão "Annalen der Physik", onde apresenta ao mundo todo o início da relatividade e da mecânica quântica. Alcançando o mesmo resultado para a constante de Planck, Einstein explicou também o efeito fotoelétrico e deu argumentações físicas para a existência dos "quanta" de energia. Postulou também que a velocidade da luz é constante em qualquer referencial inercial. Dez anos mais tarde, Einstein publicou a sua teoria da relatividade geral, estendendo a relatividade para referenciais não-inerciais e para a gravitação.
Em 1924, Louis de Broglie propõe a dualidade onda-partícula para o elétron, e dois anos mais tarde, Erwin Schrödinger publica a sua equação, que é a base da mecânica quântica moderna. No ano seguinte, Werner Heisenberg defende que não se pode mensurar a posição e a velocidade de uma partícula subatômica ao mesmo tempo, estabelecendo o Princípio da Incerteza. No final da década de 40, Richard Feynman desenvolveu a eletrodinâmica quântica, uma das teorias mais precisas já inventadas pelo homem atualmente. Feynman desenvolveu uma das primeiras teorias quânticas de campo e com a idealização e descoberta dos quarks, a cromodinâmica quântica foi elaborada. A eletrodinâmica e a cromodinâmica quântica são as bases de um conjunto de teorias quânticas de campo chamada de modelo padrão, que descreve três das quatro forças fundamentais da Natureza.
Entretanto, o Modelo Padrão não é capaz de descrever a gravitação, alvo de estudos desde o início da ciência moderna, quando Galileu realizou o experimento da queda livre. A gravitação ainda não tem um suporte teórico-experimental enraizado pela física moderna sobre a sua verdadeira causa. A relatividade geral de Einstein entra em conflito com a mecânica quântica e constitui um dos maiores desafios para os Físicos Teóricos e Experimentais atualmente.
A física estuda a natureza e seus fenômenos em seus aspectos mais essenciais e gerais. Analisa suas relações e propriedades, além de descrever e explicar a maior parte de suas consequências, mas não a sua totalidade, pois a física não é um objeto pronto e acabado, mas sim uma ciência que busca obter respostas para os inúmeros problemas em aberto. Tem como pilares fundamentais o estudo da matéria, energia, espaço e tempo, e deriva destes entes fundamentais e de suas propriedades e relações todo o vasto escopo da física.
Nesta busca por respostas e generalizações, a física tem o apoio do método científico, um conjunto de técnicas e procedimentos com o objetivo de tornar científico o conhecimento produzido, que deve ser validado, corroborado e verificável experimentalmente. Nesse processo há também o apoio da lógica, que permeia o conhecimento produzido e em produção como um conjunto de regras de raciocínio comum a todos e permite que o conhecimento esteja disponível a todos que queiram compreendê-lo e utilizá-lo, validando-o desta forma. O uso da lógica implica o uso de sua linguagem e escrita, a matemática. As regularidades encontradas no conhecimento e fundamentadas pela lógica devem ser expressadas matematicamente, pois os argumentos que as sustentam devem ser corroborados por outros que também utilizam a mesma lógica para a compreensão do conhecimento.
O escopo da física não se restringe às dimensões, pois tudo o que está contido no Universo é seu objeto de estudo, desde as partículas elementares que constroem a matéria até as estrelas, galáxias e o próprio Universo como um todo. Porém, está ciência não é exclusiva na abordagem dos fenômenos naturais, pois suas especificidades e complexidades requerem uma maior atenção de estudo. Os fenômenos mais restritos são geralmente estudados por outras ciências naturais, como a química e a biologia. A física, porém, é conhecida como a ciência fundamental por buscar a essência primordial da natureza e muitas vezes torna-se sinônimo da própria ciência natural.
Constrói modelos científicos que descrevem o funcionamento da natureza e permitem compreender e prever com a precisão requerida os comportamentos e fenômenos naturais. Porém, tais modelos não conseguem descrever e explicar a natureza em toda sua complexidade, fato inerente aos limites do conhecimento humano. Por ser uma ciência com um escopo tão amplo, costuma-se dividi-la em áreas mais restritas. Tais divisões são históricas e muitas vezes uma área desenvolve-se historicamente de forma independente, como a astronomia. Historicamente, a afirmação da física como ciência moderna está intimamente ligada ao desenvolvimento da mecânica clássica, pois desde o advento do Renascimento havia a necessidade de se entender os fenômenos físicos relacionados aos movimentos e forças, e os conhecimentos da época, sobretudo aristotélicos, já não eram mais suficientes. Este panorama começou a ser superado com os estudos de Galileu Galilei e finalizado com a publicação científica mais influente de todas as épocas, o "Philosophiae Naturalis Principia Mathematica", de Isaac Newton. A termodinâmica teve sua origem na invenção das máquinas térmicas e sua consolidação veio com a formulação de seus princípios e a generalização do conceito de energia. A ligação da eletricidade com o magnetismo foi percebida apenas no início do século XIX por Hans Christian Ørsted. As descrições físicas e matemáticas da eletricidade e magnetismo foram unificadas por James Clerk Maxwell, e a partir de então estas duas áreas, juntamente com a óptica, passaram a ser tratadas como visões diferentes do mesmo fenômeno físico, o eletromagnetismo. O início do século XX marca a fronteira entre a física clássica e a física moderna, com as profundas alterações do entendimento científico da época. A incapacidade da descrição e explicação de certos fenômenos observados levantou a necessidade de abrir novos horizontes para a física. Albert Einstein publicou a teoria da relatividade geral em 1915 afirmando a constância da velocidade da luz e suas consequências até então imagináveis. Max Planck, ao estudar a radiação de corpo negro, foi forçado a concluir que a energia está dividida em "pacotes", conhecidos como quanta. Einstein demonstrou fisicamente as ideias de Planck, fixando as primeiras raízes da mecânica quântica, a física que descreve e explica fenômenos de dimensões subatômicas. Mesmo estes campos de atuação são muito amplos e são, por sua vez, subdividios em áreas mais restritas.
Os fenômenos naturais apresentam quase sempre naturezas mais complexas e implicam, portanto, em investigações mais específicas. Surge, então, a necessidade de outras ciências naturais. Tais ciências têm necessariamente a física como ponto de partida, mas o estudo completo das complexidades físicas envolvidas nestes fenômenos torna-se inviável se estas forem abordadas apenas pela física. Por exemplo, a química se dedica ao estudo da matéria e suas mudanças, enquanto a biologia estuda os seres vivos. Para que o estudo de áreas mais específicas fossem aprofundadas, várias ciências mais especializadas se separaram da física com o decorrer dos séculos, para formar campos de estudos autônomos com conhecimentos e metodologias próprios. Embora a física esteja particularmente preocupada com os aspectos da natureza que possam ser entendidos fundamentalmente na forma de leis ou princípios elementares, o advento destas novas ciências não removeu da física o seu objetivo original: entender e explicar a estrutura da natureza e seus fenômenos mesmo em escala de maior complexidade. A teoria da termodinâmica e o consequente desenvolvimento da física estatística é um notório exemplo disto, e conceitos como o de temperatura são indissociáveis ao estudo de qualquer sistema natural, seja complexo ou não.
Um dos principais escopos da física é o estudo das quatro forças fundamentais. Dentro do cotidiano, apenas duas das quatro forças fundamentais são influentes: o eletromagnetismo, que rege praticamente todas as forças que conhecemos e seus respectivos trabalhos, e a gravidade, que age como uma simples força conservativa na superfície terrestre, sendo vertical e apontada para baixo. As forças nucleares forte e fraca praticamente não estão presentes em nosso cotidiano, embora sejam fundamentais para a constituição do próprio Universo. O estudo das quatro forças fundamentais constitui a maior aproximação fundamental para o entendimento da Natureza e de seus fenômenos que a ciência oferece.
As divisões clássicas da física foram baseadas em classes gerais de fenômenos naturais para os quais uma determinada metodologia da física aplica-se de forma comum. Estas divisões ainda são atuais e tendem a ser usadas cotidianamente. O ensino de física a nível secundário geralmente inicia-se com o estudo da mecânica clássica, seguindo para termodinâmica e para o eletromagnetismo, embora áreas como a cosmologia, a óptica e a física moderna também sejam tratadas. Por outro lado, as divisões ou ramos da física moderna são feitas em acordo com os tipos particulares de estruturas da natureza com qual cada ramo está preocupado. Costuma-se também dividir a física em aplicada e pura. Enquanto a física pura busca produzir conhecimentos sobre os princípios mais fundamentais da natureza sem a intenção de produzir conhecimentos práticos imediatos, a física aplicada busca dar resposta a problemas práticos. As engenharias se aproximam da física aplicada quando buscam resolver problemas de ordem prática, como na aeronáutica, computação, automação, mineralogia, eletrônica, fotônica, acústica, biofísica, topografia, geociências, resistência dos materiais, telecomunicações, hidráulica, metalurgia, entre outras. Entretanto, as fronteiras entre física pura e aplicada podem não ser claras. Enquanto a biofísica se preocupa em produzir conhecimentos de como o olho humano reconhece e codifica a luz visível, tentando produzir sensores que possam substituir a retina para aqueles que não são mais ou nunca foram capazes de enxergar, produz conhecimentos sobre os comportamentos físicos e biológicos de nanopartículas sem ainda ter, entretanto, alguma utilidade prática.
A física se preocupa com o estudo da matéria, energia, espaço e tempo, buscando sempre uma maior precisão e uma maior profundidade no entendimento dos elementos e princípios fundamentais. Também tem, contudo, o objetivo de construir uma teoria unificada expressada em linguagem matemática precisa e corroborada experimentalmente de forma universal, que apresente uma estrutura e um comportamento que permitam que seus modelos científicos sejam capazes de descrever e prever os fenômenos naturais na maneira mais compreensiva e detalhada possível, sejam estes quais forem. Em sintonia com este objetivo, a física está caracterizada por uma instrumentação e medições altamente precisas. Outras ciências naturais estão preocupadas em descrever e relatar os fenômenos em seus conceitos peculiares restritos às suas próprias disciplinas, mas a física sempre busca entender o mesmo fenômeno como uma manifestação especial de uma estrutura uniforme e superior da natureza como um todo.
O escopo muito amplo da física é abordado por vários campos de estudo que podem se diferir muito entre si. Tais divisões têm fundamentações históricas, e muitas áreas surgiram de forma independente. O próprio início da física clássica, durante a revolução científica está grandemente associada ao início da mecânica clássica.
Existem várias formas de dividir esta ciência tão ampla. Considera-se o início da física clássica e independente os estudos de Galileu Galilei. O paradigma de René Descartes, uma visão mecanicista da ciência onde o mundo natural é uma maquina sem espiritualidade e, portanto, deve ser dominada pela inteligência humana e ser posta a seu serviço, permeou a produção e desenvolvimento científicos até o início do século XX, quando o entendimento científico foi modificado profundamente pelo advento dos fundamentos da relatividade e da mecânica quântica, em um mundo onde o tempo pode se dilatar e as partículas elementares não são mais pontuais e locais e comportam ora como onda, ora como partícula. Esta época delimita a fronteira entre a física clássica e a física moderna.
As divisões clássicas da física, antes do início do século XX, foram baseadas em classes gerais de fenômenos naturais para os quais uma determinada metodologia da física aplica-se de forma comum. É a forma de divisão mais tradicional, pois considera-se as propriedades dos fenômenos estudados: os movimentos e forças são objeto de estudo da mecânica, a curiosidade acerca do calor e suas propriedades criou um plano de fundo para o surgimento da termodinâmica. A eletricidade, o magnetismo e a óptica surgiram de forma independente, mas foram integradas durante meados do século XIX ao serem consideradas apenas visões diferentes de um mesmo fenômeno muito mais amplo, o eletromagnetismo.
As divisões da física moderna são feitas em acordo com os tipos particulares de estruturas da natureza com qual cada ramo está preocupado. As implicações até então imagináveis de afirmações aparentemente simples, como a constância das leis da física para qualquer referencial e a constância da velocidade da luz, são a base da relatividade. A mecânica quântica é a física das dimensões subatômicas.
Ainda existem numerosas divisões interdisciplinares da física. Tem um papel crucial dentro da ciência dos materiais ao fornecer subsídios para o estudo de relações, estruturas, performance, formas de caracterização e processamento dos materiais. A biofísica surge quando a biologia necessita resolver problemas que pertencem ao escopo da física. Da mesma forma a física médica surge quando a medicina necessita da física para resolver problemas, especialmente notáveis em radiologia. Destacam-se ainda a metalurgia, que necessita da física, especialmente da mecânica, na produção de produtos metálicos; a geofísica, que busca o compreensão da estrutura, composição e dinâmica do planeta Terra sob a ótica da física; a físico-química, quando a química necessita de conceitos físicos, como o movimento, energia, força, tempo, termodinâmica, mecânica quântica e física estatística, para a resolução de problemas; a física matemática, quando a física requer a utilização da metodologia da matemática para a aplicação de problemas físicos; e a meteorologia física, a área da meteorologia que investiga os fenômenos atmosféricos do ponto de vista da física, descrevendo-os e explicando-os a partir de teorias e da análise de resultados experimentais.
A mecânica clássica descreve o movimento de objetos macroscópicos, desde projéteis a partes de máquinas, além de corpos celestes, como espaçonaves, planetas, estrelas e galáxias. A mecânica clássica em si também é muito ampla e várias especializações são derivadas dela. Referente aos conceitos abordados, pode ser dividida em Cinemática, que estuda os movimentos sem se preocupar com suas causas, a Estática, que aborda sistemas sob ação de forças que se equilibram, e a Dinâmica, que estuda o movimento considerando suas causas, em outras palavras, aborda sistemas sob ação de forças que não se equilibram.
Surgiu durante a revolução científica, juntamente com a consolidação da física como ciência moderna. Galileu Galilei pode ser considerado o marco inicial da mecânica clássica, mas sua consolidação definitiva veio com a publicação dos "Philosophiae Naturalis Principia Mathematica", de Isaac Newton, considerada a obra científica mais influente de todos os tempos. Entretanto, em certos sistemas, a mecânica de Newton passa a ser pouco eficiente para ser usado na resolução de problemas. No final do século XVIII e durante o século XIX a mecânica foi reformulada por Joseph-Louis Lagrange e William Rowan Hamilton, para que abarcasse a resolução analítica de um maior número de problemas com um ferramental matemático mais refinado.
A mecânica não se limita à análise de partículas discretas, mas estuda também meios contínuos. O momento de inércia de um disco rígido com centro de rotação coincidente com o seu próprio centro é diferente de uma partícula isolada que orbita um centro de rotação qualquer. A mecânica de meios contínuos é a mecânica que aborda o estudo dos materiais de massa contínua, em oposição de materiais de partículas discretas ou isoladas. A mecânica dos fluidos e a Dinâmica de corpo rígido são exemplos de divisões da mecânica de meios contínuos.
É considerada a divisão base da física, pois as outras divisões são derivadas dela. Seu escopo continua sendo o estudo dos entes fundamentais da física: espaço, tempo, matéria e energia. De suas relações e consequências, surgem outros conceitos, como as leis de Newton, posição, dimensão, invariância de Galileu, velocidade, aceleração, força, torque, momento linear, momento angular, energia mecânica, trabalho, potência, massa, inércia, momento de inércia, referencial, entre outros.
A ondulatória, na física clássica, estuda as características e as propriedades das ondas e seus movimentos e relações. A onda consiste-se de perturbações, pulsos ou oscilações ocorridas em um determinado meio, que pode ser material ou não. Transporta energia cinética da fonte para o meio, sendo incapaz de transportar matéria.
Seu estudo clássico também iniciou-se com Galileu Galilei e Isaac Newton inclui seu estudo em seu "Principia Mathematica" ao analisar a mecânica dos fluidos, a mecânica dos corpos que não possuem rigidez ou volume próprios. A acústica é a parte da Ondulatória que estuda especificamente a propagação das ondas sonoras pelo ar. A luz foi considerada um fenômeno ondulatório a partir da experiência da dupla fenda de Thomas Young. Seus conceitos principais são ondas (transversais e longitudinais) comprimento de onda, oscilação, amplitude, frequência, fase, reflexão, refração, difração, interferência, polarização, efeito Doppler, entre outros.
Precedendo a termodinâmica pode-se encontrar a Termologia, que é basicamente o estudo do calor, ou seja, o estudo da energia térmica em trânsito, que se diferencia de temperatura, que é o grau de agitação das moléculas. Porém, os conceitos mais arraigados desta área encontram-se na termodinâmica, que estuda as relações entre o calor trocado e o trabalho realizado.
Máquinas térmicas tinham sido inventadas e aperfeiçoadas ao longo dos séculos XVII, XVIII e XIX. No entanto, a atenção científica sobreveio apenas em meados do século XIX com Sadi Carnot. Seus estudos foram aprimorados ao longo daquele século por James Prescott Joule, Lord Kelvin e Rudolf Clausius. Seus princípios ajudaram no estabelecimento da teoria cinética e no consequente desenvolvimento da física estatística. Seus principais conceitos são calor, temperatura, pressão, volume, energia térmica, entalpia, entropia, capacidade térmica, calor específico, entre outros.
O eletromagnetismo é basicamente a unificação da eletricidade, que é o estudo das cargas elétricas, estáticas ou em movimento, com o magnetismo, que é basicamente o estudo dos ímãs. A luz é uma radiação eletromagnética, e seu campo de estudo, a óptica, também faz parte do eletromagnetismo.
William Gilbert foi o pioneiro no estudo do magnetismo e da eletrostática, parte da eletricidade que aborda o estudo das propriedades físicas das cargas elétricas estacionárias, em oposição à eletrodinâmica, que estuda a relação da força eletromagnética entre cargas e correntes elétricas. Otto von Guericke, Benjamin Franklin e Alessandro Volta contribuíram para o desenvolvimento desta área, mas Hans Christian Ørsted foi o primeiro a perceber, em 1820, a ligação entre o magnetismo e eletricidade, até então áreas independentes e sem conexões. Michael Faraday descobriu a indução eletromagnética e James Clerk Maxwell unificou as descrições matemáticas da eletricidade e magnetismo em um grupo de quatro equações, conhecidas como Equações de Maxwell.
Seus principais conceitos são capacitância, carga elétrica, corrente elétrica, condutividade elétrica, campo elétrico, permissividade elétrica, potencial elétrico, resistência elétrica, indução eletromagnética, radiação eletromagnética, campo magnético, fluxo magnético, monopolo magnético, permeabilidade magnética, entre outros.
Embora a maior parte da física clássica esteja englobada na mecânica clássica, Ondulatória, termodinâmica e eletromagnetismo, outras especializações também podem ser consideradas clássicas, pois não utilizam a princípio conceitos modernos, ou seja, conceitos que recorrem à relatividade ou a física quântica, embora não estejam delimitados exclusivamente dentro das concepções clássicas. Destaca-se a teoria do caos nesta área.
No final do século XIX, permeava no pensamento científico a satisfação de que todos os fenômenos naturais poderiam ser descritos pela ciência já desenvolvida até então. Restava apenas a conquista de uma maior precisão do valor das constantes universais e da resolução de alguns "pequenos" problemas. Estes se tornaram uma grande dor de cabeça com o passar dos anos, pois continuariam insolúveis. Entre estes fenômenos "problemas" destacam-se a radiação de corpo negro e a catástrofe do ultravioleta, o espectro de raias dos elementos e o efeito fotoelétrico. As contribuições iniciais de Max Planck e sobretudo Albert Einstein abriram novos campos para a explicação destes fenômenos e abriram margens para descobertas e ponderações até então inimagináveis.
Em 1905, Albert Einstein publicou os fundamentos da relatividade restrita, afirmando constância da velocidade da luz em qualquer referencial inercial e postulando que as leis da física são as mesmas para qualquer referencial. Isso implica efeitos e consequências que não são previstas pela mecânica clássica, como a dilatação do tempo e a contração do comprimento. Dez anos mais tarde Einstein publica a teoria da relatividade geral, que generaliza, através da equações de campo de Einstein, os efeitos descritos pela relatividade restrita para referenciais não-inerciais. Também engloba a mais completa descrição da gravidade disponível atualmente, sendo esta meramente um efeito da curvatura do espaço-tempo provocada pela presença de grande quantidade de massa.
Max Planck, em 1900, durante seus estudos sobre radiação de corpo negro, apresentou uma descrição matemática do fenômeno que coincidia com os resultados experimentais. Esta descrição tentava fugir da descrição clássica, que levava ao que foi conhecido como catástrofe do ultravioleta. Nesta descrição, Planck argumentou que a distribuição energética era discreta, não contínua, como na descrição clássica. Cinco anos mais tarde, Einstein apresentou argumentações físicas para os resultados de Planck, elucidando também o efeito fotoelétrico. Planck e Einstein fundamentaram os princípios da mecânica quântica, que é basicamente a física das dimensões subatômicas. Seu desenvolvimento foi impulsionado, entre outros, por Niels Bohr, Louis de Broglie, Werner Heisenberg e Erwin Schrödinger.
A teoria mais precisa elaborada pela ciência é a eletrodinâmica quântica de Richard Feynman, onde é utilizado as noções da mecânica quântica para a descrição e explicação de campos eletromagnéticos. Feynman elaborou uma das primeiras e a mais famosa teoria quântica de campos e foi sucedido pela elaboração da cromodinâmica quântica, a teoria quântica do campo da força forte, que levou à previsão e a posterior descoberta dos quarks. Após a fusão das descrições da força fraca com o eletromagnetismo em altas energias, três das quatro forças fundamentais são descritas por teorias quânticas de campos. Entretanto, a gravidade ainda não é descrita por nenhuma teoria quântica de campos corroborada experimentalmente.
A física moderna não está limitada apenas à relatividade e à mecânica quântica. Destacam-se também a física das partículas elementares, que estuda as propriedades das partículas elementares que constituem a matéria; a física nuclear, que estuda as propriedades dos núcleos atômicos; a física atômica e molecular, que estuda as propriedades físicas da associação dos núcleos e elétrons; a física da matéria condensada, que aborda o entendimento do comportamento da matéria composta por um grande número de átomos; e a física do plasma, que estuda as propriedades da matéria que exibe um grau de agitação térmica suficiente para que elétrons e núcleos consigam se manter separados (plasma). A óptica, que é uma área da física ligada ao eletromagnetismo, também tem pilares na Mecânia quântica, pois a luz visível, uma faixa de toda a radiação eletromagnética, exibe propriedades duais: comporta-se como ora como partícula ora como onda. As disciplinas físicas da astronomia, como a astrofísica, utilizam grandemente a mecânica clássica em seus estudos, mas a relatividade geral encontra a sua maior aplicação nesta cadeira, especialmente na cosmologia.
A física pura está preocupada com a obtenção do conhecimento básico e preciso, sem se preocupar com pesquisas que tenham utilidade prática imediata. Almeja a obtenção de conhecimentos para a resolução de problemas de caráter mais geral, embora não tenha um objetivo bem delineado. Busca atender demandas exigidas pela própria comunidade científica, como a necessidade de se propor novas teorias para problemas que são insolúveis para a teoria vigente. Em 1916, Albert Einstein propôs o modelo de emissão estimulada, onde a colisão de um átomo excitado com um fóton de mesma energia provoca a emissão de um fóton idêntico ao primeiro, que se propaga na mesma direção e sincroniza sua onda com a do estimulador, somando sua intensidade e aumentando, dessa forma, a intensidade da luz emitida. Este conceito é a base do funcionamento do laser, que viria a ser inventado apenas em 1960.
A física aplicada é o termo geral para pesquisas em física com objetivo de uso particular. Está associada à engenharia. Um físico aplicado, que pode ser ou não um engenheiro, está projetando algo em particular usando a física ou conduzindo uma pesquisa física com o objetivo de desenvolver novas tecnologias ou de resolver problemas.
A abordagem é semelhante à abordagem da matemática aplicada. Os físicos aplicados também podem estar interessados no uso da física para pesquisas científicas no desenvolvimento tecnológico ou em aplicações práticas, que podem não estar relacionados à própria engenharia. Os cientistas que trabalham em um acelerador de partículas buscam desenvolver detectores de partículas mais eficazes para permitir um maior progresso da física teórica, mas podem estar trabalhando na miniaturização de circuitos eletrônicos para que a própria tecnologia avance.
A física é muito usada na engenharia. A estática, uma subdisciplina da mecânica, é muito usada na engenharia civil. A física também pode ser utilizada na interdisciplinaridade em outras ciências, inclusive utilizando seus métodos em ciências não-naturais.
Uma teoria física é um modelo de eventos físicos, uma aproximação construída por humanos para descrever a Natureza. É endossado segundo a concordância de suas predições com as observações empíricas. Uma teoria física também é endossada pela sua habilidade de realizar novas previsões que podem ser verificadas através de novas observações. Uma teoria física difere de um teorema matemático; ambos são baseados em axiomas ou postulados, mas aplicabilidade matemática não é baseada com a concordância de resultados experimentais. Uma teoria física envolve uma ou mais relações entre as várias grandezas físicas. Em certas ocasiões, a visão provida por sistemas matemáticos puros podem prover pistas de como um sistema físico deve ser modelado.
Os avanços teóricos existem quando velhos paradigmas são postos de lado; a mecânica Newtoniana foi suplantada pela mecânica relativística, mas a mecânica Newtoniana é um de seus casos particulares. O conjunto de teorias físicas, dentro de um paradigma, é aceito quando é capaz de realizar previsões corretas, embasados pela experimentação, suplantando outro velho conjunto de teorias físicas que já não é capaz de descrever os novos fenômenos observados. O método científico existe para testar as consequências de uma teoria física.
A física experimental está preocupada com a aquisição de dados, seus métodos e conceitualizações detalhados, além da realização de experimentos laboratoriais, em contraste com os experimentos mentais. Está preocupada em obter conhecimentos da Natureza, em contraste com a física teórica, que está preocupada em entender como a Natureza se comporta. Apesar da física experimental e a física teórica terem objetivos distintos, a física experimental depende da física teórica. A maioria dos experimentos elaborados pela física experimental têm o propósito de confirmar ou contradizer as conclusões feitas pela física teórica, que, por sua vez, não pode evoluir sem o conhecimento produzido pela física experimental. Experimentos podem ser formulados para fornecerem fatos completamente novos sobre sistemas nunca estudados ou modelados, mas mesmo nestes casos não se pode negar que o ponto de partida é diretamente influenciado pelas teorias e conhecimentos até a corrente data já produzidos.
Tendo em consideração que a física sempre esteve associada à filosofia natural desde a antiguidade até o século XVIII, a filosofia da física pode ser considerada a mais antiga disciplina filosófica da história. A reflexão humana sobre o mundo físico precedeu historicamente a reflexão sobre a natureza de nossos próprios pensamentos e nossas interações sociais com outros seres humanos. No entanto, filosofia da física, como disciplina moderna, surge durante o Renascimento e começa a ser aprofundada durante o Iluminismo, tendo um caráter mais epistemológico com o avançar dos séculos.
A filosofia natural é debatida desde a antiguidade pré-clássica. As primeiras reflexões vieram sobre discussões de ordem prática acerca da mecânica, óptica e astronomia. Babilônicos e egípcios eram capazes de prever eclipses solares e lunares. Porém, os debates acerca do mundo natural estavam sempre associados a geometria. Os gregos foram os primeiros a desenvolver uma filosofia natural sem pretensões práticas. Tales de Mileto é às vezes referido como "pai da ciência", pois recusou-se aceitar explicações sobrenaturais, mitológicas e religiosas para os fenômenos naturais. Leucipo de Mileto e posteriormente Demócrito de Abdera desenvolveram o atomismo, onde tudo o que há na natureza é formado por átomos indivisíveis e eternos. Para Aristóteles, as mudanças na natureza podem ser explicadas através de quatro causas: a causa material, aquilo do qual é feita alguma coisa; a causa formal, a coisa em si e o que lhe dá a forma; a causa eficiente, aquilo que dá origem ao processo em que a coisa surge; e a causa final, aquilo para o qual a coisa é feita. Aristóteles foi pioneiro em construir uma teoria altamente coerente e elaborada para a explicação do mundo natural, com base filosófica bem muito bem fundamentada, registrada em seu livro "Física". Para ele, os elementos naturais buscavam seu lugar próprio no Universo: a terra buscaria seu centro, onde a Terra está situada, enquanto o fogo tenderia a fugir. Aristóteles também relacionou o movimento como algo provocado por uma força. Embora Aristarco de Samos tenha defendido o heliocentrismo, o auge da astronomia grega vem com o geocentrista, Ptolomeu que aperfeiçoou e complexificou a mecânica celeste grega baseada em esferas e epiciclos para englobar todos os movimentos dos astros observados, incluindo a precessão dos equinócios.
Na visão de vários cientistas atuais, as considerações filosóficas sobre a ciência e a física não influenciam diretamente suas atividades ou métodos de trabalho como cientistas no dia-a-dia, mas a filosofia da física envolve uma combinação de assuntos conceituais, metodológicos, epistemológicos e até mesmo metafísicos. Os filósofos da física colaboram juntamente com os físicos para entenderem os conceitos que empregam em suas pesquisas. Um dos primeiros estudos modernos da filosofia da física foi a reflexão sobre os componentes mais fundamentais do Universo. O Renascimento abalou profundamente as bases filosóficas medievais, fazendo que o ser humano voltasse para si próprio e a busca para uma nova postura diante do mundo precisava de verdades diferentes e de outros modos de reflexão. René Descartes recusava o pensamento tradicionalista medieval e concebia que o pensador tinha por objetivo construir um sistema filosófico semelhante à matemática. Surgia o paradigma cartesiano, com um método de investigação do mundo que rejeitava qualquer conhecimento baseado na sensibilidade, apresentando como critério verídico sua argumentação de que todas as coisas que
concebemos são verdadeiras e, portanto, não passíveis de serem contestadas.
Emerge deste pensamento, dessa mentalidade reducionista e mecanicista do Universo levou o ser humano a uma visão fragmentada da verdade, tendo como consequência a quebra da ciência nas várias especialidades, o determinismo científico, onde tudo que existe não passa de partículas e que os movimentos dessas partículas são para sempre determinados quando se mensuram as posições e as velocidades de todas as partículas no momento atual. Em outras palavras, conhecendo-se as posições de todas as partículas do Universo e as suas respectivas velocidades em um dado instante, poder-se-ia conhecer com exatidão todo o passado e o futuro, fosse qual fosse o instante desejado. Esta forma de pensar liga-se diretamente ao reducionismo. Segundo essa linha de pensamento, é possível escrever leis básicas que descrevem completamente o comportamento do Universo. Nestes termos, todo o conhecimento pode ser reduzido a essas leis básicas. Por exemplo, tem-se que todos os fenômenos químicos possam ser deduzidos da mecânica quântica se o número de cálculos envolvidos for viável. O principal objetivo da física seria então encontrar essas leis básicas que regem o Universo. O reducionismo coloca a física na posição de ciência a mais básica de todas pois, a partir dela, seria possível, em princípio, chegar-se ao mesmo conhecimento produzido em todas as outras. Isso não implica o descarte das demais, pois essas tratariam com as suas próprias metodologias os fenômenos naturais mais complexos, consolidando-se em áreas que, por questões práticas, estariam fora do alcance da física.
A crise científica no início do século XX, causada pelos seus próprios progressos, abalou o paradigma reducionista-mecanicista cartesiano. O surgimento da relatividade e da mecânica quântica e outras áreas da física moderna redefiniu conceitos como ordem, posição, tempo, espaço, momento, continuidade e separabilidade, referencial e localidade. Os métodos reducionistas já não são compatíveis com novas formas da lógica e a complexidade surge em primeiro plano. O caos, a complexidade, a probabilidade e a incerteza passaram a integrar uma nova forma da percepção da realidade.
Com a física em posição de ciência mais fundamental, certas questões metafísicas, como especulações sobre o tempo, a existência e as origens do Universo, entre outras, deveriam ser enviadas à física para se obter respostas segundo os moldes dessa ciência. Nestes termos, seja qual for a resposta que a física apresente para conceitos como tempo, causa e ação, ou mesmo identidade, estas deveriam ser consideradas em princípio corretas. Entretanto, se as noções tradicionais metafísicas entrarem em confronto com uma física bem enraizada, então essas noções metafísicas deixariam de ter significado ou dever-se-ia questionar a validade dos conhecimentos sobre o mundo físico providos pela física. Para isso, filósofos da física têm se esforçado para investigar qualquer confronto possível entre a Metafísica e a física.
A física tem sido considerada historicamente o modelo de ciência para todas as outras ciências, naturais ou não, tanto por filósofos quanto por cientistas. Por exemplo, a Sociologia, ainda nos seus primórdios com Auguste Comte, na primeira metade do século XIX, era chamada de física Social. Dentro da construção do senso comum, a física detém os melhores métodos que a ciência pode conceber. Mas também é argumentável que a física tem os seus próprios métodos, diferentes daqueles de outras ciências, e particularmente aplicáveis à própria disciplina e incomparáveis a outras. Mesmo dentro da física, os métodos podem variar e serem incomparáveis.
Esta ciência ocupa uma posição privilegiada dentre as ciências, já que lida com os mais arraigados conceitos cotidianos. O próprio conceito de cotidiano já foi várias vezes abalado com as mudanças de paradigma da física. Por exemplo, a revolução copernicana, trazendo o heliocentrismo ao primeiro plano, quebrando o paradigma geocentrista defendido pela Igreja Católica na Idade Média, a unificação da física dos Céus e da Terra com a gravitação universal de Newton, a unificação dos conhecimentos de eletricidade e magnetismo por Maxwell. As viagens no tempo e os buracos negros começaram a ganhar espaço dentro do imaginário a partir da relatividade geral de Albert Einstein.
A física tem o apoio da lógica, pilar central do conhecimento humano para a sua fundamentação, estruturação e expressão. Está ligada ao pensamento humano e distingue interferências e argumentos falsos e verdadeiros. É basicamente um conjunto de regras rígidas para que argumentações e conclusões pudessem ser aceitas como logicamente válidas. O uso da lógica leva a um raciocínio baseado em premissas e conclusões. Tem sido binária, pois aceita duas assunções, falso ou verdadeiro e nega a existência da simultaneidade de conclusões, como por exemplo, conclusões que ao mesmo tempo são parcialmente verdadeiras e parcialmente falsas. Tal conclusão e suas leis da identidade (X deve ser X), da impossibilidade da contradição (X nunca é Y), e da exclusão do terceiro elemento (X deve ser X e, portanto, nunca deverá ser Y) abordam todas as possibilidades e são a base do pensamento lógico. Define as leis ideais do pensamento e estabelece as regras do pensamento correto, sendo uma arte de pensar. E como o raciocínio é a atividade intelectual que leva a todas as outras atividades humanas, define-se a lógica como a ciência do raciocínio correto. Para tanto, a lógica é necessária para tornar o pensamento humano mais eficaz e ajuda-o a justificar suas atividades recorrendo aos princípios que baseiam a sua legitimidade. A lógica é arte, ciência que nos guia ordenadamente, facilmente e sem erros, dentro dos princípios da razão.
A lógica matemática oferece ao conhecimento humano a capacidade de esclarecer e de argumentar conceitos. Em outras palavras, permite adquirir e transmitir certezas com o propósito da validação de certas afirmações partindo-se do reconhecimento da validação de outras argumentações que são geralmente mais simples. Essa capacidade de esclarecer conceitos, apresentar definições e de argumentá-los através da exibição de demonstrações são a base do raciocínio matemático e da própria matemática e que, por sua vez, oferece o suporte lógico para os conceitos físicos.
A Natureza pode ser entendida por meio de ferramentas matemáticas. As noções de números e outras estruturas matemáticas não precisam da física para serem justificadas. Entretanto, novas afirmações matemáticas podem ser usadas, muito tempo mais tarde, para descrever um fenómeno físico. Os números complexos, que são uma das bases da mecânica quântica, já tinham sido pensados no século XVI. No entanto, a matemática é mais do que uma ferramenta da física, é a sua própria linguagem.
O próprio desenvolvimento da física está intimamente ligado com o desenvolvimento da matemática, sendo a recíproca também certamente verdadeira. Desde que os chamados "Calculatores de Merton College", no século XIV, começaram a descrever a cinemática utilizando a matemática, passando por Johannes Kepler e por Galileu Galilei, esta "simbiose" ocorre. Isaac Newton necessitava de um aparato matemático para dar apoio aos seus estudos em física, e em função desta necessidade, foi um dos criadores do Cálculo, disciplina com inegável relevância na matemática e na física, juntamente com Gottfried Leibniz.
Os cientistas em física usam o método científico, um conjunto de técnicas e procedimentos com o objetivo de tornar científico o conhecimento produzido, para validar uma teoria, usando uma aproximação metodológica para comparar as implicações da teoria com as conclusões obtidas de experimentos e observações especialmente conduzidas para testar a teoria. Os experimentos e observações são feitos em princípio com propósito pré-definido, para se coletar e se comparar os dados obtidos por estes com as previsões e teses feitos por um físico teórico, assim ajudando na validade ou não de uma teoria.
Para um cientista moderno, o método de trabalho que ele emprega geralmente apresenta-se bem definido e claro. Nesta visão, o método científico apresenta passos bem delineados e objetivos. A observação e a experimentação são o ponto de partida e o mais importante teste para a formulação das leis naturais. A abstração é o primeiro passo para a compreensão de um fenômeno natural, concentrando-se em seus aspectos mais importantes. Assim que se atinge o estágio durante o desenvolvimento de conceitos e modelos, pode-se procurar através do processo indutivo, a formulação das leis fenomenológicas obtidas diretamente dos fenômenos que foram observados e apresentá-los de forma sintética possível. Decorre então a formulação de leis de teorias físicas, que deve ser capaz de reduzir numerosos fenômenos naturais em um pequeno número de leis simples, que devem ter a natureza preditiva, ou seja, a partir das leis básicas deve ser possível prever fenômenos novos que possam ser comparados com a experiência. Finalmente, determina-se o domínio de sua validade.
Entretanto, a natureza do método científico também é motivo para vários debates filosóficos. Vários filósofos apoiam a ideia da inexistência de um único método científico "inscrito em pedra", e até mesmo a sua inexistência. Portanto, se opõem a qualquer tentativa de estruturação do método científico, que inclui a enumeração rígida dos passos, visto frequentemente na educação de ciências. Alguns filósofos, como Karl Popper, negam a existência do método científico elaborado; para Popper existe apenas um método universal, a tentativa e erro, embora para os defensores do método científico moderno a tentativa e erro fazem parte de sua definição.
As hipóteses integrantes de uma teoria que são suportadas por dados confiáveis, geralmente de natureza abrangente e que suportam as várias tentativas de falseabilidade, segundo Karl Popper, são chamadas de leis científicas ou leis naturais. naturalmente, todas as teorias, inclusive aquelas integradas por leis naturais, bem como estas mesmas, podem ser modificadas ou substituídas por outras mais precisas, quando uma anomalia que falsifica a teoria for encontrada. Entretanto, isto não é absolutamente linear. Uma teoria ou um conjunto de teorias podem ser mantidos mesmo que haja anomalias que os invalidem. Segundo Imre Lakatos, um conjunto de teorias, que é chamado por ele de "programas de pesquisa", é mantido mesmo com várias anomalias. Para que o programa de pesquisa se mantenha, tais anomalias são "encaixadas" em um "cinturão protetor" de hipóteses e teses, que podem ser modificados conforme o advento das anomalias encontradas pela física experimental, embora o "núcleo central", ou seja, a tese básica do programa de pesquisa, deve ser mantida integralmente. Um programa de pesquisa é superado apenas quando o cinturão protetor já não é capaz de suportar novas anomalias. Para Lakatos, a substituição de programas de pesquisa coincide com revoluções na história da ciência. Os programas de pesquisa vencedores podem englobar ou não programas de pesquisa superados. A evolução dos "programas de pesquisa" de Lakatos é semelhante à tese de revoluções científicas associadas a mudanças de paradigma, defendida por Thomas Kuhn, como base do desenvolvimento da ciência. Os paradigmas científicos, que englobam toda uma linha de teorias científicas, métodos e valores, contém convicções científicas que não podem ser explicadas segundo as teorias existentes sobre racionalidade.
Para Kuhn, o paradigma estabelece algumas questões sobre o mundo físico. Estas são então investigadas na tentativa de se obter respostas, mas nunca conseguem responder todas as questões que propõe, pois, para Kuhn, a física e a ciência em geral não é um empreendimento para a construção de respostas. Quanto mais respostas sobre determinado fenômeno são obtidas, mais perguntas surgem, embora não seja exatamente um problema inicialmente. Para esse processo de pesquisas Kuhn chamou de ciência normal, ou seja, o período onde determinados paradigmas são aceitos e investigados. Entretanto, as questões ou anomalias que não podem ser resolvidas com o paradigma estabelecido pode atingir níveis insuportáveis. A partir de então, inicia-se o período conhecido como "crise". Novos paradigmas tentam responder de forma mais eficaz as anomalias que o paradigma vigente não consegue mais responder. O período de crise é marcado pela cisão da comunidade científica entre o paradigma vigente e o paradigma em afloramento. Finalmente o novo paradigma ganha a preferência e substitui o antigo. Este momento Kuhn chama de "revolução científica".
As Leis de Newton, por exemplo, estão embebidas dentro da relatividade, assim como toda a mecânica Newtoniana, e, mesmo que suas aplicabilidades não sejam mais universais, os três princípios de Newton ainda são chamados de "leis" e a mecânica newtoniana ainda é ensinada nas escolas de ensino médio de todo o mundo.
Os filósofos de física discutem os assuntos tradicionais referentes ao espaço e ao tempo com base nas teorias historicamente concebidas, desde Aristóteles à relatividade geral de Einstein.
Segundo Isaac Newton, o espaço é um ente físico separado e independente dos objetos que estão contidos no seu interior. Esse ente físico, com realidade física comparável a de uma substância, determina um referencial absoluto totalmente inercial. Newton também defende que o tempo é contínuo e infinito e existe mesmo com a ausência de objetos e eventos. Newton estabeleceu, assim, a filosofia física do Substantivalismo. No entanto, Gottfried Leibniz, um dos desenvolvedores do Cálculo ao lado do próprio Newton, argumentava que o espaço contém propriedades estritamente relacionais. Se não existissem objetos, seria impossível a definição de espaço. De modo semelhante, se não existissem objetos ou eventos, também não se poderia definir o tempo. Leibniz desenvolveu, assim, a filosofia física do Relacionalismo. O Relacionalismo ganhou fôlego com o advento da relatividade geral, embora o Substantivalismo ainda tenha seguidores atualmente.
As discussões sobre a natureza do tempo e sobre simultaneidade se iniciaram com a diferença de seus significados dentro da mecânica clássica e da relatividade restrita. Dentro da teoria de Einstein, a simultaneidade deixa de ser absoluta. Os eventos que são simultâneos dentro de sistema de referências podem não sê-lo em outro. Entretanto, o alemão e filósofo da física Adolf Grünbaum argumenta que a simultaneidade dentro da relatividade restrita é apenas fruto de uma convenção, pois a velocidade da luz na relatividade restrita é sempre a mesma, constante quando medida em qualquer referencial inercial, não importando para tal seus estados relativos de movimento; não há referências, portanto, para estabelecer uma velocidade da luz em um referencial absoluto ou específico, que, segundo a teoria de Einstein, não existe: todos os referenciais inerciais são igualmente equivalentes.
A evolução da mecânica quântica trouxe consigo inevitáveis considerações sobre a definição de medida e quais são as implicações de seu processo experimental. Considerações científicas e filosóficas importantes levam não só ao "Gato de Schrödinger" quanto a um debate em relação à impossibilidade de simultaneidade de medidas com precisão absoluta para determinadas grandezas na mecânica quântica. Segundo Werner Heisenberg, em 1925, existe uma incerteza na determinação da posição de uma partícula subatômica. O produto da incerteza da posição pela incerteza de seu momento nunca será menor do que uma certa constante numérica. Não se pode, por exemplo, medir a posição e o momento de um elétron ao mesmo tempo; ao se medir a sua posição, comprometemos seu momento, e vice-versa. As relações de incerteza, à primeira vista, parecem derivar da impossibilidade inerente à natureza humana em obter tais grandezas físicas. Entretanto, Heisenberg afirmou que a incerteza é uma propriedade intrínseca à partícula; se não há meios de se definir com precisão uma grandeza física, então tal grandeza não está precisamente definida por natureza.
Isto compromete profundamente o paradigma cartesiano, a mentalidade reducionista e mecanicista do Universo, que levou o ser humano a uma visão fragmentada e demasiadamente simplória da verdade. Segundo o determinismo científico, tudo que existe não passa de partículas pontuais e seus movimentos são para sempre estritamente determinados quando se mensuram as posições e as velocidades de todas as partículas no momento atual. Não considerando a incerteza, é possível conhecer as posições de todas as partículas do Universo e as suas respectivas velocidades em um dado instante e poder-se-ia conhecer com exatidão todo o passado e o futuro, fosse qual fosse o instante desejado. Admitindo-se a incerteza como algo intrínseco às partículas subatômicas, seria impossível saber o passado e o futuro de forma absoluta, quebrando, assim, os pilares de sustentação do reducionismo e do determinismo. A complexidade e a probabilidade deixariam de ser vistos como algo inerente à incapacidade do ser humano em estabelecer grandezas físicas estritamente precisas, mas passariam a ser conceitos válidos e incontestáveis dentro da física moderna.
Defensores do paradigma cartesiano afirmam que se o Princípio da Incerteza é válido e, portanto, não há mais possibilidades de se obter com precisão estrita a posição e a velocidade, então não há mais condições de afirmar seu estado físico momentâneo. Sem a possibilidade de conhecer seu estado físico, as experiências físicas são incapazes em mensurar qualquer grandeza física, o que põe em cheque todo o conhecimento físico e a própria física. Segundo esse pensamento, portanto, o conhecimento sobre o mundo físico não passa de um simples blefe, abrindo margem para a validação de pseudociências. Porém, esta afirmação, além de radical, é falsa. De fato, o princípio da incerteza impõe restrições às medidas estritamente precisas, mas tal incerteza é observável apenas no mundo subatômico e pode ser desprezada no mundo macroscópico.
Albert Einstein foi um dos defensores do paradigma cartesiano. Embora tenha sido um dos fundadores da mecânica quântica, não aceitava a visão de Heiseberg e a interpretação de Copenhague, afirmando que a teoria quântica estava incompleta: a incerteza na verdade seria a falta de conhecimento sobre variáveis ocultas. Segundo Einstein, "Deus não joga dados com o Universo". Juntamente com Boris Podolsky e Nathan Rosen, publicaram um artigo, que ficou conhecido como paradoxo EPR, onde afirmavam que: 1) se em um sistema que não for perturbado onde pode-se prever com precisão o valor de uma grandeza física, então existe um elemento da realidade física correspondente a esta grandeza física e 2) dois sistemas não podem influenciar-se mutuamente quando estão grandemente distanciados, todas as interações são portanto "locais". Porém, em um artigo publicado em 1964, John Stewart Bell afirmou que as possíveis "variáveis ocultas" de Einstein, Podolsky e Rosen não são compatíveis empiricamente com a mecânica quântica. Se as possíveis variáveis ocultas fossem verdadeiras, existiria uma série de desigualdades, conhecidas como as desigualdades de Bell. Se a mecânica quântica ortodoxa for verdadeira, tais desigualdades não ocorrem. A discussão sobre a existência de variáveis ocultas determinísticas e locais saiu do campo filosófico e foi passado para o campo experimental, mas tais debates ainda não cessaram.
Deste modo, os filósofos da física encaram questões filosóficas que abordam questões mais gerais, como o paradigma cartesiano e o positivismo. Filosoficamente e historicamente, a mecânica quântica nega o determinismo estrito e pontual, apoiando-se na interpretação de Copenhague, onde o mensuramento e o determinismo para partículas subatômicas ganham um novo sentido filosófico, não podendo ser generalizados para a física clássica, isto é, para sistemas macroscópicos de partículas, onde a visão mecanicista do mundo ainda vigora e é essencial para a manutenção dos conhecimentos físicos já alcançados. Filósofos mais moderados defendem a continuação das bases da mecânica quântica, mas defendem que as mecânicas clássica e quântica tenham ontologias totalmente independentes, isto é, as ontologias das duas mecânicas devem ser incomensuráveis. Porém, os defensores do paradigma cartesiano e do positivismo sugerem que a própria mecânica quântica encontre uma solução; alguns defendem a superação da Equação de Schrödinger, que é a base fundamental de toda a mecânica quântica moderna, para outra que consiga garantir suas posições filosóficas tanto na mecânica quântica quanto na física clássica, ou seja, a precisão e a certeza nas medidas deveriam ser válidas, seja no mundo microscópico quanto no macroscópico, negando assim a existência do Princípio da Incerteza.
A física estatística tem por objetivo o estudo dos sistemas constituídos por "incontáveis" partículas, tão numerosas que se torna impraticável a sua descrição através da consideração de cada uma das suas partículas isoladamente. Tais sistemas não são raros e uma simples amostra de gás confinado em uma garrafa seria um exemplo. As ferramentas para solução dessa questão residem nos conceitos de probabilidade e de estatística.
Surge, então, um problema filosófico em relação ao questionamento sobre a exata definição de probabilidade. Alguns filósofos sugerem que a probabilidade seja a medida da "ignorância" sobre um número real. Entretanto, esta definição é bastante subjetiva e não explica o sentido de probabilidade usada pela física estatística ou pela mecânica quântica. Em termos físicos, a probabilidade ganha um sentido mais concreto. A probabilidade é uma propriedade intrínseca a alguns processos físicos e não depende do "nível de conhecimento" do físico experimental. Um átomo pode decair radioativamente sob certa probabilidade entre 0 e 1 e isso não depende da quantidade de "ignorância" do observador. Isso é fundamental para a própria existência da física estatística, que é a teoria dos processos físicos probabilísticos.
Dentro dos processos probabilísticos está arraigada a noção de entropia, conceito fundamental também em termodinâmica. Ludwig Boltzmann propôs que a direção da "flecha do tempo" é determinada pela entropia. Desde então, os filósofos debatem contra e a favor da tese de Boltzmann. Para alguns, a entropia, em termodinâmica, não pode ser generalizada para eventos universais. É necessário que haja determinismo estrito e pontual, inconcebível dentro da mecânica quântica; a direção do tempo determinado pela entropia não passaria de um ponto de vista metafísico. Entretanto, outros afirmam que é absolutamente possível conciliar as duas teorias e que a direção do tempo é realmente determinada pela entropia. A segunda corrente de ideias está grandemente relacionada ao relacionalismo de Leibniz, onde o tempo existiria apenas se existissem objetos e eventos em constante complexidade, que pode ser traduzida como a própria entropia.
Os filósofos da física tradicionalmente se preocupam com a natureza das teorias científicas, isto devido em grande parte ao papel central que a epistemologia da ciência teve na filosofia, principalmente após o início do século XX. Em vista do advento das teorias modernas na física, foi a partir de então que os filósofos e historiadores de física começaram a ficar mais atentos à física experimental e têm argumentado que o experimento tem seus próprios métodos e práticas, que podem se diferenciar e serem incomensuráveis dentro da diversidade do escopo da física experimental.
Para Thomas Kuhn, a ciência normal é realizada dentro de um determinado paradigma científico praticamente estável, mesmo com a presença de anomalias que contrariam tal paradigma. Analisando-se as revoluções científicas, Kuhn percebeu que estas estão associadas a mudanças de paradigma. Um paradigma não é banido imediatamente quando a física experimental encontra uma anomalia, mas apenas quando o próprio paradigma já não mais suporta a quantidade de anomalias. Segundo Imre Lakatos, que usa um conceito semelhante conhecido como programa de pesquisa, tais mudanças de ponto de visão não ocorrem abruptamente. Consequentemente, não existem experimentos cruciais na História da física. A concepção de Éter, para Lakatos, não foi abandonada abruptamente com a Experiência de Michelson-Morley, mas sim abandonada lentamente e historicamente.
A física e as outras ciências naturais são o motor de propulsão de numerosas instituições científicas de grande importância. Tais instituições, como a Organização Europeia para a Investigação Nuclear (CERN) demandam não apenas imensos investimentos, mas também o mais refinado contingente humano que se pode disponibilizar. Os países desenvolvidos e em desenvolvimento aplicam uma significativa parcela de seu produto interno bruto (PIB) na investigação científica em geral. Deste montante, uma parte importante é destinada para a física, suas divisões e e aplicações à Engenharia e à Indústria. Tais países também mantêm um aparelho burocrático para a administração desses investimentos. Tais aparelhos constituem-se de órgãos executivos e de assessoria especializada na condução e organização dos assuntos relacionados à pesquisa científica pura e aplicada. A criação dessa máquina pública foi resultado de uma lentíssima evolução, dependente do amadurecimento de numerosos fatores e demandas que não necessariamente estavam ligados à pesquisa científica, mas sim originados no amplo processo de substituição da cultura durante a revolução científica.
Essa evolução na física ganhou ares de uma revolução autêntica; o sistema heliocêntrico de Copérnico e a introdução do experimento como argumento para provar afirmações, tendo Galileu Galilei como pioneiro, abalaram definitivamente o paradigma aristotélico dominante no pensamento filosófico até a Idade Média. A astronomia tornou-se também uma ciência moderna com a primeira grande unificação da física, quando Isaac Newton uniu a física dos Céus e da Terra sob a gravitação universal e com a considerável evolução na navegação, primeiramente com a utilização do astrolábio e posteriormente com a invenção de relógios mais precisos que marcaram um fim nos problemas da navegação, problema que a filosofia natural Medieval não foi capaz de encontrar uma solução. A destruição do sistema filosófico e religioso herdado da cultura medieval e as conquistas práticas das grandes navegações libertaram a filosofia natural de sua posição de contemplação e especulação, e pavimentaram o caminho para uma era mais moderna em que passou a ter a ciência moderna como instrumento de transformação.
Durante o renascimento italiano, as primeiras universidades ditas modernas foram criadas. Essas universidades abriram a oportunidades para novas atividades intelectuais. Embora o paradigma aristotélico ainda fosse uma herança medieval até meados do século XIX, permitiram a divulgação de obras de grandes pensadores, como Galileu Galilei. As primeiras sociedades científicas são italianas, como a Accademia Nazionale dei Lincei, fundada em 1603 em Roma, e a Accademia del Cimento, fundada em Florença em 1651. Em seguida foi fundada na Inglaterra em 1662 a Royal Society e a Académie des Sciences, na França em 1666. No final do século XVIII, havia aproximadamente duzentas sociedades científicas na Europa.
Essas sociedades, ou academias, originaram-se com o intuito de dar à ciência, e sobretudo à física, um novo panorama. Segundo Robert Hooke, em 1663, ao redigir os estatutos da Royal Society, os objetivos da sociedade científica eram o aperfeiçoamento do conhecimento dos componentes da Natureza e de todos os artefatos úteis, produtos e práticas mecânicas, invenções e engenhos por meio da experimentação. Deve-se também observar a não-especulação sobre assuntos referentes a divindades, metafísica, moral, política, gramática, retórica ou lógica. As sociedades científicas tinham por objetivo aprimorar o conhecimento científico, mas eram organizações muito fechadas e excludentes, mantidas por seus membros, que eram pessoas de renda própria e alta posição social. Não havia remuneração ou recompensas financeiras pelo trabalho científico. John Harrison, inventor do relógio mais preciso até então, levou praticamente toda a sua vida para reclamar o prêmio oferecido pela Royal Society para tal feito. Essa situação continuou até a segunda metade do século XIX, quando as universidades começaram a incorporar que forma institucional a ciência. Apenas a partir dessa época o cientista pôde utilizar uma sólida estrutura para a sua formação. Antes disso, praticamente todos os cientistas eram autodidatas.
O Observatório de Paris, fundada como anexo da Académie Royale des Sciences, e o Observatório Real de Greenwich, fundada em 1675, foram as primeiras instituições dedicadas à áreas relacionadas à física e amparadas pelo poder central das respectivas nações. Suas criações dependeram intensamente do crédito científico obtido na solução de problemas de astronomia necessários ao desenvolvimento da navegação. Foram também as primeiras organizações, e as únicas durante muito tempo, a oferecer uma cadeira regular a um especialista de alguma área da física. Entretanto, nos séculos XVIII e XIX, houve a ausência grandes desenvolvimentos na organização social da física. Quase todo o desenvolvimento nesta área está confinada ao século XX, especialmente devido às Primeira e Segunda guerras mundiais, onde era necessário o desenvolvimento de armas sofisticadas que exigiam conhecimentos avançados de física, como na Aerodinâmica, física nuclear, entre outros.
A pesquisa em física está progredindo continuamente em várias frentes. Na física da matéria condensada, um importante problema em aberto é a supercondutividade a alta temperatura. Na física aplicada, muitos experimentos de matéria condensada estão objetivando a fabricação de aparelhos e computadores magnetoeletrônicos e quânticos.
Na física de partículas, as primeiras evidências experimentais de física além do modelo padrão começaram a aparecer, como a possibilidade do neutrino ter massa. Atualmente, os aceleradores de partículas são capazes de operar em energias da ordem de tera-elétrons-volt. Os físicos teóricos e experimentais, no CERN e no Fermilab, tentam encontrar o bóson de Higgs, a única partícula ainda a ser descoberta segundo o Modelo Padrão. Para tal, equipamentos sofisticadíssimos foram construídos, como o "Large Hadron Collider", o maior acelerador de partículas já construído do mundo.
A gravidade representa uma das mais importantes questões abertas na física moderna. As tentativas teóricas de unificar a mecânica quântica e a relatividade geral em uma única teoria da gravitação quântica, um programa de pesquisas que perdura por mais de cinquenta anos, ainda não foi resolvido. Existem modelos matemáticos que tentam conciliá-los, como a teoria das cordas e a gravidade quântica em loop. Muitos fenômenos astronômicos e cosmológicos, a assimetria bariônica, a aceleração da expansão do Universo e o problema da maior velocidade angular das galáxias ainda carecem de descrições satisfatórias. Embora se tenha feito progresso na mecânica quântica de altas energias e na Astrofísica, muitos fenômenos cotidianos ainda são fracamente entendidos, como a turbulência, sistemas complexos e o caos.

</doc>
<doc id="827" url="https://pt.wikipedia.org/wiki?curid=827" title="França">
França

França (; ), oficialmente República Francesa (; []) é um país, ou, mais especificamente, um Estado unitário desconcentrado, localizado na Europa Ocidental, com várias ilhas e territórios ultramarinos noutros continentes. A França Metropolitana estende-se do Mediterrâneo ao Canal da Mancha e Mar do Norte, e do Rio Reno ao Oceano Atlântico. É muitas vezes referida como "L'Hexagone" ("O Hexágono") por causa da forma geométrica do seu território e partilha fronteiras com a Bélgica e Luxemburgo a norte; Alemanha a nordeste; Suíça e Itália a leste; Espanha ao sul e com as micronações de Mônaco e Andorra. A nação é o maior país da União Europeia em área e o terceiro maior da Europa, atrás apenas da Rússia e da Ucrânia (incluindo seus territórios extraeuropeus, como a Guiana Francesa, o país torna-se maior que o território ucraniano).
Por cerca de meio milênio, o país tem sido uma grande potência, com forte influência econômica, cultural, militar e política no âmbito europeu e global. Durante muito tempo a França exerceu um papel de liderança e hegemonia na Europa (principalmente a partir da segunda metade do século XVII e parte do XVIII). Ao longo daqueles dois séculos, a nação iniciou a colonização de várias áreas do planeta e, durante o século XIX e início do século XX, chegou a constituir o segundo maior império da história, o que incluía grande parte da América do Norte, África Central e Ocidental, Sudeste Asiático e muitas ilhas do Pacífico.
O país tem seus principais ideais expressos na Declaração dos Direitos do Homem e do Cidadão. A República Francesa é definida como indivisível, laica, democrática e social pela sua constituição. A França é um dos países mais desenvolvidos do mundo, possui a quinta maior economia do mundo por PIB nominal, a nona maior por paridade do poder de compra e a segunda maior de toda a Europa. O país goza de um alto padrão de vida, bem como um elevado nível de escolaridade pública, além de ter uma das mais altas expectativas de vida do mundo. A França foi classificada como o melhor provedor de saúde pública do mundo pela Organização Mundial de Saúde (OMS). É o país mais visitado no mundo, recebendo 82 milhões de turistas estrangeiros por ano.
A França tem o terceiro maior orçamento militar do mundo, a terceira maior força militar da OTAN e o maior exército da União Europeia, além de ser um dos cinco membros permanentes do Conselho de Segurança das Nações Unidas e possuir o terceiro maior número de armas nucleares do mundo. O país é um dos membros fundadores da União Europeia e possui a maior área e a segunda maior economia do bloco. É também membro fundador da Organização das Nações Unidas, além de ser membro da Francofonia, do G8, do G20, da OTAN, da OCDE, da OMC e da União Latina.
Não há muitos relatos sobre a origem do nome França. O nome "Francia" refere-se à área original do norte da Europa, que era habitada, ou melhor dominada, por guerreiros germânicos que chamavam a si próprios de francos. "Francia" é uma adaptação latina do século III do termo "Franko(n)", nome que os francos a deram quando estavam em seu domínio, atualmente localizada provavelmente no que hoje corresponde à região de Flandres, na Bélgica. Realmente, a partir dos séculos III e IV, os romanos já tinham tido contacto com os francos. Os romanos vieram a contratá-los como mercenários em seu exército, e bem antes das invasões germânicas. O nome "Francia" não tem conotação política, mas sim de localização ou sociológica, como Magrebe ou os Bálcãs no século XXI. O povo franco era uma nação de guerreiros que elegia um chefe de guerra denominado "rei dos francos", e local livre, sob a sua competência pelos assuntos de Guerra. A guerra é considerada como o valor da liberdade, e a palavra "franco" se tornou, a partir daí, sinónimo de "livre".
Outra teoria é que o nome dos francos deriva da palavra goda "frankon", que era o nome do machado de guerra utilizado pelos habitantes da região. Esse machado atualmente é conhecido como franquisque, conforme designado no "Ethymologiarum sive originum, libri XVIII", livro escrito por Isidore de Sevilha (c. 560 - 636).
Os francos foram uma tribo germânica, provavelmente originária da Panônia, uma região do território onde hoje se situa a Hungria, e que mais tarde se mudaram para o oeste, para ocupar a região da Frísia, onde atualmente estão os Países Baixos. Em meados do século IV da nossa era, na época da decadência do Império Romano, o imperador Juliano, para pacificar estas tribos, lhes cedeu a Gália, e os francos se incorporaram ao império como um aliado federado. Na época do seu apogeu, o reino dos francos abarcou a maior parte do atual território da França e parte do que hoje é a Alemanha (Francônia). Este povo germânico uniu-se aos povoadores celtas do lugar, os gauleses, e ambos os grupos indo-europeus constituíram a origem do que séculos mais tarde seria a nação francesa. No entanto, os francos deixaram uma marca mais forte que a dos gauleses, pelo menos no nome do país: etimologicamente, França significa "terra dos francos".
As fronteiras da França moderna são muito semelhantes às fronteiras da antiga Gália, território habitado pelos gauleses, de origem celta. A Gália foi conquistada pelos Romanos no século I a.C., e os gauleses acabaram por adoptar a cultura e a língua latinas. O cristianismo instalou-se durante os séculos II e III. As fronteiras do leste da Gália ao longo do rio Reno foram atravessadas por tribos germânicas - principalmente os Francos, dos quais o antigo nome "Francie" vem - durante o século IV.
Apesar de a monarquia francesa ser muitas vezes datada do século V, a existência contínua da França como uma entidade separada começa com a divisão do império franco de Carlos Magno em uma parte leste e uma parte oeste. A parte do leste pode ser considerada como o começo do que é a atual Alemanha, a parte oeste como a França.
Os sucessores de Carlos Magno dirigiram a França até 987, quando Hugo Capeto, Duque de França e conde de Paris, foi coroado Rei da França. Seus sucessores, a dinastia dos Capetos, dirigiram a França até 1789, quando a Revolução Francesa instalou uma República, em uma época de mudanças radicais que começou em 1789.
Após diversas mudanças, a França chegou ao século XX como um país em transição política constante, passando, diversas vezes, por diferentes regimes políticos, piorando sua imagem no mundo (sendo que não possuía tantas colônias como a Inglaterra, que tinha um vasto império que agregava 1/4 do mundo). Com eclosão da Segunda Guerra Mundial (1939-1945), em 1940 a Alemanha declarou guerra à França e invadiu o país. Após apenas 43 dias de combates, os franceses se renderam e precisaram da ajuda dos aliados (em destaque, o Reino Unido e os Estados Unidos) para sua libertação (iniciada no Dia D, 6 de Junho de 1944).
Apesar disso, no final da guerra, a França obteve o estatuto de membro permanente do Conselho de Segurança das Nações Unidas, conseguiu entrar no restrito clube de potências nucleares e foi, juntamente com a Alemanha, o principal incentivador da criação da Comunidade Europeia.
Atualmente, a França é um país de língua latina, que ocupa a maior parte das antigas tribos gaulesas célticas, conquistada por Júlio César, mas que leva seu nome dos francos uma tribo germânica, cujo nome significa "homens livres", que foi formada tardiamente e instalada em uma parte do terreno do Império Romano.
A França metropolitana está situada na faixa entre as latitudes 41° e 51° N (Dunquerque está um pouco a norte da latitude 51° N) e as longitudes 6° W e 10° E, na parte ocidental da Europa e, portanto, situada na zona de clima temperado do hemisfério norte.
Enquanto a França metropolitana está localizada na Europa Ocidental, a França também tem territórios na América do Norte, Caribe, América do Sul, sul do Oceano Índico, Oceano Pacífico e uma reivindicação na Antártida. Estes territórios têm diferentes formas de governo que vão desde departamento de ultramar à coletividade de ultramar. Os departamentos e coletividades ultramarinas da França e partilham fronteiras terrestres com o Brasil e Suriname (fronteira com a Guiana Francesa) e com as antigas Antilhas Holandesas (fronteira com Saint-Martin).
A França metropolitana abrange km² e têm a maior área territorial entre os membros da União Europeia. A França possui uma grande variedade de paisagens, desde as planícies costeiras no norte e oeste, as cordilheiras dos Alpes no sudeste, o Maciço Central da região centro-sul até aos Pirenéus no sudoeste. Com metros de altitude acima do nível do mar, o Mont Blanc é o ponto mais alto da Europa Ocidental, situado nos Alpes, sobre a fronteira França-Itália. A França Metropolitana também tem sistemas fluviais extensos como o Sena, o Loire, Garona e o Ródano, que divide o Maciço Central dos Alpes e desagua no Mar Mediterrâneo. A Córsega está ao largo da costa do Mediterrâneo.
A área total terrestre da França, com seus departamentos e territórios ultramarinos (excluindo Terra de Adélia), é de 674843 km², 0,45% da área total da Terra. Contudo, a França possui a segunda maior Zona Econômica Exclusiva (ZEE) do mundo, que abrange 11.035.000 km², cerca de 8% da superfície total de todos as ZEEs do mundo, atrás apenas dos Estados Unidos (11351000 km²) e à frente da Austrália (8232000 km²).
A França tem temperaturas amenas o ano todo. As chuvas são abundantes, o sol generoso. É mais fresco e úmido a norte e a oeste; mais quente e seco nas cidades do Mediterrâneo.
O norte e o noroeste do país têm um clima temperado, enquanto que uma combinação de influências marítimas, latitude e altitude produzem um clima variado no resto da França metropolitana. No sudeste prevalece o clima mediterrâneo. No oeste, o clima é predominantemente oceânico, com um elevado nível de pluviosidade, invernos suaves e verões quentes. No interior o clima torna-se mais continental, com verões quentes e tempestuosos, invernos mais frios e menos chuva. O clima dos Alpes e de outras regiões montanhosas é principalmente alpino, com o número de dias com temperaturas abaixo de zero passando de 150 por ano e com uma cobertura de neve com duração de até seis meses.
No inverno, a neve nas montanhas possibilita a prática de esportes de inverno. A neve é rara nas planícies, caindo essencialmente a norte do rio Loire e, esporadicamente, em Paris. Na primavera, as temperaturas são acima de 20 °C no sul, como em Nice e Cannes. De junho em diante, pode-se andar pelas ruas sem agasalho. Os dias são mais longos, época para viagens ao campo, montanhas e para atividades ao ar livre. O verão é quente e calmo. O sol predomina em todo o país. A temperatura chega, muitas vezes, a 30 °C em Marselha, a 25 °C em Brest. As praias ficam lotadas. No outono regressa a chuva, depois as temperaturas amenas no mês de dezembro. Nas ruas, as pessoas se agasalham e os dias vão ficando mais curtos.
A população da França é de aproximadamente 65,4 milhões de pessoas (segundo estimativas para janeiro de 2010), dos quais 62 793 432 habitam a França Metropolitana, com uma densidade de 115 habitantes por quilômetros quadrado, 2 653 942 habitam a França Ultramarina, incluindo uma comunidade de dois mil cientistas e investigadores destacados na Antártida.
Segundo dados do "CIA World Factbook", 77% da população francesa vivem em áreas urbanas. Paris, junto à sua área metropolitana (correspondente à região conhecida como Ilha de França), concentra habitantes, o que a converte em uma das maiores do mundo, e a mais povoada da União Europeia. Outras áreas metropolitanas como mais de um milhão de habitantes são Marselha e Lyon, com mais de um milhão e meio habitantes cada uma.
A esperança de vida ao nascer é de 80,7 anos, sendo 77,1 para os homens e 84,1 para as mulheres. Os homens tendem a ter empregos a tempo completo, enquanto nas mulheres tende a ser parcial. Na França, as férias legais pagas somam cinco semanas para cada ano de trabalho. É considerado como um dos países com melhor qualidade de vida do planeta. Sua população desfruta de um alto grau de serviços, e o índice de saúde é um dos melhores do mundo.
A população está composta por descendentes de vários grupos étnicos, principalmente de origem celta (mas também ligure e ibero), fundamentalmente gauleses fusionados com a população precedente, que deram à região o nome de Gália (que hoje é a França), que incluía também Bélgica, Suíça e Luxemburgo. Cronologicamente, foram-se somando outros grupos étnicos: no processo histórico formativo da França atual, são também significativas as populações de origem grega, romana, basca, germânica (principalmente de francos, como também de burgúndios), viking (na Normandia) e, em menor medida, os sarracenos.
Desde o século XIX, a França é um país de imigração. Mais de 90% da população nasceu dentro do próprio país. Entre os estrangeiros que vêm se integrando, predominam os magrebes, italianos e espanhóis, portugueses, polacos, subsaarianos, chineses (um milhão em 2007), turcos (entre 400 e 500 mil), vietnamitas (250 mil) e ciganos (entre 200 e 300 mil). A maior parte de imigrantes nos últimos anos provêm do Magrebe. No total, existem 4,5 milhões de imigrantes, do qual aproximadamente um milhão e meio nasceram em terras estrangeiras, mas têm adquirido a nacionalidade francesa, ainda que mais de três milhões desses imigrantes sejam considerados estrangeiros.
Os estudos da população francesa mostram que a maioria dos cidadãos são de origem europeia (91,6%), entre os quais franceses (85%) os outros 6,5% provêm de outros países. 5,75 vêm de países da África, 3% da Ásia e 0,6% da América. Esta composição é consequência da evolução migratória e da presença significativa da população nascida na França, porém estrangeira, geralmente imigrantes que através dos anos foram obtendo a cidadania francesa. A população de origem judia era estimada em 550 mil habitantes, a princípios dos anos 2000, ainda que não existam dados estatísticos, pois a lei proíbe recolher dados sobre etnias ou religiões.
França é um país secular e a liberdade de religião é um direito constitucional. O governo francês não mantém estatísticas sobre adesão religiosa, etnias ou filiação política. No entanto, existem algumas estimativas não oficiais.
O catolicismo romano tem sido a religião predominante na França há mais de um milênio, embora não seja tão ativamente praticado hoje como era antes. Uma pesquisa realizada pelo jornal católico "La Croix" descobriu que, enquanto em 1965, 81% dos franceses se declaravam como católicos, em 2009 essa proporção era de 64%. Além disso, embora 27% dos franceses ia à missa uma vez por semana ou mais em 1952, apenas 4,5% o fizeram em 2006; 15,2% assistiam à missa pelo menos uma vez por mês. O mesmo estudo constatou que os protestantes responderam por 3% da população, um aumento em relação às pesquisas anteriores e 5% seguiam outras religiões, sendo que os restantes 28% declarando que não tinham nenhuma religião.
De acordo com uma sondagem de janeiro de 2007 realizada pela "Catholic World News", apenas 5% da população francesa frequentava a igreja regularmente (ou 10% frequentam os serviços da igreja regularmente entre os entrevistados que se identificaram como católicos). A pesquisa mostrou que 51% dos entrevistados se identificou como católicos, 31% se identificou como agnósticos ou ateus (outra pesquisa define a proporção de ateus como igual a 27%), 10% se identificou como sendo de outras religiões ou sem opinião, 4% identificados como muçulmanos, 3% se identificaram como protestantes, 1% se identificaram como budistas e 1% se identificaram como judeus. Enquanto isso, uma estimativa independente do politologista Pierre Bréchon, em 2009, concluiu que a proporção de católicos havia caído para 42% enquanto o número de ateus e agnósticos havia subido para 50%. Os valores mais recentes da World Christian Database datados de 2010 e divulgados pelo site The ARDA mostram que 68,23% dos franceses são seguidores do Cristianismo, 16,41% são agnósticos, 8,55% são muçulmanos, os ateus são 4,13%, os judeus 1% e outras religiões são seguidas por 1,67% da população. De acordo com o Fórum Pew "Na França, os defensores de uma lei de 2004 que proíbe o uso de símbolos religiosos nas escolas dizem que protegem as meninas muçulmanas de serem forçadas a usar um lenço na cabeça, mas a lei também restringe aqueles que querem usar o véu - ou qualquer outro símbolo "conspícuo" religioso, incluindo grandes cruzes cristãs e turbantes sikh - como expressão de sua fé."
De acordo com pesquisa do Eurobarômetro, de 2005, 34% dos cidadãos franceses responderam que "acreditam que existe um deus", enquanto 27% responderam que "acreditam que existe algum tipo de espírito ou força vital e 33% que "não acredito que haja qualquer tipo de espírito, deus, ou força vital." Um outro estudo mostra 32% de pessoas na França se declaram como ateus e outros 32% declaram-se como "cético sobre a existência de Deus, mas não um ateu." Segundo pesquisa de 2010, também do "Eurobarometer", a França é o país mais ateu da Europa, com 40% da sua população não acreditando na existência de um deus; 27% dos franceses disseram crer em algum deus, ao passo que 27% acreditavam em algum tipo de espírito ou força vital.
As estimativas do número de muçulmanos na França variam amplamente. De acordo com o censo francês de 1999, havia 3,7 milhões de pessoas "provavelmente de fé muçulmana" na França (6,3% da população total). Em 2003, o Ministério do Interior francês estimou que o número total de muçulmanos estava entre cinco e seis milhões (8-10%). A comunidade judaica atual na França é de cerca de 600.000 pessoas de acordo com o Congresso Mundial Judaico e é a maior na Europa. No entanto, tanto o Banco de Dados Judeus Norte-Americano quanto a Biblioteca Virtual Judaica colocam essas estimativas mais perto de 480 mil pessoas em 2010.
Desde 1905 o governo francês tem seguido o princípio da laicidade, em que é proibido de reconhecer qualquer direito específico de uma comunidade religiosa. Em vez disso, o governo apenas reconhece as organizações religiosas, de acordo com critérios formais legais que não tratam a doutrina religiosa. Por outro lado, as organizações religiosas devem abster-se de intervir na elaboração de políticas.
O idioma oficial na França é o francês, proveniente do "françano", variante linguística falada na Ilha de França que nos princípios da Idade Média e, ao longo dos séculos, se impôs ao resto das línguas e variantes linguísticas que se falam em quaisquer partes da França.
Apesar disto, esta imposição do francês tem sido fruto de decisões políticas tomadas ao longo da história, com o objetivo de criar um Estado uniformizado linguisticamente. Feito isto, o artigo 2 da constituição francesa de 1958 disse textualmente que «"La langue de la République est le français"».
Este artigo tem servido para não permitir o uso oficial nos âmbitos de uso culto das línguas que se falam na França: o catalão, o bretão, o corso, o ocitano, o provençal, o franco-provençal, o basco e o alsaciano. Somente se tem permitido ensinar alguma destas línguas como segunda língua estrangeira optativa na escola pública. A imigração proveniente de fora do país, assim como de regiões exclusivamente francófonas, faz com que a porcentagem de falantes destas línguas seja cada vez mais baixa.
Do século XVII a meados do século XX, o francês serviu como língua internacional preeminente da diplomacia e das relações internacionais, bem como uma língua franca entre as classes cultas da Europa. A posição dominante da língua francesa nas relações internacionais tem apenas sido desafiada recentemente pelo inglês, desde o surgimento dos Estados Unidos como uma grande potência.
A República Francesa é uma república unitária semipresidencialista com fortes tradições democráticas. A constituição da V República foi aprovada por referendo em 28 de setembro de 1958. É extremamente reforçada a autoridade do executivo em relação ao Parlamento. O poder executivo em si tem dois dirigentes: o presidente da República, atualmente François Hollande, que é chefe de estado e é eleito diretamente por sufrágio universal para um mandato de cinco anos (antes de sete anos) e o Governo, liderado pelo primeiro-ministro nomeado pelo presidente. O primeiro-ministro atual é Manuel Valls.
O parlamento francês é uma legislatura bicameral, composto por uma Assembleia Nacional ("Assemblée Nationale") e um Senado. Os deputados da Assembleia Nacional representam círculos eleitorais locais e são diretamente eleitos para mandatos de cinco anos. A Assembleia tem o poder de demitir o gabinete e, assim, a maioria na Assembleia determina a escolha do governo. Os senadores são escolhidos por um colégio eleitoral para mandatos de seis anos (inicialmente nove termos homólogos), e metade dos assentos são submetidos à eleição três cada três anos. Os poderes legislativos do Senado são limitados; em caso de desacordo entre as duas câmaras, a Assembleia Nacional tem a palavra final, exceto para as leis constitucionais e "lois organiques" (leis que são diretamente previstas pela Constituição), em alguns casos. O governo tem uma forte influência na formação da ordem do dia do Parlamento.
A política francesa caracteriza-se por dois grupos políticos opostos: um de esquerda, centrada em torno do Partido Socialista Francês, e os outros da ala direita, anteriormente centrada em torno do "Rassemblement pour la République" (RPR) e agora seu sucessor, o "Union pour un mouvement populaire" (UMP). O poder executivo é atualmente composto na sua maioria por membros do UMP.
França usa um sistema romano-germânico; isto é, a lei surge principalmente a partir de estatutos escritos; os juízes não fazem leis, mas apenas as interpretam (embora a quantidade de interpretação judicial em determinadas áreas faz com que seja equivalente a jurisprudência). Os princípios básicos do Estado de direito foram estabelecidas no Código de Napoleão (que era, por sua vez, em grande parte, baseado na lei real codificada no reinado de Luís XIV). De acordo com os princípios da Declaração dos Direitos do Homem e do Cidadão a lei só deve proibir as ações prejudiciais à sociedade. Como Guy Canivet, o primeiro presidente do Tribunal de Cassação da França, escreveu sobre a gestão das prisões: "A liberdade é a regra e sua restrição é a exceção; qualquer restrição de liberdade deve ser prevista por lei e deve seguir os princípios da necessidade e proporcionalidade". Ou seja, a lei legislar proibições somente se elas forem necessárias e se os inconvenientes causados ​​por essa restrição não excedam os inconvenientes que a proibição supostamente irá resolver.
A lei francesa é dividida em duas áreas principais: o direito privado e o direito público. O direito privado inclui, na lei, nomeadamente o direito penal e civil. O direito público inclui, na lei, designadamente o direitos administrativo e constitucional. No entanto, em termos práticos, a lei francesa compreende três principais áreas do direito: direito civil, direito penal e direito administrativo.
A França não reconhece a lei religiosa, nem reconhece crenças religiosas ou a moralidade como uma motivação para a promulgação de proibições. Como consequência, a França há muito tempo não tem qualquer lei de blasfêmia nem leis contra a sodomia (a última sendo abolida em 1791). No entanto, "os crimes contra a decência pública" ("moeurs contraires aux bonnes") ou perturbação da ordem pública ("rouble à l'ordre public") foram usados ​​para reprimir manifestações públicas de homossexualidade ou a prostituição de rua. Leis penais só podem abordar o futuro e não o passado criminal (leis "ex post facto" são proibidas), e para serem aplicáveis, as leis devem ser oficialmente publicadas no "Journal Officiel de la République française". Em 2010, a França aprovou uma lei que proíbe véus de rosto em público, incluindo aqueles usados ​​pelas mulheres muçulmanas. A Anistia Internacional condenou a lei como uma violação da liberdade de expressão. Em setembro de 2011, duas mulheres muçulmanas foram multadas por usar o nicabe, mas elas recorreram das multas.
A França é tolerante com a comunidade LGBT. Desde 1999, as uniões civis para casais homossexuais são permitidas, embora o casamento homossexual só foi legalizado na França em 2013. Leis de condenação ao racismo, sexismo ou o anti-semitismo são antigas e importantes, por exemplo, leis que proíbem o discurso discriminatório na imprensa são tão antigas como 1881.
A França é um membro da Organização das Nações Unidas (ONU) e é um dos membros permanentes do seu Conselho de Segurança, com direito a veto. O país também é membro do G8, Organização Mundial do Comércio (OMC), do Secretariado da Comunidade do Pacífico (SCP) e da Comissão do Oceano Índico (COI), além de ser membro fundador da Organização do Tratado do Atlântico Norte (OTAN), membro associado da Associação dos Estados do Caribe (AEC) e um dos principais participantes da Organização Internacional da Francofonia (OIF), que reúne 51 países de língua francesa. Como um polo importante para as relações internacionais, a França abriga o segundo maior conjunto de missões diplomáticas em todo o mundo e a sede de diversas organizações internacionais, como a OCDE, a UNESCO, a Interpol, o Escritório Internacional de Pesos e Medidas e a Francofonia. A política externa francesa do pós-guerra tem sido amplamente moldada pela adesão à União Europeia (UE), da qual foi um dos membros fundadores. Desde 1960, a França desenvolveu laços estreitos com a Alemanha reunificada para se tornar a força motriz mais influente da UE.
O país ainda mantém forte influência política e econômica em suas antigas colônias africanas e fornece ajuda econômica e tropas para missões de manutenção da paz na Costa do Marfim e no Chade. Recentemente, após a declaração unilateral de independência do norte do Mali pelo Movimento Nacional de Libertação do Azauade (MNLA), durante a rebelião tuaregue, e do subsequente conflito regional com vários grupos islâmicos, como Ansar Dine, a França e outros países africanos intervieram militarmente para ajudar o exército do Mali a retomar o controle. Em 2009, a França foi o segundo maior (em números absolutos) financiador de ajuda humanitária no mundo, atrás dos Estados Unidos e à frente de Alemanha, Japão e Reino Unido, o que representa apenas 0,5% do PIB francês. A organização que administra a ajuda francesa ao exterior é a Agência Francesa de Desenvolvimento, que financia projetos humanitários, principalmente na África subsaariana. Os principais objetivos desta ajuda são "o desenvolvimento de infraestrutura, o acesso a assitência médica e educação, a implementação de políticas econômicas adequadas e a consolidação do Estado de direito e da democracia".
As Forças Armadas Francesas ("Armées françaises") são as forças militares e paramilitares do governo francês, sendo o presidente seu comandante-em-chefe. Elas são compostas pelo Exército Francês ("Armée de Terre"), pela Marinha Francesa ("Marine Nationale"), pela Força Aérea Francesa ("Armée de l' Air") e por uma força paramilitar auxiliar, a Gendarmaria Nacional ("Gendarmerie Nationale"), e estão entre as maiores forças armadas em todo o mundo. Embora administrativamente as forças armadas francesas estejam sob o comando do Ministério da Defesa, a Gendarmeria é operacionalmente ligada ao Ministério do Interior. A França é membro permanente do Conselho de Segurança das Nações Unidas e é um Estado nuclear reconhecido desde 1960. O país assinou e ratificou o Tratado de Interdição Completa de Ensaios Nucleares e aderiu ao Tratado de Não Proliferação de Armas Nucleares. As despesas militares anuais da França em 2011 foram de 62,5 bilhões de dólares, ou 2,3% de seu PIB, o quinto maior gasto militar do mundo, atrás apenas de Estados Unidos, China, Rússia e Reino Unido.
A dissuasão nuclear francesa conta com total independência. A corrente de força nuclear francesa é composta por quatro submarinos da classe "Triomphant" equipados com mísseis balísticos. Além da frota de submarinos, estima-se que a França tenha cerca de sessenta mísseis ar-superfície "ASMP" de médio alcance equipados com ogivas nucleares, dos quais cerca de 50 são usados pela Força Aérea em caças Dassault Mirage 2000N, de longo alcance e com capacidade nuclear, enquanto que cerca de dez estão implantados em aeronaves de ataque Dassault-Breguet Super Étendard da Marinha, que operam a partir do porta-aviões de propulsão nuclear FS Charles de Gaulle. A nova aeronave Rafale F3 irá substituir gradualmente todos os Mirage 2000N e SEM no uso nuclear com a melhoria do míssil "ASMP-A" com uma ogiva nuclear.
A França tem grandes indústrias militares, além de uma das maiores indústrias aeroespaciais do mundo. Suas plantas industriais produziram equipamentos como o caça Rafale, o porta-aviões Charles de Gaulle, o míssil Exocet e o tanque Leclerc, entre outros. Apesar de se retirar do projeto Eurofighter, a França está investindo ativamente em projetos europeus conjuntos, como o Eurocopter Tiger, fragatas multiusos, VANTs, o nEUROn e o Airbus A400M Atlas. A França é um dos maiores vendedores de armas do mundo, sendo que a maior parte de seu arsenal está disponível para o mercado de exportação, com exceção dos dispositivos de propulsão nuclear.
A França está dividida em 26 regiões administrativas. 22 estão na França metropolitana (21 estão na parte continental da França metropolitana, é uma colectividade territorial da Córsega), e quatro são regiões ultramarinas. As regiões estão subdivididas em 100 departamentos que são numerados (principalmente em ordem alfabética). Esse número é usado em códigos postais e placas de matrícula, entre outros. Os cerca de 100 departamentos estão subdivididos em 341 circunscrições que são, por sua vez, subdivididas em 4.032 cantões. Estes cantões estão divididos em 36.680 comunas, que são municípios com um conselho municipal eleito. Também existem 2.588 entidades intermunicipais, agrupando 33.414 das 36.680 comunas (ou seja, 91,1% de todos os municípios). Três municípios, Paris, Lyon e Marselha também estão subdivididos em 45 circunscrições municipais.
As regiões, departamentos e comunas são todos conhecidos como coletividades territoriais, o que significa que eles possuem assembleias locais, bem como um executivo. Arrondissements e cantões são divisões meramente administrativas. No entanto, este não foi sempre o caso. Até 1940, os arrondissements também eram coletividades territoriais, com uma assembleia eleita, mas estas foram suspensas pelo regime de Vichy e definitivamente abolida pela Quarta República, em 1946. Historicamente, os cantões eram também coletividades territoriais, com suas assembleias eleitas.
Um membro G8, grupo líder dos principais países industrializados, o país é classificado como a quinta maior economia do mundo e segunda maior da Europa é por PIB nominal; com 39 das 500 maiores empresas do mundo em 2010, a França ocupa o quarto lugar no mundo e o primeiro na Europa na lista Fortune Global 500, à frente da Alemanha e do Reino Unido. A França se juntou aos onze outros membros da União Europeia para criar o euro em 1 de Janeiro de 1999, substituindo completamente o franco francês (₣) no início de 2002.
A França tem uma economia mista que combina a iniciativa privada extensa (cerca de 2,5 milhões de empresas registradas) com substanciais (embora em declínio) empresas estatais e intervenção do governo. O governo mantém considerável influência sobre segmentos-chave dos setores de infra-estrutura, com participação majoritária em estradas de ferro, eletricidade, aviões, usinas nucleares e telecomunicações. O país vem relaxando gradualmente o controle sobre estes sectores desde o início dos anos 1990. O governo está lentamente corporatizando o setor estatal e vendendo participações na France Télécom, Air France, assim como ações, seguros e indústrias de defesa. A França tem uma importante indústria aeroespacial liderada pelo consórcio europeu Airbus e tem o seu próprio espaçoporto nacional, o Centro Espacial de Kourou.
Segundo a Organização Mundial do Comércio (OMC), em 2009 a França foi 6º maior exportador do mundo e o 4º maior importador de produtos manufaturados. Em 2008, a França foi o terceiro maior destinatário de investimentos estrangeiros diretos nos países da OCDE em 117,9 bilhões dólares, atrás de Luxemburgo (onde o investimento estrangeiro direto foi de transferências essencialmente monetárias aos bancos localizados no país) e dos Estados Unidos (316.100 milhões dólares), mas acima do Reino Unido (96,9 bilhões dólares), Alemanha (US $ 24,9 bilhões) e Japão ($ 24,4 bilhões). No mesmo ano, as empresas francesas investiram 220.000 milhões de dólares fora da França, classificando a França como o segundo mais importante investidor externo direto no âmbito da OCDE, atrás dos Estados Unidos (311,8 bilhões de dólares) e à frente do Reino Unido (111,4 bilhões de dólares), Japão (128 bilhões de dólares) e Alemanha (156,5 bilhões de dólares).
Serviços financeiros, bancários e do setor de seguros são uma parte importante da economia francesa. A Bolsa de Valores de Paris é uma instituição antiga, criada por Luís XV em 1724. Em 2000, as bolsas de valores de Paris, Amesterdã e Bruxelas foram incorporadas à Euronext. Em 2007, a Euronext se fundiu com a Bolsa de Nova Iorque para formar NYSE Euronext, a maior bolsa de valores do mundo.Euronext Paris, o ramo francês do grupo NYSE Euronext, é o segundo maior mercado europeu de ações, por trás da London Stock Exchange.
As empresas francesas mantiveram posições-chave na indústria de seguros e bancária: a AXA é a maior empresa do mundo seguro e está classificada pela revista "Fortune" como a nona empresa mais lucrativa do mundo. Os principais bancos franceses são BNP Paribas e o Crédit Agricole, classificados como 1º e 6º maiores bancos do mundo em 2010.
Com 81,9 milhões de turistas estrangeiros em 2007, a França está classificado como o maior destino turístico do mundo, à frente da Espanha (58,5 milhões em 2006) e Estados Unidos (51,1 milhões em 2006). Este valor exclui 81,9 milhões de pessoas que ficam menos de 24 horas na França, como europeus do norte cruzando a França a caminho de Espanha ou da Itália durante o verão.
A França tem 41 locais classificados como Patrimônio Mundial da UNESCO e apresenta cidades de interesse cultural elevado (principalmente Paris, além de Toulouse, Estrasburgo, Bordéus, Lyon e outros), praias e balneários, estâncias de esqui e regiões rurais. O país e, especialmente a sua capital, tem alguns dos maiores e mais renomados museus do mundo, incluindo o Louvre, que é o museu de arte mais visitado no mundo, além do Musée d'Orsay, principalmente dedicado ao impressionismo, e o Beaubourg, dedicado à arte contemporânea. A Disneyland Paris é o parque temático mais popular da França e de toda a Europa, com mais visitantes em 2009.
Com mais de 10 milhões de turistas por ano, a Riviera Francesa (ou "Côte d'Azur"), no sudeste da França, é o segundo principal destino turístico no país, após a região parisiense. De acordo com a Agência de Desenvolvimento Econômico "Côte d'Azur", a região é beneficiada por 300 dias de sol por ano, 115 km de litoral, 18 campos de golfe, 14 estações de esqui e 3.000 restaurantes. Todos os anos a "Côte d'Azur" hospeda 50% da frota mundial de iates luxuosos, sendo que 90% desses iates visitam costa da região pelo menos uma vez na vida.
Um outro destino principal são os castelos do Vale do Loire, este Patrimônio Mundial é notável pela qualidade do seu patrimônio arquitectónico, nas suas cidades históricas, como Amboise, Angers, Blois, Chinon, Nantes, Orléans, Saumur e Tours, mas em particular pelos seus castelos.
Os locais turísticos mais populares incluem (de acordo com um ranking de 2003 por visitantes por ano): Torre Eiffel (6,2 milhões), Museu do Louvre (5,7 milhões), Palácio de Versalhes (2,8 milhões), Museu de Orsay (2,1 milhões ), Arco do Triunfo (1,2 milhões), Centro Pompidou (1,2 milhões), Monte Saint-Michel (1 milhão), o Castelo de Chambord (711.000), Sainte-Chapelle (683 mil), Castelo de Haut-Koenigsbourg (549.000), Puy de Dôme (500.000), Museu Picasso (441.000), Carcassonne (362 mil).
A França é o menor emissor de dióxido de carbono entre os sete países mais industrializados do mundo, devido ao seu forte investimento em energia nuclear. Como resultado de grandes investimentos em tecnologia nuclear, a maior parte da eletricidade produzida no país é gerada por 59 usinas nucleares (78% em 2006, a partir de apenas 8% em 1973, 24% em 1980, e 75% em 1990).
A rede ferroviária da França, que se estende por 31.840 quilômetros, é a mais extensa da Europa Ocidental. É operada pela SNCF, e os trens de alta velocidade incluem o Thalys, Eurostar e TGV, que viaja a 320 km/h em uso comercial. O Eurostar, juntamente com o Serviço de Transferência do Eurotúnel, conecta-se com o Reino Unido através do Túnel da Mancha. As ligações ferroviárias estendem-se para todos os outros países vizinhos na Europa, com exceção de Andorra. Ligações intra-urbanas também são bem desenvolvidas, com os serviços de metrô e bondes complementando os serviços de ônibus.
Há aproximadamente 893.300 quilômetros de rodovias utilizáveis na França. A região de Paris está envolvida com uma rede densa de estradas e rodovias que a ligam com praticamente todas as partes do país. Estradas francesas também lidam com um importante tráfego internacional, conectando-se com cidades da vizinha Bélgica, Espanha, Andorra, Mônaco, Suíça, Alemanha e Itália. Não há taxa de matrícula anual ou estrada fiscal, entretanto, o uso da auto-estrada é através de pedágios, exceto nas imediações dos municípios de grandes dimensões. O mercado de carros novos é dominado por marcas domésticas como a Renault (27% dos carros vendidos na França, em 2003), Peugeot (20,1%) e Citroën (13,5%). Mais de 70% dos carros novos vendidos em 2004, tinham motores a diesel, muito mais do que continha gasolina ou a GPL. A França também possui a ponte mais alta estrada do mundo: o Viaduto de Millau, e construiu muitas pontes importantes, como a Ponte da Normandia.
Há cerca de 478 aeroportos na França, incluindo campos de pouso. O Aeroporto de Paris-Charles de Gaulle, situado nos arredores de Paris, é o maior e mais movimentado aeroporto do país, e manipula grande maioria do tráfego popular e comercial do país e liga Paris com praticamente todas as grandes cidades em todo o mundo. A Air France é a companhia aérea nacional, apesar de numerosas companhias aéreas privadas que fornecem serviços de viagens domésticas e internacionais. Há dez principais portos na França, a maior das quais é, em Marselha, que também é a maior fronteira com o Mar Mediterrâneo. 14.932 quilômetros de canais atravessam a França, incluindo o Canal do Meio-dia, que liga o Mar Mediterrâneo ao Oceano Atlântico através do rio Garona.
Em 1802, Napoleão Bonaparte criou o "lycée". No entanto, é Jules Ferry que é considerado o pai da moderna escola francesa, que é gratuita, laica e obrigatória até aos 13 anos de idade desde 1882 (o comparecimento escolar na França agora é obrigatório até os 16 anos de idade).
Atualmente, o sistema de ensino na França é centralizado e é composto de três fases, o ensino primário, secundário e ensino superior. O Programa Internacional de Avaliação de Alunos, coordenado pela Organização para a Cooperação e Desenvolvimento Econômico (OCDE), classifica a educação da França como a 25ª melhor do mundo, não sendo nem significativamente superior nem inferior à média da OCDE. A educação primária e secundária são predominantemente públicas, administradas pelo Ministério da Educação Nacional.
O sistema educacional francês é subdividido em cinco diferentes níveis:
Desde a Idade Média, a França tem sido um dos principais contribuintes para a produção científica. Por volta do início do século XI o Papa Silvestre II reintroduziu o ábaco e a esfera armilar e apresentou os algarismos indo-arábicos e os relógios para a Europa do norte e ocidental. A Universidade de Paris, fundada em meados do século XII, ainda é uma das mais importantes universidades do mundo ocidental.
No século XVII, René Descartes definiu um método para a aquisição de conhecimento científico, enquanto Blaise Pascal tornou-se famoso por seu trabalho sobre a probabilidade e a mecânica de fluidos. Ambos foram figuras-chave da revolução científica que eclodiu na Europa durante este período. A Académie des Sciences foi fundada por Luís XIV para incentivar e proteger o espírito de pesquisa científica francesa. Esteve na vanguarda dos progressos científicos na Europa nos séculos XVII e XVIII. É uma das primeiras academias de ciências.
O período do Iluminismo foi marcado pelo trabalho do biólogo Buffon e do químico Lavoisier, que descobriu o papel do oxigênio na combustão, enquanto Diderot e D'Alembert publicaram a "Encyclopédie", que tinha como objetivo dar acesso ao "conhecimento útil" para o povo, um conhecimento que possam aplicar à sua vida cotidiana.
Com a Revolução Industrial, no século XIX, desenvolvimentos científicos espetaculares aconteceram na França com cientistas como Augustin Fresnel, fundador da óptica moderna; Sadi Carnot, que lançou as bases da termodinâmica; ou Louis Pasteur, um dos pioneiros da microbiologia. Outros cientistas franceses eminentes do século XIX têm seus nomes inscritos na Torre Eiffel, em Paris.
Cientistas franceses famosos do século XX incluem o matemático e físico Henri Poincaré, os físicos Henri Becquerel e Pierre e Marie Curie tornaram-se famosos por seus trabalhos sobre a radioatividade, o físico Paul Langevin ou o virologista Luc Montagnier, co-descobridor do HIV/AIDS. Até 2012, 65 franceses ganharam o Prêmio Nobel e 11 receberam a Medalha Fields.
O sistema de saúde francês ficou em primeiro lugar a nível mundial de acordo com a Organização Mundial de Saúde em 1997 e depois novamente em 2000. O sistema de saúde é geralmente livre para as pessoas afetadas por doenças crônicas ("Affections de longues durées"), tais como câncer, AIDS ou fibrose cística. A expectativa de vida média ao nascer é de 77 anos para homens e 84 anos para as mulheres, uma das mais altas da União Europeia. Existem 3,22 médicos para cada 1000 habitantes na França, enquanto que o gasto médio "per capita" de saúde foi de US$ 4.719 em 2008. Em 2007 existiam cerca de 140.000 habitantes (0,4%) da França que viviam com HIV/AIDS.
Apesar dos franceses terem a reputação de ser um dos povos mais magros entre os países desenvolvidos, a França, como outros países ricos, enfrenta uma epidemia crescente e recente de obesidade, principalmente devido à substituição da culinária tradicional francesa saudável por "junk food" nos hábitos alimentares franceses. No entanto, a taxa de obesidade francesa é muito inferior a dos Estados Unidos (por exemplo, taxa de obesidade na França é a mesma que a estadunidense era na década de 1970) e ainda é a mais baixa da Europa,mas agora é considerada pelas autoridades como um dos principais problemas de saúde pública e é ferozmente combatida; taxas de obesidade infantil estão a abrandar na França, enquanto continua a crescer em outros países.
A França tem sido um centro de criação cultural por séculos. Muitos artistas franceses estiveram entre os mais famosos de seu tempo e a França ainda é reconhecida no mundo pela sua rica tradição cultural.
Os sucessivos regimes políticos que sempre promoveram a criação artística e a criação do Ministério da Cultura em 1959 ajudaram a preservar o patrimônio cultural do país e torná-lo disponível ao público. O Ministério da Cultura tem sido muito ativo desde a sua criação na concessão de subsídios aos artistas, promovendo a cultura francesa no mundo, apoiando festivais e eventos culturais, além de proteger monumentos históricos. O governo francês também conseguiu manter uma exceção cultural para defender produtos audiovisuais feitos no país.
A França recebe o maior número de turistas por ano, em grande parte graças aos inúmeros estabelecimentos culturais e edifícios históricos implantados em todo o seu território. Dispõe de 1.200 museus que recebem mais de 50 milhões de pessoas anualmente. Os locais culturais mais importantes são mantidos pelo governo, por exemplo, através da agência pública do Centro Nacional de Monumentos, que tem cerca de uma centena de monumentos históricos nacionais sob seu cuidado.
Os 43.180 edifícios protegidos como monumentos históricos incluem principalmente residências (muitos castelos) e edifícios religiosos (catedrais, basílicas, igrejas, etc), mas também estátuas, memoriais e jardins. A UNESCO inscreveu 37 locais na França como Patrimônios Mundiais.
As primeiras manifestações artísticas vêm do período pré-histórico, em estilo franco-cantábrico. A época carolíngia marca o nascimento de uma escola de iluminadores que se prolongará ao longo de toda a Idade Média, culminando nas ilustrações do livro "As Horas Muito Ricas do duque de Berry". Os pintores clássicos do século XVII francês são: Poussin e Lorrain. No século XVIII predomina o rococó, com Watteau, Boucher e Fragonard. Nos finais do século começa o classicismo de Jacques-Louis David. O romanticismo está dominado pelas figuras de Géricault e Delacroix. A paisagem realista da Escola de Barbizon tem sua continuação em artistas de um realismo mais testemunhial sobre a realidade social de seu tempo, como Millet e Courbet. Nos finais do século XIX Paris, convertida em centro da pintura, vê nascer o impressionismo, precedido pela obra de Édouard Manet. A este seguem Toulouse-Lautrec, Gauguin e Cézanne. Já no século XX, surgem os fauvistas em torno da Matisse e o cubismo da mão de Georges Braque e do espanhol Pablo Picasso que trabalham em Paris. Outros movimentos artísticos vão se sucedendo, na Paris de entreguerras, decaindo como centro pictórico mundial depois da Segunda Guerra Mundial.
Na França, a escultura evoluiu por diversos estilos, se sobressaindo em todos eles: pré-histórico, romano, cristão, românico, gótico, renascentista, barroco e rococó, neoclássico (Frédéric Auguste Bartholdi: "Estátua da Liberdade"), romântico (Auguste Rodin: "O pensador"), e os contemporâneos.
No que se refere à arquitetura, os celtas deixaram seus rastros também na construção de grandes monólitos ou megálitos, e a presença grega desde o século VI a. C. que hoje é recordada na herança clássica de Marselha. O estilo românico tem exemplos na "Maison Carrée", templo romano edificado entre 138-161 a. C., ou no Pont du Gard construído entre os anos 1940 e 60 d. C., em Nimes e declarado patrimônio universal em 1985. Na França se inventou o estilo gótico, plasmado em Catedrais como as de Chartres, Amiens, Notre Dame ou Estrasburgo. O renascimento surgido na Itália, tem seu estilo arquitetônico representado magistralmente no Castelo de Blois ou no Palácio de Fontainebleau entre outros. A arte barroca (também de origem italiana), e o rococó (invenção francesa) têm obras extraordinárias na França. Tal é o caso do Palácio do Louvre e o Panthéon de Paris entre tantos outros. O modernismo ou arte moderna na arquitetura engloba todo o século XIX e a primeira metade do XX, e Gustave Eiffel revolucionou a teoria e prática arquitetônica de seu tempo na construção de gigantescas pontes e no emprego de materiais como o aço. Sua obra mais famosa é a chamada Torre Eiffel. Outro grande ícone da arquitectura universal é Le Corbusier, um inovador e funcionalista celebrado especialmente por seus aportes urbanísticos nas edificações de vivendas e conjuntos habitacionais.
A França é o país com o maior número de Prémios Nobel de Literatura. Tanto os cidadãos franceses, como os francógrafos de outros países (como o belga Maurice Maeterlinck, o senegalês Léopold Sédar Senghor ou o luxemburguês Daniel Herrendorf), compõem o que se denomina como literatura francesa, que marcou a literatura de importantes autores, países e línguas. Tal é o caso do cubano Alejo Carpentier ou do denominado ""boom" latino-americano".
Na música francesa desde antes do ano 1000 se destaca o canto gregoriano empregado nas liturgias. Na França se criou a polifonia. Na denominada "Ars Antiqua", se atribui a Carlos Magno o "Scholae Cantorum" (783). Os "Juramentos de Estrasburgo", é a obra lírica francesa mais importante da Idade Média, período no que se desenvolvem as Canções de Gesto como a "Canção de Roland". A França foi o berço dos trovadores no século XII, assim como do "Ars Nova" dos séculos posteriores. Durante o Romantismo Paris se converte no centro musical do mundo e na atualidade, a França mantém um lugar privilegiado na criação musical graças a novas gerações de compositores. Dentro dos exponentes da música popular francesa, se encontram figuras como Edith Piaf, Mireille Mathieu, Dalida, Charles Aznavour, Vanessa Paradis, Serge Gainsbourg e Gilbert Becaud.
A França foi por duas vezes sede dos Jogos Olímpicos de Verão: a segunda edição, em 1900, e a oitava edição, em 1924. Também sediou os Jogos Olímpicos de Inverno três vezes: a primeira edição, em 1924; a décima edição, em 1968; e a décima-sexta edição, em 1992.
No futebol, a França sediou a Copa do Mundo FIFA por duas vezes, sendo a primeira delas em 1938, quando a Itália conquistou o título, e a segunda em 1998, quando a seleção nacioal, após duas tentativas frustradas de chegar à fase final das Copas de 1958 e 1986, pôde finalmente chegar a final da competição. Durante o mundial, os jogos foram realizados nas cidades de Saint-Denis, Marselha, Paris, Lens, Lyon, Nantes, Toulouse, Saint-Étienne, Bordeaux, e Montpellier. O Mundial foi conquistado pela propria França, seleção anfitriã, sagrando-se pela primeira vez campeã na história, ao vencer a Seleção Brasileira de Futebol por 3 a 0 na final. Nos Jogos Olímpicos de Verão, a França já foi medalha de ouro na modalidade masculina, em 1984. No futebol feminino, a melhor posição da Seleção Francesa foi o 4º lugar na Copa do Mundo de Futebol Feminino de 2011 e nos Jogos Olímpicos de Verão de 2012. Em 2016 sediou a Eurocopa e chegou até a final, mas perdeu na prorrogação para Portugal.
A França também tem forte tradição no tênis. Sedia o Grand Slam de Roland Garros e já foi 9 vezes campeã da Copa Davis. René Lacoste, no entanto, foi o único tenista francês a ser nº 1 do mundo. Na atualidade o melhor tenista francês é Jo-Wilfried Tsonga, ex-nº 5 do mundo.
Um dos maiores esportistas da história da França foi Alain Prost, quatro vezes campeão do Mundial de Pilotos da Fórmula 1, considerado um dos mais bem sucedidos pilotos da categoria de todos os tempos.
A França vem tendo resultados expressivos na natação mundial com nomes como Alain Bernard, Frédérick Bousquet, Laure Manaudou e Camille Muffat (todos ex-recordistas mundiais e medalhistas olímpicos). O destaque histórico é Jean Boiteux, primeiro francês campeão olímpico na natação.
No atletismo, a França tem como destaques históricos Alain Mimoun, Marie-José Perec e Renaud Lavillenie
Outro destaque francês é o judoca Teddy Riner, tido como praticamente imbatível em sua categoria. Entre 2007 e 2012 ele foi pentacampeão mundial na categoria +100 kg e em 2012 se tornou campeão olímpico.

</doc>
<doc id="828" url="https://pt.wikipedia.org/wiki?curid=828" title="Ficção científica">
Ficção científica

Ficção científica é um gênero literário desenvolvido no século XIX, que lida principalmente com o impacto da ciência, tanto verdadeira como imaginada, sobre a sociedade ou os indivíduos. A ação pode girar em torno de um grande leque de possibilidades como: viagem espacial, viagem no tempo, mais rápido que a luz, universos paralelos e vida extraterrestre.
Em inglês o termo ficção científica é às vezes abreviado para sci-fi ou SF. Em português, é abreviado para FC.
A ficção científica muitas vezes explora as potenciais consequências de inovações científicas e outras, e tem sido chamado de uma "literatura das ideias".
Este tipo de literatura pode consistir numa cuidadosa e bem informada extrapolação sobre fatos e princípios científicos, ou abranger áreas profundamente rebuscadas, que contrariam definitivamente esses factos e princípios. Em qualquer dos casos, o ser de forma plausível baseado na ciência é um requisito indispensável, e assim obras precursoras deste gênero literário, como os romance de Mary Wollstonecraft Shelley, "Frankenstein ou o Prometeu Moderno" (1818) e O Último Homem (1826), ou a obra de Robert Louis Stevenson, "O Médico e o Monstro" (1886) são considerados ficção científica, enquanto que "Drácula", de Bram Stoker (1897), não é.
Há, evidentemente, muitos tipos de ficção científica. Os dois principais tipos são a ficção científica soft como por exemplo as séries televisivas "Star Trek" ("Jornada nas Estrelas"), "Battlestar Galactica" e Doctor Who, e também a ficção científica hard como por exemplo os filmes "", "Blade Runner" e "Solaris". Há também alguns filmes que se utilizam de temas recorrentes na ficção científica embora tenham mais características do gênero fantasia, como por exemplo a série de filmes "Star Wars", classificada como fantasia científica e space opera.
Além da antiquíssima literatura fantástica, que não é considerada para o efeito, o gênero teve precursores notáveis: "História verdadeira" de Luciano de Samósata, e considerada a obra mais antiga que pode ser chamada de ficção científica, sido escrita no século II d.c. Outras viagens imaginárias à Lua, planetas e viagens espaciais incluem "Micromégas" de Voltaire (1752), culturas alienígenas n'As Viagens de Gulliver de Jonathan Swift (1726), e elementos de ficção científica nas histórias de Edgar Allan Poe, Nathaniel Hawthorne e Fitz-James O'Brien, todos do século XIX. 
O verdadeiro início da ficção científica, contudo, dá-se durante o século XIX pós-Revolução Industrial, possibilitado pela ascenção da ciência moderna, sobretudo pelas revoluções operadas na astronomia, na física, química e na biologia. Em 1818, a escritora londrina Mary Shelley, inspirada pelas primeiras descobertas no campo da bioeletricidade, publica seu célebre romance "Frankenstein", amplamente considerado a obra inaugural deste gênero literário.
Destacam-se também os livros dos astrônomos Percival Lowell e Camille Flammarion, publicados entre o final do século XIX e início do século XX que conjecturavam a existência de dos canais de Marte e de vida extraterrestre, que inspiraram diversos autores.
Posteriormente, os romances científicos de Júlio Verne, cuja ciência se situava ao nível da invenção, bem como com as novelas, cientificamente orientadas, de crítica social de H. G. Wells contribuiriam grandemente para a popularização do estilo.
A ficção científica francesa do século 19, também foi representada com artistas como Albert Robida e Jean-Marc Côté.
Embora mais conhecido por outros trabalhos, Sir Arthur Conan Doyle também escreveu ficção científica.
Na América Latina, os primeiros exemplos são : "Páginas da história do Brasil, escritas no ano 2000" de Joaquim Felício dos Santos, uma sátira política publicada entre 1868 a 1872 no jornal "O Jequitinhonha", em 1875, surgem três obras em países diferentes: "El maravilloso viaje del Señor Nic-Nac" de Eduardo Holmberg (Argentina), "O Doutor Benignus" de Augusto Emílio Zaluar (Brasil) e "Historia de un Muerto" de Francisco Calcagno (Cuba).
Há outros precursores ilustres e mais antigos. O astrónomo Johannes Kepler (1571 - 1630) escreveu uma história, a que deu o título de "Somnium" (O Sonho), em que descreve uma viagem até outro planeta. Em 1656, o francês Savinien Cyrano de Bergerac escreveu "Histoire Comique des États et Empires de la Lune", que relata também uma viagem até à Lua e a forma como os Selenitas vêem os terrestres.
O desenvolvimento da ficção científica como género consciente de si próprio data de 1926, quando Hugo Gernsback, que cunhou a palavra combinada "scientifiction" (que se poderia traduzir para português como cientificção), fundou a revista "Amazing Stories", dedicada exclusivamente a histórias de ficção científica. 
Publicadas nesta e noutras revistas "pulp" com um sucesso grande e crescente, tais histórias não eram vistas pelos sectores literários como literatura, mas sim como sensacionalismo. Com a chegada, em 1937, de um editor exigente, John W. Campbell, da "Astounding Science Fiction" (fundada em 1930) e com a publicação de contos e novelas por escritores como Isaac Asimov, Arthur C. Clarke e Robert A. Heinlein, a ficção científica emergiu como uma forma de ficção séria. As aproximações ao género por escritores que não se dedicavam exclusivamente à ficção científica, como Aldous Huxley, C. S. Lewis e Kurt Vonnegut, também adicionaram respeitabilidade. Capas de revistas com monstros de olhos esbugalhados e mulheres seminuas preservaram em muitas mentes a imagem de sensacionalismo.
Assistiu-se a um grande incremento na popularidade da ficção científica a seguir à Segunda Guerra Mundial. Alguns trabalhos de ficção científica tornaram-se "best-sellers". A crescente sofisticação intelectual do género e a ênfase em assuntos psicológicos e sociais mais latos alargaram de forma significativa o apelo da ficção científica junto do público leitor. Nos países anglo-saxônicos tomou-se consciência de ficção científica escrita noutras línguas, em especial na União Soviética e noutros países da Europa de Leste. É agora comum ver-se crítica séria ao género, e estuda-se ficção científica em instituições de ensino superior de várias partes do mundo, havendo especial interesse nas suas características literárias e na forma como ela se relaciona com a ciência e a sociedade.
Uma das características únicas do género é a sua forte comunidade de fãs, da qual muitos autores também fazem parte. Existem grupos locais de fãs um pouco por todo o mundo que fala inglês, e também no Japão, Europa e noutros locais. É frequente que estes grupos publiquem os seus próprios trabalhos. Existem muitas revistas de fãs (e também algumas profissionais) que se dedicam apenas a informar o fã de ficção científica de todas as vertentes do género. Os principais prémios da ficção científica, os Prémios Hugo, são atribuídos pelos participantes da convenção anual Worldcon, que é organizada quase exclusivamente por fãs voluntários.
A ficção científica também se tem tornado popular na rádio, nas histórias em quadrinhos (banda desenhada em Portugal), na televisão e no cinema.

</doc>
